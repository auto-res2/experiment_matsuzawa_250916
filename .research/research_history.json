{
  "research_topic": "Test-Time Adaptationã‚’åŽæŸé€Ÿåº¦ã«é–¢ã—ã¦æ”¹å–„ã—ãŸã„",
  "queries": [
    "convergence test-time adaptation",
    "fast test-time adaptation",
    "learning rate adaptation TTA",
    "entropy minimization TTA",
    "meta-learning test-time adaptation"
  ],
  "research_study_list": [
    {
      "title": "Test Time Adaptation With Regularized Loss for Weakly Supervised Salient Object Detection"
    },
    {
      "title": "Robust Test-Time Adaptation in Dynamic Scenarios",
      "abstract": "Test-time adaptation (TTA) intends to adapt the pretrained model to test\ndistributions with only unlabeled test data streams. Most of the previous TTA\nmethods have achieved great success on simple test data streams such as\nindependently sampled data from single or multiple distributions. However,\nthese attempts may fail in dynamic scenarios of real-world applications like\nautonomous driving, where the environments gradually change and the test data\nis sampled correlatively over time. In this work, we explore such practical\ntest data streams to deploy the model on the fly, namely practical test-time\nadaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA)\nmethod against the complex data stream in PTTA. More specifically, we present a\nrobust batch normalization scheme to estimate the normalization statistics.\nMeanwhile, a memory bank is utilized to sample category-balanced data with\nconsideration of timeliness and uncertainty. Further, to stabilize the training\nprocedure, we develop a time-aware reweighting strategy with a teacher-student\nmodel. Extensive experiments prove that RoTTA enables continual testtime\nadaptation on the correlatively sampled data streams. Our method is easy to\nimplement, making it a good choice for rapid deployment. The code is publicly\navailable at https://github.com/BIT-DA/RoTTA",
      "full_text": "Robust Test-Time Adaptation in Dynamic Scenarios Longhui Yuan Binhui Xie Shuang Li \f School of Computer Science and Technology, Beijing Institute of Technology {longhuiyuan,binhuixie,shuangli}@bit.edu.cn Abstract Test-time adaptation (TTA) intends to adapt the pre- trained model to test distributions with only unlabeled test data streams. Most of the previous TTA methods have achieved great success on simple test data streams such as independently sampled data from single or multiple distri- butions. However, these attempts may fail in dynamic sce- narios of real-world applications like autonomous driving, where the environments gradually change and the test data is sampled correlatively over time. In this work, we ex- plore such practical test data streams to deploy the model on the fly, namely practical test-time adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA) method against the complex data stream in PTTA. More specifically, we present a robust batch normalization scheme to estimate the normalization statistics. Meanwhile, a memory bank is utilized to sample category-balanced data with consideration of timeliness and uncertainty. Further, to stabilize the training procedure, we develop a time-aware reweighting strategy with a teacher-student model. Exten- sive experiments prove that RoTTA enables continual test- time adaptation on the correlatively sampled data streams. Our method is easy to implement, making it a good choice for rapid deployment. The code is publicly available at https://github.com/BIT-DA/RoTTA 1. Introduction In recent years, many machine learning problems have made considerable headway with the success of deep neu- ral networks [13, 22, 33, 38]. Unfortunately, the perfor- mance of deep models drops significantly when training data and testing data come from different distributions [59], which limits their utility in real-world applications. To re- duce the distribution shift, a handful of works focus on transfer learning field [56], in particular, domain adapta- tion (DA) [17, 42, 45, 48, 69, 72] or domain generalization (DG) [40, 41, 52, 71, 83], in which one or more different but \fCorresponding author Test data stream Continual TTANon-i.i.d.TTAPractical  TTACategoryDistribution Fully TTA Correlation samplingDistributionchanging Figure 1. We consider the practical test-time adaptation (TTA) setup and compare it with related ones. First, Fully TTA [70] adapts models on a fixed test distribution with an independently sampled test stream. Then, on this basis, Continual TTA [73] takes the continually changing distributions into consideration. Next, Non-i.i.d. TTA [19] tries to tackle the correlatively sampled test streams on a single test distribution, where the label distribution among a batch of data deviates from that of the test distribution. To be more practical, Practical TTA strives to connect both worlds: distribution changing and correlation sampling. related labeled datasets (a.k.a. source domain) are collected to help the model generalize well to unlabeled or unseen samples in new datasets (a.k.a. target domain). While both DA and DG have extensively studied the problem of distribution shifts, they typically assume acces- sibility to the raw source data. However, in many practical scenarios like personal consumption records, the raw data should not be publicly available due to data protection reg- ulations. Further, existing methods have to perform heavy backward computation, resulting in unbearable training costs. Test-time adaptation (TTA) [3,11,16,24,26,54,65,81] attempts to address the distribution shift online at test time with only unlabeled test data streams. Unequivocally, TTA has drawn widespread attention in a variety of applications, e.g., 2D/3D visual recognition [2, 29, 49, 65, 82], multi- modality [63, 64] and document understanding [15]. Prior TTA studies [7, 20, 70, 73] mostly concentrate on a simple adaptation scenario, where test samples are inde- pendently sampled from a fixed target domain. To name a few, Sun et al. [65] adapt to online test samples drawn from a constant or smoothly changing distribution with an auxil- iary self-supervised task. Wang et al. [70] adapt to a fixed arXiv:2303.13899v1  [cs.CV]  24 Mar 2023Table 1. Comparison between our proposed practical test-time adaptation (PTTA) and related adaptation settings. Setting Adaptation StageAvailable Data Test Data Stream Train Test Source Target Distribution Sampling Protocol Domain Adaptation ! % ! ! - - Domain Generalization ! % ! % - - Test-Time Training [65] ! ! ! ! stationary independently Fully Test-Time Adaptation [70] % ! % ! stationary independently Continual Test-Time Adaptation [73]% ! % ! continually changing independently Non-i.i.d. Test-Time Adaptation [5, 19]% ! % ! stationary correlatively Practical Test-Time Adaptation (Ours)% ! % ! continually changing correlatively target distribution by performing entropy minimization on- line. However, such an assumption is violated when the test environments change frequently [73]. Later on, Boudiaf et al. [5] and Gonget al. [19] consider the temporal correlation ship within test samples. For example, in autonomous driv- ing, test samples are highly correlated over time as the car will follow more vehicles on the highway or will encounter more pedestrians in the streets. More realistically, the data distribution changes as the surrounding environment alerts in weather, location, or other factors. In a word, distribution change and data correlation occur simultaneously in reality. Confronting continually changing distributions, tradi- tional algorithms like pseudo labeling or entropy minimiza- tion become more unreliable as the error gradients cumu- late. Moreover, the high correlation among test samples re- sults in the erroneous estimation of statistics for batch nor- malization and collapse of the model. Driven by this analy- sis, adapting to such data streams will encounter two major obstacles: 1) incorrect estimation in the batch normaliza- tion statistics leads to erroneous predictions of test samples, consequently resulting in invalid adaptation; 2) the model will easily or quickly overfit to the distribution caused by the correlative sampling. Thus, such dynamic scenarios are pressing for a new TTA paradigm to realize robust adapta- tion. In this work, we launch a more realistic TTA setting, where distribution changing and correlative sampling oc- cur simultaneously at the test phase. We call this Practical Test-Time Adaptation, or briefly,PTTA. To understand more clearly the similarities and differences between PTTA and the previous setups, we visualize them in Figure 1 and sum- marize them in Table 1. To conquer this challenging prob- lem, we propose a Robust Test-Time Adaptation (RoTTA) method, which consists of three parts: 1) robust statistics es- timation, 2) category-balanced sampling considering time- liness and uncertainty and 3) time-aware robust training. More concretely, we first replace the erroneous statistics of the current batch with global ones maintained by the expo- nential moving average. It is a more stable manner to esti- mate the statistics in BatchNorm layers. Then, we simulate a batch of independent-like data in memory with category- balanced sampling while considering the timeliness and un- certainty of the buffered samples. That is, samples that are newer and less uncertain are kept in memory with higher priority. With this batch of category-balanced, timely and confident samples, we can obtain a snapshot of the current distribution. Finally, we introduce a time-aware reweight- ing strategy that considers the timeliness of the samples in the memory bank, with a teacher-student model to perform robust adaptation. With extensive experiments, we demon- strate that RoTTA can robustly adapt in the practical setup, i.e., PTTA. In a nutshell, our contributions can be summarized as: â€¢ We propose a new test-time adaptation setup that is more suitable for real-world applications, namely practical test-time adaptation (PTTA). PTTA considers both distribution changing and correlation sampling. â€¢ We benchmark the performance of prior methods in PTTA and uncover that they only consider one aspect of the problem, resulting in ineffective adaptation. â€¢ We propose a robust test-time adaptation method (RoTTA), which has a more comprehensive considera- tion of PTTA challenges. Ease of implementation and effectiveness make it a practical deployment option. â€¢ We extensively demonstrate the practicality of PTTA and the effectiveness of RoTTA on common TTA benchmarks [23], i.e., CIFAR-10-C and CIFAR-100- C and a large-scale DomainNet [58] dataset. RoTTA obtains state-of-the-art results, outperforming the best baseline by a large margin (reducing the averaged classification error by over 5.9%, 5.5% and 2.2% on CIFAR-10-C, CIFAR-100-C and DomainNet, respec- tively). 2. Related Work Domain adaptation (DA) studies the problem of transfer- ring the knowledge learned from a labeled source dataset to an unlabeled target dataset [8, 17, 43, 51, 67, 68]. Represen- tative techniques include latent distribution alignment [48, 77], adversarial training [17, 62], or self-training [75, 85]. The limitation of this setting, however, is that an unlabeled test dataset (target domain) is needed at training time, in addition to a labeled training dataset (source domain). Ac- cordingly, it might fail to handle more practical scenariosFeature ð¹Robust batch normalization (RBN)Updateðœ‡à¯š, ðœŽà¯šà¬¶NormalizeFeatureð¹â€²Update bank with current sample  Training lossâ„’à¯¥in Eq. (7) Teacher StudentAdaptation with RBNMemorybankEMA ð‘¡A stream of online dataUpdateTest timeCorrelationsamplingStrong & weakaugmentation flowDistributionsCategoryTeacherMajor classhas highest â„‹in majorRemoveAddWhen â„‹>â„‹Samples to beadded& removed Figure 2. Framework overview. Firstly, we replace the batch normalization layer with RBN which robustly normalizes the feature map. During the inference of the online test stream of PTTA, we utilize the predictions of samples to maintain a memory bank by category- balanced sampling with timeliness and uncertainty. Finally, we use the category-balanced, timely and confident data in the memory bank combined with a robust loss to adapt the model at test time. like test-time adaptation. Our practical test-time adaptation setting can be viewed as performing correlatively sample adaptation on the fly. It is worth noting that standard domain adaptation techniques might collapse when only continual data streams from multiple target domains are accessible. Domain generalization (DG) assumes that multiple source domains are available for model training and tries to learn models that can generalize well to any unseen domains [4, 26,40,41,52,84]. A broad spectrum of methodologies based on data augmentation [78, 84], meta-learning [14, 40], or domain alignment [50,52] has made great progress. In con- trast, this work instead aims to improve the performance of source pre-trained models at the test time by using unla- beled online data streams from multiple continually chang- ing target domains. Continual learning (CL) (also known as incremental learning, life-long learning) addresses the problem of learn- ing a model for many tasks sequentially without forgetting knowledge obtained from the preceding tasks. [1, 6, 31, 37, 60]. CL methods can often be categorized into replay- based [60, 66] and regularization-based [31, 44] methods. Ideas from continual learning are also adopted for continu- ous domain adaptation approaches [34, 74] In our work, we share the same motivation as CL and point out that prac- tical test-time adaptation (PTTA) also suffers catastrophic forgetting (i.e., performance degradation on new test sam- ples due to correlation sampling), which makes test-time adaptation approaches are unstable to deploy. Test-time adaptation (TTA) focus on more challenging settings where only source model and unlabeled target data are available [9, 18, 27, 28, 35, 46, 61]. A similar paradigm is source-free domain adaptation (SFDA) [10, 36, 47, 79], which also requires no access to the training (source) data. To name a few, Liang et al . [45] fit the source hypoth- esis by exploiting the information maximization and self- supervised pseudo-labeling. Kundu et al. [35] formalize a unified solution that explores SFDA without any category- gap knowledge. To fully utilize any arbitrary pre-trained model, Sun et al. [65] propose conducting adaptation on the fly with an auxiliary self-supervised task. Later on, Wanget al. [70] take a source pre-trained model and adapt it to the test data by updating a few trainable parameters in Batch- Norm layers [25] using entropy minimization [21]. While standard TTA has been widely studied in many tasks [2, 20, 63, 64, 70, 82], the fact remains that both dis- tribution changing [73] and data correlation sampling [19] has only been considered in isolation. For example, Gong et al. [19] propose instance-aware batch normalization and prediction-balanced reservoir sampling to address the chal- lenges of correlatively sampled test streams, however, it does not consider unstable adaptation resulting from long- term adaptation on continually changing distributions. On the other hand, Wang et al. [73] assume that the target test data is streamed from a continually changing environment and continually adapt an off-the-shelf source pre-trained model to the current test data. In this work, we launch PTTA, a more practical TTA setting to connect both worlds: distribution changing and correlation sampling. 3. Method 3.1. Problem Definition and Motivation Given a model fÎ¸0 with parameter Î¸0 pre-trained on source domain DS = {(xS, yS)}, the proposed practical test-time adaptation (PTTA) aims to adapt fÎ¸0 to a stream of online unlabeled samples X0, X1, ...,XT , where Xt is a batch of highly correlated samples from the distribution Ptest that changes with time t continually. More specifi- cally, at test time, with time going on, the test distribution Ptest changes continually as P0, P1, ...,Pâˆž. At time step t, we will receive a batch of unlabeled and correlated samplesmotion distribution changing snow time  Distributions and Labels of PTTA T est Stream uniform 10 1 0.1 0.01 0.001 Dirichlet Parameter  Figure 3. Illustration of the labels and distributions of the test stream of CIFAR10-C under the setup PTTA. And we adopt Dirichlet distribution to simulate the process of correlative sam- pling. It is clear that as the concentration parameter Î´ decreases, the correlation among sampled data increases, which is reflected in the increasing aggregation of categories. Xt from Ptest. Next, Xt is fed into the model fÎ¸t and the model needs to adapt itself to the current test data streams and make predictions fÎ¸t (Xt) on the fly. As a matter of fact, this setup is largely driven the prac- tical demands of deploying models in dynamic scenarios. Taking for example the case of autonomous driving men- tioned in Â§ 1, test samples are highly correlated and the data distribution changes continually with the weather or loca- tion. Another example is the situation of intelligent moni- toring, the camera will continuously capture more people at certain times, such as after work, but fewer of them during work time. Meanwhile, the light condition changes con- tinually from day to night. The deployed model should be robustly adapted in such dynamic scenarios. In a word, dis- tribution change and data correlation often happen simul- taneously in the real world. For this reason, existing TTA methods [7,9,19,28,70,73,81] might become unstable when the test stream is sampled from such dynamic scenarios. To obtain the test stream of PTTA, we adopt Dirich- let Distribution with parameter Î´ to simulate the correla- tion among test samples. We present the test data streams corresponding to different values of Î´ on the CIFAR10-C dataset in Figure 3. We can observe that the smaller Î´ is, the higher the correlation will be. For the sake of unity, we set Î´ = 0.1 as the default for all experiments. In the follow- ing, we present a robust test-time adaptation framework for the practical test-time adaptation setup defined above. An overview of our RoTTA is illustrated in Figure 2. 3.2. Robust Test-Time Adaptation Motivated by the fact that the statistics of current batch data, which are commonly used in previous TTA meth- ods [7, 20, 65, 70, 73], become unreliable when they en- counter correlative test data streams, we first turn to the global robust statistics for normalization. Then, to effec- tively adapt to the current distribution, we maintain a mem- ory bank by category-balanced sampling with considering timeliness and uncertainty, which captures a more stable snapshot of the distribution. Finally, we utilize the teacher- student model and design a timeliness-based reweighting strategy to train the model robustly. Robust batch normalization (RBN). Batch Normaliza- tion (BN) [25] is a widely-used training technique as it can accelerate the training and convergence speed of networks and stabilize the training process by reducing the risk of gradient explosion and vanishing. Given the feature map F âˆˆ RBÃ—CÃ—HÃ—W as the input for a BN layer when train- ing, the channel-wise mean Âµ âˆˆ RC and variance Ïƒ2 âˆˆ RC are calculated as follows: Âµc = 1 BHW BX b=1 HX h=1 WX w=1 F(b,c,h,w) , (1) Ïƒ2 c = 1 BHW BX b=1 HX h=1 WX w=1 (F(b,c,h,w) âˆ’ Âµc)2 . (2) Then the feature map is normalized and refined in a channel-wise manner as BN (F(b,c,h,w); Âµ, Ïƒ2) =Î³c F(b,c,h,w) âˆ’ Âµc âˆšÏƒ2c + Ïµ + Î²c , (3) where Î³, Î²âˆˆ RC are learnable parameters in the layer and Ïµ > 0 is a constant for numerical stability. Meanwhile, during training, the BN layer maintains a group of global running mean and running variance (Âµs, Ïƒ2 s) for inference. Due to the domain shift at test time, the global statis- tics (Âµs, Ïƒ2 s) normalize test features inaccurately, causing significant performance degradation. To tackle the prob- lem above, some methods [55, 70, 73] use the statistics of the current batch to perform normalization. Unfortunately, when the test samples have a high correlation under PTTA setup, the statistics of the current batch also fail to correctly normalize the feature map, as demonstrated in Figure 4c. Specifically, the performance of BN [53] decreases rapidly as the data correlation increases. Based on the analysis above, we propose a robust batch normalization (RBN) module, which maintains a group of global statistics (Âµg, Ïƒ2 g) to normalize the feature map ro- bustly. Before the whole test-time adaptation, (Âµg, Ïƒ2 g) is initialized as the running mean and variance (Âµs, Ïƒ2 s) of the pre-trained model. When adapting the model, we update the global statistics first by exponential moving average as Âµg = (1âˆ’ Î±)Âµg + Î±Âµ , (4) Ïƒ2 g = (1âˆ’ Î±)Ïƒ2 g + Î±Ïƒ2 , (5) where (Âµ, Ïƒ2) is the statistics of the buffered samples in the memory bank. Then we normalize and affine the feature as Eq. (3) with (Âµg, Ïƒ2 g). When inferring for test samples, we directly utilize (Âµg, Ïƒ2 g) to calculate the output as Eq (3). Al- though simple, RBN is effective enough to tackle the prob- lem of normalization on test streams of PTTA.Category-balanced sampling with timeliness and uncer- tainty (CSTU). In the PTTA setup, the correlation among test samples Xt at time t leads to a deviation between the observed distribution bPtest and the test distribution Ptest. Specifically, the marginal label distribution p(y|t) tends to differ from p(y). Continuously learning with Xt over time t can lead to model adaptation to an unreliable distribution bPtest, resulting in ineffective adaptation and an increased risk of model collapse. To address this issue, we propose a category-balanced memory bank M with a capacity of N, which takes into account the timeliness and uncertainty of samples when up- dating. In particular, we adopt the predictions of test sam- ples as pseudo labels to guide the update ofM. Meanwhile, to guarantee the balance among categories, we distribute the capacity of M equally to each category, and samples of the major categories will be replaced first (refer to lines 5-9 in Algorithm 1). Furthermore, due to the continually changing test distribution, old samples in M are limited in value, and could even impair the ability of the model to adapt to the current distribution. Additionally, samples of high uncer- tainty always produce erroneous gradient information that can hinder model adaptation, as suggested by [55]. With this in mind, we attach each sample in M with a group of heuristics (A, U), where A, initialized as 0 and in- creasing with time t, is the age of the sample, and U the un- certainty calculated as the entropy of the prediction. Next, we combine the timeliness and uncertainty to calculate a heuristic score, i.e., category-balanced sampling with time- liness and uncertainty (CSTU), as follows: H = Î»t 1 1 + exp(âˆ’A/N) + Î»u U log C , (6) where Î»t and Î»u make the trade-off between timeliness and uncertainty, and for simplicity, Î»t and Î»u are set to 1.0 for all experiments, andC is the number of categories. We sum- marize our sampling algorithm in Algorithm 1. With CSTU, we can obtain a robust snapshot of the current test distribu- tion Ptest, and effectively adapt the model to it. Robust training with timeliness. Actually, after replacing BN layers with our RBN and obtaining the memory bank selected via CSTU, we can directly adopt the widely used techniques like pseudo labeling or entropy minimization to perform test-time adaptation. However, we notice that too old or unreliable instances still have the opportunity to stay in M since keeping the category balance is assigned the top priority. In addition, too aggressive updates of the model will make the category balance ofM unreliable, resulting in unstable adaptation. Meanwhile, error accumulation caused by the distribution change also makes the aforementioned approaches unworkable. To further reduce the risk of error gradients information from old and unreliable instances and stabilize the adapta- tion, we turn to the robust unsupervised learning method Algorithm 1: CSTU for one test sample. 1 Input: a test sample x and the teacher model fÎ¸T . 2 Define: memory bank M and its capacity N, number of classes C, per class occupation O âˆˆRC, total occupation â„¦, classes to pop instance D. 3 Infer as p(y|x) =Softmax(fÎ¸T (x)). 4 Calculate the predicted category of x as Ë†y = arg maxc p(c|x), the uncertainty as Ux = âˆ’PC c=1 p(c|x) log(p(c|x)), the age as Ax = 0, and the heuristic score Hx of x with Eq (6) 5 if OË†y < N C then 6 if â„¦ <N: Search range D = âˆ…. 7 else: Search range D = {j|j = arg maxc Oc} 8 else 9 Search range D = {Ë†y} 10 if D is âˆ… then 11 Add (x, Ë†y, Hx, Ux) into M. 12 else 13 Find the instance (Ë†x, yË†x, AË†x, UË†x) with the highest value in Eq (6) HË†x among D. 14 if Hx < HË†x then 15 Remove (Ë†x, yË†x, AË†x, UË†x) from M. 16 Add (x, Ë†y, Hx, Ux) into M. 17 else 18 Discard x. 19 Increase the age of all instances in M. teacher-student model and propose a timeliness reweight- ing strategy. In addition, for the sake of time efficiency and stability, only affine parameters in RBN are trained during adaptation. At time step t, after inferring for the correlated data Xt with the teacher model fÎ¸T t and updating the memory bank M with Xt, we begin updating the student model fÎ¸S t and the teacher model fÎ¸T t . Firstly, we update parameters of stu- dent model Î¸S t â†’ Î¸S t+1 by minimizing the following loss: Lr = 1 â„¦ â„¦X i=1 L(xM i , Ai; Î¸T t , Î¸S t ) , (7) where â„¦ = |M| is the total occupation of the memory bank, and xM i and Ai(i = 1, ..., â„¦) are instances in the memory bank and their age respectively. Subsequently, the teacher model is updated by exponential moving average as Î¸T t+1 = (1âˆ’ Î½)Î¸T t + Î½Î¸S t+1 . (8) To calculate the loss value of an instancexM i from the mem- ory bank, the timeliness reweighting term is computed as E(Ai) = exp(âˆ’Ai/N) 1 + exp(âˆ’Ai/N) , (9)where Ai is the age of xM i , and N is the capacity of the bank. And then we calculate the cross entropy between the soft-max prediction pS(y|xâ€²â€² i ) of the strong-augmented view xâ€²â€² i from the student model and that pT (y|xâ€² i) of the weak- augmented view 1 xâ€² i from the teacher model as follows: â„“(xâ€² i, xâ€²â€² i ) =âˆ’1 C CX c=1 pT (c|xâ€² i) logpS(c|xâ€²â€² i ) . (10) Finally, equipped with Eq. (9) and Eq. (10), the right-hand side of Eq. (7) reduces to L(xM i , Ai; Î¸T t , Î¸S t ) =E(Ai)â„“(xâ€² i, xâ€²â€² i ) . (11) To sum up, equipped with RBN, CSTU, and robust training with timeliness, our RoTTA is capable of effectively adapt- ing any pre-trained models in dynamic scenarios. 4. Experiments 4.1. Setup Datasets. CIFAR10-C and CIFAR100-C [23] are the com- monly used TTA benchmarks to testify the robustness un- der corruptions. Both of them are obtained by applying 15 kinds of corruption with 5 different degrees of severity on their clean test images of original datasets CIFAR10 and CIFAR100 respectively. CIFAR10/CIFAR100 [32] have 50,000/10,000 training/test images, all of which fall into 10/100 categories. DomainNet [58] is the largest and hard- est dataset to date for domain adaptation and consists of about 0.6 million images with 345 classes. It consists of six different domains including Clipart (clp), Infograph (inf), Painting (pnt), Quickdraw (qdr), Real (rel), and Sketch (skt). We first pre-train a source model on the train set in one of six domains and testify all baseline methods on the test set of the remaining five domains. Implementation details. All experiments are conducted with PyTorch [57] framework. In the case of robustness to corruption, following the previous methods [55, 70, 73], we obtain the pre-trained model from RobustBench bench- mark [12], including the WildResNet-28 [80] for CIFAR10 â†’ CIFAR10-C, and the ResNeXt-29 [76] for CIFAR100 â†’ CIFAR100-C. Then, we change the test corruption at the highest severity 5 one by one to simulate that the test distri- bution continually changes with time in PTTA. And in the case of generalization under the huge domain gap, we train a ResNet-101 [22] by standard classification loss for each domain in DomainNet and adapt them continually to differ- ent domains except the source domain. Meanwhile, we uti- lize the Dirichlet distribution to simulate the correlatively sampled test stream for all datasets. For optimization, we adopt Adam [30] optimizer with learning rate 1.0 Ã— 10âˆ’3, 1Weak augmentation is ReSize+CenterCrop. Strong augmentation is a combination nine operations like Clip, ColorJitter, and RandomAffine. Î² = 0.9. For a fair comparison, we set the batch size for all methods as 64 and the capacity of the memory bank of RoTTA as N = 64. Concerning the hyperparameters, we adopt a unified set of values for RoTTA across all experi- ments including Î± = 0.05, Î½ = 0.001, Î»t = 1.0, Î»u = 1.0, and Î´ = 0.1. More details are provided in the appendix. 4.2. Comparisons with the State-of-the-arts Robustness under corruptions. The classification error on CIFAR10â†’CIFAR10-C and CIFAR100â†’CIFAR100-C are shown in Table 2 and Table 3 respectively. We change the type of the current corruption at the highest severity 5 as time goes on, and sample data correlatively for infer- ence and adaptation simultaneously. The same test stream is shared across all compared methods. From Table 2 and Table 3, we can see that RoTTA achieves the best performance compared to previous meth- ods. Moreover, RoTTA has a significant performance gain to the second-best method that 5.9% improvement on CIFAR10 â†’CIFAR10-C and 5.5% improvement on CIFAR100â†’CIFAR100-C respectively, verifying the effec- tiveness of RoTTA to adapt the model under PTTA. In more detail, we can observe that BN [53], PL [39], TENT [70] and CoTTA [73] negatively adapt the model to the test streams of both datasets compared to Source (âˆ’6.5 âˆ¼ âˆ’46.4%). This is attributed to the fact that these methods overlook the issues posed by correlation sampling, which can result in highly correlated data within a batch. As a consequence, traditional normalization statistics may be ineffective in appropriately normalizing the feature maps. Equipped with RBN and CSTU, RoTTA no longer suffers from this issue. Meanwhile, in Table 3, if focus on the adaptation procedure, we can see that the performance of PL [39], TENT [70] and NOTE [19] becomes worse and worse, and eventually, the model even collapses (error rate > 97%). This reveals that the impact of error accumula- tion on long-term adaptation can be catastrophic. To tackle this problem, RoTTA turns to robustly adapt the model with timeliness reweighting and confident samples in the mem- ory bank, and superior performance throughout the adapta- tion process demonstrates its effectiveness. In addition, we find that although LAME [5] never tunes the parameters of the model, it is still a competi- tive baseline for example it achieves the second-best result on CIFAR100â†’CIFAR100-C. However, its performance is very dependent on the performance of the pre-trained model e.g. negligible improvement on difficult corruptions (shot, gaussian, pixelate). On the contrary, our RoTTA is more flexible and achieves better and more robust results. Generalization under domain shift. We also evalu- ate RoTTA under a more challenging dataset DomainNet, where we continually adapt a source pre-trained model to correlatively sampled test streams of the rest domains. AsTable 2. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 3. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 4. Average classification error of DomainNet while continually adapting to different domains with correlatively sampled test stream. Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Sourceclp inf pnt qdr rel sktAvg. BN clp inf pnt qdr rel sktAvg. PL clp inf pnt qdr rel sktAvg.TENTclp inf pnt qdr rel sktAvg. clp N/A 83.9 65.4 88.6 48.0 59.1 69.0clp N/A 88.6 70.7 90.5 65.4 67.0 76.5clp N/A 94.5 98.9 99.5 99.7 99.7 98.5clp N/A 87.5 71.9 94.2 96.2 98.9 89.7inf 61.8 N/A 66.9 96.0 50.0 70.6 69.1inf 68.6 N/A 74.2 96.2 69.9 76.8 77.1inf 82.6 N/A 99.2 99.6 99.7 99.3 96.1inf 68.6 N/A 75.0 97.3 95.9 98.7 87.1pnt 56.5 83.7 N/A 94.2 42.6 63.4 68.1pnt 60.8 87.9 N/A 94.3 62.3 68.7 74.8pnt 78.6 99.4 N/A 99.7 99.6 99.7 95.4pnt 61.7 87.1 N/A 96.4 95.3 98.8 87.8qdr 89.2 99.0 98.6 N/A 95.0 92.3 94.8qdr 80.3 97.7 92.6 N/A 88.7 88.1 89.5qdr 81.7 99.5 99.6 N/A 99.7 99.8 96.1qdr 78.9 97.1 91.6 N/A 89.2 88.7 89.1rel 49.4 80.4 51.5 93.4 N/A 63.3 67.6rel 57.9 87.1 63.1 94.3 N/A 70.8 74.6rel 73.5 99.4 99.2 99.6 N/A 99.7 94.3rel 57.8 86.4 68.1 96.9 N/A 96.7 81.2skt 47.5 88.2 62.9 87.1 51.8 N/A 67.5skt 50.4 87.6 64.6 89.6 63.1 N/A 71.1skt 64.8 99.2 99.4 99.7 99.7 N/A 92.6skt 51.9 87.2 69.1 95.3 97.3 N/A 80.1Avg.60.9 87.0 69.1 91.9 57.5 69.7 72.7Avg.63.6 89.8 73.0 93.0 69.9 74.3 77.3Avg.76.2 98.4 99.3 99.6 99.7 99.6 95.5Avg.63.8 89.0 75.1 96.0 94.8 96.4 85.8 Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’LAMEclp inf pnt qdr rel sktAvg.COTTAclp inf pnt qdr rel sktAvg.NOTEclp inf pnt qdr rel sktAvg.RoTTAclp inf pnt qdr rel sktAvg. clp N/A 82.2 64.5 87.7 46.9 58.9 68.0clp N/A 90.6 77.9 89.3 76.3 72.7 81.4clp N/A 89.2 73.0 94.8 98.4 99.4 91.0clp N/A 85.5 62.0 82.0 49.3 59.8 67.7inf 60.1 N/A 65.7 95.4 48.5 69.4 67.8inf 74.5 N/A 82.0 95.7 80.2 81.5 82.8inf 75.4 N/A 78.7 98.7 98.1 99.5 90.1inf 61.8 N/A 63.7 91.5 52.5 67.6 67.4pnt 55.8 81.5 N/A 93.3 41.3 62.1 66.8pnt 66.3 89.8 N/A 93.4 74.0 75.4 79.8pnt 64.7 89.8 N/A 97.8 98.4 99.2 90.0pnt 53.3 84.1 N/A 89.1 47.3 61.4 67.0qdr 88.3 99.1 99.0 N/A 94.9 92.2 94.7qdr 82.3 98.2 94.6 N/A 92.5 90.1 91.5qdr 74.7 97.2 92.2 N/A 93.5 99.6 91.4qdr 77.5 97.0 89.8 N/A 80.3 82.2 85.3rel 48.0 79.3 50.1 91.6 N/A 60.2 65.8rel 64.0 90.3 73.2 93.5 N/A 77.6 79.7rel 61.3 89.2 68.9 98.8 N/A 99.2 83.5rel 49.1 82.3 50.3 88.0 N/A 61.1 66.2skt 45.6 87.1 59.5 83.9 49.9 N/A 65.2skt 56.1 89.2 71.9 89.2 73.5 N/A 76.0skt 55.2 89.7 70.1 96.9 98.3 N/A 82.0skt 42.6 83.7 54.4 80.9 47.5 N/A 61.8Avg.59.6 85.8 67.8 90.4 56.3 68.6 71.4Avg.68.6 91.6 79.9 92.2 79.3 79.5 81.9Avg.66.3 91.0 76.6 97.4 97.3 99.4 88.0Avg.56.8 86.5 64.0 86.3 55.4 66.469.2(+2.2) shown in Table 4, consistent with the previous analysis, most of the methods include BN [53], PL [39], TENT [70], CoTTA [73] and NOTE [19] even perform worse than the Source model ( âˆ’4.6 âˆ¼ âˆ’22.8%). RoTTA consistently achieves the best performance and has 2.2% gain than the second method LAME [5], demonstrating RoTTAâ€™s effec- tiveness again. 4.3. Ablation Study Effect of each component. To further investigate the effi- cacy of each component, we replace each part with the nor- mally used solutions to obtain three variants: (1) RoTTA w/o RBN, replace RBN with test-time BN in TENT [70]; (2) RoTTA w/o CSTU, directly adapt the model on test stream; (3) RoTTA w/o robust training (RT), directly adapt the model only with entropy minimization. As shown in Table 5, we can observe that significant performance degra- dation occurs for all variants, proving that every part of our proposed method is valid for PTTA. Take one com- ponent for a detailed example, without RBN robustly nor- malizing feature maps, the performance of RoTTA drops 50.2% and 16.3% on CIFAR10-C and CIFAR100-C respec- tively, proving that RBN is robust enough to tackle the prob- lem of normalization of correlatively sampled data streams. CSTU enables RoTTA to adapt to a more stable distribu- tion by maintaining a timely and confident snapshot of the test distribution. Meanwhile, robust training with timeliness greatly reduces the accumulation of errors. Every compo- nent behaves significantly to enable effective adaptation un- der PTTA. Effect of the distribution changing order. To exclude the effect of a fixed order of distribution changing, we con- ducted experiments on ten different sequences of changes on CIFAR10-C and CIFAR100-C with independently andBN PL TENT LAME CoTTA NOTE RoTTA0 10 20 30 40 50 60 70 80Classification error (%) Source CIFAR-10  CIFAR-10-C Independent Correlative (a) CIFAR10-C. BN PL TENT LAME CoTTA NOTE RoTTA0 20 40 60 80Classification error (%) Source CIFAR-100  CIFAR-100-C Independent Correlative (b) CIFAR100-C. uniform 10 1 0.1 0.01 0.001 30 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (c) Î´. 16 32 64 128 256 512 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (d) Batch size. Figure 4. (a) & (b) we adapt the model continually to different corruptions of 10 different orders with independently and correlatively sampled test streams on CIFAR10-C and CFAR100-C respectively and report their average classification error. (c) & (d) we verify the effect of Î´ and batch size to different methods on CIFAR100-C respectively. Table 5. Classification error of different variants of our RoTTA. Variant CIFAR10-C CIFAR100-C Avg. RoTTA w/o RBN 75.4 51.3 63.4 RoTTA w/o CSTU 47.1 46.3 46.7 RoTTA w/o RT 78.2 95.0 81.6 RoTTA 25.2 35.0 30.1 correlatively sampled test streams respectively. As shown in Figure 4a and 4b, no matter what kind of setup, RoTTA can achieve excellent results. The detailed results on the correlatively sampled test streams are shown in Table 6, RoTTA achieves 4.3% and 4.7% progress on CIFAR10- C and CIFAR100-C respectively. This shows that RoTTA can adapt the model robustly and effectively in long-term scenarios where distribution continually changes and test streams are sampled either independently or correlatively, making it a good choice for model deployment. Effect of Dirichlet concentration parameter Î´. We vary the value of Î´ on CIFAR100-C and compare RoTTA with other approaches in Figure 4c. As the value of Î´ increases, the performance of BN [53], PL [39], TENT [70] and CoTTA [73] drops quickly, because they never consider the increasing correlation among test samples. NOTE [19] is stable to correlatively sampled test streams but does not consider the distribution changing, causing ineffective adaptation. Meanwhile, the higher correlation between test samples will make the propagation of labels more accurate, which is why the result of LAME [5] slightly improves. Fi- nally, excellent and stable results once again prove the sta- bility and effectiveness of RoTTA. Effect of batch size. In real scenarios, considering deploy- ment environments may use different test batch sizes, we conduct experiments with different values of test batch sizes and results are shown in Figure 4d. For a fair comparison, we control the frequency of updating the model of RoTTA so that the number of samples involved in back-propagation is the same. As the batch size increases, we can see that all of the compared methods have a significant improvement except for lame which has a slight decrease. This is be- cause the number of categories in a batch increases with the Table 6. Average classification error of tasks CIFAR10 â†’ CIFAR10-C and CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions of 10 different orders at the high- est severity 5 with correlatively sampled test stream. Method CIFAR10-C CIFAR100-C Avg. Source 43.5 46.4 46.9 BN [53] 75.2 52.9 64.1 PL [39] 75.2 52.9 60.1 TENT [70] 82.3 93.2 87.8 LAME [5] 39.5 40.6 40.1 NOTE [19] 30.5 76.1 53.3 CoTTA [73] 83.1 52.8 67.9 RoTTA 26.2(+4.3) 35.9(+4.7) 31.1(+9.0) increasing batch size, causing the overall correlation to be- come lower but the propagation of labels to become more difficult. Most significantly, RoTTA achieves the best re- sults across different batch sizes, demonstrating its robust- ness in dynamic scenarios once again. 5. Conclusion This work proposes a more realistic TTA setting where distribution changing and correlative sampling occur si- multaneously at the test phase, namely Practical Test-Time Adaptation (PTTA). To tackle the problems of PTTA, we propose Robust Test-Time Adaptation (RoTTA) method against the complex data stream. More specifically, a group of robust statistics for the normalization of feature maps is estimated by robust batch normalization. Meanwhile, a memory bank is adopted to capture a snapshot of the test distribution by category-balanced sampling with consider- ing timeliness and uncertainty. Further, we develop a time- aware reweighting strategy with a teacher-student model to stabilize the adaptation process. Extensive experiments and ablation studies are conducted to verify the robustness and effectiveness of the proposed method. We believe this work will pave the way for thinking about adapting models into real-world applications by test-time adaptation algorithm. Acknowledgements. This paper was supported by National Key R&D Program of China (No. 2021YFB3301503), and also supported by the National Natural Science Foundation of China under Grant No. 61902028.References [1] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Ben- gio. Gradient based sample selection for online continual learning. In NeurIPS, pages 11816â€“11825, 2019. 3 [2] Fatemeh Azimi, Sebastian Palacio, Federico Raue, J Â¨orn Hees, Luca Bertinetto, and Andreas Dengel. Self-supervised test-time adaptation on video data. In WACV, pages 2603â€“ 2612, 2022. 1, 3 [3] Mathilde Bateson, Herve Lombaert, and Ismail Ben Ayed. Test-time adaptation with shape moments for image segmen- tation. In MICCAI, pages 736â€“745, 2022. 1 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. General- izing from several related classification tasks to a new unla- beled sample. In NeurIPS, pages 2178â€“2186, 2011. 3 [5] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In CVPR, pages 8344â€“8353, 2022. 2, 6, 7, 8, 13, 14, 15, 16, 17 [6] Francisco M Castro, Manuel J Mar Â´Ä±n-JimÂ´enez, NicolÂ´as Guil, Cordelia Schmid, and Karteek Alahari. End-to-end incre- mental learning. In ECCV, pages 233â€“248, 2018. 3 [7] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, pages 295â€“305, 2022. 1, 4 [8] Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Domain adaptive faster r-cnn for object de- tection in the wild. In CVPR, pages 3339â€“3348, 2018. 2 [9] Zhixiang Chi, Yang Wang, Yuanhao Yu, and Jin Tang. Test- time fast adaptation for dynamic scene deblurring via meta- auxiliary learning. In CVPR, pages 9137â€“9146, 2021. 3, 4 [10] Boris Chidlovskii, St Â´ephane Clinchant, and Gabriela Csurka. Domain adaptation in the absence of source domain data. In KDD, pages 451â€“460, 2016. 3 [11] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sun- grack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, pages 440â€“458, 2022. 1 [12] Francesco Croce, Maksym Andriushchenko, Vikash Se- hwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In Neurips, 2021. 6 [13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2021. 1 [14] Ying-Jun Du, Jun Xu, Huan Xiong, Qiang Qiu, Xiantong Zhen, Cees G. M. Snoek, and Ling Shao. Learning to learn with variational information bottleneck for domain general- ization. In ECCV, pages 200â€“216, 2020. 3 [15] Sayna Ebrahimi, Sercan Â¨O. Arik, and Tomas Pfister. Test- time adaptation for visual document understanding. CoRR, abs/2206.07240, 2022. 1 [16] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 1 [17] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Franc Â¸ois Laviolette, Mario Marchand, and Victor S. Lempitsky. Domain-adversarial training of neural networks. J. Mach. Learn. Res., 17:59:1â€“ 59:35, 2016. 1, 2 [18] Yunhe Gao, Xingjian Shi, Yi Zhu, Hao Wang, Zhiqiang Tang, Xiong Zhou, Mu Li, and Dimitris N. Metaxas. Vi- sual prompt tuning for test-time domain adaptation. CoRR, abs/2210.04831, 2022. 3 [19] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Robust continual test- time adaptation: Instance-aware BN and prediction-balanced memory. In NeurIPS, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [20] Sachin Goyal, Mingjie Sun, Aditi Raghunathan, and J Zico Kolter. Test time adaptation via conjugate pseudo-labels. In NeurIPS, 2022. 1, 3, 4 [21] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, pages 529â€“ 536, 2004. 3 [22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770â€“778, 2016. 1, 6 [23] Dan Hendrycks and Thomas G. Dietterich. Benchmarking neural network robustness to common corruptions and per- turbations. In ICLR, 2019. 2, 6 [24] Hengguan Huang, Xiangming Gu, Hao Wang, Chang Xiao, Hongfu Liu, and Ye Wang. Extrapolative continuous-time bayesian neural network for fast training-free test-time adap- tation. In NeurIPS, 2022. 1 [25] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In ICML, pages 448â€“456, 2015. 3, 4 [26] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier ad- justment module for model-agnostic domain generalization. In NeurIPS, pages 2427â€“2440, 2021. 1, 3 [27] Vidit Jain and Erik Learned-Miller. Online domain adapta- tion of a pre-trained cascade of classifiers. In CVPR, pages 577â€“584, 2011. 3 [28] Minguk Jang and Sae-Young Chung. Test-time adaptation via self-training with nearest neighbor information. CoRR, abs/2207.10792, 2022. 3, 4 [29] Junho Kim, Inwoo Hwang, and Young Min Kim. Ev-tta: Test-time adaptation for event-based object recognition. In CVPR, pages 17724â€“17733, 2022. 1 [30] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. 6 [31] James Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska- Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Ku- maran, and Raia Hadsell. Overcoming catastrophic forget- ting in neural networks. CoRR, abs/1612.00796, 2016. 3 [32] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 6[33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural net- works. In NeurIPS, pages 1097â€“1105, 2012. 1 [34] Ananya Kumar, Tengyu Ma, and Percy Liang. Understand- ing self-training for gradual domain adaptation. In ICML, pages 5468â€“5479, 2020. 3 [35] Jogendra Nath Kundu, Naveen Venkat, Rahul M. V ., and R. Venkatesh Babu. Universal source-free domain adapta- tion. In CVPR, pages 4543â€“4552, 2020. 3 [36] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free do- main adaptation method. In WACV, pages 615â€“625, 2021. 3 [37] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying for- getting in classification tasks. IEEE Trans. Pattern Anal. Mach. Intell., 44(7):3366â€“3385, 2022. 3 [38] Yann LeCun, Yoshua Bengio, and Geoffrey E. Hinton. Deep learning. Nat., 521(7553):436â€“444, 2015. 1 [39] Dong-Hyun Lee et al. Pseudo-label: The simple and effi- cient semi-supervised learning method for deep neural net- works. In Workshop on challenges in representation learn- ing, ICML, volume 3, page 896, 2013. 6, 7, 8, 12, 14, 15, 16, 17 [40] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, pages 3490â€“3497, 2018. 1, 3 [41] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In CVPR, pages 5400â€“5409, 2018. 1, 3 [42] Shuang Li, Binhui Xie, Qiuxia Lin, Chi Harold Liu, Gao Huang, and Guoren Wang. Generalized domain conditioned adaptation network. IEEE Trans. Pattern Anal. Mach. Intell., 44(8):4093â€“4109, 2022. 1 [43] Shuang Li, Mixue Xie, Kaixiong Gong, Chi Harold Liu, Yulin Wang, and Wei Li. Transferable semantic augmen- tation for domain adaptation. In CVPR, pages 11516â€“11525, 2021. 2 [44] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE Trans. Pattern Anal. Mach. Intell., 40(12):2935â€“2947, 2018. 3 [45] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for un- supervised domain adaptation. In ICML, pages 6028â€“6039, 2020. 1, 3 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. TTT++: when does self-supervised test-time training fail or thrive? In NeurIPS, pages 21808â€“21820, 2021. 3 [47] Yuang Liu, Wei Zhang, and Jun Wang. Source-free do- main adaptation for semantic segmentation. In CVPR, pages 1215â€“1224, 2021. 3 [48] Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and Michael I. Jordan. Transferable representation learning with deep adaptation networks. IEEE Trans. Pattern Anal. Mach. Intell., 41(12):3071â€“3085, 2019. 1, 2 [49] Wenao Ma, Cheng Chen, Shuang Zheng, Jing Qin, Huimao Zhang, and Qi Dou. Test-time adaptation with calibration of medical image classification nets for label distribution shift. In MICCAI, pages 313â€“323, 2022. 1 [50] Divyat Mahajan, Shruti Tople, and Amit Sharma. Domain generalization using causal matching. In ICML, pages 7313â€“ 7324, 2021. 3 [51] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT, 2009. 2 [52] Krikamol Muandet, David Balduzzi, and Bernhard SchÂ¨olkopf. Domain generalization via invariant fea- ture representation. In ICML, pages 10â€“18, 2013. 1, 3 [53] Zachary Nado, Shreyas Padhy, D. Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robust- ness under covariate shift. CoRR, abs/2006.10963, 2020. 4, 6, 7, 8, 12, 14, 15, 16, 17 [54] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, pages 16888â€“16905, 2022. 1 [55] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, volume 162, pages 16888â€“16905, 2022. 4, 5, 6 [56] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans. Knowl. Data Eng., 22(10):1345â€“1359, 2010. 1 [57] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, pages 8024â€“8035, 2019. 6 [58] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, pages 1406â€“1415, 2019. 2, 6 [59] Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in ma- chine learning. 2008. 1 [60] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. icarl: Incremental classi- fier and representation learning. InCVPR, pages 5533â€“5542, 2017. 3 [61] Amelie Royer and Christoph H Lampert. Classifier adapta- tion at prediction time. In CVPR, pages 1401â€“1409, 2015. 3 [62] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat- suya Harada. Maximum classifier discrepancy for unsuper- vised domain adaptation. In CVPR, pages 3723â€“3732, 2018. 2 [63] Inkyu Shin, Yi-Hsuan Tsai, Bingbing Zhuang, Samuel Schulter, Buyu Liu, Sparsh Garg, In So Kweon, and Kuk- Jin Yoon. MM-TTA: multi-modal test-time adaptation for 3d semantic segmentation. In CVPR, pages 16907â€“16916, 2022. 1, 3[64] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test- time prompt tuning for zero-shot generalization in vision- language models. In NeurIPS, 2022. 1, 3 [65] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, pages 9229â€“9248, 2020. 1, 2, 3, 4 [66] Rishabh Tiwari, KrishnaTeja Killamsetty, Rishabh K. Iyer, and Pradeep Shenoy. GCR: gradient coreset based replay buffer selection for continual learning. In CVPR, pages 99â€“ 108, 2022. 3 [67] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Ki- hyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic seg- mentation. In CVPR, pages 7472â€“7481, 2018. 2 [68] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In ICCV, pages 4068â€“4076, 2015. 2 [69] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In CVPR, pages 2962â€“2971, 2017. 1 [70] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno A. Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17 [71] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. Generalizing to unseen domains: A survey on domain generalization. IEEE Trans. Knowl. Data Eng., 2022. 1 [72] Mei Wang and Weihong Deng. Deep visual domain adapta- tion: A survey. Neurocomputing, 312:135â€“153, 2018. 1 [73] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Con- tinual test-time domain adaptation. In CVPR, pages 7191â€“ 7201, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [74] Markus Wulfmeier, Alex Bewley, and Ingmar Posner. Incre- mental adversarial domain adaptation for continually chang- ing environments. In ICRA, pages 4489â€“4495, 2018. 3 [75] Binhui Xie, Shuang Li, Mingjia Li, Chi Harold Liu, Gao Huang, and Guoren Wang. Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation. IEEE Trans. Pattern Anal. Mach. Intell., pages 1â€“17, 2023. 2 [76] Saining Xie, Ross Girshick, Piotr Doll Â´ar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, pages 5987â€“5995, 2017. 6 [77] Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin. Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation. In ICCV, pages 1426â€“ 1435, 2019. 2 [78] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 3 [79] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adapta- tion. In ICCV, pages 8978â€“8987, 2021. 3 [80] Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In BMVC, 2016. 6 [81] Marvin Mengxin Zhang, Sergey Levine, and Chelsea Finn. MEMO: Test time robustness via adaptation and augmenta- tion. In NeurIPS, 2022. 1, 4 [82] Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In WACV, pages 2633â€“2642, 2022. 1, 3 [83] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE Trans. Pattern Anal. Mach. Intell., 2022. 1 [84] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 3 [85] Yang Zou, Zhiding Yu, BVK Vijaya Kumar, and Jinsong Wang. Unsupervised domain adaptation for semantic seg- mentation via class-balanced self-training. In ECCV, pages 289â€“305, 2018. 26. Appendix 6.1. Discussion Societal impact. RoTTA enables adapting pre-trained models on continually changing distributions with correl- atively sampled test streams without any more raw data or label requirements. Thus, our work may have a positive im- pact on communities to effectively deploy and adapt models in various real-world scenarios, which is economically and environmentally friendly. And since no training data is re- quired, this protects data privacy and has potential commer- cial value. We carry out experiments on benchmark datasets and do not notice any societal issues. It does not involve sensitive attributes. Future work. Our work suggests a few promising direc- tions for future work. Firstly, the proposed RoTTA is a preliminary attempt to perform test-time adaptation for the more realistic test stream under the setup PTTA. One could experiment to improve the algorithm by replacing some parts of RoTTA. More importantly, we hope that with this work, we can open a path to the original goal of test-time adaptation, which is performing test-time adaptation in real- world scenarios. Thus, one could improve PTTA to make it more realistic. Limitations. RoTTA achieves excellent performance on various tasks under the setup PTTA as demonstrated in Sec- tion 4 in the main paper, but we still find some limitations of it. Firstly, the adopted robust batch normalization (RBN) is a naive solution to the normalization of the correlatively sampled batch of data. This requires careful design of the value of Î± in RBN. Secondly, we observe that during the adaptation procedure of some methods like PL [39] and TENT [70], the model collapse finally. Although we de- sign many strategies to stabilize the adaptation and model collapse never occurs in the experiments of RoTTA, we are still missing a way to recover the model from the collapse state as a remedy. Thirdly, category similarity is only one kind of correlation. Although we conduct experiments on different datasets with Dirichlet distribution to simulate cor- relatively sampled test streams, we still need to validate our approach in some real-world scenarios. 6.2. Sensitivity to different hyper-parameters In this section, we conduct a detailed sensitivity analy- sis of the hyperparameters involved in RoTTA. All experi- ments are conducted on CIFAR100â†’CIFAR100-C, and the corruptions changes as motion, snow, fog, shot, defocus, contrast, zoom, brightness, frost, elastic, glass, gaussian, pixelate, jpeg, and impulse, and test streams are sampled correlatively with the Dirichlet parameter Î´ = 0.1. When we investigate the sensitivity to a specific hyperparameter, other hyperparameters are fixed to the default values, i.e., Î»t = 1.0, Î»u = 1.0, Î± = 0.05, and Î½ = 0.001, for all experiments. Table 7. Classification error with different value of Î»t/Î»u. Î»t/Î»u 0.0/2.0 0.5/1.5 1.0/1.0 1.5/ 0.5 2.0/ 0.0 CIFAR100-C 57.5 36.9 35.0 35.9 38.9 Trade-off between timeliness and uncertainty. When updating the memory bank, we take the timeliness and uncertainty of samples into account simultaneously, and Î»t and Î»u will make a trade-off between them. In Table 7, we show the results of RoTTA with varying Î»t/Î»u, i.e., Î»t/Î»u âˆˆ {0.0/2.0, 0.5/1.5, 1.0/1.0, 1.5/0.5, 2.0/0.0}. When we consider both of them, the results are relatively stable (35.0-36.9%). When we only think about one side, the performance drops significantly. For example, when we set Î»t/Î»u = 0.0/2.0 which means only considering uncer- tainty, the performance drops 22.5%. Thatâ€™s because some confident samples get stuck in the memory bank, making it not work the way we design it. Table 8. Classification error with varying Î± Î± 0.5 0.1 0.05 0.01 0.005 0.001 CIFAR100-C 39.0 36.0 35.0 36.0 38.1 41.5 Sensitivity to Î±. We show the results of RoTTA with vary- ing Î±, i.e., Î± âˆˆ {0.5, 0.1, 0.05, 0.01, 0.005, 0.001} in Ta- ble 8. A larger value of Î± means updating the global statis- tics faster and vice versa. We can see that RoTTA achieves competitive results (35.0 âˆ’ 36.0%) at appropriate values of Î±, i.e., Î± âˆˆ {0.1, 0.05, 0.01}. Updating too aggressively or too gently can lead to unreliable estimates of statistics. Table 9. Classification error with varying Î½ Î½ 0.05 0.01 0.005 0.001 0.0005 0.0001 CIFAR100-C 44.8 39.1 37.1 35.0 37.6 43.6 Sensitivity to Î½. We show the results of RoTTA with vary- ing Î½, i.e., Î½ âˆˆ {0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001} in Table 9. As we can see, the best performance is achieved at Î½ = 0.001. Updating the teacher model too quickly or too slowly can cause performance degradation. 6.3. Additional experiment details and results 6.3.1 Compared methods BN [53] utilizes statistics of the current batch of data to nor- malize their feature maps without tuning any parameters. PL [39] is based on BN [53], and adopts pseudo labels to train the affine parameters in BN layers.TENT [70] is the first to propose fully test-time adaptation. It adopts test-time batch normalization and utilizes entropy minimization to train the affine parameters of BN layers. We reimplement it following the released code https:// github.com/DequanWang/tent. LAME [5] adapts the output of the pre-trained model by optimizing a group of latent variables without tuning any in- ner parts of the model. We reimplement it following the re- leased code https://github.com/fiveai/LAME. CoTTA [73] considers performing test-time adapta- tion on continually changing distributions and pro- pose augmentation-averaged pseudo-labels and stochastic restoration to address error accumulation and catastrophic forgetting. We reimplement it following the released code https://github.com/qinenergy/cotta. NOTE [19] proposes instance-aware normalization and prediction-balanced reservoir sampling to stable the adapta- tion on temporally correlated test streams. We reimplement it following the released code https://github.com/ TaesikGong/NOTE. 6.3.2 Simulate correlatively sampling As we described in the scenarios of autonomous driving that the car will follow more vehicles on the highway or will en- counter more pedestrians on the sidewalk, so we use the same category to simulate correlation. From a macro point of view, the test distribution Ptest changes continually as P0, P1, ...,Pâˆž. During the period when Ptest = Pt, we adopt Dirichlet distribution to simulate correlatively sam- pled test stream. More specifically, we consider dividing samples of C classes into T slots. Firstly, we utilize Dirich- let distribution with parameter Î³ to generate the partition criterion q âˆˆ RCÃ—T . Then for each class c, we split samples into T parts according to qc and assign each part to each slot respectively. Finally, we concatenate all slots to sim- ulate the correlatively sampled test stream for Ptest = Pt. And as Ptest changes, we use the above method again to generate the test stream. 6.3.3 Detailed results of different orders We report the average classification error of ten different distribution changing orders in Table 6 of the main pa- per. And then we present the specific results here, includ- ing Table 10, 11, 12, 13, 14, 15, 16, 17, 18, and 19 for CIFAR10â†’CIFAR10-C and Table 20, 21, 22, 23, 24, 25, 26, 27, 28, and 29 for CIFAR100 â†’CIFAR100-C. We can see consistently superior performance of RoTTA. One thing to mention is that on DomainNet we use alphabetical order to determine the order of domain changes.Table 10. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 9.3 58.5 72.3 34.8 42.0 54.3 72.9 30.3 46.9 26.6 65.7 41.3 25.1 26.0 46.7 43.5BN [53] 71.1 75.2 76.8 74.2 73.7 80.1 79.3 77.5 73.8 77.7 77.2 73.3 73.8 72.7 71.7 75.2PL [39] 71.7 75.9 80.2 78.4 80.2 85.2 85.3 85.4 85.1 86.7 87.9 87.9 88.1 88.3 87.9 83.6TENT [70] 71.6 75.9 81.3 80.5 82.3 85.6 87.1 87.0 87.1 88.1 88.2 87.8 87.9 88.3 88.2 84.4LAME [5] 5.4 56.8 73.1 29.1 37.0 50.5 71.4 22.3 42.8 18.6 65.5 37.3 18.8 20.4 43.6 39.5CoTTA [73] 75.0 79.8 83.1 83.4 83.2 84.0 84.5 83.2 83.5 83.3 83.6 83.0 83.0 83.4 83.7 82.6NOTE [19] 10.1 29.9 47.1 23.4 28.4 48.4 46.1 41.8 26.9 36.1 37.5 25.0 25.0 23.2 14.2 30.9 RoTTA 10.4 26.6 37.5 23.9 17.0 40.9 39.7 30.1 18.0 29.9 30.1 23.6 21.7 17.6 19.0 25.7(+5.2) Table 11. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 30.3 65.7 42.0 41.3 46.7 26.0 46.9 26.6 72.3 9.3 54.3 72.9 58.5 25.1 34.8 43.5BN [53] 77.6 75.8 73.4 74.1 73.1 72.5 72.9 77.1 77.2 72.2 79.9 79.9 75.5 74.6 72.9 75.2PL [39] 77.6 77.1 76.6 78.3 77.5 79.8 82.0 84.8 86.1 83.5 87.8 87.1 86.5 85.6 85.7 82.4TENT [70] 78.5 78.2 79.2 81.8 84.8 84.8 86.4 87.3 87.9 86.7 87.3 87.8 87.2 87.5 87.1 84.8LAME [5] 22.5 65.2 37.0 37.1 44.0 20.3 41.7 18.7 72.8 5.2 51.2 71.5 57.0 19.0 29.4 39.5CoTTA [73]78.5 81.0 82.8 84.1 84.9 83.4 83.5 83.5 84.5 83.3 84.7 84.6 83.0 84.4 83.4 83.3NOTE [19]35.4 36.1 22.1 21.3 11.6 24.8 24.5 36.0 37.7 18.4 49.0 47.4 43.9 30.4 29.2 31.2 RoTTA 33.2 33.3 19.8 24.1 24.9 20.5 16.2 31.7 28.4 11.8 43.1 36.9 32.5 20.7 20.6 26.5(+4.7) Table 12. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 46.7 46.9 72.3 65.7 25.1 41.3 54.3 42.0 26.6 30.3 58.5 9.3 72.9 34.8 26.0 43.5BN [53] 72.3 72.6 76.9 77.1 74.8 73.5 80.0 73.2 77.4 78.6 76.4 71.0 79.1 73.9 71.5 75.2PL [39] 72.4 75.3 80.7 82.6 83.3 83.5 86.6 85.7 86.6 88.4 87.5 86.6 88.3 88.2 86.8 84.1TENT [70] 73.5 77.9 85.5 86.9 87.6 87.8 88.3 87.7 88.6 89.2 88.5 88.5 89.3 88.6 88.6 86.4LAME [5] 43.5 42.3 73.1 65.3 19.2 37.3 51.1 36.8 18.5 22.5 56.9 5.5 71.1 29.1 20.5 39.5CoTTA [73]79.4 80.3 83.8 83.9 83.9 83.4 85.0 83.2 85.1 84.3 83.9 83.3 84.7 83.9 82.5 83.4NOTE [19] 9.6 21.8 40.1 31.0 25.5 22.6 44.8 22.8 33.2 39.4 33.2 18.1 50.0 28.3 29.8 30.0 RoTTA 18.4 17.9 38.4 31.9 23.3 19.8 40.7 17.4 31.4 29.8 27.8 11.3 43.8 19.7 18.8 26.0(+4.0) Table 13. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 65.7 26.0 54.3 58.5 25.1 26.6 9.3 72.9 46.9 41.3 46.7 72.3 34.8 30.3 42.0 43.5BN [53] 76.4 72.0 80.4 76.2 74.8 77.0 71.1 79.6 73.8 74.4 73.0 77.0 72.5 78.3 72.5 75.3PL [39] 77.0 73.3 82.4 79.8 81.0 82.3 79.5 84.4 82.7 83.5 83.5 85.5 84.8 87.0 84.5 82.1TENT [70]76.9 74.6 82.3 81.7 82.0 84.9 84.8 87.3 86.6 87.3 87.6 89.2 88.3 88.9 87.3 84.6LAME [5] 65.3 20.6 50.9 56.7 19.2 18.8 5.4 71.8 42.8 37.2 43.3 73.2 29.4 22.6 36.9 39.6CoTTA [73]77.4 77.6 83.8 81.9 82.2 82.6 80.4 83.3 82.3 81.5 82.7 82.6 81.1 82.9 81.0 81.6NOTE [19]34.0 20.9 43.1 36.6 24.0 36.4 12.1 48.0 25.9 23.9 13.4 38.1 25.0 43.2 24.2 29.9 RoTTA 35.0 21.1 43.9 29.2 22.1 29.7 10.8 44.6 25.3 22.7 24.6 29.4 26.9 34.4 16.1 27.7(+2.2) Table 14. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 58.5 54.3 42.0 25.1 26.0 72.9 9.3 34.8 41.3 30.3 72.3 65.7 46.7 46.9 26.6 43.5BN [53] 76.0 79.6 73.3 75.2 72.9 79.8 71.1 73.5 74.1 78.6 77.4 76.1 72.0 73.8 76.4 75.3PL [39] 76.7 81.3 77.4 80.3 81.2 86.3 83.3 85.9 86.2 87.7 88.1 88.4 87.4 87.6 87.7 84.4TENT [70] 76.4 80.2 77.8 81.2 83.0 87.1 85.6 87.2 87.6 88.7 88.6 88.9 88.5 88.6 88.2 85.2LAME [5] 56.9 50.7 37.0 19.0 20.3 71.5 5.4 29.2 37.2 22.5 73.0 65.3 43.8 42.4 18.7 39.5CoTTA [73]77.1 83.6 84.1 84.8 84.4 85.2 84.0 84.3 84.9 84.9 85.0 84.7 85.3 84.4 84.3 84.1NOTE [19] 27.8 52.2 24.5 22.3 21.6 44.5 14.5 21.3 25.9 42.5 38.8 36.0 16.7 28.1 40.6 30.5 RoTTA 25.9 43.3 17.7 22.1 20.2 41.5 12.2 22.9 22.5 31.2 33.8 26.0 31.4 17.7 27.6 26.4(+4.1)Table 15. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 16. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 41.3 72.9 30.3 46.7 42.0 54.3 58.5 25.1 46.9 34.8 9.3 26.6 65.7 26.0 72.3 43.5BN [53] 73.8 79.1 77.9 73.0 73.7 80.1 75.7 74.4 73.7 74.0 71.7 77.0 75.9 72.8 76.2 75.3PL [39] 74.2 80.9 80.4 79.5 81.8 85.9 83.9 85.1 84.7 85.9 85.9 86.7 87.2 87.0 87.8 83.8TENT [70]73.9 80.3 81.8 81.6 83.6 86.3 85.6 85.7 86.4 87.7 87.4 88.8 88.8 88.5 88.4 85.0LAME [5] 37.4 71.8 22.4 43.5 37.0 50.5 57.0 19.0 42.8 29.1 5.4 18.7 65.2 20.4 72.9 39.5CoTTA [73]76.5 82.2 82.8 85.0 82.9 85.0 83.0 82.9 83.5 83.4 82.6 83.7 83.2 83.3 83.6 82.9NOTE [19]21.1 41.4 36.3 10.2 21.7 46.7 37.5 26.4 26.1 21.4 14.3 37.9 38.5 24.4 40.7 29.6 RoTTA 22.2 44.9 35.2 18.8 19.7 41.5 28.5 23.2 21.2 18.6 12.4 30.0 27.4 20.0 31.2 26.3(+3.3) Table 17. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 46.9 34.8 42.0 65.7 72.3 54.3 30.3 26.0 46.7 58.5 41.3 25.1 9.3 26.6 72.9 43.5BN [53] 72.8 72.7 73.3 77.2 77.3 80.0 77.6 72.6 73.3 76.6 73.8 74.1 70.3 77.5 79.0 75.2PL [39] 73.2 74.6 76.5 81.7 82.8 84.6 85.1 84.6 86.2 86.4 86.1 87.1 86.8 88.4 88.1 83.5TENT [70] 73.7 74.3 77.1 82.5 84.3 86.9 87.4 86.6 88.0 88.5 88.1 88.5 88.4 89.4 88.9 84.8LAME [5] 42.5 29.3 37.0 65.3 73.2 50.5 22.5 20.5 43.5 56.9 37.1 18.9 5.4 18.5 71.3 39.5CoTTA [73]76.3 79.8 82.4 83.3 83.8 84.5 83.1 82.7 84.7 82.9 83.0 83.3 81.4 83.8 83.8 82.6NOTE [19] 18.5 18.8 23.6 36.5 33.7 47.8 38.6 22.8 13.0 40.0 29.2 26.3 17.5 44.0 52.9 30.9 RoTTA 17.0 17.5 16.5 33.8 33.3 42.7 29.4 18.0 19.6 29.5 20.7 22.1 11.5 29.5 38.1 25.3(+5.6) Table 18. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.3 42.0 72.9 26.0 25.1 30.3 72.3 41.3 65.7 9.3 46.7 34.8 58.5 46.9 26.6 43.5BN [53] 79.7 72.3 79.8 73.2 74.7 77.7 76.6 73.2 77.1 72.2 73.0 73.3 75.5 73.8 76.4 75.2PL [39] 79.6 73.2 81.3 77.3 79.1 83.0 83.2 83.0 85.5 84.3 87.0 86.9 86.4 86.5 87.6 82.9TENT [70] 79.5 74.1 84.2 82.2 84.5 86.5 86.7 85.9 87.2 86.6 86.8 87.3 86.9 87.4 87.3 84.9LAME [5] 50.8 36.9 71.3 20.6 19.2 22.4 72.5 37.2 65.4 5.2 43.3 29.1 57.0 42.4 18.7 39.5CoTTA [73]81.5 79.4 85.2 84.1 84.5 84.2 84.8 84.0 84.8 83.2 85.2 83.8 83.2 84.6 83.6 83.7NOTE [19]45.0 21.2 42.3 21.0 21.6 38.4 36.4 21.4 33.1 16.7 14.6 25.4 43.5 29.1 38.5 29.9 RoTTA 42.6 17.6 48.1 23.9 21.9 32.6 32.1 20.7 30.2 12.0 21.9 20.0 33.7 16.4 28.1 26.8(+3.1) Table 19. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 46.7 72.3 46.9 42.0 41.3 54.3 30.3 26.0 58.5 26.6 65.7 72.9 25.1 34.8 9.3 43.5BN [53] 72.4 76.2 73.2 73.7 73.6 80.0 77.6 72.6 76.4 77.7 77.2 79.9 73.8 73.9 70.0 75.2PL [39] 73.0 78.2 76.7 79.7 81.6 85.6 86.0 85.3 87.2 88.2 88.3 88.9 88.5 89.2 88.2 84.3TENT [70] 73.6 80.9 83.1 85.6 87.1 88.5 88.8 88.4 89.2 89.3 89.0 89.0 89.3 89.9 89.1 86.7LAME [5] 43.5 73.2 42.3 37.0 37.2 50.5 22.5 20.5 57.0 18.6 65.5 71.5 18.8 29.1 5.6 39.5CoTTA [73]79.5 81.4 83.4 83.6 83.9 85.0 84.0 82.8 84.8 84.8 84.5 84.7 84.1 84.4 82.8 83.6NOTE [19] 9.6 43.6 26.5 24.8 23.9 46.9 38.0 23.4 34.0 41.2 41.5 45.0 27.6 25.8 19.0 31.4 RoTTA 18.4 36.0 21.1 15.6 23.0 41.7 30.8 19.1 34.1 31.1 31.3 39.9 26.0 18.8 12.8 26.6(+4.8)Table 20. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 29.5 74.7 73.0 30.8 28.8 54.1 39.4 41.2 29.3 37.2 68.0 45.8 39.5 50.3 55.1 46.4BN [53] 46.5 52.0 58.6 47.4 47.4 57.6 58.2 56.9 47.0 53.4 56.0 52.5 53.1 57.7 49.1 52.9PL [39] 48.5 60.7 77.1 85.9 91.5 95.5 95.8 96.6 96.8 96.9 97.3 97.5 97.6 97.7 97.9 88.9TENT [70] 49.8 69.4 92.2 96.0 96.7 97.3 97.5 97.9 97.5 97.9 98.0 98.2 98.2 98.2 98.2 92.2LAME [5] 21.7 75.1 72.7 22.9 20.6 49.0 32.1 33.3 21.2 28.0 66.8 40.0 30.6 43.9 51.3 40.6CoTTA [73] 46.8 48.4 54.7 48.7 48.6 53.5 55.4 52.8 49.8 51.8 53.5 52.9 54.1 56.7 53.6 52.1NOTE [19] 42.6 53.0 69.9 52.1 53.3 70.4 73.1 76.7 80.8 96.0 97.7 97.1 96.6 97.2 95.8 76.8 RoTTA 28.4 37.3 44.6 31.9 28.3 41.8 43.6 39.9 28.0 35.2 38.2 33.7 33.0 39.5 31.0 35.6(+5.0) Table 21. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 41.2 68.0 28.8 45.8 55.1 50.3 29.3 37.2 73.0 29.5 54.1 39.4 74.7 39.5 30.8 46.4BN [53] 58.3 56.8 47.8 51.8 48.9 57.3 46.8 53.5 57.8 45.5 57.1 58.5 51.7 53.3 48.8 52.9PL [39] 59.4 66.3 74.9 87.5 94.2 95.5 96.2 97.1 97.4 97.2 97.5 97.7 98.0 98.2 98.2 90.4TENT [70] 62.0 79.3 91.7 95.8 96.9 97.0 97.4 97.7 97.6 97.7 97.9 97.9 98.0 97.9 97.9 93.5LAME [5] 33.6 66.7 21.1 39.9 50.6 43.9 21.0 28.6 72.5 21.6 48.6 32.5 74.5 30.6 22.5 40.6CoTTA [73]54.6 54.1 49.6 52.1 52.7 58.0 50.3 53.3 55.0 49.1 55.4 55.7 51.0 54.6 52.1 53.2NOTE [19]60.4 63.0 49.9 55.7 47.0 65.2 59.4 76.6 90.9 87.2 96.8 97.0 97.3 96.7 96.8 76.0 RoTTA 43.9 45.3 31.0 37.3 35.7 41.2 27.7 34.8 39.7 26.6 39.5 41.9 32.0 33.0 30.5 36.0(+4.6) Table 22. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 55.1 29.3 73.0 68.0 39.5 45.8 54.1 28.8 37.2 41.2 74.7 29.5 39.4 30.8 50.3 46.4BN [53] 49.4 47.2 58.6 56.2 52.7 52.0 57.9 46.1 54.4 57.7 50.5 46.2 58.2 47.6 58.5 52.9PL [39] 54.8 64.2 83.3 92.4 95.5 96.5 96.9 96.4 97.2 97.4 97.8 97.8 97.9 97.7 98.0 90.9TENT [70] 60.2 83.1 95.2 96.5 96.9 97.3 97.0 97.3 97.8 97.8 97.6 97.9 97.8 97.9 98.1 93.9LAME [5] 51.3 21.3 72.7 66.3 30.2 40.0 48.6 20.9 27.7 33.3 75.0 21.5 32.2 22.5 43.8 40.5CoTTA [73]52.1 48.6 55.1 52.7 53.4 51.9 55.9 49.2 53.2 52.8 49.2 49.7 56.2 50.7 58.1 52.6NOTE [19] 39.5 45.9 68.8 61.8 57.4 58.5 71.4 66.5 80.8 90.9 94.2 94.9 97.0 95.5 96.6 74.6 RoTTA 41.7 30.5 44.9 40.5 35.4 34.1 40.5 28.2 34.5 39.5 31.1 26.7 43.3 31.4 38.8 36.1(+4.4) Table 23. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 68.0 50.3 54.1 74.7 39.5 37.2 29.5 39.4 29.3 45.8 55.1 73.0 30.8 41.2 28.8 46.4BN [53] 57.5 58.6 58.5 50.5 52.7 53.1 45.9 57.9 47.0 51.5 47.8 58.2 48.2 57.1 47.7 52.8PL [39] 59.5 72.9 85.1 89.6 94.5 96.8 97.1 97.9 97.8 98.0 98.3 98.2 98.0 98.0 98.2 92.0TENT [70]60.3 81.4 95.0 96.6 97.0 97.3 97.3 97.7 97.7 97.7 97.8 97.7 97.6 97.6 97.9 93.8LAME [5] 66.4 43.2 49.0 75.2 30.2 28.5 21.6 32.5 21.2 39.5 52.0 72.8 22.3 33.1 20.5 40.5CoTTA [73]54.5 58.4 55.6 50.0 53.9 53.4 50.3 56.7 51.3 53.2 53.7 56.1 52.0 54.5 51.5 53.7NOTE [19]61.8 60.2 63.4 55.6 59.8 65.9 58.6 75.1 77.8 93.8 94.2 97.0 95.0 95.5 94.4 76.5 RoTTA 45.5 44.5 43.5 35.6 35.1 35.7 26.2 44.0 29.7 34.2 32.0 40.7 31.4 39.4 27.7 36.3(+4.2) Table 24. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 74.7 54.1 28.8 39.5 50.3 39.4 29.5 30.8 45.8 41.2 73.0 68.0 55.1 29.3 37.2 46.4BN [53] 51.7 58.6 47.8 52.9 57.1 58.2 45.9 47.6 52.9 57.8 57.5 56.7 49.5 46.1 54.0 52.9PL [39] 52.4 68.0 73.4 87.9 93.7 96.1 95.7 96.0 96.5 96.7 97.5 97.7 97.7 97.3 97.7 89.6TENT [70] 53.5 77.8 91.1 96.0 97.0 97.6 97.4 97.6 97.9 98.1 98.1 98.0 98.1 97.9 98.1 92.9LAME [5] 74.8 48.2 21.1 30.6 43.4 32.5 21.6 23.0 39.6 33.3 72.7 66.5 51.5 20.7 27.5 40.5CoTTA [73]49.3 55.1 49.1 52.9 56.8 55.7 49.5 50.0 53.6 53.4 54.9 53.9 53.8 50.1 53.5 52.8NOTE [19] 52.2 64.9 47.5 57.0 61.9 67.3 60.4 67.8 77.4 90.6 97.1 96.8 92.8 95.9 96.6 75.1 RoTTA 36.4 44.4 29.7 36.5 41.0 44.1 26.8 29.5 33.0 40.3 40.3 38.2 33.9 28.5 34.9 35.8(+4.7)Table 25. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 26. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 45.8 39.4 41.2 55.1 28.8 54.1 74.7 39.5 29.3 30.8 29.5 37.2 68.0 50.3 73.0 46.4BN [53] 52.9 58.8 57.6 48.2 47.4 57.6 50.9 52.4 47.0 47.2 45.1 54.0 56.4 57.7 58.2 52.8PL [39] 56.9 73.3 86.7 94.4 95.8 97.3 97.2 97.4 97.6 97.4 97.7 97.6 97.8 98.3 98.1 92.2TENT [70]60.1 84.2 95.7 97.2 97.4 97.9 97.8 98.0 98.1 98.2 98.3 98.4 98.4 98.4 98.4 94.4LAME [5] 39.9 32.4 33.4 51.4 20.6 49.0 74.4 31.3 21.2 22.6 21.9 28.1 66.9 43.9 72.5 40.6CoTTA [73]51.5 55.3 54.3 51.8 49.4 55.3 50.7 54.2 51.4 50.6 49.5 53.6 55.0 57.1 55.8 53.0NOTE [19]51.6 60.9 60.3 45.4 54.3 70.8 68.8 75.0 75.7 87.1 94.7 95.6 96.7 96.4 97.2 75.4 RoTTA 40.0 46.3 42.8 36.4 29.2 42.3 33.2 34.4 28.4 29.2 26.4 34.5 38.5 39.8 39.3 36.0(+4.6) Table 27. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 29.3 30.8 28.8 68.0 73.0 54.1 41.2 50.3 55.1 74.7 45.8 39.5 29.5 37.2 39.4 46.4BN [53] 47.1 48.6 47.8 56.2 57.6 57.6 57.6 57.5 48.7 50.6 51.8 53.2 46.9 53.5 58.8 52.9PL [39] 48.8 58.7 69.9 88.0 95.1 96.6 96.7 96.9 97.4 97.4 98.2 98.2 98.2 98.3 98.5 89.1TENT [70] 51.0 67.6 85.8 95.9 97.2 97.5 97.2 97.7 98.1 97.9 97.7 97.7 98.0 98.0 98.2 91.7LAME [5] 21.2 22.8 21.1 66.3 72.8 49.0 33.3 44.8 51.7 74.9 39.8 31.2 21.3 27.3 32.3 40.6CoTTA [73]48.4 48.8 48.2 52.9 54.0 53.8 52.7 57.2 52.6 48.6 51.8 53.9 49.4 52.3 56.0 52.0NOTE [19] 45.1 46.7 49.1 67.3 65.5 69.4 75.5 80.3 83.8 96.0 97.6 97.1 96.1 97.9 98.7 77.7 RoTTA 29.6 31.3 28.8 43.9 41.5 41.3 40.9 39.8 32.1 32.6 33.1 33.0 26.5 34.5 42.9 35.4(+5.2) Table 28. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.1 28.8 39.4 50.3 39.5 41.2 73.0 45.8 68.0 29.5 55.1 30.8 74.7 29.3 37.2 46.4BN [53] 58.8 47.7 59.2 57.6 52.7 56.9 58.2 52.0 56.7 45.5 47.8 48.2 51.7 46.1 54.0 52.9PL [39] 60.1 59.5 75.1 85.7 91.5 94.6 96.5 97.1 97.4 97.3 98.0 97.7 97.9 97.8 97.7 89.6TENT [70] 61.6 71.5 91.0 95.9 96.6 97.1 96.9 97.3 97.4 97.2 97.9 98.0 98.1 97.9 97.8 92.8LAME [5] 48.6 20.6 32.3 44.4 30.2 33.6 72.4 40.0 66.3 21.6 52.0 22.8 74.6 20.7 27.5 40.5CoTTA [73]56.4 48.9 56.1 57.8 54.1 54.2 56.2 53.6 55.4 50.0 53.6 51.6 51.2 50.7 54.4 53.6NOTE [19]62.5 46.3 61.5 61.1 58.6 68.4 76.1 78.3 92.0 93.4 96.1 95.4 96.2 95.8 96.4 78.5 RoTTA 45.5 30.0 45.9 42.6 35.3 41.8 42.2 34.5 40.2 27.3 31.3 30.2 32.7 28.1 34.9 36.2(+4.3) Table 29. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 55.1 73.0 29.3 28.8 45.8 54.1 41.2 50.3 74.7 37.2 68.0 39.4 39.5 30.8 29.5 46.4BN [53] 49.5 58.8 47.0 46.5 52.2 57.6 57.6 57.6 51.7 53.5 56.0 58.5 53.1 47.6 46.3 52.9PL [39] 53.6 70.4 76.0 85.1 91.2 95.2 96.0 97.0 96.9 97.3 97.3 97.6 97.5 97.6 97.7 89.8TENT [70] 60.2 89.1 95.0 96.2 96.9 97.0 96.5 97.0 97.0 97.2 97.6 97.8 97.5 97.9 97.7 94.0LAME [5] 51.3 72.5 21.5 21.0 39.6 49.0 33.3 44.8 74.8 28.0 66.8 32.5 30.6 22.5 21.4 40.6CoTTA [73]52.3 55.3 49.5 48.1 52.1 54.8 52.7 56.9 50.6 52.6 53.7 55.8 54.6 50.6 50.5 52.7NOTE [19] 39.1 64.7 48.9 50.6 59.1 70.1 71.7 75.0 85.2 95.7 96.9 98.4 96.0 95.9 94.9 76.1 RoTTA 41.4 46.2 30.5 28.5 36.0 40.9 40.5 39.6 33.0 35.0 38.2 43.1 33.9 30.7 27.1 36.3(+4.3)",
      "meta_data": {
        "arxiv_id": "2303.13899v1",
        "authors": [
          "Longhui Yuan",
          "Binhui Xie",
          "Shuang Li"
        ],
        "published_date": "2023-03-24T10:19:14Z",
        "pdf_url": "https://arxiv.org/pdf/2303.13899v1.pdf"
      }
    },
    {
      "title": "DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION",
      "abstract": "Fully test-time adaptation aims at adapting a pre-trained model to the test\nstream during real-time inference, which is urgently required when the test\ndistribution differs from the training distribution. Several efforts have been\ndevoted to improving adaptation performance. However, we find that two\nunfavorable defects are concealed in the prevalent adaptation methodologies\nlike test-time batch normalization (BN) and self-learning. First, we reveal\nthat the normalization statistics in test-time BN are completely affected by\nthe currently received test samples, resulting in inaccurate estimates. Second,\nwe show that during test-time adaptation, the parameter update is biased\ntowards some dominant classes. In addition to the extensively studied test\nstream with independent and class-balanced samples, we further observe that the\ndefects can be exacerbated in more complicated test environments, such as\n(time) dependent or class-imbalanced data. We observe that previous approaches\nwork well in certain scenarios while show performance degradation in others due\nto their faults. In this paper, we provide a plug-in solution called DELTA for\nDegradation-freE fuLly Test-time Adaptation, which consists of two components:\n(i) Test-time Batch Renormalization (TBR), introduced to improve the estimated\nnormalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to\naddress the class bias within optimization. We investigate various test-time\nadaptation methods on three commonly used datasets with four scenarios, and a\nnewly introduced real-world dataset. DELTA can help them deal with all\nscenarios simultaneously, leading to SOTA performance.",
      "meta_data": {
        "arxiv_id": "2301.13018v1",
        "authors": [
          "Bowen Zhao",
          "Chen Chen",
          "Shu-Tao Xia"
        ],
        "published_date": "2023-01-30T15:54:00Z",
        "pdf_url": "https://arxiv.org/pdf/2301.13018v1.pdf"
      }
    },
    {
      "title": "Towards Stable Test-time Adaptation in Dynamic Wild World",
      "abstract": "Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.",
      "meta_data": {
        "arxiv_id": "2302.12400v1",
        "authors": [
          "Shuaicheng Niu",
          "Jiaxiang Wu",
          "Yifan Zhang",
          "Zhiquan Wen",
          "Yaofo Chen",
          "Peilin Zhao",
          "Mingkui Tan"
        ],
        "published_date": "2023-02-24T02:03:41Z",
        "pdf_url": "https://arxiv.org/pdf/2302.12400v1.pdf"
      }
    },
    {
      "title": "Towards Stable Test-time Adaptation in Dynamic Wild World",
      "abstract": "Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.",
      "meta_data": {
        "arxiv_id": "2302.12400v1",
        "authors": [
          "Shuaicheng Niu",
          "Jiaxiang Wu",
          "Yifan Zhang",
          "Zhiquan Wen",
          "Yaofo Chen",
          "Peilin Zhao",
          "Mingkui Tan"
        ],
        "published_date": "2023-02-24T02:03:41Z",
        "pdf_url": "https://arxiv.org/pdf/2302.12400v1.pdf"
      }
    },
    {
      "title": "Test Time Adaptation With Regularized Loss for Weakly Supervised Salient Object Detection"
    },
    {
      "title": "Tent: Fully Test-Time Adaptation by Entropy Minimization",
      "abstract": "A model must adapt itself to generalize to new and different data during\ntesting. In this setting of fully test-time adaptation the model has only the\ntest data and its own parameters. We propose to adapt by test entropy\nminimization (tent): we optimize the model for confidence as measured by the\nentropy of its predictions. Our method estimates normalization statistics and\noptimizes channel-wise affine transformations to update online on each batch.\nTent reduces generalization error for image classification on corrupted\nImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on\nImageNet-C. Tent handles source-free domain adaptation on digit recognition\nfrom SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to\nCityscapes, and on the VisDA-C benchmark. These results are achieved in one\nepoch of test-time optimization without altering training.",
      "full_text": "Published as a conference paper at ICLR 2021 TENT : F ULLY TEST-TIME ADAPTATION BY ENTROPY MINIMIZATION Dequan Wang1âˆ—, Evan Shelhamer2âˆ—â€ , Shaoteng Liu1, Bruno Olshausen1, Trevor Darrell1 dqwang@cs.berkeley.edu, shelhamer@google.com UC Berkeley1 Adobe Research2 ABSTRACT A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent 1): we optimize the model for conï¬dence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise afï¬ne transformations to update online on each batch. Tent reduces generalization error for image classiï¬cation on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adapta- tion on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training. 1 I NTRODUCTION Deep networks can achieve high accuracy on training and testing data from the same distribution, as evidenced by tremendous benchmark progress (Krizhevsky et al., 2012; Simonyan & Zisserman, 2015; He et al., 2016). However, generalization to new and different data is limited (Hendrycks & Dietterich, 2019; Recht et al., 2019; Geirhos et al., 2018). Accuracy suffers when the training (source) data differ from the testing (target) data, a condition known as dataset shift(Quionero-Candela et al., 2009). Models can be sensitive to shifts during testing that were not known during training, whether natural variations or corruptions, such as unexpected weather or sensor degradation. Nevertheless, it can be necessary to deploy a model on different data distributions, so adaptation is needed. During testing, the model must adapt given only its parameters and the target data. Thisfully test-time adaptation setting cannot rely on source data or supervision. Neither is practical when the model ï¬rst encounters new testing data, before it can be collected and annotated, as inference must go on. Real-world usage motivates fully test-time adaptation by data, computation, and task needs: 1. Availability. A model might be distributed without source data for bandwidth, privacy, or proï¬t. 2. Efï¬ciency. It might not be computationally practical to (re-)process source data during testing. 3. Accuracy. A model might be too inaccurate without adaptation to serve its purpose. To adapt during testing we minimize the entropy of model predictions. We call this objective the test entropy and name our method tent after it. We choose entropy for its connections to error and shift. Entropy is related to error, as more conï¬dent predictions are all-in-all more correct (Figure 1). Entropy is related to shifts due to corruption, as more corruption results in more entropy, with a strong rank correlation to the loss for image classiï¬cation as the level of corruption increases (Figure 2). To minimize entropy, tent normalizes and transforms inference on target data by estimating statistics and optimizing afï¬ne parameters batch-by-batch. This choice of low-dimensional, channel-wise feature modulation is efï¬cient to adapt during testing, even for online updates. Tent does not restrict or alter model training: it is independent of the source data given the model parameters. If the model can be run, it can be adapted. Most importantly, tent effectively reduces not just entropy but error. âˆ—Equal contribution. â€ Work done at Adobe Research; the author is now at DeepMind. 1Please see the project page at https://github.com/DequanWang/tent for the code and more. 1 arXiv:2006.10726v3  [cs.LG]  18 Mar 2021Published as a conference paper at ICLR 2021 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Entropy 0 20 40 60 80Error (%) Figure 1: Predictions with lower entropy have lower error rates on corrupted CIFAR-100-C. Certainty can serve as supervision during testing. 0.2 0.3 0.4 0.5 0.6 Entropy 0.2 0.4 0.6 0.8 1.0 1.2Loss = 0.61 original noise blur digital weather  level level Figure 2: More corruption causes more loss and entropy on CIFAR-100-C. Entropy can estimate the degree of shift without training data or labels. Our results evaluate generalization to corruptions for image classiï¬cation, to domain shift for digit recognition, and to simulation-to-real shift for semantic segmentation. For context with more data and optimization, we evaluate methods for robust training, domain adaptation, and self-supervised learning given the labeled source data. Tent can achieve less error given only the target data, and it improves on the state-of-the-art for the ImageNet-C benchmark. Analysis experiments support our entropy objective, check sensitivity to the amount of data and the choice of parameters for adaptation, and back the generality of tent across architectures. Our contributions â€¢ We highlight the setting of fully test-time adaptation with only target data and no source data. To emphasize practical adaptation during inference we benchmark with ofï¬‚ine and online updates. â€¢ We examine entropy as an adaptation objective and propose tent: a test-time entropy minimization scheme to reduce generalization error by reducing the entropy of model predictions on test data. â€¢ For robustness to corruptions, tent reaches 44.0% error on ImageNet-C, better than the state-of- the-art for robust training (50.2%) and the strong baseline of test-time normalization (49.9%). â€¢ For domain adaptation, tent is capable of online and source-free adaptation for digit classiï¬cation and semantic segmentation, and can even rival methods that use source data and more optimization. 2 S ETTING : F ULLY TEST-TIME ADAPTATION Adaptation addresses generalization from source to target. A model fÎ¸(x) with parameters Î¸trained on source data and labels xs,ys may not generalize when tested on shifted target data xt. Table 1 summarizes adaptation settings, their required data, and types of losses. Our fully test-time adaptation setting uniquely requires only the model fÎ¸ and unlabeled target data xt for adaptation during inference. Existing adaptation settings extend training given more data and supervision. Transfer learning by ï¬ne-tuning (Donahue et al., 2014; Yosinski et al., 2014) needs target labels to (re-)train with a supervised loss L(xt,yt). Without target labels, our setting denies this supervised training. Domain adaptation (DA) (Quionero-Candela et al., 2009; Saenko et al., 2010; Ganin & Lempitsky, 2015; Tzeng et al., 2015) needs both the source and target data to train with a cross-domain loss L(xs,xt). Test-time training (TTT) (Sun et al., 2019b) adapts during testing but ï¬rst alters training to jointly optimize its supervised loss L(xs,ys) and self-supervised loss L(xs). Without source, our setting denies joint training across domains (DA) or losses (TTT). Existing settings have their purposes, but do not cover all practical cases when source, target, or supervision are not simultaneously available. Unexpected target data during testing requires test-time adaptation. TTT and our setting adapt the model by optimizing an unsupervised loss during testing L(xt). During training, TTT jointly optimizes this same loss on source data L(xs) with a supervised loss L(xs,ys), to ensure the parameters Î¸are shared across losses for compatibility with adaptation by L(xt). Fully test-time adaptation is independent of the training data and training loss given the parameters Î¸. By not changing training, our setting has the potential to require less data and computation for adaptation. 2Published as a conference paper at ICLR 2021 Table 1: Adaptation settings differ by their data and therefore losses during training and testing. Of the source s and target t data xand labels y, our fully test-time setting only needs the target data xt. setting source data target data train loss test loss ï¬ne-tuning - xt,yt L(xt,yt) - domain adaptation xs, ys xt L(xs,ys) + L(xs,xt) - test-time training xs, ys xt L(xs,ys) + L(xs) L(xt) fully test-time adaptation - xt - L(xt)     = f (     ; Î¸)  Loss (   ,      ) Î¸ (a) training <latexit sha1_base64=\"YDIW6Mi/jc4gnv843zXedRTilJU=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49mF654lbdGcgy8XJSgRyNXvmr249ZGnGFTFJjOp6boJ9RjYJJPil1U8MTykZ0wDuWKhpx42ezUyfkxCp9EsbalkIyU39PZDQyZhwFtjOiODSL3lT8z+ukGF74mVBJilyx+aIwlQRjMv2b9IXmDOXYEsq0sLcSNqSaMrTplGwI3uLLy6R1VvVqVc+7qVXql3keRTiCYzgFD86hDtfQgCYwGMAzvMKbI50X5935mLcWnHzmEP7A+fwBBSaOGg==</latexit> x s <latexit sha1_base64=\"1psCF/1OyjuZ4TwBu21voNG0XaI=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8eK1hbaWDbbSbt0swm7GyGE/gQvHhTEq3/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dkorq2vrG+XNytb2zu5edf/gQcepYthisYhVJ6AaBZfYMtwI7CQKaRQIbAfj66nffkKleSzvTZagH9Gh5CFn1FjpLnvU/WrNrbszkGXiFaQGBZr96ldvELM0QmmYoFp3PTcxfk6V4UzgpNJLNSaUjekQu5ZKGqH289mpE3JilQEJY2VLGjJTf0/kNNI6iwLbGVEz0oveVPzP66YmvPRzLpPUoGTzRWEqiInJ9G8y4AqZEZkllClubyVsRBVlxqZTsSF4iy8vk/ZZ3Tuve97tea1xVeRRhiM4hlPw4AIacANNaAGDITzDK7w5wnlx3p2PeWvJKWYO4Q+czx8GrY4b</latexit> y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"1psCF/1OyjuZ4TwBu21voNG0XaI=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8eK1hbaWDbbSbt0swm7GyGE/gQvHhTEq3/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dkorq2vrG+XNytb2zu5edf/gQcepYthisYhVJ6AaBZfYMtwI7CQKaRQIbAfj66nffkKleSzvTZagH9Gh5CFn1FjpLnvU/WrNrbszkGXiFaQGBZr96ldvELM0QmmYoFp3PTcxfk6V4UzgpNJLNSaUjekQu5ZKGqH289mpE3JilQEJY2VLGjJTf0/kNNI6iwLbGVEz0oveVPzP66YmvPRzLpPUoGTzRWEqiInJ9G8y4AqZEZkllClubyVsRBVlxqZTsSF4iy8vk/ZZ3Tuve97tea1xVeRRhiM4hlPw4AIacANNaAGDITzDK7w5wnlx3p2PeWvJKWYO4Q+czx8GrY4b</latexit> y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"YDIW6Mi/jc4gnv843zXedRTilJU=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49mF654lbdGcgy8XJSgRyNXvmr249ZGnGFTFJjOp6boJ9RjYJJPil1U8MTykZ0wDuWKhpx42ezUyfkxCp9EsbalkIyU39PZDQyZhwFtjOiODSL3lT8z+ukGF74mVBJilyx+aIwlQRjMv2b9IXmDOXYEsq0sLcSNqSaMrTplGwI3uLLy6R1VvVqVc+7qVXql3keRTiCYzgFD86hDtfQgCYwGMAzvMKbI50X5935mLcWnHzmEP7A+fwBBSaOGg==</latexit> x s (b) fully test-time adaptation Î¸    = f (    ; Î¸+Î”)  Entropy (    ) <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t <latexit sha1_base64=\"m/ZzdjACtPk7VVv8qMUMxHkn5f0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49YK9ccavuDGSZeDmpQI5Gr/zV7ccsjbhCJqkxHc9N0M+oRsEkn5S6qeEJZSM64B1LFY248bPZqRNyYpU+CWNtSyGZqb8nMhoZM44C2xlRHJpFbyr+53VSDC/8TKgkRa7YfFGYSoIxmf5N+kJzhnJsCWVa2FsJG1JNGdp0SjYEb/HlZdI6q3q1qufd1Cr1yzyPIhzBMZyCB+dQh2toQBMYDOAZXuHNkc6L8+58zFsLTj5zCH/gfP4ABquOGw==</latexit> x t <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t <latexit sha1_base64=\"m/ZzdjACtPk7VVv8qMUMxHkn5f0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49YK9ccavuDGSZeDmpQI5Gr/zV7ccsjbhCJqkxHc9N0M+oRsEkn5S6qeEJZSM64B1LFY248bPZqRNyYpU+CWNtSyGZqb8nMhoZM44C2xlRHJpFbyr+53VSDC/8TKgkRa7YfFGYSoIxmf5N+kJzhnJsCWVa2FsJG1JNGdp0SjYEb/HlZdI6q3q1qufd1Cr1yzyPIhzBMZyCB+dQh2toQBMYDOAZXuHNkc6L8+58zFsLTj5zCH/gfP4ABquOGw==</latexit> x t <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t     = f (     ; Î¸)  Loss (   ,      ) Î¸ (a) training <latexit sha1_base64=\"YDIW6Mi/jc4gnv843zXedRTilJU=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49mF654lbdGcgy8XJSgRyNXvmr249ZGnGFTFJjOp6boJ9RjYJJPil1U8MTykZ0wDuWKhpx42ezUyfkxCp9EsbalkIyU39PZDQyZhwFtjOiODSL3lT8z+ukGF74mVBJilyx+aIwlQRjMv2b9IXmDOXYEsq0sLcSNqSaMrTplGwI3uLLy6R1VvVqVc+7qVXql3keRTiCYzgFD86hDtfQgCYwGMAzvMKbI50X5935mLcWnHzmEP7A+fwBBSaOGg==</latexit> x s <latexit sha1_base64=\"1psCF/1OyjuZ4TwBu21voNG0XaI=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8eK1hbaWDbbSbt0swm7GyGE/gQvHhTEq3/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dkorq2vrG+XNytb2zu5edf/gQcepYthisYhVJ6AaBZfYMtwI7CQKaRQIbAfj66nffkKleSzvTZagH9Gh5CFn1FjpLnvU/WrNrbszkGXiFaQGBZr96ldvELM0QmmYoFp3PTcxfk6V4UzgpNJLNSaUjekQu5ZKGqH289mpE3JilQEJY2VLGjJTf0/kNNI6iwLbGVEz0oveVPzP66YmvPRzLpPUoGTzRWEqiInJ9G8y4AqZEZkllClubyVsRBVlxqZTsSF4iy8vk/ZZ3Tuve97tea1xVeRRhiM4hlPw4AIacANNaAGDITzDK7w5wnlx3p2PeWvJKWYO4Q+czx8GrY4b</latexit> y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"1psCF/1OyjuZ4TwBu21voNG0XaI=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8eK1hbaWDbbSbt0swm7GyGE/gQvHhTEq3/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dkorq2vrG+XNytb2zu5edf/gQcepYthisYhVJ6AaBZfYMtwI7CQKaRQIbAfj66nffkKleSzvTZagH9Gh5CFn1FjpLnvU/WrNrbszkGXiFaQGBZr96ldvELM0QmmYoFp3PTcxfk6V4UzgpNJLNSaUjekQu5ZKGqH289mpE3JilQEJY2VLGjJTf0/kNNI6iwLbGVEz0oveVPzP66YmvPRzLpPUoGTzRWEqiInJ9G8y4AqZEZkllClubyVsRBVlxqZTsSF4iy8vk/ZZ3Tuve97tea1xVeRRhiM4hlPw4AIacANNaAGDITzDK7w5wnlx3p2PeWvJKWYO4Q+czx8GrY4b</latexit> y s <latexit sha1_base64=\"XlB1POiMMxMFBsxKqM8k7anLbzY=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8mj61Zpbd2cgy8QrSA0KtPrVr94gZmnEFTJJjel6boJ+TjUKJvmk0ksNTygb0yHvWqpoxI2fzw6ekBOrDEgYa1sKyUz9PZHTyJgsCmxnRHFkFr2p+J/XTTG88HOhkhS5YvNFYSoJxmT6PRkIzRnKzBLKtLC3EjaimjK0GVVsCN7iy8ukc1b3GnXPu2nUmpdFHmU4gmM4BQ/OoQnX0II2MIjgGV7hzdHOi/PufMxbS04xcwh/4Hz+ANhzkOg=</latexit> Ë†y s <latexit sha1_base64=\"YDIW6Mi/jc4gnv843zXedRTilJU=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49mF654lbdGcgy8XJSgRyNXvmr249ZGnGFTFJjOp6boJ9RjYJJPil1U8MTykZ0wDuWKhpx42ezUyfkxCp9EsbalkIyU39PZDQyZhwFtjOiODSL3lT8z+ukGF74mVBJilyx+aIwlQRjMv2b9IXmDOXYEsq0sLcSNqSaMrTplGwI3uLLy6R1VvVqVc+7qVXql3keRTiCYzgFD86hDtfQgCYwGMAzvMKbI50X5935mLcWnHzmEP7A+fwBBSaOGg==</latexit> x s (b) fully test-time adaptation Î¸    = f (    ; Î¸+Î”)  Entropy (    ) <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t <latexit sha1_base64=\"m/ZzdjACtPk7VVv8qMUMxHkn5f0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49YK9ccavuDGSZeDmpQI5Gr/zV7ccsjbhCJqkxHc9N0M+oRsEkn5S6qeEJZSM64B1LFY248bPZqRNyYpU+CWNtSyGZqb8nMhoZM44C2xlRHJpFbyr+53VSDC/8TKgkRa7YfFGYSoIxmf5N+kJzhnJsCWVa2FsJG1JNGdp0SjYEb/HlZdI6q3q1qufd1Cr1yzyPIhzBMZyCB+dQh2toQBMYDOAZXuHNkc6L8+58zFsLTj5zCH/gfP4ABquOGw==</latexit> x t <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t <latexit sha1_base64=\"m/ZzdjACtPk7VVv8qMUMxHkn5f0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrS20sWy2m3bpZhN2J2IJ/QlePCiIV/+QN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzJYhnrdkANl0LxJgqUvJ1oTqNA8lYwupr6rUeujYjVHY4T7kd0oEQoGEUr3T49YK9ccavuDGSZeDmpQI5Gr/zV7ccsjbhCJqkxHc9N0M+oRsEkn5S6qeEJZSM64B1LFY248bPZqRNyYpU+CWNtSyGZqb8nMhoZM44C2xlRHJpFbyr+53VSDC/8TKgkRa7YfFGYSoIxmf5N+kJzhnJsCWVa2FsJG1JNGdp0SjYEb/HlZdI6q3q1qufd1Cr1yzyPIhzBMZyCB+dQh2toQBMYDOAZXuHNkc6L8+58zFsLTj5zCH/gfP4ABquOGw==</latexit> x t <latexit sha1_base64=\"uzCfvi+otYu2ihjbD7PaMp0JG7Y=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48VrFXaWDbbTbt0swm7EyGE/govHhTEq//Gm//GbZuDtj4YeLw3w8y8IJHCoOt+O6WV1bX1jfJmZWt7Z3evun9wZ+JUM95msYz1fUANl0LxNgqU/D7RnEaB5J1gfDX1O09cGxGrW8wS7kd0qEQoGEUrPfRGFPNs8oj9as2tuzOQZeIVpAYFWv3qV28QszTiCpmkxnQ9N0E/pxoFk3xS6aWGJ5SN6ZB3LVU04sbPZwdPyIlVBiSMtS2FZKb+nshpZEwWBbYzojgyi95U/M/rphhe+LlQSYpcsfmiMJUEYzL9ngyE5gxlZgllWthbCRtRTRnajCo2BG/x5WXSOat7jbrn3TRqzcsijzIcwTGcggfn0IRraEEbGETwDK/w5mjnxXl3PuatJaeYOYQ/cD5/ANn4kOk=</latexit> Ë†y t Figure 3: Method overview. Tent does not alter training (a), but minimizes the entropy of predictions during testing (b) over a constrained modulation âˆ†, given the parameters Î¸and target data xt. 3 M ETHOD : T EST ENTROPY MINIMIZATION VIA FEATURE MODULATION We optimize the model during testing to minimize the entropy of its predictions by modulating its features. We call our method tent for test entropy. Tent requires a compatible model, an objective to minimize (Section 3.1), and parameters to optimize over (Section 3.2) to fully deï¬ne the algorithm (Section Section 3.3). Figure 3 outlines our method for fully test-time adaptation. The model to be adapted must be trained for the supervised task, probabilistic, and differentiable. No supervision is provided during testing, so the model must already be trained. Measuring the entropy of predictions requires a distribution over predictions, so the model must be probabilistic. Gradients are required for fast iterative optimization, so the model must be differentiable. Typical deep networks for supervised learning satisfy these model requirements. 3.1 E NTROPY OBJECTIVE Our test-time objective L(xt) is to minimize the entropy H(Ë†y) of model predictions Ë†y= fÎ¸(xt). In particular, we measure the Shannon entropy (Shannon, 1948), H(Ë†y) = âˆ’âˆ‘ cp(Ë†yc) logp(Ë†yc) for the probability Ë†yc of class c. Note that optimizing a single prediction has a trivial solution: assign all probability to the most probable class. We prevent this by jointly optimizing batched predictions over parameters that are shared across the batch. Entropy is an unsupervised objective because it only depends on predictions and not annotations. However, as a measure of the predictions it is directly related to the supervised task and model. In contrast, proxy tasks for self-supervised learning are not directly related to the supervised task. Proxy tasks derive a self-supervised label yâ€²from the input xt without the task label y. Examples of these proxies include rotation prediction (Gidaris et al., 2018), context prediction (Doersch et al., 2015), and cross-channel auto-encoding (Zhang et al., 2017). Too much progress on a proxy task could interfere with performance on the supervised task, and self-supervised adaptation methods have to limit or mix updates accordingly (Sun et al., 2019b;a). As such, care is needed to choose a proxy compatible with the domain and task, to design the architecture for the proxy model, and to balance optimization between the task and proxy objectives. Our entropy objective does not need such efforts. 3.2 M ODULATION PARAMETERS The model parameters Î¸are a natural choice for test-time optimization, and these are the choice of prior work for train-time entropy minimization (Grandvalet & Bengio, 2005; Dhillon et al., 2020; Carlucci et al., 2017). However, Î¸is the only representation of the training/source data in our setting, and altering Î¸could cause the model to diverge from its training. Furthermore, f can be nonlinear and Î¸can be high dimensional, making optimization too sensitive and inefï¬cient for test-time usage. 3Published as a conference paper at ICLR 2021 IN OUT+ <latexit sha1_base64=\"FGMSn1olAms3UkJ+mUM6lRBkJrw=\">AAAB6HicbVDLSgNBEOyNryS+oh69DAZBEMKuKHoMevGYgHlgsoTZSW8yZvbBzKwYlnyBFw+K5OoP+C/e/BqdJB40saChqOqmu8uLBVfatj+tzNLyyupaNpdf39jc2i7s7NZVlEiGNRaJSDY9qlDwEGuaa4HNWCINPIENb3A18Rv3KBWPwhs9jNENaC/kPmdUG6l63CkU7ZI9BVkkzg8plnPx+Pb94avSKXy0uxFLAgw1E1SplmPH2k2p1JwJHOXbicKYsgHtYcvQkAao3HR66IgcGqVL/EiaCjWZqr8nUhooNQw80xlQ3Vfz3kT8z2sl2r9wUx7GicaQzRb5iSA6IpOvSZdLZFoMDaFMcnMrYX0qKdMmm7wJwZl/eZHUT0rOaemsatK4hBmysA8HcAQOnEMZrqECNWCA8AjP8GLdWU/WqzWetWasn5k9+APr7RuTUJCF</latexit> \u0000 <latexit sha1_base64=\"8eHH7cr25vA7s0zJYYCDPQNSaT0=\">AAAB7XicbVDLSgNBEOyNrxhfUY+KDAbBU9gVQb0FvXhMwDwgWcLsZDYZM7OzzMwKYcnRuxcPinj1F/Id3vwGf8LJ46CJBQ1FVTfdXUHMmTau++VklpZXVtey67mNza3tnfzuXk3LRBFaJZJL1QiwppxFtGqY4bQRK4pFwGk96N+M/foDVZrJ6M4MYuoL3I1YyAg2Vqq1ulgI3M4X3KI7AVok3owUSoejyvfj0ajczn+2OpIkgkaGcKx103Nj46dYGUY4HeZaiaYxJn3cpU1LIyyo9tPJtUN0YpUOCqWyFRk0UX9PpFhoPRCB7RTY9PS8Nxb/85qJCS/9lEVxYmhEpovChCMj0fh11GGKEsMHlmCimL0VkR5WmBgbUM6G4M2/vEhqZ0XvvHhVsWlcwxRZOIBjOAUPLqAEt1CGKhC4hyd4gVdHOs/Om/M+bc04s5l9+APn4wd3ypLI</latexit> â‡¥ <latexit sha1_base64=\"r9CoIRh1LwyAxszWUWZZpZEIYvU=\">AAAB7XicbVA9TwJBEJ3DL8Av1NLmIjGxIndGoyXRxhIT+YhwIXvLHqzs7V5254yE8B9sLDDG1tL/Yuev0QUsFHzJJC/vzWRmXpgIbtDzPp3M0vLK6lo2l1/f2NzaLuzs1oxKNWVVqoTSjZAYJrhkVeQoWCPRjMShYPWwfznx6/dMG67kDQ4SFsSkK3nEKUEr1VrIY2bahaJX8qZwF4n/Q4rlXDK+fX/4qrQLH62OomnMJFJBjGn6XoLBkGjkVLBRvpUalhDaJ13WtFQSuyQYTq8duYdW6biR0rYkulP198SQxMYM4tB2xgR7Zt6biP95zRSj82DIZZIik3S2KEqFi8qdvO52uGYUxcASQjW3t7q0RzShaAPK2xD8+ZcXSe245J+UTq9tGhcwQxb24QCOwIczKMMVVKAKFO7gEcbw7CjnyXlxXmetGednZg/+wHn7Btf2kwo=</latexit> \u0000 <latexit sha1_base64=\"icKTvSnYuWAwxCN4MXaVcPxJrUE=\">AAAB7HicbVBNS8NAEN34WetX1aMiwSJ4KokI6q3oxWMLpi20oWy2k3bpZhN2J0IJPXr24kERr/6G/g5v/gb/hNuPg7Y+GHi8N8PMvCARXKPjfFlLyyura+u5jfzm1vbObmFvv6bjVDHwWCxi1QioBsEleMhRQCNRQKNAQD3o3479+gMozWN5j4ME/Ih2JQ85o2gkrxUA0nah6JScCexF4s5IsXw0qn4/Ho8q7cJnqxOzNAKJTFCtm66ToJ9RhZwJGOZbqYaEsj7tQtNQSSPQfjY5dmifGqVjh7EyJdGeqL8nMhppPYgC0xlR7Ol5byz+5zVTDK/8jMskRZBsuihMhY2xPf7c7nAFDMXAEMoUN7farEcVZWjyyZsQ3PmXF0ntvORelK6rJo0bMkWOHJITckZccknK5I5UiEcY4eSJvJBXS1rP1pv1Pm1dsmYzB+QPrI8ftLWSVw==</latexit> \u0000 <latexit sha1_base64=\"6pSYsGji0D9Bm0vY9by0e43+pZo=\">AAAB6HicbVDLSgNBEOyNrxhfUY9eBoPgxbArAfUW9OIxAfOAZAmzk95kzOzsMjMrhJAv8OJBEa9+kjf/xkmyB00saCiquunuChLBtXHdbye3tr6xuZXfLuzs7u0fFA+PmjpOFcMGi0Ws2gHVKLjEhuFGYDtRSKNAYCsY3c381hMqzWP5YMYJ+hEdSB5yRo2V6he9Ysktu3OQVeJlpAQZar3iV7cfszRCaZigWnc8NzH+hCrDmcBpoZtqTCgb0QF2LJU0Qu1P5odOyZlV+iSMlS1pyFz9PTGhkdbjKLCdETVDvezNxP+8TmrCa3/CZZIalGyxKEwFMTGZfU36XCEzYmwJZYrbWwkbUkWZsdkUbAje8surpHlZ9irlm3qlVL3N4sjDCZzCOXhwBVW4hxo0gAHCM7zCm/PovDjvzseiNedkM8fwB87nD3htjL0=</latexit> Ã· <latexit sha1_base64=\"KLNiQjydwC+UjsLtIanox9T+rq8=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoN6KXjxWsB/QhrLZbNqlu5uwuymU0L/gxYMiXv1D3vw3btoctPXBwOO9GWbmBQln2rjut1Pa2Nza3invVvb2Dw6PqscnHR2nitA2iXmsegHWlDNJ24YZTnuJolgEnHaDyX3ud6dUaRbLJzNLqC/wSLKIEWxyaRCy6bBac+vuAmideAWpQYHWsPo1CGOSCioN4Vjrvucmxs+wMoxwOq8MUk0TTCZ4RPuWSiyo9rPFrXN0YZUQRbGyJQ1aqL8nMiy0nonAdgpsxnrVy8X/vH5qohs/YzJJDZVkuShKOTIxyh9HIVOUGD6zBBPF7K2IjLHCxNh4KjYEb/XlddK5qnuN+u1jo9a8K+IowxmcwyV4cA1NeIAWtIHAGJ7hFd4c4bw4787HsrXkFDOn8AfO5w8aWY5N</latexit> Âµ <latexit sha1_base64=\"lbHwl5bkUbenc+Yo+u8yNzpxsy0=\">AAAB6nicbVDLSgNBEOyNrxhfUY+KDAbBU9gVQb0FvXhM0DwgWcLsZDYZMjO7zMwKYcnRoxcPinj1I/Id3vwGf8LJ46CJBQ1FVTfdXUHMmTau++VklpZXVtey67mNza3tnfzuXk1HiSK0SiIeqUaANeVM0qphhtNGrCgWAaf1oH8z9usPVGkWyXsziKkvcFeykBFsrHTXEkk7X3CL7gRokXgzUigdjirfj0ejcjv/2epEJBFUGsKx1k3PjY2fYmUY4XSYayWaxpj0cZc2LZVYUO2nk1OH6MQqHRRGypY0aKL+nkix0HogAtspsOnpeW8s/uc1ExNe+imTcWKoJNNFYcKRidD4b9RhihLDB5Zgopi9FZEeVpgYm07OhuDNv7xIamdF77x4VbFpXMMUWTiAYzgFDy6gBLdQhioQ6MITvMCrw51n5815n7ZmnNnMPvyB8/EDTj2RiQ==</latexit> \u0000 <latexit sha1_base64=\"xnrzB72KzfqBMQ17s1zlsxQWR+k=\">AAAB7XicbZDLSgMxFIbP1Fsdb1WXboJFcFVmRFAXYtGNywr2Au1QMmmmjU0yQ5IRytB3cONCETcufBT3bsS3Mb0stPWHwMf/n0POOWHCmTae9+3kFhaXllfyq+7a+sbmVmF7p6bjVBFaJTGPVSPEmnImadUww2kjURSLkNN62L8a5fV7qjSL5a0ZJDQQuCtZxAg21qq1NOsK3C4UvZI3FpoHfwrFiw/3PHn7civtwmerE5NUUGkIx1o3fS8xQYaVYYTTodtKNU0w6eMubVqUWFAdZONph+jAOh0Uxco+adDY/d2RYaH1QIS2UmDT07PZyPwva6YmOg0yJpPUUEkmH0UpRyZGo9VRhylKDB9YwEQxOysiPawwMfZArj2CP7vyPNSOSv5x6ezGK5YvYaI87ME+HIIPJ1CGa6hAFQjcwQM8wbMTO4/Oi/M6Kc05055d+CPn/Qf/xpJs</latexit> <latexit sha1_base64=\"9MzbukliF0G5U4WyINCTJmMNjA8=\">AAACNnicdVBNS8NAFNz4bf2KevSyWAQFLUlR9CiK4EWoYFuhiWWz3dSlu0nYfVFL6K/y4u/w1osHRbz6E9y0PWjVgYVhZh773gSJ4Bocp29NTE5Nz8zOzRcWFpeWV+zVtZqOU0VZlcYiVtcB0UzwiFWBg2DXiWJEBoLVg85p7tfvmNI8jq6gmzBfknbEQ04JGKlpX3gyxZ5gIRCl4nvsSQK3QZCd9RoPTfB3sad5W5Kb8j+h7Xx+D5vszk3Zb9pFp+QMgH8Td0SKaIRK0372WjFNJYuACqJ1w3US8DOigFPBegUv1SwhtEParGFoRCTTfjY4u4e3jNLCYazMiwAP1O8TGZFad2VgkvnCetzLxb+8RgrhkZ/xKEmBRXT4UZgKDDHOO8QtrhgF0TWEUMXNrpjeEkUomKYLpgR3/OTfpFYuuQcl53K/eHwyqmMObaBNtI1cdIiO0TmqoCqi6BH10St6s56sF+vd+hhGJ6zRzDr6AevzC4nRq7w=</latexit> Âµ  E [ x t ] , \u0000 2  E [( Âµ \u0000 x t ) 2 ] <latexit sha1_base64=\"5uCFLjsyhVlotMr43Rw1BdZFk0s=\">AAACYXicbZFLS+RAFIUrGZ/tK+Ms3RQ2gqC0iSgzy2bcuHTAVqHTNDfVN21hVRKqbmamCf0nZzcbN/4RKzH4vlBw+O659TiVFEpaCsP/nv9lYXFpeWW1s7a+sbkVfN2+snlpBA5ErnJzk4BFJTMckCSFN4VB0InC6+TurO5f/0ZjZZ5d0qzAkYZpJlMpgBwaB3/jKWgNPFaYEhiT/+EtOeBxAYYkqFgD3UqqzudHL6wxHfI4QXo73YBPh59RbRkH3bAXNsU/iqgVXdbWxTj4F09yUWrMSCiwdhiFBY2qekuhcN6JS4sFiDuY4tDJDDTaUdUkNOd7jkx4mhu3MuINfT1RgbZ2phPnrO9r3/dq+FlvWFL6Y1TJrCgJM/F0UFoqTjmv4+YTaVCQmjkBwkh3Vy5uwYAg9ykdF0L0/skfxdVxLzrthb9Ouv2fbRwrbIftsn0Wse+sz87ZBRswwe69BW/D2/Qe/FU/8LefrL7Xznxjb8rfeQSpH7dZ</latexit> \u0000  \u0000 + @ H / @\u0000 , \u0000  \u0000 + @ H / @\u0000 normalization transformation Figure 4: Tent modulates features during testing by estimating normalization statistics Âµ,Ïƒ and optimizing transformation parameters Î³,Î². Normalization and transformation apply channel-wise scales and shifts to the features. The statistics and parameters are updated on target data without use of source data. In practice, adapting Î³,Î² is efï¬cient because they make up <1% of model parameters. For stability and efï¬ciency, we instead only update feature modulations that are linear (scales and shifts), and low-dimensional (channel-wise). Figure 4 shows the two steps of our modulations: normalization by statistics and transformation by parameters. Normalization centers and standardizes the input xinto Â¯x= (xâˆ’Âµ)/Ïƒby its mean Âµand standard deviation Ïƒ. Transformation turns Â¯xinto the output xâ€²= Î³Â¯x+ Î²by afï¬ne parameters for scale Î³and shift Î². Note that the statistics Âµ,Ïƒ are estimated from the data while the parameters Î³,Î² are optimized by the loss. For implementation, we simply repurpose the normalization layers of the source model. We update their normalization statistics and afï¬ne parameters for all layers and channels during testing. 3.3 A LGORITHM Initialization The optimizer collects the afï¬ne transformation parameters {Î³l,k,Î²l,k}for each normalization layer land channel kin the source model. The remaining parameters Î¸\\{Î³l,k,Î²l,k} are ï¬xed. The normalization statistics {Âµl,k,Ïƒl,k}from the source data are discarded. Iteration Each step updates the normalization statistics and transformation parameters on a batch of data. The normalization statistics are estimated for each layer in turn, during the forward pass. The transformation parameters Î³,Î² are updated by the gradient of the prediction entropy âˆ‡H(Ë†y), during the backward pass. Note that the transformation update follows the prediction for the current batch, and so it only affects the next batch (unless forward is repeated). This needs just one gradient per point of additional computation, so we use this scheme by default for efï¬ciency. Termination For online adaptation, no termination is necessary, and iteration continues as long as there is test data. For ofï¬‚ine adaptation, the model is ï¬rst updated and then inference is repeated. Adaptation may of course continue by updating for multiple epochs. 4 E XPERIMENTS We evaluate tent for corruption robustness on CIFAR-10/CIFAR-100 and ImageNet, and for domain adaptation on digit adaptation from SVHN to MNIST/MNIST-M/USPS. Our implementation is in PyTorch (Paszke et al., 2019) with the pycls library (Radosavovic et al., 2019). Datasets We run on image classiï¬cation datasets for corruption and domain adaptation conditions. For large-scale experiments we choose ImageNet (Russakovsky et al., 2015), with 1,000 classes, a training set of 1.2 million, and a validation set of 50,000. For experiments at an accessible scale we choose CIFAR-10/CIFAR-100 (Krizhevsky, 2009), with 10/100 classes, a training set of 50,000, and a test set of 10,000. For domain adaptation we choose SVHN (Netzer et al., 2011) as source and MNIST (LeCun et al., 1998)/MNIST-M (Ganin & Lempitsky, 2015)/USPS (Hull, 1994) as targets, with ten classes for the digits 0â€“9. SVHN has color images of house numbers from street views with a training set of 73,257 and test set of 26,032. MNIST/MNIST-M/USPS have handwritten digits with a training sets of 60,000/60,000/7,291 and test sets of 10,000/10,000/2,007. Models For corruption we use residual networks (He et al., 2016) with 26 layers (R-26) on CIFAR- 10/100 and 50 layers (R-50) on ImageNet. For domain adaptation we use the R-26 architecture. For fair comparison, all methods in each experimental condition share the same architecture. Our networks are equipped with batch normalization (Ioffe & Szegedy, 2015). For the source model without adaptation, the normalization statistics are estimated during training on the source data. For all test-time adaptation methods, we estimate these statistics during testing on the target data, as done in concurrent work on adaptation by normalization (Schneider et al., 2020; Nado et al., 2020). 4Published as a conference paper at ICLR 2021 Table 2: Corruption benchmark on CIFAR-10-C and CIFAR-100-C for the highest severity. Tent has least error, with less optimization than domain adaptation (RG, UDA-SS) and test-time training (TTT), and improves on test-time norm (BN). Method Source Target Error (%) C10-C C100-C Source train 40.8 67.2 RG train train 18.3 38.9 UDA-SS train train 16.7 47.0 TTT train test 17.5 45.0 BN test 17.3 42.6 PL test 15.7 41.2 Tent (ours) test 14.3 37.3 originalgaussshot impulsedefocus glassmotionzoomsnowfrostfog bright contrastelasticpixeljpeg 0 25 50 75Error (%) source 59.5% norm 49.9% tent 44.0% ANT 50.2% Figure 5: Corruption benchmark on ImageNet-C: error for each type averaged over severity levels. Tent improves on the prior state-of-the-art, adver- sarial noise training (Rusak et al., 2020), by fully test-time adaptation without altering training. Optimization We optimize the modulation parameters Î³,Î² following the training hyperparameters for the source model with few changes. On ImageNet we optimize by SGD with momentum; on other datasets we optimize by Adam (Kingma & Ba, 2015). We lower the batch size (BS) to reduce memory usage for inference, then lower the learning rate (LR) by the same factor to compensate (Goyal et al., 2017). On ImageNet, we set BS = 64 and LR = 0.00025, and on other datasets we set BS = 128 and LR = 0.001.We control for ordering by shufï¬‚ing and sharing the order across methods. Baselines We compare to domain adaptation, self-supervision, normalization, and pseudo-labeling: â€¢ source applies the trained classiï¬er to the test data without adaptation, â€¢ adversarial domain adaptation (RG) reverses the gradients of a domain classiï¬er on source and target to optimize for a domain-invariant representation (Ganin & Lempitsky, 2015), â€¢ self-supervised domain adaptation (UDA-SS) jointly trains self-supervised rotation and position tasks on source and target to optimize for a shared representation (Sun et al., 2019a), â€¢ test-time training (TTT) jointly trains for supervised and self-supervised tasks on source, then keeps training the self-supervised task on target during testing (Sun et al., 2019b), â€¢ test-time normalization (BN) updates batch normalization statistics (Ioffe & Szegedy, 2015) on the target data during testing (Schneider et al., 2020; Nado et al., 2020), â€¢ pseudo-labeling (PL) tunes a conï¬dence threshold, assigns predictions over the threshold as labels, and then optimizes the model to these pseudo-labels before testing (Lee, 2013). Only test-time normalization (BN), pseudo-labeling (PL), and tent (ours) are fully test-time adaptation methods. See Section 2 for an explanation and contrast with domain adaptation and test-time training. 4.1 R OBUSTNESS TO CORRUPTIONS To benchmark robustness to corruption, we make use of common image corruptions (see Appendix A for examples). The CIFAR-10/100 and ImageNet datasets are turned into the CIFAR-10/100-C and ImageNet-C corruption benchmarks by duplicating their test/validation sets and applying 15 types of corruptions at ï¬ve severity levels (Hendrycks & Dietterich, 2019). Tent improves more with less data and computation.Table 2 reports errors averaged over corrup- tion types at the severest level of corruption. On CIFAR-10/100-C we compare all methods, including those that require joint training across domains or losses, given the convenient sizes of these datasets. Adaptation is ofï¬‚ine for fair comparison with ofï¬‚ine baselines. Tent improves on the fully test-time adaptation baselines (BN, PL) but also the domain adaptation (RG, UDA-SS) and test-time training (TTT) methods that need several epochs of optimization on source and target. Tent consistently improves across corruption types.Figure 5 plots the error for each corruption type averaged over corruption levels on ImageNet-C. We compare the most efï¬cient methodsâ€”source, normalization, and tentâ€”given the large scale of the source data (>1 million images) needed by other methods and the 75 target combinations of corruption types and levels. Tent and BN adapt online to rival the efï¬ciency of inference without adaptation. Tent reaches the least error for most corruption types without increasing the error on the original data. 5Published as a conference paper at ICLR 2021 Table 3: Digit domain adaptation from SVHN to MNIST/MNIST-M/USPS. Source-free adaptation is not only feasible, but more efï¬cient. Tent always improves on normalization (BN), and in 2/3 cases achieves less error than domain adaptation (RG, UDA-SS) without joint training on source & target. Method Source Target Epochs Error (%) Source + Target MNIST MNIST-M USPS Source train - 18.2 39.7 19.3 RG train train 10 + 10 15.0 33.4 18.9 UDA-SS train train 10 + 10 11.1 22.2 18.4 BN test 0 + 1 15.7 39.7 18.0 Tent (ours) test 0 + 1 10.0 37.0 16.3 Tent (ours) test 0 + 10 8.2 36.8 14.4 Tent reaches a new state-of-the-art without altering training.The state-of-the-art methods for robustness extend training with adversarial noise (ANT) (Rusak et al., 2020) for 50.2% error or mixtures of data augmentations (AugMix) (Hendrycks et al., 2020) for 51.7% error. Combined with stylization from external images (SIN) (Geirhos et al., 2019), ANT+SIN reaches 47.4%. Tent reaches a new state-of-the-art of 44.0% by online adaptation and 42.3% by ofï¬‚ine adaptation. It improves on ANT for all types except noise, on which ANT is trained. This requires just one gradient per test point, without more optimization on the training set (ANT, AugMix) or use of external images (SIN). Among fully test-time adaptation methods, tent reduces the error beyond test-time normalization for 18% relative improvement. In concurrent work, Schneider et al. (2020) report 49.3% error for test-time normalization, for which tent still gives 14% relative improvement. 4.2 S OURCE -FREE DOMAIN ADAPTATION We benchmark digit adaptation (Ganin & Lempitsky, 2015; Tzeng et al., 2015; 2017; Shu et al., 2018) for shifts from SVHN to MNIST/MNIST-M/USPS. Recall that unsupervised domain adaptation makes use the labeled source data and unlabeled target data, while our fully test-time adaptation setting denies use of source data. Adaptation is ofï¬‚ine for fair comparison with ofï¬‚ine baselines. Tent adapts to target without source.Table 3 reports the target errors for domain adaptation and fully test-time adaptation methods. Test-time normalization (BN) marginally improves, while adversarial domain adaptation (RG) and self-supervised domain adaptation (UDA-SS) improve more by joint training on source and target. Tent always has lower error than the source model and BN, and it achieves the lowest error in 2/3 cases, even in just one epoch and without use of source data. While encouraging for fully test-time adaptation, unsupervised domain adaptation remains necessary for the highest accuracy and harder shifts. For SVHN-to-MNIST, DIRT-T (Shu et al., 2018) achieves a remarkable 0.6% error 2. For MNIST-to-SVHN, a difï¬cult shift with source-only error of 71.3%, DIRT-T reaches45.5% and UDA-SS reaches 38.7%. Tent fails on this shift and increases error to 79.8%. In this case success presently requires joint optimization over source and target. Tent needs less computation, but still improves with more.Tent adapts efï¬ciently on target data alone with just one gradient per point. RG & UDA-SS also use the source data (SVHN train), which is âˆ¼7Ã—the size of the target data (MNIST test), and optimize for 10 epochs. Tent adapts with âˆ¼80Ã— less computation. With more updates, tent reaches 8.2% error in 10 epochs and 6.5% in 100 epochs. With online updates, tent reaches 12.5% error in one epoch and 8.4% error in 10 epochs. Tent scales to semantic segmentation.To show scalability to large models and inputs, we evaluate semantic segmentation (pixel-wise classiï¬cation) on a domain shift from a simulated source to a real target. The source is GTA (Richter et al., 2017), a video game in an urban environment, and the target is Cityscapes (Cordts et al., 2016), an urban autonomous driving dataset. The model is HRNet-W18, a fully convolutional network (Shelhamer et al., 2017) with high-resolution architecture (Wang et al., 2020). The target intersection-over-union scores (higher is better) are source 28.8%, BN 31.4%, and tent 35.8% with ofï¬‚ine optimization by Adam. For adaptation to a single image, tent reaches 36.4% in 10 iterations with episodic optimization. See the appendix for a qualitative example (Appendix B). 2We exclude DIRT-T from our experiments because of incomparable differences in architecture and model selection. DIRT-T tunes with labeled target data, but we do not. Please refer to Shu et al. (2018) for more detail. 6Published as a conference paper at ICLR 2021 Figure 6: Tent reduces the entropy and loss. We plot changes in entropyâˆ†Hand loss âˆ†Lfor all of CIFAR-100-C. Change in entropy rank-correlates with change in loss: note the dark diagonal and the rank correlation coefï¬cient of 0.22. (a) Source (b) BN  (c) Tent (d) Oracle  Figure 7: Adapted features on CIFAR-100-C with Gaussian noise (front) and reference features without corruption (back). Corruption shifts fea- tures away from the reference, but BN reduces the shifts. Tent instead shifts features more, and closer to an oracle that optimizes on target labels. Tent scales to the VisDA-C challenge.To show adaptation on a more difï¬cult benchmark, we evaluate on the VisDA-C challenge (Peng et al., 2017). The task is object recognition for 12 classes where the source data is synthesized by rendering 3D models and the target data is collected from real scenes. The validation error for our source model (ResNet-50, pretrained on ImageNet) is 56.1%, while tent reaches 45.6%, and improves to 39.6% by updating all layers except for the ï¬nal classiï¬er as done by Liang et al. (2020). Although ofï¬‚ine source-free adaptation by model adaptation (Li et al., 2020) or SHOT (Liang et al., 2020) can reach lower error with more computation and tuning, tent can adapt online during testing. 4.3 A NALYSIS Tent reduces entropy and error.Figure 6 veriï¬es tent does indeed reduce the entropy and the task loss (softmax cross-entropy). We plot changes in entropy and loss on CIFAR-100-C for all 75 corruption type/level combinations. Both axes are normalized by the maximum entropy of a prediction (log 100) and clipped to Â±1. Most points have lower entropy and error after adaptation. Tent needs feature modulation.We ablate the normalization and transformation steps of feature modulation. Not updating normalization increases errors, and can fail to improve over BN and PL. Not updating transformation parameters reduces the method to test-time normalization. Updating only the last layer of the model can improve but then degrades with further optimization. Updating the full model parameters Î¸never improves over the unadapted source model. Tent generalizes across target data.Adaptation could be limited to the points used for updates. We check that adaptation generalizes across points by adapting on target train and not target test. Test errors drop: CIFAR-100-C error goes from 37.3% to 34.2% and SVHN-to-MNIST error goes from 8.2% to 6.5%. (Train is larger than test; when subsampling to the same size errors differ by <0.1%.) Therefore the adapted modulation is not point speciï¬c but general. Tent modulation differs from normalization.Modulation normalizes and transforms features. We examine the combined effect. Figure 7 contrasts adapted features on corrupted data against reference features on uncorrupted data. We plot features from the source model, normalization, tent, and an oracle that optimizes on the target labels. Normalization makes features more like the reference, but tent does not. Instead, tent makes features more like the oracle. This suggests a different and task-speciï¬c effect. See the appendix for visualizations of more layers (Appendix C). 7Published as a conference paper at ICLR 2021 Tent adapts alternative architectures.Tent is architecture agnostic in principle. To gauge its generality in practice, we evaluate new architectures based on self-attention (SAN) (Zhao et al., 2020) and equilibrium solving (MDEQ) (Bai et al., 2020) for corruption robustness on CIFAR-100-C. Table 4 shows that tent reduces error with the same settings as convolutional residual networks. Table 4: Tent adapts alternative architectures on CIFAR-100-C without tuning. Results are error (%). SAN-10 (pair) SAN-10 (patch) MDEQ (large) Source BN Tent Source BN Tent Source BN Tent 55.3 39.7 36.7 48.0 31.8 29.2 53.3 44.9 41.7 5 R ELATED WORK We relate tent to existing adaptation, entropy minimization, and feature modulation methods. Train-Time AdaptationDomain adaptation jointly optimizes on source and target by cross-domain losses L(xs,xt) to mitigate shift. These losses optimize feature alignment (Gretton et al., 2009; Sun et al., 2017), adversarial invariance (Ganin & Lempitsky, 2015; Tzeng et al., 2017), or shared proxy tasks (Sun et al., 2019a). Transduction (Gammerman et al., 1998; Joachims, 1999; Zhou et al., 2004) jointly optimizes on train and test to better ï¬t speciï¬c test instances. While effective in their settings, neither applies when joint use of source/train and target/test is denied. Tent adapts on target alone. Recent â€œsource-freeâ€ methods (Li et al., 2020; Kundu et al., 2020; Liang et al., 2020) also adapt without source data. Li et al. (2020); Kundu et al. (2020) rely on generative modeling and optimize multiple models with multiple losses. Kundu et al. (2020); Liang et al. (2020) also alter training. Tent does not need generative modeling, nor does it alter training, and so it can deployed more generally to adapt online with much more computational efï¬ciency. SHOT (Liang et al., 2020) adapts by informa- tion maximization (entropy minimization and diversity regularization), but differs in its other losses and its parameterization. These source-free methods optimize ofï¬‚ine with multiple losses for multiple epochs, which requires more tuning and computation than tent, but may achieve more accuracy with more computation. Tent optimizes online with just one loss and an efï¬cient parameterization of modulation to emphasize fully test-time adaptation during inference. We encourage examination of each of these works on the frontier of adaptation without source data. Chidlovskii et al. (2016) are the ï¬rst to motivate adaptation without source data for legal, commercial, or technical concerns. They adapt predictions by applying denoising auto-encoders while we adapt models by entropy minimization. We share their motivations, but the methods and experiments differ. Test-Time AdaptationTent adapts by test-time optimization and normalization to update the model. Test-time adaptation of predictions, through which harder and uncertain cases are adjusted based on easier and certain cases (Jain & Learned-Miller, 2011), provides inspiration for certainty-based model adaptation schemes like our own. Test-time training (TTT) (Sun et al., 2019b) also optimizes during testing, but differs in its loss and must alter training. TTT relies on a proxy task, such as recognizing rotations of an image, and so its loss depends on the choice of proxy. (Indeed, its authors caution that the proxy must be â€œboth well-deï¬ned and non-trivial in the new domainâ€). TTT alters training to optimize this proxy loss on source before adapting to target. Tent adapts without proxy tasks and without altering training. Normalizing feature statistics is common for domain adaptation (Gretton et al., 2009; Sun et al., 2017). For batch normalization Li et al. (2017); Carlucci et al. (2017) separate source and target statistics during training. Schneider et al. (2020); Nado et al. (2020) estimate target statistics during testing to improve generalization. Tent builds on test-time normalization to further reduce generalization error. Entropy MinimizationEntropy minimization is a key regularizer for domain adaptation (Carlucci et al., 2017; Shu et al., 2018; Saito et al., 2019; Roy et al., 2019), semi-supervised learning (Grandvalet & Bengio, 2005; Lee, 2013; Berthelot et al., 2019), and few-shot learning (Dhillon et al., 2020). Regularizing entropy penalizes decisions at high densities in the data distribution to improve accuracy for distinct classes (Grandvalet & Bengio, 2005). These methods regularize entropy during training in concert with other supervised and unsupervised losses on additional data. Tent is the ï¬rst to minimize 8Published as a conference paper at ICLR 2021 entropy during testing, for adaptation to dataset shifts, without other losses or data. Entropic losses are common; our contribution is to exhibit entropy as the sole lossfor fully test-time adaptation. Feature ModulationModulation makes a model vary with its input. We optimize modulations that are simpler than the full model for stable and efï¬cient adaptation. We modulate channel-wise afï¬ne transformations, for their effectiveness in tandem with normalization (Ioffe & Szegedy, 2015; Wu & He, 2018), and for their ï¬‚exibility in conditioning for different tasks (Perez et al., 2018). These normalization and conditioning methods optimize the modulation during training by a supervised loss, but keep it ï¬xed during testing. We optimize the modulation during testing by an unsupervised loss, so that it can adapt to different target data. 6 D ISCUSSION Tent reduces generalization error on shifted data by test-time entropy minimization. In minimizing entropy, the model adapts itself to feedback from its own predictions. This is truly self-supervised self-improvement. Self-supervision of this sort is totally deï¬ned by the supervised task, unlike proxy tasks designed to extract more supervision from the data, and yet it remarkably still reduces error. Nevertheless, errors due to corruption and other shifts remain, and therefore more adaptation is needed. Next steps should pursue test-time adaptation on more and harder types of shift, over more general parameters, and by more effective and efï¬cient losses. Shifts Tent reduces error for a variety of shifts including image corruptions, simple changes in appearance for digits, and simulation-to-real discrepancies. These shifts are popular as standardized benchmarks, but other real-world shifts exist. For instance, the CIFAR 10.1 and ImageNetV2 test sets (Recht et al., 2018; 2019), made by reproducing the dataset collection procedures, entail natural but unknown shifts. Although error is higher on both sets, indicating the presence of shift, tent does not improve generalization. Adversarial shifts (Szegedy et al., 2014) also threaten real-world usage, and attackers keep adapting to defenses. While adversarial training (Madry et al., 2018) makes a difference, test-time adaptation could help counter such test-time attacks. Parameters Tent modulates the model by normalization and transformation, but much of the model stays ï¬xed. Test-time adaptation could update more of the model, but the issue is to identify parameters that are both expressive and reliable, and this may interact with the choice of loss. TTT adapts multiple layers of features shared by supervised and self-supervised models and SHOT adapts all but the last layer(s) of the model. These choices depend on the model architecture, the loss, and tuning. For tent modulation is reliable, but the larger shift on VisDA is better addressed by the SHOT parameterization. Jointly adapting the input could be a more general alternative. If a model can adapt itself on target, then perhaps its input gradients might optimize spatial transformations or image translations to reduce shift without source data. Losses Tent minimizes entropy. For more adaptation, is there an effective loss for general but episodic test-time optimization? Entropy is general across tasks but limited in scope. It needs batches for optimization, and cannot update episodically on one point at a time. TTT can do so, but only with the right proxy task. For less computation, is there an efï¬cient loss for more local optimization? Tent and TTT both require full (re-)computation of the model for updates because they depend on its predictions. If the loss were instead deï¬ned on the representation, then updates would require less forward and backward computation. Returning to entropy speciï¬cally, this loss may interact with calibration (Guo et al., 2017), as better uncertainty estimation could drive better adaptation. We hope that the fully test-time adaptation setting can promote new methods for equipping a model to adapt itself, just as tent yields a new model with every update. ACKNOWLEDGMENTS We thank Eric Tzeng for discussions on domain adaptation, Bill Freeman for comments on the experiments, Yu Sun for consultations on test-time training, and Kelsey Allen for feedback on the exposition. We thank the anonymous reviewers of ICLR 2021 for their feedback, which certainly improved the latest adaptation of the paper. 9Published as a conference paper at ICLR 2021 REFERENCES Shaojie Bai, Vladlen Koltun, and J Zico Kolter. Multiscale deep equilibrium models. arXiv preprint arXiv:2006.08656, 2020. David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. Mixmatch: A holistic approach to semi-supervised learning. In NeurIPS, 2019. Fabio Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel Rota Bulo. Autodial: Automatic domain alignment layers. In 2017 IEEE International Conference on Computer Vision (ICCV), pp. 5077â€“5085. IEEE, 2017. Boris Chidlovskii, Stephane Clinchant, and Gabriela Csurka. Domain adaptation in the absence of source domain data. In SIGKDD, pp. 451â€“460, 2016. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In CVPR, 2016. Guneet Singh Dhillon, Pratik Chaudhari, Avinash Ravichandran, and Stefano Soatto. A baseline for few-shot image classiï¬cation. In ICLR, 2020. Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsupervised visual representation learning by context prediction. In ICCV, 2015. J. Donahue, Y . Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014. A Gammerman, V V ovk, and V Vapnik. Learning by transduction. InUAI, 1998. Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML, 2015. Robert Geirhos, Carlos RM Temme, Jonas Rauber, Heiko H SchÃ¼tt, Matthias Bethge, and Felix A Wichmann. Generalisation in humans and deep neural networks. In NeurIPS, 2018. Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, and Wieland Brendel. Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. In International Conference on Learning Representations, 2019. Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation learning by predicting image rotations. In ICLR, 2018. Priya Goyal, Piotr DollÃ¡r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, 2005. A. Gretton, AJ. Smola, J. Huang, M. Schmittfull, KM. Borgwardt, and B. SchÃ¶lkopf. Covariate shift and local learning by distribution matching. In Dataset Shift in Machine Learning, pp. 131â€“160. MIT Press, Cambridge, MA, USA, 2009. Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In ICML, 2017. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, June 2016. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In ICLR, 2019. Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness and uncertainty. In ICLR, 2020. Jonathan J. Hull. A database for handwritten text recognition research. TPAMI, 1994. Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 10Published as a conference paper at ICLR 2021 Vidit Jain and Erik Learned-Miller. Online domain adaptation of a pre-trained cascade of classiï¬ers. In CVPR, 2011. Thorsten Joachims. Transductive inference for text classiï¬cation using support vector machines. In ICML, 1999. Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiï¬cation with deep convolutional neural networks. NeurIPS, 25, 2012. Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009. Jogendra Nath Kundu, Naveen Venkat, R Venkatesh Babu, et al. Universal source-free domain adaptation. In CVPR, pp. 4544â€“4553, 2020. Y . LeCun, L. Bottou, Y . Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278â€“2324, 1998. Dong-Hyun Lee. Pseudo-label: The simple and efï¬cient semi-supervised learning method for deep neural networks. In ICML Workshop on challenges in representation learning, 2013. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In CVPR, June 2020. Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical domain adaptation. In ICLRW, 2017. Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In ICML, 2020. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learning Representations, 2018. Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. NeurIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, 2019. Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. VisDA: The visual domain adaptation challenge. arXiv preprint arXiv:1710.06924, 2017. Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In AAAI, 2018. Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in machine learning. MIT Press, Cambridge, MA, USA, 2009. Ilija Radosavovic, Justin Johnson, Saining Xie, Wan-Yen Lo, and Piotr DollÃ¡r. On network design spaces for visual recognition. In ICCV, 2019. Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do cifar-10 classiï¬ers generalize to cifar-10? arXiv preprint arXiv:1806.00451, 2018. Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do ImageNet classiï¬ers generalize to ImageNet? In ICML, 2019. Stephan R Richter, Zeeshan Hayder, and Vladlen Koltun. Playing for benchmarks. In ICCV, 2017. Subhankar Roy, Aliaksandr Siarohin, Enver Sangineto, Samuel Rota Bulo, Nicu Sebe, and Elisa Ricci. Unsuper- vised domain adaptation using feature-whitening and consensus loss. In CVPR, 2019. 11Published as a conference paper at ICLR 2021 Evgenia Rusak, Lukas Schott, Roland S Zimmermann, Julian Bitterwolf, Oliver Bringmann, Matthias Bethge, and Wieland Brendel. A simple way to make neural networks robust against diverse image corruptions. In ECCV, 2020. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. ImageNet large scale visual recognition challenge. IJCV, 2015. Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new domains. In European conference on computer vision, pp. 213â€“226. Springer, 2010. Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Trevor Darrell, and Kate Saenko. Semi-supervised domain adaptation via minimax entropy. In ICCV, 2019. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improv- ing robustness against common corruptions by covariate shift adaptation. arXiv preprint arXiv:2006.16971, 2020. C.E. Shannon. A mathematical theory of communication. Bell system technical journal, 27, 1948. Evan Shelhamer, Jonathan Long, and Trevor Darrell. Fully convolutional networks for semantic segmentation. PAMI, 2017. Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised domain adaptation. In ICLR, 2018. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015. Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment for unsupervised domain adaptation. In Domain Adaptation in Computer Vision Applications, pp. 153â€“171. Springer, 2017. Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A Efros. Unsupervised domain adaptation through self- supervision. arXiv preprint arXiv:1909.11825, 2019a. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A Efros, and Moritz Hardt. Test-time training for out-of-distribution generalization. arXiv preprint arXiv:1909.13231, 2019b. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. 2014. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In ICCV, 2015. Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In CVPR, 2017. Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution representation learning for visual recognition. PAMI, 2020. Yuxin Wu and Kaiming He. Group normalization. In ECCV, 2018. Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in deep neural networks? In NeurIPS, 2014. Richard Zhang, Phillip Isola, and Alexei A Efros. Split-brain autoencoders: Unsupervised learning by cross- channel prediction. In CVPR, 2017. Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun. Exploring self-attention for image recognition. In CVPR, 2020. Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, and Bernhard SchÃ¶lkopf. Learning with local and global consistency. NeurIPS, 2004. 12Published as a conference paper at ICLR 2021 APPENDIX This supplement summarizes the image corruptions used in our experiments, highlights a qualitative example of instance-wise adaptation for semantic segmentation, and visualizes feature shifts across more layers. A R OBUSTNESS TO CORRUPTIONS In Section 4.1 we evaluate methods on a common image corruptions benchmark. Table 2 reports errors on the most severe level of corruption, level 5, and Figure 5 reports errors for each corruption type averaged across each of the levels 1â€“5. We summarize these corruptions types by example in Figure 8. Gaussian Noise  Shot Noise  Impulse Noise  Defocus Blur  Frosted Glass Blur Motion Blur  Zoom Blur  Snow  Frost  Fog Brightness  Contrast  Elastic  Pixelate  JPEG Figure 8: Examples of each corruption type in the image corruptions benchmark. While synthetic, this set of corruptions aims to represent natural factors of variation like noise, blur, weather, and digital imaging effects. This ï¬gure is reproduced from Hendrycks & Dietterich (2019). B S OURCE -FREE ADAPTATION FOR SEMANTIC SEGMENTATION Figure 9 shows a qualitative result on source-free adaptation for semantic segmentation (pixel-wise classiï¬cation) with simulation-to-real (sim-to-real) shift. For this sim-to-real condition, the source data is simulated while the target data is real. Our source data is GTA Richter et al. (2017), a visually-sophisticated video game set in an urban environment, and our target data is Cityscapes Cordts et al. (2016), an urban autonomous driving dataset. The supervised model is HRnet-W18, a fully convolutional network Shelhamer et al. (2017) in the high-resolution network family Wang et al. (2020). For this qualitative example, we run tent on a single image for multiple iterations, because an image is in effect a batch of pixels. This demonstrates adaptation to a target instance, without any further access to the target domain through usage of multiple images from the target distribution. 13Published as a conference paper at ICLR 2021 image label source-only tent, iteration 1 tent, iteration 5 tent, iteration 10 Figure 9: Adaptation for semantic segmentation with simulation-to-real shift from GTA Richter et al. (2017) to Cityscapes Cordts et al. (2016). Tent only uses the target data, and optimizes over a single image as a dataset of pixel-wise predictions. This episodic optimization in effect ï¬ts a custom model to each image of the target domain. In only 10 iterations our method suppresses noise (see the completion of the street segment, in purple) and recovers missing classes (see the motorcycle and rider, center). 14Published as a conference paper at ICLR 2021 C F EATURE SHIFTS ACROSS LAYERS AND METHODS (a) Source (b) BN (c) Tent (d) Oracle Layer 2 Layer 5 Layer 8 Layer 11 Layer 14 Layer 18 Layer 20 Layer 23 Layer 26 Figure 10: Adapted features on CIFAR-100-C with Gaussian noise (front) and reference features without corruption (back). Corruption shifts the source features from the reference. BN shifts the features back to be more like the reference. Tent shifts features to be less like the reference, and more like an oracle that optimizes on target labels. 15",
      "meta_data": {
        "arxiv_id": "2006.10726v3",
        "authors": [
          "Dequan Wang",
          "Evan Shelhamer",
          "Shaoteng Liu",
          "Bruno Olshausen",
          "Trevor Darrell"
        ],
        "published_date": "2020-06-18T17:55:28Z",
        "pdf_url": "https://arxiv.org/pdf/2006.10726v3.pdf"
      }
    },
    {
      "title": "What How and When Should Object Detectors Update in Continually Changing Test Domains?",
      "abstract": "It is a well-known fact that the performance of deep learning models\ndeteriorates when they encounter a distribution shift at test time. Test-time\nadaptation (TTA) algorithms have been proposed to adapt the model online while\ninferring test data. However, existing research predominantly focuses on\nclassification tasks through the optimization of batch normalization layers or\nclassification heads, but this approach limits its applicability to various\nmodel architectures like Transformers and makes it challenging to apply to\nother tasks, such as object detection. In this paper, we propose a novel online\nadaption approach for object detection in continually changing test domains,\nconsidering which part of the model to update, how to update it, and when to\nperform the update. By introducing architecture-agnostic and lightweight\nadaptor modules and only updating these while leaving the pre-trained backbone\nunchanged, we can rapidly adapt to new test domains in an efficient way and\nprevent catastrophic forgetting. Furthermore, we present a practical and\nstraightforward class-wise feature aligning method for object detection to\nresolve domain shifts. Additionally, we enhance efficiency by determining when\nthe model is sufficiently adapted or when additional adaptation is needed due\nto changes in the test distribution. Our approach surpasses baselines on widely\nused benchmarks, achieving improvements of up to 4.9\\%p and 7.9\\%p in mAP for\nCOCO $\\rightarrow$ COCO-corrupted and SHIFT, respectively, while maintaining\nabout 20 FPS or higher.",
      "full_text": "What, How, and When Should Object Detectors Update in Continually Changing Test Domains? Jayeon Yoo1 Dongkwan Lee1 Inseop Chung1 Donghyun Kim2âˆ— Nojun Kwak1âˆ— 1Seoul National University 2Korea University 1{jayeon.yoo, biancco, jis3613, nojunk}@snu.ac.kr 2d kim@korea.ac.kr Abstract It is a well-known fact that the performance of deep learning models deteriorates when they encounter a dis- tribution shift at test time. Test-time adaptation (TTA) al- gorithms have been proposed to adapt the model online while inferring test data. However, existing research pre- dominantly focuses on classification tasks through the op- timization of batch normalization layers or classification heads, but this approach limits its applicability to various model architectures like Transformers and makes it chal- lenging to apply to other tasks, such as object detection. In this paper, we propose a novel online adaption approach for object detection in continually changing test domains, considering which part of the model to update, how to up- date it, and when to perform the update. By introducing architecture-agnostic and lightweight adaptor modules and only updating these while leaving the pre-trained backbone unchanged, we can rapidly adapt to new test domains in an efficient way and prevent catastrophic forgetting. Fur- thermore, we present a practical and straightforward class- wise feature aligning method for object detection to resolve domain shifts. Additionally, we enhance efficiency by deter- mining when the model is sufficiently adapted or when ad- ditional adaptation is needed due to changes in the test dis- tribution. Our approach surpasses baselines on widely used benchmarks, achieving improvements of up to 4.9%p and 7.9%p in mAP for COCO â†’ COCO-corrupted and SHIFT, respectively, while maintaining about 20 FPS or higher. 1. Introduction Although deep learning models have demonstrated remark- able success in numerous vision-related tasks, they remain susceptible to domain shifts where the test data distribu- tion differs from that of the training data [3, 25, 40]. In real-world applications, domain shifts frequently occur at test-time due to natural variations, corruptions, changes in weather conditions (e.g., fog, rain) , camera sensor differ- Figure 1. We propose an online adaptation method for object detection in continually changing test domains. Object detectors trained with clean images suffer from performance degradation due to various corruption, such as camera sensor degradation or environmental changes (Direct-Test). Updating full parameters for online adaptation require a large number of test samples and vul- nerable to drastic domain changes (Full-Finetuning), while using only our lightweight adaptor is robust and quickly adapts within a few time steps (Ours). We can further improve efficiency by skip- ping unnecessary adaptation steps (Ours-Skip). ences (e.g., pixelate, defocus blur) , and various other fac- tors. Test-Time Adaptation (TTA) [3, 25, 30, 40, 43, 47] has been proposed to solve the domain shifts in test-time by adapting models to a specific target (test) distribution in an online manner. Furthermore, it is essential to take into account continuously changing test distributions, as the test distribution has the potential to undergo changes and devel- opments as time progresses (i.e., Continual Test-time Adap- tation (CTA)). For instance, autonomous driving systems may experience transitions from clear and sunny conditions to rainy or from daytime to nighttime, which causes contin- ually changing domain shifts [39]. While it is an important research topic, continual test-time adaptation for object de- tection has not been well explored. Recently, several TTA methods [6, 29, 36] tailored for 1 arXiv:2312.08875v1  [cs.CV]  12 Dec 2023object detection have been proposed. ActMAD [29] aligns all the output feature maps ( RCÃ—HÃ—W ) after Batch Nor- malization (BN) layers [14] to adapt the test domain to be similar to that of the training domain. However, this ap- proach requires significant memory during adaptation and does not explicitly consider the objects present in the image. TeST [36] and STFAR [6] adapt to a test domain by utiliz- ing weak and strong augmented test samples with a teacher- student network [37], but they significantly increase infer- ence costs since they require additional forward passes and update steps. Also, these methods update all network pa- rameters, making them highly inefficient in online adapta- tion and vulnerable to losing task-specific knowledge when the test domain experiences continual or drastic changes. In this paper, we aim to develop an efficient continual test-time adaptation (CTA) method for object detection. We investigate the following three key aspects to improve ef- ficiency; what to update: while previous TTA methods for object detection [6, 29, 36] use full fine-tuning, updating all parameters at test time, they are inefficient and prone to losing task-specific knowledge in relatively complex object detection tasks. Updating BN layers, as done in many TTA methods for classification [17, 30, 43, 47], is not as effective for object detection, given its smaller batch size compared to classification and the limitation in applying various back- bones, such as Transformer [26, 41].how to update: several previous TTA methods for object detection [6, 36] adapt the model by using teacher-student networks, resulting in a significant decrease in inference speed, which is detri- mental during test time. While another existing method [29] aligns feature distributions for adaptation, it does not con- sider each object individually, focusing only on image fea- tures, making it less effective for object detection. when to update: most TTA or CTA methods update models using all incoming test samples. However, it is inefficient to update continuously the model if it is already sufficiently adapted when the change of the test domain is not significant. To this end, (1) we propose an efficient continual test- time adaptation method for object detectors to adapt to continually changing test domains through the use of lightweight adaptors which require only 0.54%âˆ¼0.89% ad- ditional parameters compared to the full model. It exhibits efficiency in parameters, memory usage, and adaptation time, along with robustness to continuous domain shifts without catastrophic forgetting. Additionally, it demon- strates wide applicability to various backbone types com- pared to BN-based TTA methods [17, 22, 30, 43, 47, 48]. (2) To enhance the adaptation effectiveness in the object detec- tion task, we align the feature distribution of the test domain with that of the training domain at both the image-level and object-level using only the mean and variance of features. For estimating the mean of the test domain features, we employ Exponentially Moving Average (EMA) as we can leverage only the current incoming test samples, not the en- tire test domain data. Due to the unavailability of training data access, we utilize only the mean and variance of the features from a few training samples. (3) We also introduce two novel criteria that do not require additional resources to determine when the model needs adaptation to enhance efficiency in a continually changing test domain environ- ment. As illustrated in Fig. 1, our approach Ours, employ- ing adaptors, tends to adapt much faster to domain changes compared to full parameter updates. This enables efficient TTA by using only a few test samples to update the adaptor and skipping the rest of the updates as shown in Ours-Skip. Our main contributions are summarized as follows: â€¢ We introduce an architecture-agnostic lightweight adap- tor, constituting only a maximum of 0.89% of the total model parameters, into the backbone of the object de- tector to adapt the model in a continually changing test domain. This approach ensures efficiency in parameters, memory usage, and adaptation speed, demonstrating the robust preservation of task-specific knowledge owing to its inherent structural characteristics. â€¢ We propose a straightforward and effective adaptation loss for CTA in object detection tasks. This is achieved by aligning the distribution of training and test domain fea- tures at both the image and object levels, utilizing only the mean and variance of a few training samples and EMA- updated mean features of the test domain. â€¢ We also propose two criteria to determine when the model requires adaptation, enabling dynamic skipping or resum- ing adaptation as needed. This enhancement significantly boosts inference speed by up to about 2 times while main- taining adaptation performance. â€¢ Our adaptation method proves effective for diverse types of domain shifts, including weather changes and sensor variations, regardless of whether the domain shift is dras- tic or continuous. In particular, our approach consistently improves the mAP by up to 7.9% in COCO â†’COCO-C and SHIFT-Discrete/Continuous with higher than 20 FPS. 2. Related Work Test-time adaptation. Recently, there has been a surge of interest in research that adapts models online using unla- beled test samples while simultaneously inferring the test sample to address the domain shift problem, where the test data distribution differs from that of the training data. There are two lines for online adaptation to the test do- main, Test-time Training (TTT) and Test-time Adaptation (TTA). TTT [1, 2, 25, 40] involves modifying the model architecture during training to train it with self-supervised loss, allowing adaptation to the test domain in the test time by applying this self-supervised loss to the unlabeled test samples. On the other hand, TTA aims to adapt the trained model directly to the test domain without specifically tai- 2lored model architectures or losses during training time. NORM [35] and DUA [28] address the domain shifts by adjusting the statistics of batch normalization (BN) layers using the current test samples, without updating other pa- rameters, inspired by [21]. Following this, [22, 30, 43, 48] and [17] update the affine parameters of BN layers using unsupervised loss, entropy minimization loss to enhance the confidence of test data predictions, and feature distribution alignments loss, respectively. Several studies [15, 16] up- date the classifier head using the pseudo-prototypes from the test domain. However, these methods limit their appli- cability to architectures without BN layers or to object de- tection tasks that involve multiple objects in a single im- age. Others [29, 38, 47] update full parameters for online adaptation to the test domain in an online manner, but this approach is inefficient and susceptible to the noisy signal from the unsupervised loss. While existing TTA methods are oriented towards classification tasks, we aim to propose an effective and efficient method for online adaptation in the object detection task. Continual test-time adaptation. Recent studies [31, 44] point out that existing TTA methods have primarily focused on adapting to test domains following an i.i.d assumption and may not perform well when the test data distribution deviates from this assumption. [44] introduces a Contin- ual TTA (CTA) method designed for scenarios where the test domain continuously changes over time. This poses challenges in preventing the model from over-adapting to a particular domain shift and preserving the knowledge of the pre-trained model to avoid catastrophic forgetting. In the field of CTA, the self-training strategy adopting an Exponentially Moving Average (EMA) teacher-student structure is attracting interest as an effective algorithm en- abling robust representation to be learned through self- knowledge distillation. In many studies, the EMA teacher- student structure and catastrophic restoration of source model weights have been proposed as a solution to achieve the goal of CTA [4, 44, 45]. Approaches using source re- play [32], and anti-forgetting regularization [30] have also achieved good performances in robust continuous adapta- tion. Furthermore, there is growing attention on methods that mitigate the computational and memory challenges as- sociated with CTA, such as [12], which relies on updates to batch normalization statistics. Test-time adaptive object detection. Research on TTA for Object Detection (TTAOD) is progressively emerging [6, 29, 36, 42]. Most existing TTAOD methods [6, 36, 42] exploit a teacher-student network to adapt to the test do- main, following the self-training approach commonly em- ployed in Unsupervised Domain Adaptation for object de- tection [7, 18, 19, 34]. However, it is inefficient for TTA due to data augmentation requirements and additional for- ward and backward steps, resulting in slower inference speeds and higher memory usage. Another approach, Act- MAD [29], aligns the distributions of output feature maps after all BN layers along the height, width, and channel axes to adapt to the test domain. However, this location-aware feature alignment is limited to datasets with fixed location priors, such as driving datasets, and is less effective for nat- ural images like COCO. Additionally, CTA for Object De- tection (CTAOD)have not been thoroughly explored. There- fore, there is a need for an effective CTAOD method con- sidering memory and time efficiency. 3. Method To enable the efficient and effective Continual Test-time Adaptation of Object Detectors (CTAOD), we introduce an approach that specifies which part of the model should be updated, describes how to update those using unlabeled test data, and determines whether we perform model updates or not to improve efficiency. 3.1. Preliminary Assume that we have an object detector h â—¦ gÎ˜, here h and g are the RoI head and the backbone, respectively with their parameters being Î˜. The training dataset is denoted as Dtrain = {(xi, yi)}N i=1, where xi âˆ¼ Ptrain(x) and yi = ( bboxi, ci), containing information on the bounding box (bbox) and class label ci âˆˆ C. Consider deploying the detector to the test environments where the test data at pe- riod T is denoted as xT j âˆ¼ PT test(x), PT test Ì¸= Ptrain and PT test deviates from the i.i.d. assumption. In addition, the domain of PT test continually changes according to T (i.e., PT test Ì¸= PTâˆ’1 test ). Our goal is to adapt the detector h â—¦ g to PT test using only test data xT j while making predictions. 3.2. What to update: Adaptation via an adaptor Previous methods [6, 29, 36, 42] adapt the model to the test domain by updating all parameters Î˜, leading to in- efficiency at test time and a high risk of losing task knowl- edge from the training data. In contrast, we adapt the model by introducing an adaptor with an extremely small set of parameters and updating only this module while freezing Î˜. We introduce a shallow adaptor in parallel for each block, inspired by [5, 13], where transformer-based mod- els are fine-tuned for downstream tasks through parameter- efficient adaptors, as shown in Fig. 2. Each adaptor consists of down-projection layers Wdown âˆˆ RdÃ—d r , up-projection layers Wup âˆˆ R d r Ã—d and ReLUs, where d denotes the in- put channel dimension and r is the channel reduction ratio set to 32 for all adaptors. We use MLP layers for the Trans- former block (Fig. 2a) and 1Ã—1 convolutional layers for the ResNet block (Fig. 2b) to introduce architecture-agnostic adaptors. The up-projection layer is initialized to 0 values so that the adaptor does not modify the output of the block, 3(a) A block of Transformer  (b) A block of ResNet Figure 2. We attach an adaptor, which is a shallow and low-rank MLP or CNN, to every N block in parallel. We update only these adaptors while other parameters are frozen. Our approach can be applied to diverse architectures including CNNs and Transformers. but as the adaptor is gradually updated, it adjusts the output of the block to adapt to the test domain. Even as the adaptor is updated in the test domain, the original backbone param- eter Î˜ remains frozen and fully preserved. This structural preservation, as evident in Ours in Fig. 1, enables robust and efficient adaptation to domain changes by maintaining relatively complex task knowledge in object detection and updating very few parameters. 3.3. How to update: EMA feature alignment To adapt the object detector to the test domain, we align the feature distribution of the test domain with that of the training data, inspired by [17, 29, 38]. In contrast to these methods that solely align image feature distribution, we ad- ditionally align object-level features in a class-wise manner, considering class frequency, to enhance its effectiveness for object detection. As the training data is not accessible dur- ing test time, we pre-compute the first and second-order statistics, denoted as Âµtr = E[Ftr] and Î£tr = Var[Ftr], where the operators E and Var represent the mean and vari- ance respectively. The features Ftr = {gÎ˜(xtr)} are com- puted using only 2,000 training samples, a small subset of the training data. Since a sufficient amount of test domain data is not available at once, and only the current incoming test data, whose features are denoted as Ft te, is accessible at time step t, we estimate the mean of test data features using an exponentially moving average (EMA) as follows: Âµt te = (1 âˆ’ Î±) Â· Âµtâˆ’1 te + Î± Â· E[Ft te], s.t. Âµ0 te = Âµtr. (1) Considering the typically small batch size in object detec- tion compared to classification, we approximate the vari- ance of the test features as Î£te â‰ƒ Î£tr to reduce instability. Image-level feature alignment. We estimate the training and test feature distributions as normal distributions and minimize the KL divergence between them as follows: Limg = DKL(N(Âµtr, Î£tr), N(Âµt te, Î£tr)). (2) Region-level class-wise feature alignment. In object de- tection, we deal with multiple objects within a single image, making it challenging to apply the class-wise feature align- ment proposed in [38], a TTA method for classification. To handle region-level features that correspond to an object, we use ground truth bounding boxes for the training data and utilize the class predictions of RoI pooled features, ft te, for unlabeled test data. In object detection, domain shifts often result in lower recall rates, as a significant number of proposals are predicted as background [20]. To mitigate this issue, we filter out features with background scores exceed- ing a specific threshold. Subsequently, we assign them to the foreground class with the highest probability, as follows: Fk,t te = {ft te|argmax c pfg = k, pbg < 0.5}, where hcls(ft te) = [pfg , pbg] = [p0, ..., pCâˆ’1, pbg]. (3) We estimate the class-wise feature distribution of the test domain by exploiting Fk,t te and Eq.1. Furthermore, we in- troduce a weighting scheme for aligning features of less frequently appearing classes, taking into account the severe class imbalance where specific instance ( e.g., person) may appear multiple times within a single image, as follows: Nk,t = Nk,tâˆ’1 + ||Fk,t te ||, s.t. Nk,0 = 0 wk,t = log \u0012maxi Ni,t Nk,t \u0013 + 0.01 Lobj = X k wk,t Â· DKL(N(Âµk tr, Î£k tr), N(Âµk,t te , Î£k tr)). (4) Here, the class-wise mean Âµk and variance Î£k of the train- ing and test data are obtained in the same way as the image- level features. We can effectively adapt the object detector by updating the model to align the feature distribution at both the image and object levels as L = Limg + Lobj. 3.4. When to update: Adaptation on demand As shown in Fig. 1, Ours, which only updates the adaptor proposed in Sec. 3.2, efficiently adapts to changes in the test domain, even with a small subset of early test samples. We leverage its rapid adaptation characteristics to reduce com- putational costs by skipping model updates ( i.e., skipping backward passes) when the model has already sufficiently adapted to the current test domain and resuming model up- dates when confronted with a new test domain. Therefore, we introduce two criteria to determine when to update the model or not as follows: (Criterion 1) When the distribution gap exceeds the in- domain distribution gap. Recall that Limg (Eq. 2) mea- sures the distribution gap between the test and train distri- butions. We assume a model is well-adapted to the current test domain when Limg is closer to the in-domain distri- bution gap. We measure the in-domain distribution gap by 4(a) The ratio of Limg to Din KL (b) The ratio of Limg to Lt ema Figure 3. The test domain undergoes a shift every 4,000 time steps, and each metric reaches its peak at the same intervals. sampling two disjoint subsets, xi and xj, of training fea- tures Ftr from Sec. 3.3 as follows: Din KL = DKL(N(Âµi tr, Î£i tr), N(Âµj tr, Î£j tr)), (5) where Âµi tr, Î£i tr are obtained from xi âˆ¼ Ptrain(x) and Âµj tr, Î£j tr from xj âˆ¼ Ptrain(x). In other words, if Limg is noticeably higher than the in-domain distribution gapDin KL, we consider a model encountering a test domain whose dis- tribution differs from Ptrain(x) and needs to be updated. Based on this, we introduce a new index Limg Din KL . Fig. 3a plots the trend of this index during the model adaptation to a con- tinually changing test domain. It shows that the index has a large value in the early stages of a domain change, decreases rapidly, and then maintains a value close to 1. This index exhibits a similar trend regardless of the backbone type and dataset, as included in the appendix. Therefore, we establish the criterion that model updates are necessary when this in- dex exceeds a certain threshold, Ï„1, as Limg Din KL > Ï„1. (Criterion 2 ) When the distribution gap suddenly in- creases. Additionally, we can determine when the test dis- tribution changes and model updates are necessary by ob- serving the trend of the distribution gap ( i.e., Limg). The convergence of Limg indicates that a model is well-adapted to the current test domain. To put it differently, Limg will exhibit a sudden increase when the model encounters a new test domain. We introduce an additional index, denoted as Limg Ltema , representing the ratio of the currentLimg to its expo- nentially moving averageLt ema at time t. We calculate it us- ing the following formula:Lt ema = 0.99Â·Ltâˆ’1 ema+0.01Â·Limg. Fig. 3b illustrates the trend of the ratio of Limg over the timesteps. It tends to reach a value of 1 as the loss stabilizes at a specific level. Nevertheless, when the model encounters shifts in the test distribution, the ratio experiences a sharp increase, indicating the necessity of a model update when it exceeds a specific threshold, Ï„2, as Limg Ltema > Ï„2. If at least one of the two criteria is satisfied, we conclude that the model requires adaptation and proceed to update it. 4. Experiments Sec. 4.1 presents the two object detection benchmark datasets with test distributions that change continuously, ei- ther in a drastic or gradual manner, and our implementation detail is in 4.2. Sec. 4.4 compares our method with other TTA baselines described in Secs. 4.3.. We present detailed ablation studies of our method analyzing the effectiveness and efficiency of our method in terms of what, how, and when to update the models for CTAOD in Sec. 4.5. 4.1. Datasets We experiment with the following three scenarios. COCO â†’ COCO-C simulates continuous and drastic real- istic test domain changes over a long sequence. MS-COCO [23] collects 80 classes of common objects in their natural context with 118k training images and 5k validation images. COCO-C is created by employing 15 types of realistic cor- ruptions [27], such as image distortion and various weather conditions, to simulate test domain changes. In the experi- ments, the model is only trained on the COCO train set and sequentially evaluated on each corruption in the COCO-C validation set during test-time for reproducing continually changing test domains. Finally, the model is evaluated on the original COCO validation set to assess how well it pre- serves knowledge of the original domain (denoted as Org.). SHIFT-(Discrete / Continuous) [39] is a synthetic driving image dataset with 6 classes under different conditions us- ing five weather attributes (clear, cloudy, overcast, fog, rain) and three time-of-day attributes ( daytime, dawn, night ). In SHIFT-Discrete, there are image sets for each attribute, and the model is sequentially evaluated on these attributes, cloudy â†’ overcast â†’ foggy â†’ rainy â†’ dawn â†’ night â†’ clear which contains 2.4k, 1.6k, 2.7k, 3.2k, 1.2k, 1.4k, and 2.8k validation images, respectively. This simulates scenar- ios where the domain undergoes drastic changes. InSHIFT- Continuous, the model is evaluated on four sequences, each consisting of 4k frames, continuously transitioning from clear to foggy (or rainy) and back to clear. 4.2. Implementation Detail We experiment with Faster-RCNN [33] models using ResNet50 [10] and Swin-Tiny [26] as a backbone with FPN [24]. For the COCO â†’ COCO-C adaptation, we em- ploy the publicity available models trained on COCO re- leased in [46] and [26] for ResNet5- and Swin-Tiny-based Faster-RCNN, respectively. For SHIFT experiments, mod- els are trained on the training domain using the detectron2 framework following [33] and [26]. For test-time adapta- tion, we always set the learning to 0.001 for the SGD opti- mizer, and Î± of Eq. 1 to 0.01, while Ï„1 and Ï„2 are set to 1.1 5Table 1. Comparison of mAP, the number of backward and forward passes, and FPS between baselines and our model on COCOâ†’ COCO- C. Our model consistently outperforms baselines on the two different backbones. Furthermore, Ours-Skip with ResNet notably reduces backward passes by as much as 90.5%, leading to a significantly improved frames per second (FPS) rate by up to 109.9%. Noise Blur Weather Digital # step Backbone Method Gau Sht Imp Def Gls Mtn Zm Snw Frs Fog Brt Cnt Els Px Jpg Org. Avg. For. Back. FPS Swin-T [26] Direct-Test 9.7 11.4 10.0 13.4 7.5 12.1 5.2 20.7 24.8 36.1 36.0 12.9 19.1 4.9 15.8 43.0 17.7 80K 0 21.5 ActMAD 10.7 12.0 9.4 12.3 5.7 9.5 4.5 15.3 17.5 27.6 28.2 1.1 16.7 2.6 8.7 36.3 13.9 80K 80K 8.3 Mean-Teacher 10.0 12.1 11.2 12.8 8.1 12.1 4.9 19.6 23.7 34.9 34.0 8.0 18.9 6.1 17.6 41.0 17.2 160K 80K 6.9 Ours 13.6 16.6 16.1 14.0 13.6 14.2 8.3 23.7 27.2 37.4 36.4 27.2 27.2 22.2 22.3 42.3 22.6 80K 80K 9.5 Ours-Skip 13.3 15.3 15.1 14.0 12.8 13.9 6.5 22.0 25.4 35.5 34.9 26.5 25.9 23.4 20.2 41.2 21.6 80K 9.7K 17.7 ResNet50 [10] Direct-Test 9.1 11.0 9.8 12.6 4.5 8.8 4.6 19.1 23.1 38.4 38.0 21.4 15.6 5.3 11.9 44.2 17.3 80K 0 25.8 NORM 9.9 11.9 11.0 12.6 5.2 9.1 5.1 19.4 23.5 38.2 37.6 22.4 17.2 5.7 10.3 43.4 17.5 80K 0 25.8 DUA 9.8 11.7 10.8 12.8 5.2 8.9 5.1 19.3 23.7 38.4 37.8 22.3 17.2 5.4 10.1 44.1 17.1 80K 0 25.8 ActMAD 9.1 9.6 7.0 11.0 3.2 6.1 3.3 12.8 14.0 27.7 27.8 3.9 12.9 2.3 7.2 34.3 10.5 80K 80K 9.6 Mean-Teacher 9.6 12.5 12.0 4.0 2.9 4.8 3.1 16.2 23.5 35.1 34.0 21.8 16.6 8.2 12.7 40.3 14.5 160K 80K 8.1 Ours 12.7 17.8 17.5 12.4 11.5 11.3 6.6 22.8 26.9 38.6 38.5 28.0 25.1 21.2 22.2 41.8 22.2 80K 80K 10.1 Ours-Skip 14.4 17.1 16.0 13.9 11.7 12.2 6.3 22.1 25.5 37.7 37.1 25.5 24.1 23.1 21.1 42.8 21.9 80K 7.6K 21.2 and 1.05, respectively. We use the same hyper-parameters across all backbones and datasets. All experiments are con- ducted with a batch size of 4. 4.3. Baselines Direct-Test evaluates the model trained in the training do- main without adaptation to the test domain. ActMAD [29] is a TTA method aligning the distribution of output features across all BN layers. To apply ActMAD to the Swin Trans- former-based model, we align the output features of the LN layers. We implement Mean-Teacher using a teacher- student network framework to reproduce as close as possi- ble to TeST [36], as its implementation is not publicly avail- able. We follow the FixMatch [37] augmentation method and report results after tuning all hyper-parameters in our scenario. NORM [35] and DUA [28], TTA methods ini- tially designed for classification, are directly applicable to detection tasks by either mixing a certain amount of current batch statistics or updating batch statistics via EMA. How- ever, these are only compatible with architectures contain- ing BN layers. Additional details are provided in Appendix. 4.4. Main Results We compare the performance of each method using mAP and efficiency metrics, including the number of forward and backward passes, as well as FPS during test-time adapta- tion. Results of COCO and SHIFT are in Tab. 1 and 2, re- spectively. COCO â†’ COCO-C. Tab. 1 demonstrates the effective adaptation performance of Ours in the challenging COCO benchmark with 80 classes due to object-level class-wise feature alignment. ActMAD also aligns feature distribution for TTA, but is not effective since it only aligns whole fea- ture maps without considering specific classes in the im- age. NORM and DUA, applicable only to ResNet [10], show minimal performance improvement by adaptation as they are not specifically tailored for object detection and only modify batch statistics across the entire feature map. Ad- ditionally, ActMAD and Mean-Teacher, updating full pa- rameters, gradually lose task knowledge in the continually changing test distributions, resulting in much lower perfor- mance on Org. , the domain identical to the training data, than that of Direct-Test. In contrast, Ours effectively pre- vents catastrophic forgetting by freezing the original param- eters of the models and updating only the adaptor, obtain- ing performance on par with Direct-Test on the Org. do- main and consistently high performance across corrupted domains, with an average mAP improvement of 4.9%p compared to that of Direct-Test. Furthermore, leveraging the rapid adaptation ability of the adaptor,Ours-Skip, which skips unnecessary adaptation, allows using only a maxi- mum of about 12% of the total samples for adaptation with- out significant performance loss. This leads to a substantial improvement in inference speed, more than doubling com- pared to other TTA methods, reaching over 17.7 FPS. SHIFT-Discrete. Ours is also effective in SHIFT, which simulates continuous changes in weather and time in driv- ing scenarios according to the left section of Tab. 2. Espe- cially, Ours shows significant improvements in mAP by 7- 9%p, particularly for the foggy and dawn attributes where Direct-Test obtains lower performance due to severe do- main shift. In contrast, with ActMAD, catastrophic forget- ting takes place when adapting to the cloudy and overcast weather. This is due to the updating of the full parame- ters, despite that Direct-Test already shows proficient per- formance in these conditions. As a result, the performance in the later domains is worse than that of the Direct-Test. DUA, which updates batch statistics using EMA, shows a gradual decrease in performance as the domain contin- uously changes, resulting in much lower performance in the original clear domain ( i.e., clear ). On the other hand, NORM, which utilizes the statistics of the current batch samples, exhibits no catastrophic forgetting and relatively good adaptation, as SHIFT is a relatively easier task com- pared to COCO due to having only 6 classes. Compared to NORM, Ours shows better adaptation performance, and is 6Table 2. Comparison of mAP, the number of backward and forward passes, and FPS between baselines and our model on SHIFT-Discrete and SHIFT-Continuous. Baselines perform effectively in a particular setting but lack generalizability across various settings. Our method consistently achieves results that are either better or on par with the best model in all settings, demonstrating its strong stability. Ours-Skip also effectively reduces the number of backward passes without compromising mAP performance, resulting in a higher FPS. SHIFT-Discrete SHIFT-Continuous mAP # step mAP # Avg. step Backbone Method cloudy overc. fog rain dawn night clear Avg. For. Back. FPS clearâ†”fog clear â†”rain For. Back. FPS Swin-T [26] Direct-Test 50.0 38.9 23.1 45.1 26.9 39.5 45.9 38.5 15.3K 0 27.5 18.1 21.1 4K 0 28.3 ActMAD 49.8 38.4 21.4 43.1 19.0 32.0 44.8 35.5 15.3K 15.3K 9.3 15.6 16.3 4K 4K 9.8 Mean-Teacher 50.0 39.2 25.7 45.4 26.0 37.5 42.2 38.0 15.3K 15.3K 7.8 20.4 24.3 8K 4K 6.5 Ours 50.3 39.2 32.2 46.7 30.4 39.9 44.3 40.4 15.3K 15.3K 11.2 23.9 22.6 4K 4K 11.6 Ours-Skip 50.3 39.7 29.1 47.1 30.2 41.5 45.9 40.6 15.3K 6.1K 20.0 25.1 23.8 4K 0.83K 19.2 ResNet50 [10] Direct-Test 49.4 37.9 19.7 43.1 20.1 35.3 45.6 35.9 15.3K 0 30.1 12.1 15.4 4K 0 30.0 NORM 49.7 38.6 22.9 44.7 25.1 37.4 45.5 37.7 15.3K 0 30.1 16.9 19.4 4K 0 30.0 DUA 45.2 31.5 27.7 31.9 15.2 18.6 21.1 27.3 15.3K 0 30.1 22.5 22.4 4K 0 30.0 ActMAD 49.2 37.7 18.0 40.6 16.0 32.9 44.3 34.1 15.3K 15.3K 11.3 12.7 16.3 4K 4K 11.2 Mean-Teacher 49.6 38.4 26.8 43.4 26.6 33.1 41.6 37.1 15.3K 15.3K 9.9 16.0 20.8 8K 4K 9.8 Ours 49.7 38.7 27.4 46.3 27.4 37.6 43.8 38.7 15.3K 15.3K 12.9 20.9 21.9 4K 4K 13.9 Ours-Skip 49.7 38.8 26.9 46.2 27.6 38.8 45.0 39.0 15.3K 8.9K 21.5 20.0 22.5 4K 0.75K 21.3 Table 3. Comparison of adaptation performance (mAP), the num- ber of trainable parameters (# Params), and memory usage (Cache) according to which part of the backbone is updated. SD / SC de- notes SHIFT-Discrete/Continuous, respectively. mAP # Params Cache Backbone Trainable Params SD SC Num Ratio Avg. Max Swin-T Full-params 38.4 20.6 27.7M 100% 0.86 11.0 LayerNorm 38.5 20.0 0.03M 0.1% 0.65 7.49 adaptor (Ours) 40.4 23.2 0.15M 0.5% 0.65 6.96 ResNet50 Full-params 37.6 20.4 23.7M 100% 1.65 9.29 BatchNorm 37.9 20.2 0.05M 0.2% 1.47 9.11 adaptor (Ours) 38.7 21.7 0.21M 0.9% 1.48 5.41 also applicable to BN-layer-free Swin Transformers. SHIFT-Continuous. In scenarios where the test domain gradually changes across the entire sequence, Ours also demonstrates effectiveness, improving mAP by up to 7%p, as shown in the right section of Tab. 2. WhileDUA performs well in the clear to foggy transition, it is prone to catas- trophic forgetting in situations where the sequence becomes longer, and the test domain changes more diversely, as seen in the left section. Our strategy for determining when model adaptation is necessary is particularly effective in SHIFT. It improves FPS by about 9, reaching about 20 FPS, while en- hancing mAP. This is likely due to avoiding overfitting that can occur when adapting to all repetitive frames in SHIFT, which consists of continuous frames, leading to improve- ments in both inference speed and adaptation performance. 4.5. Additional Analyses We aim to demonstrate the effectiveness and detailed anal- ysis of our proposed model in terms of 1) which parts of, 2) how, and 3) when the model should be updated. Which part to update? Tab. 3 shows how updating dif- ferent parts of the backbone model affects the performance and the memory usage during continual test-time adapta- Table 4. Ablation on each component of our loss. SHIFT-D / C denotes SHIFT-Discrete / Continuous, respectively. The left and right value in each cell corresponds to the mAP for the Swin-T and ResNet50 backbone, respectively. Limg Lobj COCO SHIFT-D. SHIFT-C. - - 17.7/ 17.3 38.5/ 35.9 19.6/ 13.8 âœ” - 16.7/ 18.1 36.6/ 37.0 19.1/ 16.0 âœ” no class weight 17.8/ 18.9 39.7/ 38.0 25.1/ 23.4 âœ” class weight wk,t 22.6/ 22.2 40.4/ 38.7 23.2/ 21.7 tion. We compare (1) updating full parameters, (2) affine parameters of the normalization layer, and (3) our proposed adaptor for each backbone on the SHIFT dataset. Although our adaptor has fewer parameters, about 0.9% or less of the full parameters, it demonstrates the best adaptation perfor- mance. Updating only the affine parameters of the normal- ization layer, while having fewer parameters, seems less ef- fective for adaptation in object detection compared to clas- sification [30, 43]. Additionally, our adaptor requires only about 60% of the memory compared to updating the full parameters, making it memory-efficient. Ablation study on each component in our loss. Tab. 4 presents the effects of image-level feature alignment,Limg, object-level feature class-wise alignment Lobj, and class frequency weighting wk,t proposed to address class im- balance. Aligning only the image-level feature distribu- tion with Limg (first row) leads to modest adaptation in the ResNet50 backbone, while performance in the Swin- T backbone is even lower than without adaptation. No- tably, aligning object-level features with Lobj leads to a substantial improvement, with the mAP increasing by approximately 10%p compared to the no-adaptation sce- nario. Introducing class-specific frequency-based weighting wk,t, despite a slight performance decrease in the SHIFT- Continuous setting, proves highly effective, particularly in scenarios with significant class imbalance, such as COCO 7(a) Swin Transformer backbone  (b) ResNet50 backbone Figure 4. Comparison of mAP and FPS fromOurs-Skip with vary- ing values of Ï„1 (â™¦) and Ï„2 (â–²) against Evenly-Skip (Ã—), adapting every N-th instances, on COCOâ†’COCO-C using both (a) Swin- T and (b) ResNet50. The upward and rightward movement indi- cates a better strategy with higher mAP and faster inference speed, showing that Ours-Skip is consistently better than Evenly-Skip. (a) Accumulated number of backward steps (b) Number of backward steps and mAP of Direct-Test in each domain Figure 5. Analysis of the adaptation of Ours-Skip. with 80 classes, where it enhances the mAP by around 5%p. Trade-off between adaptation performance and effi- ciency according to different skipping strategies. Fig. 4 presents mAP and FPS depending on the values ofÏ„1 and Ï„2 in the Sec. 3.4 on COCO â†’ COCO-C, which are used for two criteria to determine when the adaptation is needed. We also show the simple baselineEvenly-Skip, which adapts ev- ery N-th step and skips the rest. In Fig. 4, the blue lines (â–²) show the results when Ï„1 is changing from 1.0 to infinity, where only criterion 2 is used, while Ï„2 is fixed at 1.05. As Ï„1 decreases, more adaptation is required, leading to slower FPS but higher mAP. The green lines (â™¦) show the results of changing Ï„2, where â€˜Ï„2 = infâ€™ denotes using only criterion 1, without criterion 2. For all main experiments, we set Ï„1 and Ï„2 as 1.1 and 1.05, respectively, considering the balance between mAP and FPS. Additionally, our skipping strategy consistently outperforms Evenly-Skip, achieving higher val- ues in both mAP and FPS. This indicates that our criterion for deciding when to bypass model updates provides an ef- fective balance between accuracy and speed. When do models actually update? We analyze when the model actually skips adaptation and only performs infer- ence or actively utilizes test samples for model adaptation based on the two criteria we propose. This analysis is con- ducted in COCO to COCO-C with 15 corruption domains and 1 original domain. Fig. 5a plots the number of back- ward passes, i.e., the number of batches of test samples used for adaptation, with different values of Ï„1 for the two backbones. The horizontal and vertical axes represent se- quentially incoming test domains and the cumulative back- ward numbers, respectively. A steep slope in a region in- dicates frequent adaptation, while a gentle slope indicates skipping adaptation, performing only inference. Notably, even without explicit information about when the test do- main changes, the model actively performs adaptation, es- pecially right after the test domain changes. This trend is consistent regardless of changes in Ï„ value or backbone type. Furthermore, it is evident that the number of backward passes is primarily determined by the value ofÏ„1 rather than the type of backbone, suggesting that a consistent Ï„1 value can be used irrespective of the backbone. Fig. 5b visually represents the adaptation tendencies by dividing backward steps for each domain in the case of Swin-T backbone with Ï„1 = 1.1. More clearly, it shows that adaptation occurs ac- tively around the points where each domain changes, and af- terward, adaptation happens intermittently or almost not at all. The light pink bars represent the performance ofDirect- Test, showing that domains with initially high model per- formance tend to have less adaptation, while domains with lower performance initially need more adaptation. In other words, the amount of skipping adaptation is proportional to the amount of the domain shift. Interestingly, the second do- main, â€™Shot Noiseâ€™, shows almost no adaptation despite the lower performance of the Direct-Test. We conjecture that the preceding domain, â€™Gaussian Noiseâ€™, shares a similar nature of noise, leading the model to decide that additional adaptation steps may not be necessary. As a result, our skip- ping strategy enables the model to efficiently adapt, consid- ering both the original domain the model is trained on and the previous domain the model has been adapted to. 5. Conclusion We introduce an efficient Continual Test-time Adaptation (CTA) method for object detection in the continually chang- ing domain. Our approach involves 1) lightweight adap- tors, 2) class-wise object-level feature alignment, and 3) skipping unnecessary adaptation. These contributions col- lectively yield a highly efficient and effective adaptation method, showcasing robustness to diverse domain shifts, and achieving notable improvements in mAP performance across various CTA scenarios without serious slowdown in the inference speed. 8What, How, and When Should Object Detectors Update in Continually Changing Test Domains? Supplementary Material 6. Additional Details for Baselines We provide additional implementation details for each base- line model. Our framework incorporates all baseline models using the official code except Mean-Teacher. The results of the experiments are reported based on the optimal hyperpa- rameters that yield the best results in our scenario. ActMAD [29] As ActMAD exclusively conducts experi- ments on the KITTI dataset, where all images have a con- stant height and width (e.g., 370 x 1224), ensuring consis- tent feature map sizes for all samples. ActMAD can easily align them along the spatial axis. However, in the general setting of object detection tasks, such as the COCO bench- mark set, where image sizes and width-to-height ratios vary, aligning feature maps along the spatial axis becomes chal- lenging due to different sizes. To adapt ActMAD to our COCO â†’ COCO-C scenario, we perform center cropping on the feature maps to match the size of training domain fea- ture maps and the current test sample feature maps. We em- ploy a learning rate of 1e-5 for COCO and 1e-4 for SHIFT, respectively. Mean-Teacher As the official code of TeST [36] is not available, we implement the EMA-updated Teacher and Student models following TeST [36], to conduct experi- ments in our scenarios. TeST involves three forward steps for a batch: forwarding weakly augmented samples through the student network, strong augmented samples through the teacher network, and original samples through the teacher network for outputs. However, for a fair comparison, we perform two forward steps, forwarding the original sample through the teacher network and strong augmented sam- ples through the student network, to make predictions be- fore adaptation for every samples. We utilize a learning rate of 1e-5 and set the EMA update rate for the teacher network to 0.999. NORM [35] We set the hyperparameter N that controls the trade-off between training statistics and estimated tar- get statistics as 128. DUA [28] We set the momentum decay as 0.94, minimum momentum constant as 1e-4, and the initial momentum de- cay as 1e-3. 7. The effect of Bottleneck Reduction Ratio in the Adaptor Table 5 shows the results for COCO â†’ COCO-C, SHIFT- Discrete, and SHIFT-Continuous based on the dimension reduction ratio ( r) discussed in Section 3.2, representing Table 5. Comparison of adaptation performance (mAP), the num- ber of trainable parameters (# Params), and memory usage (Cache) according to r of Sec. 3.2, the bottleneck reduction ratio in the adaptor. We set r as 32 for all our experiments in the main paper. SD / SC denotes SHIFT-Discrete / Continuous, respectively. mAP # Params Cache Backbone r COCO SD SC Num Ratio Avg. Max Swin-T 1 22.6 40.0 21.3 4.33M 15.7% 0.75 7.51 2 22.6 40.3 23.2 2.17M 7.85% 0.73 7.27 4 22.6 40.4 23.2 1.09M 3.95% 0.70 7.06 8 22.6 40.4 23.2 0.55M 2.00% 0.69 7.00 16 22.6 40.4 23.2 0.28M 1.02% 0.67 6.98 32 22.6 40.4 23.2 0.15M 0.54% 0.65 6.96 64 22.6 40.4 23.2 0.08M 0.29% 0.65 6.95 ResNet50 1 22.5 38.7 20.8 6.31M 26.7% 1.55 5.89 2 22.4 38.7 20.9 3.16M 13.4% 1.51 5.64 4 22.3 38.6 21.3 1.59M 6.71% 1.49 5.52 8 22.3 38.6 21.4 0.80M 3.39% 1.48 5.46 16 22.2 38.6 21.4 0.41M 1.73% 1.48 5.43 32 22.2 38.7 21.4 0.21M 0.89% 1.48 5.41 64 22.1 38.7 21.3 0.11M 0.48% 1.48 5.40 the ratio of bottleneck size compared to the input size in the adaptor. The adaptation performance remains consistent across different r values. However, in the case of r = 1 in SHIFT experiments, mAP decreases, potentially due to catastrophic forgetting resulting from a large number of adaptable parameters. Since increasing the value of r sig- nificantly reduces the number of learnable parameters and memory usage, we set r to 32 in all other experiments. 8. Results on the KITTI Dataset We conduct additional experiments on the KITTI [8] dataset, the commonly used object detection dataset consist- ing of driving scenes with 8 classes (car, van, truck, person, person sitting, cyclist, tram, misc). To simulate the continu- ally changing domains, we use the following scenario ( Fog â†’ Rain â†’ Snow â†’ Clear) as done in [29]. We use the physics-based rendered dataset [9] forfog and rain and sim- ulate snow using the corruption library from [11]. We use the same split of [29], which divides the 7,441 training sam- ples into 3,740 training and 3,741 test samples. We train the Faster-RCNN using 3,741 training samples representing the Clear attribute with Swin-Transformer and ResNet50 back- bones, and evaluate it sequentially on Fog, Rain, Snow, and Clear test samples. We conduct all experiments with a batch size of 16 on 1 RTX A6000 GPU. Table 6 shows the mAP@50, the num- 1Table 6. Comparison of mAP, the number of backward and forward passes, FPS, and memory usage between baselines and our models on the continually changing KITTI datasets ( Fog â†’ Rain â†’ Snow â†’ Clear). Our models improve mAP@50 by 15.1 and 11.3 for Swin-T and ResNet50 backbone, respectively, compared to Direct-Test while maintaining comparable FPS. All experiments are conducted with a batch size of 16. mAP@50 # For. Steps # Backward Steps FPS Cache Backbone Method Fog Rain Snow Clear Avg. All Fog Rain Snow Clear All Avg. Avg. Max Swin-T Direct-Test 46.9 69.5 28.7 89.6 58.7 936 0 0 0 0 0 24.7 0.4 5.5 ActMAD 53.3 78.1 41.2 90.7 65.8 936 234 234 234 234 936 16.8 0.8 21.9 Mean-Teacher 54.5 80.2 43.2 92.4 67.6 936 234 234 234 234 936 10.0 1.0 22.6 Ours 56.7 82.1 64.6 91.8 73.8 936 234 234 234 234 936 17.1 0.4 11.8 Ours-Skip 57.4 81.5 64.3 91.3 73.6 936 234 65 224 36 559 22.9 0.4 11.8 ResNet50 Direct-Test 33.4 63.5 29.8 88.6 53.8 936 0 0 0 0 0 27.7 0.8 4.3 NORM 38.4 66.4 35.9 87.3 57.0 936 0 0 0 0 0 27.7 0.8 4.3 DUA 34.8 67.7 30.9 89.0 55.6 936 0 0 0 0 0 27.7 0.8 4.3 ActMAD 40.4 66.5 42.7 84.5 58.5 936 234 234 234 234 936 18.5 1.6 22.6 Mean-Teacher 39.6 71.3 43.5 88.2 60.6 936 234 234 234 234 936 11.1 1.8 31.1 Ours 45.6 71.4 52.5 88.3 64.5 936 234 234 234 234 936 18.8 0.8 9.4 Ours-Skip 45.8 71.3 50.9 88.4 64.1 936 234 111 98 45 488 24.5 0.8 9.4 (a) GT bounding boxes. (b) Prediction results of Direct-Test. (c) Prediction results of Ours. Figure 6. Results of COCO images corrupted by Shot-Noise. In the analysis of Sec. 4.5, we conjecture that Ours largely skips adaptation in Shot-Noise domain, despite the low mAP of Direct-Test, because the model has already adapted to a similar domain, Gaussian-Noise. In (c), at the first step before adaptation to the Shot-Noise, our model already predicts â€™Ovenâ€™ and â€™Refrigeratorâ€™ which Direct-Test fails to detect. This results in a much faster adaptation, and Ours successfully detects various objects, including rare ones such as â€™Fire Hydrantsâ€™, in the remaining images of the Shot-Noise domain. ber of forward and backward steps, FPS, and memory usage (Cache). Ours improves the mAP@50 by 15.1 and 10.7 for Swin-T and ResNet50 backbones, respectively, compared to Direct-Test. Compared to ActMAD and Mean-Teacher, our model not only improves the adaptation performance but also reduces memory usage, as we update only an ex- tremely small number of parameters of the adaptor. Further- more, using our skipping criteria of Sec. 3.4 with Ï„ = 1.1 and Î² = 1.05, we can improve FPS by more than 5.8 with- out sacrificing mAP@50, resulting in much faster inference 2(a) GT bounding boxes. (b) Prediction results of Direct-Test. (c) Prediction results of Ours. Figure 7. Results for COCO images corrupted by Pixelate. In the Pixelate domain, where the model has already experienced various corruptions in a long sequence, Ours initially incorrectly detects objects. In (c), it misidentifies a bed as a couch in the first step. However, it rapidly adapts to the Pixelate domain and effectively detects various objects. Notably, even in cases whereDirect-Testcorrectly identifies objects but with low confidence, Ours detects them with much higher confidence. (a) GT bounding boxes. (b) Prediction results of Direct-Test. (c) Prediction results of Ours. Figure 8. Results for SHIFT-Discrete with continually changing attributes, foggy â†’ rainy â†’ dawn â†’ night. speed compared to other TTA baselines. 39. Qualitative Results Fig. 6 and 7 and Fig. 8 show the qualitative results of Ours and Direct-Test which predict the samples without adapta- tion for COCO â†’ COCO-C and SHIFT, respectively. 9.1. COCO â†’ COCO-C Fig. 6 and 7 compare the prediction results for COCO im- ages corrupted. When the model encounters test images with various corruptions sequentially ( Gaussian-Noise â†’ Shot-Noise â†’ Impulse-Noise â†’ Defocus-Blur â†’ Glass- Blur â†’ Motion-Blur â†’ Zoom-Blur â†’ Snow â†’ Frost â†’ Fog â†’ Brightness â†’ Contrast â†’ Elastic-Transform â†’ Pixelate â†’ JPEG-Compression â†’ Original), Fig. 6 and 7 shows the results when the test images are corrupted by Shot-Noise and Pixelate, respectively. Compared to Direct- Test, our model adapts to the current domain within a few steps, such as 100 iterations, and detects various objects very well in the remaining incoming images. 9.2. SHIFT-Discrete Fig. 8 shows the qualitative results for SHIFT-Discrete. In the SHIFT-Discrete scenario, the model encounters environ- ments sequentially, transitioning from cloudy â†’ overcast â†’ foggy â†’ rainy â†’ dawn â†’ night â†’ clear. Figure. 8 se- lectively shows the foggy â†’ rainy â†’ dawn â†’ night se- quence, where the domain gap from the original clear envi- ronments is relatively large. Compared to Direct-Test, Ours detects various objects such as â€™carsâ€™ and â€™pedestriansâ€™ re- gardless of distribution changes. References [1] Alexander Bartler, Florian Bender, Felix Wiewel, and Bin Yang. Ttaps: Test-time adaption by aligning prototypes using self-supervision. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1â€“8. IEEE, 2022. 2 [2] Alexander Bartler, Andre B Â¨uhler, Felix Wiewel, Mario DÂ¨obler, and Bin Yang. Mt3: Meta test-time training for self- supervised test-time adaption. In International Conference on Artificial Intelligence and Statistics , pages 3080â€“3090. PMLR, 2022. 2 [3] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pages 8344â€“8353, 2022. 1 [4] Dhanajit Brahma and Piyush Rai. A probabilistic frame- work for lifelong test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3582â€“3591, 2023. 3 [5] Shoufa Chen, Chongjian Ge, Zhan Tong, Jiangliu Wang, Yib- ing Song, Jue Wang, and Ping Luo. Adaptformer: Adapting vision transformers for scalable visual recognition.Advances in Neural Information Processing Systems, 35:16664â€“16678, 2022. 3 [6] Yijin Chen, Xun Xu, Yongyi Su, and Kui Jia. Stfar: Im- proving object detection robustness at test-time by self- training with feature alignment regularization.arXiv preprint arXiv:2303.17937, 2023. 1, 2, 3 [7] Jinhong Deng, Wen Li, Yuhua Chen, and Lixin Duan. Un- biased mean teacher for cross-domain object detection. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pages 4091â€“4101, 2021. 3 [8] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research , 32(11):1231â€“1237, 2013. 1 [9] Shirsendu Sukanta Halder, Jean-Franc Â¸ois Lalonde, and Raoul de Charette. Physics-based rendering for improving robustness to rain. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 10203â€“10212, 2019. 1 [10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770â€“778, 2016. 5, 6, 7 [11] Dan Hendrycks and Thomas Dietterich. Benchmarking neu- ral network robustness to common corruptions and perturba- tions. arXiv preprint arXiv:1903.12261, 2019. 1 [12] Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, and Michael Spranger. Mecta: Memory-economic continual test-time model adaptation. In The Eleventh International Conference on Learning Representations, 2022. 3 [13] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen- Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021. 3 [14] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In International conference on machine learn- ing, pages 448â€“456. pmlr, 2015. 2 [15] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for modelagnostic domain generaliza- tion. In Advances in Neural Information Processing Systems (NeurIPS), 2021. 3 [16] Minguk Jang, Sae-Young Chung, and Hye Won Chung. Test- time adaptation via self-training with nearest neighbor infor- mation. In International Conference on Learning Represen- tations (ICLR), 2023. 3 [17] Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Sha- ban, Byron Boots, and Jaegul Choo. Cafa: Class-aware fea- ture alignment for test-time adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vi- sion, 2023. 2, 3, 4 [18] Mehran Khodabandeh, Arash Vahdat, Mani Ranjbar, and William G Macready. A robust learning approach to domain adaptive object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 480â€“ 490, 2019. 3 [19] Seunghyeon Kim, Jaehoon Choi, Taekyung Kim, and Chang- ick Kim. Self-training and adversarial background regular- ization for unsupervised domain adaptive one-stage object 4detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6092â€“6101, 2019. 3 [20] Xianfeng Li, Weijie Chen, Di Xie, Shicai Yang, Peng Yuan, Shiliang Pu, and Yueting Zhuang. A free lunch for unsuper- vised domain adaptive object detection without source data. In Proceedings of the AAAI Conference on Artificial Intelli- gence, pages 8474â€“8481, 2021. 4 [21] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical do- main adaptation, 2017. 3 [22] Hyesu Lim, Byeonggeun Kim, Jaegul Choo, and Sungha Choi. Ttn: A domain-shift aware batch normalization in test- time adaptation, 2023. 2, 3 [23] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÂ´ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer Visionâ€“ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740â€“755. Springer, 2014. 5 [24] Tsung-Yi Lin, Piotr Doll Â´ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyra- mid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recogni- tion, pages 2117â€“2125, 2017. 5 [25] Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems , 34: 21808â€“21820, 2021. 1, 2 [26] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision, pages 10012â€“10022, 2021. 2, 5, 6, 7 [27] Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver Bringmann, Alexander S Ecker, Matthias Bethge, and Wieland Brendel. Benchmarking ro- bustness in object detection: Autonomous driving when win- ter is coming. arXiv preprint arXiv:1907.07484, 2019. 5 [28] M Jehanzeb Mirza, Jakub Micorek, Horst Possegger, and Horst Bischof. The norm must go on: Dynamic unsuper- vised domain adaptation by normalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition, pages 14765â€“14775, 2022. 3, 6, 1 [29] Muhammad Jehanzeb Mirza, Pol Jan Â´e Soneira, Wei Lin, Ma- teusz Kozinski, Horst Possegger, and Horst Bischof. Act- mad: Activation matching to align distributions for test-time- training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 24152â€“ 24161, 2023. 1, 2, 3, 4, 6 [30] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In Interna- tional conference on machine learning, pages 16888â€“16905. PMLR, 2022. 1, 2, 3, 7 [31] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. arXiv preprint arXiv:2302.12400, 2023. 3 [32] Mario obler, Robert A Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pages 7704â€“7714, 2023. 3 [33] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. 2016. 5 [34] Aruni RoyChowdhury, Prithvijit Chakrabarty, Ashish Singh, SouYoung Jin, Huaizu Jiang, Liangliang Cao, and Erik Learned-Miller. Automatic adaptation of object detectors to new domains using self-training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019. 3 [35] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in neural information processing sys- tems, 33:11539â€“11551, 2020. 3, 6, 1 [36] Samarth Sinha, Peter Gehler, Francesco Locatello, and Bernt Schiele. Test: Test-time self-training under distribution shift. In Proceedings of the IEEE/CVF Winter Conference on Ap- plications of Computer Vision, pages 2759â€“2769, 2023. 1, 2, 3, 6 [37] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. Advances in neural information processing systems, 33:596â€“ 608, 2020. 2, 6 [38] Yongyi Su, Xun Xu, and Kui Jia. Revisiting realistic test- time training: Sequential inference and adaptation by an- chored clustering. Advances in Neural Information Process- ing Systems, 35:17543â€“17555, 2022. 3, 4 [39] Tao Sun, Mattia Segu, Janis Postels, Yuxuan Wang, Luc Van Gool, Bernt Schiele, Federico Tombari, and Fisher Yu. Shift: a synthetic driving dataset for continuous multi-task domain adaptation. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 21371â€“21382, 2022. 1, 5 [40] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229â€“ 9248. PMLR, 2020. 1, 2 [41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- reit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. 2 [42] Vibashan VS, Poojan Oza, and Vishal M Patel. Towards on- line domain adaptive object detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 478â€“488, 2023. 3 [43] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. arXiv preprint arXiv:2006.10726, 2020. 1, 2, 3, 7 5[44] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201â€“7211, 2022. 3 [45] Zehao Xiao, Xiantong Zhen, Shengcai Liao, and Cees GM Snoek. Energy-based test sample adaptation for domain gen- eralization. arXiv preprint arXiv:2302.11215, 2023. 3 [46] Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan Wang, Fangyun Wei, Xiang Bai, and Zicheng Liu. End- to-end semi-supervised object detection with soft teacher. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. 5 [47] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. Advances in Neural Information Processing Systems , 35: 38629â€“38642, 2022. 1, 2, 3 [48] Bowen Zhao, Chen Chen, and Shu-Tao Xia1. Delta: Degradation-free fully test-time adaptation. In International Conference on Learning Representations (ICLR), 2023. 2, 3 6",
      "meta_data": {
        "arxiv_id": "2312.08875v1",
        "authors": [
          "Jayeon Yoo",
          "Dongkwan Lee",
          "Inseop Chung",
          "Donghyun Kim",
          "Nojun Kwak"
        ],
        "published_date": "2023-12-12T07:13:08Z",
        "pdf_url": "https://arxiv.org/pdf/2312.08875v1.pdf"
      }
    },
    {
      "title": "DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION",
      "abstract": "Fully test-time adaptation aims at adapting a pre-trained model to the test\nstream during real-time inference, which is urgently required when the test\ndistribution differs from the training distribution. Several efforts have been\ndevoted to improving adaptation performance. However, we find that two\nunfavorable defects are concealed in the prevalent adaptation methodologies\nlike test-time batch normalization (BN) and self-learning. First, we reveal\nthat the normalization statistics in test-time BN are completely affected by\nthe currently received test samples, resulting in inaccurate estimates. Second,\nwe show that during test-time adaptation, the parameter update is biased\ntowards some dominant classes. In addition to the extensively studied test\nstream with independent and class-balanced samples, we further observe that the\ndefects can be exacerbated in more complicated test environments, such as\n(time) dependent or class-imbalanced data. We observe that previous approaches\nwork well in certain scenarios while show performance degradation in others due\nto their faults. In this paper, we provide a plug-in solution called DELTA for\nDegradation-freE fuLly Test-time Adaptation, which consists of two components:\n(i) Test-time Batch Renormalization (TBR), introduced to improve the estimated\nnormalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to\naddress the class bias within optimization. We investigate various test-time\nadaptation methods on three commonly used datasets with four scenarios, and a\nnewly introduced real-world dataset. DELTA can help them deal with all\nscenarios simultaneously, leading to SOTA performance.",
      "meta_data": {
        "arxiv_id": "2301.13018v1",
        "authors": [
          "Bowen Zhao",
          "Chen Chen",
          "Shu-Tao Xia"
        ],
        "published_date": "2023-01-30T15:54:00Z",
        "pdf_url": "https://arxiv.org/pdf/2301.13018v1.pdf"
      }
    },
    {
      "title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
      "abstract": "In this paper, we propose Test-Time Training, a general approach for\nimproving the performance of predictive models when training and test data come\nfrom different distributions. We turn a single unlabeled test sample into a\nself-supervised learning problem, on which we update the model parameters\nbefore making a prediction. This also extends naturally to data in an online\nstream. Our simple approach leads to improvements on diverse image\nclassification benchmarks aimed at evaluating robustness to distribution\nshifts.",
      "full_text": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Yu Sun1 Xiaolong Wang1 2 Zhuang Liu1 John Miller1 Alexei A. Efros1 Moritz Hardt1 Abstract In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a sin- gle unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on di- verse image classiï¬cation benchmarks aimed at evaluating robustness to distribution shifts. 1. Introduction Supervised learning remains notoriously weak at generaliza- tion under distribution shifts. Unless training and test data are drawn from the same distribution, even seemingly minor differences turn out to defeat state-of-the-art models (Recht et al., 2018). Adversarial robustness and domain adapta- tion are but a few existing paradigms that try to anticipate differences between the training and test distribution with either topological structure or data from the test distribution available during training. We explore a new take on gener- alization that does not anticipate the distribution shifts, but instead learns from them at test time. We start from a simple observation. The unlabeled test sample xpresented at test time gives us a hint about the distribution from which it was drawn. We propose to take advantage of this hint on the test distribution by allowing the model parameters Î¸to depend on the test sample x, but not its unknown label y. The concept of a variable decision boundary Î¸(x) is powerful in theory since it breaks away from the limitation of ï¬xed model capacity (see additional discussion in Section A1), but the design of a feedback mechanism from xto Î¸(x) raises new challenges in practice that we only begin to address here. 1University of California, Berkeley 2University of California, San Diego. Correspondence to: Yu Sun <yusun@berkeley.edu>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s). Our proposed test-time training method creates a self- supervised learning problem based on this single test sample x, updating Î¸at test time before making a prediction. Self- supervised learning uses an auxiliary task that automatically creates labels from unlabeled inputs. In our experiments, we use the task of rotating each input image by a multiple of 90 degrees and predicting its angle (Gidaris et al., 2018). This approach can also be easily modiï¬ed to work outside the standard supervised learning setting. If several test samples arrive in a batch, we can use the entire batch for test-time training. If samples arrive in an online stream, we obtain further improvements by keeping the state of the parameters. After all, prediction is rarely a single event. The online version can be the natural mode of deployment under the additional assumption that test samples are produced by the same or smoothly changing distribution shifts. We experimentally validate our method in the context of object recognition on several standard benchmarks. These include images with diverse types of corruption at various levels (Hendrycks & Dietterich, 2019), video frames of moving objects (Shankar et al., 2019), and a new test set of unknown shifts collected by (Recht et al., 2018). Our algorithm makes substantial improvements under distribu- tion shifts, while maintaining the same performance on the original distribution. In our experiments, we compare with a strong baseline (labeled joint training) that uses both supervised and self- supervised learning at training-time, but keeps the model ï¬xed at test time. Recent work shows that training-time self- supervision improves robustness (Hendrycks et al., 2019a); our joint training baseline corresponds to an improved imple- mentation of this work. A comprehensive review of related work follows in Section 5. We complement the empirical results with theoretical inves- tigations in Section 4, and establish an intuitive sufï¬cient condition on a convex model of when Test-Time Training helps; this condition, roughly speaking, is to have correlated gradients between the loss functions of the two tasks. Project website: https://test-time-training.github.io/. arXiv:1909.13231v3  [cs.LG]  1 Jul 2020Test-Time Training with Self-Supervision for Generalization under Distribution Shifts 2. Method This section describes the algorithmic details of our method. To set up notation, consider a standard K-layer neural net- work with parameters Î¸k for layer k. The stacked parameter vector Î¸ = ( Î¸1,...,Î¸ K) speciï¬es the entire model for a classiï¬cation task with loss function lm(x,y; Î¸) on the test sample (x,y). We call this the main task, as indicated by the subscript of the loss function. We assume to have training data (x1,y1),..., (xn,yn) drawn i.i.d. from a distribution P. Standard empirical risk minimization solves the optimization problem: min Î¸ 1 n nâˆ‘ i=1 lm(xi,yi; Î¸). (1) Our method requires a self-supervised auxiliary task with loss function ls(x). In this paper, we choose the rotation prediction task (Gidaris et al., 2018), which has been demon- strated to be simple and effective at feature learning for convolutional neural networks. The task simply rotates x in the image plane by one of 0, 90, 180 and 270 degrees and have the model predict the angle of rotation as a four- way classiï¬cation problem. Other self-supervised tasks in Section 5 might also be used for our method. The auxiliary task shares some of the model parameters Î¸e = ( Î¸1,...,Î¸ Îº) up to a certain Îº âˆˆ {1,...,K }. We designate those Îºlayers as a shared feature extractor. The auxiliary task uses its own task-speciï¬c parameters Î¸s = (Î¸â€² Îº+1,...,Î¸ â€² K). We call the unshared parameters Î¸s the self-supervised task branch, and Î¸m = (Î¸Îº+1,...,Î¸ K) the main task branch . Pictorially, the joint architecture is a Y-structure with a shared bottom and two branches. For our experiments, the self-supervised task branch has the same architecture as the main branch, except for the output dimensionality of the last layer due to the different number of classes in the two tasks. Training is done in the fashion of multi-task learning (Caru- ana, 1997); the model is trained on both tasks on the same data drawn fromP. Losses for both tasks are added together, and gradients are taken for the collection of all parameters. The joint training problem is therefore min Î¸e,Î¸m,Î¸s 1 n nâˆ‘ i=1 lm(xi,yi; Î¸m,Î¸e) + ls(xi; Î¸s,Î¸e). (2) Now we describe the standard version of Test-Time Training on a single test sample x. Simply put, Test-Time Training ï¬ne-tunes the shared feature extractor Î¸e by minimizing the auxiliary task loss on x. This can be formulated as min Î¸e ls(x; Î¸s,Î¸e). (3) Denote Î¸âˆ— e the (approximate) minimizer of Equation 3. The model then makes a prediction using the updated parameters Î¸(x) = (Î¸âˆ— e,Î¸m). Empirically, the difference is negligible between minimizing Equation 3 over Î¸e versus over both Î¸e and Î¸s. Theoretically, the difference exists only when optimization is done with more than one gradient step. Test-Time Training naturally beneï¬ts from standard data augmentation techniques. On each test sample x, we per- form the exact same set of random transformations as for data augmentation during training, to form a batch only con- taining these augmented copies of xfor Test-Time Training. Online Test-Time Training. In the standard version of our method, the optimization problem in Equation 3 is al- ways initialized with parameters Î¸= (Î¸e,Î¸s) obtained by minimizing Equation 2. After making a prediction on x, Î¸âˆ— e is discarded. Outside of the standard supervised learning setting, when the test samples arrive online sequentially, the online version solves the same optimization problem as in Equation 3 to update the shared feature extractor Î¸e. How- ever, on test sample xt, Î¸is instead initialized with Î¸(xtâˆ’1) updated on the previous sample xtâˆ’1. This allows Î¸(xt) to take advantage of the distributional information available in x1,...,x tâˆ’1 as well as xt. 3. Empirical Results We experiment with both versions of our method (standard and online) on three kinds of benchmarks for distribution shifts, presented here in the order of visually low to high- level. Our code is available at the project website. Network details. Our architecture and hyper-parameters are consistent across all experiments. We use ResNets (He et al., 2016b), which are constructed differently for CIFAR-10 (Krizhevsky & Hinton, 2009) (26-layer) and Ima- geNet (Russakovsky et al., 2015) (18-layer). The CIFAR-10 dataset contains 50K images for training, and 10K images for testing. The ImageNet contains 1.2M images for train- ing and the 50K validation images are used as the test set. ResNets on CIFAR-10 have three groups, each containing convolutional layers with the same number of channels and size of feature maps; our splitting point is the end of the second group. ResNets on ImageNet have four groups; our splitting point is the end of the third group. We use Group Normalization (GN) instead of Batch Nor- malization (BN) in our architecture, since BN has been shown to be ineffective when training with small batches, for which the estimated batch statistics are not accurate (Ioffe & Szegedy, 2015). This technicality hurts Test-Time Training since each batch only contains (augmented) copies of a single image. Different from BN, GN is not dependent on batch size and achieves similar results on our baselines.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40 50Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure 1.Test error (%) on CIFAR-10-C with level 5 corruptions.We compare our approaches, Test-Time Training (TTT) and its online version (TTT-Online), with two baselines: object recognition without self-supervision, and joint training with self-supervision but keeping the model ï¬xed at test time. TTT improves over the baselines and TTT-Online improves even further. We report results with BN in Section A4 of the appendix for completeness. We directly compare our architecture to that of Hendrycks et al. (2018) in subsection A4.5. Optimization details. For joint training (Equation 2), we use stochastic gradient descent with standard hyper- parameters as (Huang et al., 2016; He et al., 2016a). For Test-Time Training (Equation 3), we use stochastic gradient descent with the learning rate set to that of the last epoch during training, which is 0.001 in all our experiments. We set weight decay and momentum to zero during Test-Time Training, inspired by practice in (He et al., 2018; Liu et al., 2018). For the standard version of Test-Time Training, we take ten gradient steps, using batches independently gener- ated by the same image. For online version of Test-Time Training, we take only one gradient step given each new im- age. We use random crop and random horizontal ï¬‚ip for data augmentation. See Section A2 of the appendix for computa- tional aspects of our method. In all the tables and ï¬gures, object recognition task onlyrefers to the plain ResNet model (using GN, unless otherwise speciï¬ed); joint training refers to the model jointly trained on both the main task and the self-supervised task, ï¬xed at test time; this has been pro- posed as the method in Hendrycks et al. (2019a); Test-Time Training (TTT) refers to the standard version described sec- tion 2; and online Test-Time Training (TTT-Online)refers to the online version that does not discardÎ¸(xt) for xt arriving sequentially from the same distribution. Performance for TTT-Online is calculated as the average over the entire test set; we always shufï¬‚e the test set before TTT-Online to avoid ordering artifacts. 3.1. Object Recognition on Corrupted Images Hendrycks & Dietterich (2019) propose to benchmark ro- bustness of object recognition with 15 types of corruptions from four broad categories: noise, blur, weather and digital. Each corruption type comes in ï¬ve levels of severity, with level 5 the most severe (details and sample images in the ap- pendix). The corruptions are simulated to mimic real-world corruptions as much as possible on copies of the test set for both CIFAR-10 and ImageNet. The new test sets are named as CIFAR-10-C and ImageNet-C, respectively. In the pro- posed benchmark, training should be done on the original training set, and the diversity of corruption types should make it difï¬cult for any methods to work well across the board if it relies too much on corruption speciï¬c knowledge. For online Test-Time Training, we take the entire test set as a stream of incoming images, and update and test on each image in an online manner as it arrives. CIFAR-10-C. Our results on the level 5 corruptions (most severe) are shown in Figure 1. The results on levels 1-4 are shown in Section A4 in appendix. Across all ï¬ve levels and 15 corruption types, both standard and online versions of Test-Time Training improve over the object recognition task only baseline by a large margin. The standard version always improves over joint training, and the online version often improves signiï¬cantly (>10%) over joint training and never hurts by more than 0.2%. Speciï¬cally, TTT-Online contributes >24% on the three noise types and 38% on pix- elation. For a learning problem with the seemingly unstable setup that abuses a single image, this kind of consistency is rather surprising. The baseline ResNet-26 with object recognition task only has error 8.9% on the original test set of CIFAR-10. The joint training baseline actually improves performance on the original to 8.1%. More surprisingly, unlike many other methods that trade off original performance for robustness, Test-Time Training further improves on the original test set by 0.2% consistently over multiple independent trials. This suggests that our method does not choose between speciï¬city and generality.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 20 40 60Accuracy (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online 0 20000 40000 Number of samples 60 62 64 66 68 70 72 74 76Accuracy (%) Original Sliding window average 0 20000 40000 Number of samples 12 15 18 21 24 27 30 33Accuracy (%) Gaussian Noise Sliding window average 0 20000 40000 Number of samples 16 18 20 22 24 26 28 30 32Accuracy (%) Defocus Blur Sliding window average 0 20000 40000 Number of samples 28 30 32 34 36 38Accuracy (%) Zoom Blur Sliding window average 0 20000 40000 Number of samples 33 36 39 42 45 48 51 54Accuracy (%) Fog Sliding window average 0 20000 40000 Number of samples 30 33 36 39 42 45 48 51Accuracy (%) Elastic Transform Sliding window average Figure 2.Test accuracy (%) on ImageNet-C with level 5 corruptions.Upper panel: Our approaches, TTT and TTT-Online, show signiï¬cant improvements in all corruption types over the two baselines. Lower panel: We show the accuracy of TTT-Online as the average over a sliding window of 100 samples; TTT-Online generalizes better as more samples are evaluated (x-axis), without hurting on the original distribution. We use accuracy instead of error here because the baseline performance is very low for most corruptions. Separate from our method, it is interesting to note that joint training consistently improves over the single-task baseline, as discovered by Hendrycks et al. (2019a). Hendrycks & Dietterich (2019) have also experimented with various other training methods on this benchmark, and point to Adversar- ial Logit Pairing (ALP) (Kannan et al., 2018) as the most effective approach. Results of this additional baseline on all levels of CIFAR-10-C are shown in the appendix, along with its implementation details. While surprisingly robust under some of the most severe corruptions (especially the three noise types), ALP incurs a much larger error (by a factor of two) on the original distribution and some corruptions (e.g. all levels of contrast and fog), and hurts performance signiï¬cantly when the corruptions are not as severe (espe- cially on levels 1-3); this kind of tradeoff is to be expected for methods based on adversarial training. ImageNet-C. Our results on the level 5 corruptions (most severe) are shown in Figure 2. We use accuracy instead of error for this dataset because the baseline performance is very low for most corruptions. The general trend is roughly the same as on CIFAR-10-C. The standard version of TTT always improves over the baseline and joint training, while the online version only hurts on the original by 0.1% over the baseline, but signiï¬cantly improves (by a factor of more than three) on many of the corruption types. In the lower panel of Figure 2, we visualize how the accu- racy (averaged over a sliding window) of the online version changes as more images are tested. Due to space constraints, we show this plot on the original test set, as well as every third corruption type, following the same order as in the original paper. On the original test set, there is no visible trend in performance change after updating on the 50,000 samples. With corruptions, accuracy has already risen sig- niï¬cantly after 10,000 samples, but is still rising towards the end of the 50,000 samples, indicating room for additional improvements if more samples were available. Without seeing a single label, TTT-Online behaves as if we were training on the test set from the appearance of the plots.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg TTT-Online 8.2 25.8 22.6 30.6 14.6 34.4 18.3 17.1 20.0 18.0 16.9 11.2 15.6 21.6 18.1 21.2 UDA-SS 9.0 28.2 26.5 20.8 15.6 43.7 24.5 23.8 25.0 24.9 17.2 12.7 11.6 22.1 20.3 22.6 Table 1.Test error (%) on CIFAR-10-C with level 5 corruption.Comparison between online Test-Time Training (TTT-Online) and unsupervised domain adaptation by self-supervision (UDA-SS) (Sun et al., 2019) with access to the entire (unlabeled) test set during training. We highlight the lower error in bold. We have abbreviated the names of the corruptions, in order: original test set, Gaussian noise, shot noise, impulse noise, defocus blur, glass blue, motion blur, zoom blur, snow, frost, fog, brightness, contrast, elastic transformation, pixelation, and JPEG compression. The reported numbers for TTT-Online are the same as in Figure 1. See complete table in Table A2. 0 2000 4000 6000 8000 Number of samples 12 16 20 24 28 32 36 40 44 48Error (%) Gaussian Noise Joint training TTT TTT-Online UDA-SS 0 2000 4000 6000 8000 Number of samples 9 12 15 18 21 24 27 30 33 36Error (%) Shot Noise Joint training TTT TTT-Online UDA-SS 0 2000 4000 6000 8000 Number of samples 15 20 25 30 35 40 45 50Error (%) Impulse Noise Joint training TTT TTT-Online UDA-SS Figure 3.Test error (%) on CIFAR-10-C, for the three noise types, with gradually changing distribution.The distribution shifts are created by increasing the standard deviation of each noise type from small to large, the further we go on the x-axis. As the samples get noisier, all methods suffer greater errors the more we evaluate into the test set, but online Test-Time Training (TTT-Online) achieves gentler slopes than joint training. For the ï¬rst two noise types, TTT-Online also achieves better results over unsupervised domain adaptation by self-supervision (UDA-SS) (Sun et al., 2019). Comparison with unsupervised domain adaptation. Table 1 empirically compares online Test-Time Training (TTT-Online) with unsupervised domain adaptation through self-supervision (UDA-SS) (Sun et al., 2019), which is sim- ilar to our method in spirit but is designed for the setting of unsupervised domain adaptation (Section 5 provides a sur- vey of other related work in this setting). Given labeled data from the training distribution and unlabeled data from the test distribution, UDA-SS hopes to ï¬nd an invariant repre- sentation that extracts useful features for both distributions by learning to perform a self-supervised task, speciï¬cally rotation prediction, simultaneously on data from both. It then learns a labeling function on top of the invariant rep- resentation using the labeled data. In our experiments, the unlabeled data given to UDA-SS is the entire test set itself without the labels. Because TTT-Online can only learn from the unlabeled test samples that have already been evaluated on, it is given less information than UDA-SS at all times. In this sense, UDA- SS should be regarded as an oracle rather than a baseline. Surprisingly, TTT-Online outperforms UDA-SS on 13 out of the 15 corruptions as well as the original distribution. Our explanation is that UDA-SS has to ï¬nd an invariant representation for both distributions, while TTT-Online only adapts the representation to be good for the current test distribution. That is, TTT-Online has the ï¬‚exibility to forget the training distribution representation, which is no longer relevant. This suggests that in our setting, forgetting is not harmful and perhaps should even be taken advantage of. Gradually changing distribution shifts.In our previous experiments, we have been evaluating the online version under the assumption that the test inputs xt for t= 1...nare all sampled from the same test distribution Q, which can be different from the training distribution P. This assumption is indeed satisï¬ed for i.i.d. samples from a shufï¬‚ed test set. But here we show that this assumption can in fact be relaxed to allow xt âˆ¼Qt, where Qt is close to Qt+1 (in the sense of distributional distance). We call this the assumption of gradually changing distribution shifts. We perform experiments by simulating such distribution shifts on the three noise types of CIFAR-10-C. For each noise type, xt is corrupted with standard deviation Ïƒt, and Ïƒ1,...,Ïƒ n interpolate between the standard deviation of level 1 and level 5. So xt is more severely corrupted as we evaluate further into the test set and t grows larger. As shown in Figure 3, TTT-Online still improves upon joint training (and our standard version) with this relaxed assumption, and even upon UDA-SS for the ï¬rst two noise types.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Accuracy (%) Airplane Bird Car Dog Cat Horse Ship Average Object recognition task only 67.9 35.8 42.6 14.7 52.0 42.0 66.7 41.4 Joint training (Hendrycks et al., 2019a) 70.2 36.7 42.6 15.5 52.0 44.0 66.7 42.4 TTT (standard version) 70.2 39.2 42.6 21.6 54.7 46.0 77.8 45.2 TTT-Online 70.2 39.2 42.6 22.4 54.7 46.0 77.8 45.4 Table 2.Class-wise and average classiï¬cation accuracy (%) on CIFAR classes in VID-Robust, adapted from (Shankar et al., 2019). Test-Time Training (TTT) and online Test-Time Training (TTT-Online) improve over the two baselines on average, and by a large margin on â€œshipâ€ and â€œdogâ€ classes where the rotation task is more meaningful than in classes like â€œairplaneâ€ (sample images in Figure A7). 3.2. Object Recognition on Video Frames The Robust ImageNet Video Classiï¬cation (VID-Robust) dataset was developed by Shankar et al. (2019) from the Ima- geNet Video detection dataset (Russakovsky et al., 2015), to demonstrate how deep models for object recognition trained on ImageNet (still images) fail to adapt well to video frames. The VID-Robust dataset contains 1109 sets of video frames in 30 classes; each set is a short video clip of frames that are similar to an anchor frame. Our results are reported on the anchor frames. To map the 1000 ImageNet classes to the 30 VID-Robust classes, we use the max-conversion function in Shankar et al. (2019). Without any modiï¬cations for videos, we apply our method to VID-Robust on top of the same ImageNet model as in the previous subsection. Our classiï¬cation accuracy is reported in Table 3. In addition, we take the seven classes in VID-Robust that overlap with CIFAR-10, and re-scale those video frames to the size of CIFAR-10 images, as a new test set for the model trained on CIFAR-10 in the previous subsection. Again, we apply our method to this dataset without any modiï¬cations. Our results are shown in Table 2, with a breakdown for each class. Noticing that Test-Time Training does not improve on the airplane class, we inspect some airplane samples (Figure A7), and observe black margins on two sides of most images, which provide a trivial hint for rotation prediction. In addition, given an image of airplanes in the sky, it is often impossible even for humans to tell if it is rotated. This shows that our method requires the self-supervised task to be both well deï¬ned and non-trivial. 3.3. CIFAR-10.1: Unknown Distribution Shifts CIFAR-10.1 (Recht et al., 2018) is a new test set of size 2000 modeled after CIFAR-10, with the exact same classes and image dimensionality, following the dataset creation process documented by the original CIFAR-10 paper as closely as possible. The purpose is to investigate the distribution shifts present between the two test sets, and the effect on object recognition. All models tested by the authors suffer a large performance drop on CIFAR-10.1 comparing to CIFAR-10, even though there is no human noticeable difference, and Method Accuracy (%) Object recognition task only 62.7 Joint training (Hendrycks et al., 2019a) 63.5 TTT (standard version) 63.8 TTT-Online 64.3 Table 3.Test accuracy (%) on VID-Robust dataset (Shankar et al., 2019). TTT and TTT-Online improve over the baselines. Method Error (%) Object recognition task only 17.4 Joint training (Hendrycks et al., 2019a) 16.7 TTT (standard version) 15.9 Table 4.Test error (%) on CIFAR-10.1 (Recht et al., 2018). TTT is the ï¬rst method to improve the performance of an existing model on this new test set. both have the same human accuracy. This demonstrates how insidious and ubiquitous distribution shifts are, even when researchers strive to minimize them. The distribution shifts from CIFAR-10 to CIFAR-10.1 pose an extremely difï¬cult problem, and no prior work has been able to improve the performance of an existing model on this new test set, probably because: 1) researchers cannot even identify the distribution shifts, let alone describe them mathematically; 2) the samples in CIFAR-10.1 are only revealed at test time; and even if they were revealed during training, the distribution shifts are too subtle, and the sample size is too small, for domain adaptation (Recht et al., 2018). On the original CIFAR-10 test set, the baseline with only object recognition has error 8.9%, and with joint training has 8.1%; comparing to the ï¬rst two rows of Table 4, both suffer the typical performance drop (by a factor of two). TTT yields an improvement of 0.8% (relative improvement of 4.8%) over joint training. We recognize that this improve- ment is small relative to the performance drop, but see it as an encouraging ï¬rst step for this very difï¬cult problem.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts 0 10 20 30 40 50 60 Gradient inner product 0 1 2 3 4 5Improvement (%) Level 5 Level 4 Level 3 Level 2 Level 1 0 10 20 30 40 50 60 Gradient inner product 0 5 10 15 20 25 30 35Improvement (%) Level 5 Level 4 Level 3 Level 2 Level 1 Figure 4.Scatter plot of the inner product between the gradients (on the shared feature extractor Î¸e) of the main task lm and the self- supervised task le, and the improvement in test error (%) from Test-Time Training, for the standard (left) and online (right) version. Each point is the average over a test set, and each scatter plot has 75 test sets, from all 15 types of corruptions over ï¬ve levels as described in subsection 3.1. The blue lines and bands are the best linear ï¬ts and the 99% conï¬dence intervals. The linear correlation coefï¬cients are 0.93 and 0.89 respectively, indicating strong positive correlation between the two quantities, as suggested by Theorem 1. 4. Theoretical Results This section contains our preliminary study of when and why Test-Time Training is expected to work. For convex models, we prove that positive gradient correlation between the loss functions leads to better performance on the main task after Test-Time Training. Equipped with this insight, we then empirically demonstrate that gradient correlation governs the success of Test-Time Training on the deep learning model discussed in Section 3. Before stating our main theoretical result, we ï¬rst illustrate the general intuition with a toy model. Consider a regression problem where xâˆˆRd denotes the input, y1 âˆˆR denotes the label, and the objective is the square loss (Ë†yâˆ’y1)2/2 for a prediction Ë†y. Consider a two layer linear network parametrized by AâˆˆRhÃ—d and v âˆˆRh (where hstands for the hidden dimension). The prediction according to this model is Ë†y= vâŠ¤Ax, and the main task loss is lm(x,y1; A,v) = 1 2 ( y1 âˆ’vâŠ¤Ax )2 . (4) In addition, consider a self-supervised regression task that also uses the square loss and automatically generates a label ys for x. Let the self-supervised head be parametrized by wâˆˆRh. Then the self-supervised task loss is ls(x,y2; A,w) = 1 2 ( y2 âˆ’wâŠ¤Ax )2 . (5) Now we apply Test-Time Training to update the shared feature extractor Aby one step of gradient descent on ls, which we can compute with y2 known. This gives us Aâ€²â†Aâˆ’Î· ( y2 âˆ’wâŠ¤Ax )( âˆ’wxâŠ¤) , (6) where Aâ€²is the updated matrix and Î·is the learning rate. If we set Î·= Î·âˆ—where Î·âˆ—= y1 âˆ’vâŠ¤Ax (y2 âˆ’wâŠ¤Ax) vâŠ¤wxâŠ¤x, (7) then with some simple algebra, it is easy to see that the main task loss lm(x,y1; Aâ€²,v) = 0. Concretely, Test-Time Training drives the main task loss down to zero with a single gradient step for a carefully chosen learning rate. In prac- tice, this learning rate is unknown since it depends on the unknown y1. However, since our model is convex, as long as Î·âˆ—is positive, it sufï¬ces to set Î· to be a small positive constant (see details in the appendix). If xÌ¸= 0, one sufï¬- cient condition for Î·âˆ—to be positive (when neither loss is zero) is to have sign ( y1 âˆ’vâŠ¤Ax ) = sign ( y2 âˆ’wâŠ¤Ax ) (8) and vâŠ¤w>0 . (9) For our toy model, both parts of the condition above have an intuition interpretation. The ï¬rst part says that the mistakes should be correlated, in the sense that predictions from both tasks are mistaken in the same direction. The second part, vâŠ¤w>0, says that the decision boundaries on the feature space should be correlated. In fact, these two parts hold iff. âŸ¨âˆ‡lm(A),âˆ‡ls(A)âŸ©>0 (see a simple proof of this fact in the appendix). To summarize, if the gradients have positive correlation, Test-Time Training is guaranteed to reduce the main task loss. Our main theoretical result extends this to general smooth and convex loss functions.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Theorem 1. Let lm(x,y; Î¸) denote the main task loss on test instance x,y with parameters Î¸, and ls(x; Î¸) the self- supervised task loss that only depends onx. Assume that for all x,y, lm(x,y; Î¸) is differentiable, convex andÎ²-smooth in Î¸, and both âˆ¥âˆ‡lm(x,y; Î¸)âˆ¥,âˆ¥âˆ‡ls(x,Î¸)âˆ¥â‰¤ Gfor all Î¸. With a ï¬xed learning rate Î·= Ïµ Î²G2 , for every x,y such that âŸ¨âˆ‡lm(x,y; Î¸),âˆ‡ls(x; Î¸)âŸ©>Ïµ, (10) we have lm(x,y; Î¸) >lm(x,y; Î¸(x)), (11) where Î¸(x) = Î¸âˆ’Î·âˆ‡ls(x; Î¸) i.e. Test-Time Training with one step of gradient descent. The proof uses standard techniques in optimization, and is left for the appendix. Theorem 1 reveals gradient correlation as a determining factor of the success of Test-Time Training in the smooth and convex case. In Figure 4, we empirically show that our insight also holds for non-convex loss func- tions, on the deep learning model and across the diverse set of corruptions considered in Section 3; stronger gradient cor- relation clearly indicates more performance improvement over the baseline. 5. Related Work Learning on test instances. Shocher et al. (2018) pro- vide a key inspiration for our work by showing that image super-resolution could be learned at test time simply by try- ing to upsample a downsampled version of the input image. More recently, Bau et al. (2019) improve photo manipula- tion by adapting a pre-trained GAN to the statistics of the input image. One of the earlier examples of this idea comes from Jain & Learned-Miller (2011), who improve Viola- Jones face detection (Viola et al., 2001) by bootstrapping the more difï¬cult faces in an image from the more easily detected faces in that same image. The online version of our algorithm is inspired by the work of Mullapudi et al. (2018), which makes video segmentation more efï¬cient by using a student model that learns online from a teacher model. The idea of online updates has also been used in Kalal et al. (2011) for tracking and detection. A recent work in echocardiography (Zhu et al., 2019) improves the deep learning model that tracks myocardial motion and cardiac blood ï¬‚ow with sequential updates. Lastly, we share the philosophy of transductive learning (Vapnik, 2013; Gam- merman et al., 1998), but have little in common with their classical algorithms; recent work by Tripuraneni & Mackey (2019) theoretically explores this for linear prediction, in the context of debiasing the LASSO estimator. Self-supervised learning studies how to create labels from the data, by designing various pretext tasks that can learn semantic information without human annotations, such as context prediction (Doersch et al., 2015), solving jig- saw puzzles (Noroozi & Favaro, 2016), colorization (Lars- son et al., 2017; Zhang et al., 2016), noise prediction (Bo- janowski & Joulin, 2017), feature clustering (Caron et al., 2018). Our paper uses rotation prediction (Gidaris et al., 2018). Asano et al. (2019) show that self-supervised learn- ing on only a single image, surprisingly, can produce low- level features that generalize well. Closely related to our work, Hendrycks et al. (2019a) propose that jointly training a main task and a self-supervised task (our joint training baseline in Section 3) can improve robustness on the main task. The same idea is used in few-shot learning (Su et al., 2019), domain generalization (Carlucci et al., 2019), and unsupervised domain adaptation (Sun et al., 2019). Adversarial robustness studies the robust risk RP,âˆ†(Î¸) = Ex,yâˆ¼P maxÎ´âˆˆâˆ† l(x + Î´,y; Î¸), where l is some loss function, and âˆ† is the set of perturbations; âˆ† is often chosen as the Lp ball, for p âˆˆ{1,2,âˆž}. Many popular algorithms formulate and solve this as a robust optimization problem (Goodfellow et al., 2014; Madry et al., 2017; Sinha et al., 2017; Raghunathan et al., 2018; Wong & Kolter, 2017; Croce et al., 2018), and the most well known technique is adversarial training. Another line of work is based on randomized smoothing (Cohen et al., 2019; Salman et al., 2019), while some other approaches, such as input transformations (Guo et al., 2017; Song et al., 2017), are shown to be less effective (Athalye et al., 2018). There are two main problems with the approaches above. First, all of them can be seen as smoothing the decision boundary. This establishes a theoretical tradeoff between accuracy and robustness (Tsipras et al., 2018; Zhang et al., 2019), which we also observe empirically with our adversarial training baseline in Section 3. Intuitively, the more diverse âˆ† is, the less effective this one-boundary-ï¬ts-all approach can be for a particular element of âˆ†. Second, adversarial methods rely heavily on the mathematical structure of âˆ†, which might not accurately model perturbations in the real world. Therefore, generalization remains hard outside of the âˆ† we know in advance or can mathematically model, especially for non-adversarial distribution shifts. Empirically, Kang et al. (2019) shows that robustness for one âˆ† might not transfer to another, and training on the Lâˆžball actually hurts robustness on the L1 ball. Non-adversarial robustness studies the effect of corrup- tions, perturbations, out-of-distribution examples, and real- world distribution shifts (Hendrycks et al., 2019b;a; 2018; Hendrycks & Gimpel, 2016). Geirhos et al. (2018) show that training on images corrupted by Gaussian noise makes deep learning models robust to this particular noise type, but does not improve performance on images corrupted by another noise type e.g. salt-and-pepper noise.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Unsupervised domain adaptation (a.k.a. transfer learn- ing) studies the problem of distribution shifts, when an unlabeled dataset from the test distribution (target domain) is available at training time, in addition to a labeled dataset from the training distribution (source domain) (Chen et al., 2011; Gong et al., 2012; Long et al., 2015; Ganin et al., 2016; Long et al., 2016; Tzeng et al., 2017; Hoffman et al., 2017; Csurka, 2017; Chen et al., 2018). The limitation of the problem setting, however, is that generalization might only be improved for this speciï¬c test distribution, which can be difï¬cult to anticipate in advance. Prior work try to anticipate broader distributions by using multiple and evolv- ing domains (Hoffman et al., 2018; 2012; 2014). Test-Time Training does not anticipate any test distribution, by chang- ing the setting of unsupervised domain adaptation, while taking inspiration from its algorithms. Our paper is a follow- up to Sun et al. (2019), which we explain and empirically compare with in Section 3. Our update rule can be viewed as performing one-sample unsupervised domain adaptation on the ï¬‚y, with the caveat that standard domain adaptation techniques might become ill-deï¬ned when there is only one sample from the target domain. Domain generalization studies the setting where a meta distribution generates multiple environment distributions, some of which are available during training (source), while others are used for testing (target) (Li et al., 2018; Shankar et al., 2018; Muandet et al., 2013; Balaji et al., 2018; Ghifary et al., 2015; Motiian et al., 2017; Li et al., 2017a; Gan et al., 2016). With only a few environments, information on the meta distribution is often too scarce to be helpful, and with many environments, we are back to the i.i.d. setting where each environment can be seen as a sample, and a strong baseline is to simply train on all the environments (Li et al., 2019). The setting of domain generalization is limited by the inherent tradeoff between speciï¬city and generality of a ï¬xed decision boundary, and the fact that generalization is again elusive outside of the meta distribution i.e. the actual P learned by the algorithm. One (few)-shot learning studies how to learn a new task or a new classiï¬cation category using only one (or a few) sample(s), on top of a general representation that has been learned on diverse samples (Snell et al., 2017; Vinyals et al., 2016; Fei-Fei et al., 2006; Ravi & Larochelle, 2016; Li et al., 2017b; Finn et al., 2017; Gidaris & Komodakis, 2018). Our update rule can be viewed as performing one-shot self- supervised learning and can potentially be improved by progress in one-shot learning. Continual learning (a.k.a. learning without forgetting) studies the setting where a model is made to learn a sequence of tasks, and not forget about the earlier ones while training for the later (Li & Hoiem, 2017; Lopez-Paz & Ranzato, 2017; Kirkpatrick et al., 2017; Santoro et al., 2016). In contrast, with Test-Time Training, we are not concerned about forgetting the past test samples since they have already been evaluated on; and if a past sample comes up by any chance, it would go through Test-Time Training again. In addition, the impact of forgetting the training set is minimal, because both tasks have already been jointly trained. Online learning (a.k.a. online optimization) is a well- studied area of learning theory (Shalev-Shwartz et al., 2012; Hazan et al., 2016). The basic setting repeats the following: receive xt, predict Ë†yt, receive yt from a worst-case oracle, and learn. Final performance is evaluated using the regret, which colloquially translates to how much worse the online learning algorithm performs in comparison to the best ï¬xed model in hindsight. In contrast, our setting never reveals any yt during testing even for the online version, so we do not need to invoke the concept of the worst-case oracle or the regret. Also, due to the lack of feedback from the envi- ronment after predicting, our algorithm is motivated to learn (with self-supervision) before predicting Ë†yt instead of after. Note that some of the previously covered papers (Hoffman et al., 2014; Jain & Learned-Miller, 2011; Mullapudi et al., 2018) use the term â€œonline learningâ€ outside of the learning theory setting, so the term can be overloaded. 6. Discussion The idea of test-time training also makes sense for other tasks, such as segmentation and detection, and in other ï¬elds, such as speech recognition and natural language process- ing. For machine learning practitioners with prior domain knowledge in their respective ï¬elds, their expertise can be leveraged to design better special-purpose self-supervised tasks for test-time training. Researchers for general-purpose self-supervised tasks can also use test-time training as an evaluation benchmark, in addition to the currently prevalent benchmark of pre-training and ï¬ne-tuning. More generally, we hope this paper can encourage re- searchers to abandon the self-imposed constraint of a ï¬xed decision boundary for testing, or even the artiï¬cial division between training and testing altogether. Our work is but a small step toward a new paradigm where much of the learning happens after a model is deployed. Acknowledgements. This work is supported by NSF grant 1764033, DARPA and Berkeley DeepDrive. This paper took a long time to develop, and beneï¬ted from con- versations with many of our colleagues, including Ben Recht and his students Ludwig Schmidt, Vaishaal Shanker and Becca Roelofs; Ravi Teja Mullapudi, Achal Dave and Deva Ramanan; and Armin Askari, Allan Jabri, Ashish Kumar, Angjoo Kanazawa and Jitendra Malik.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts References Asano, Y . M., Rupprecht, C., and Vedaldi, A. Surprising effectiveness of few-image unsupervised feature learning. arXiv preprint arXiv:1904.13132, 2019. Athalye, A., Carlini, N., and Wagner, D. Obfuscated gradients give a false sense of security: Circumvent- ing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018. Balaji, Y ., Sankaranarayanan, S., and Chellappa, R. Metareg: Towards domain generalization using meta-regularization. In Advances in Neural Information Processing Systems, pp. 998â€“1008, 2018. Bau, D., Strobelt, H., Peebles, W., Wulff, J., Zhou, B., Zhu, J.-Y ., and Torralba, A. Semantic photo manipulation with a generative image prior. ACM Transactions on Graphics (TOG), 38(4):59, 2019. Bojanowski, P. and Joulin, A. Unsupervised learning by predicting noise. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 517â€“ 526. JMLR. org, 2017. Carlucci, F. M., Dâ€™Innocente, A., Bucci, S., Caputo, B., and Tommasi, T. Domain generalization by solving jigsaw puzzles. In Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition , pp. 2229â€“2238, 2019. Caron, M., Bojanowski, P., Joulin, A., and Douze, M. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 132â€“149, 2018. Caruana, R. Multitask learning. Machine learning, 28(1): 41â€“75, 1997. Chen, M., Weinberger, K. Q., and Blitzer, J. Co-training for domain adaptation. In Advances in neural information processing systems, pp. 2456â€“2464, 2011. Chen, X., Sun, Y ., Athiwaratkun, B., Cardie, C., and Wein- berger, K. Adversarial deep averaging networks for cross- lingual sentiment classiï¬cation. Transactions of the Asso- ciation for Computational Linguistics, 6:557â€“570, 2018. Cohen, J. M., Rosenfeld, E., and Kolter, J. Z. Certiï¬ed adversarial robustness via randomized smoothing. arXiv preprint arXiv:1902.02918, 2019. Croce, F., Andriushchenko, M., and Hein, M. Provable robustness of relu networks via maximization of linear regions. arXiv preprint arXiv:1810.07481, 2018. Csurka, G. Domain adaptation for visual applications: A comprehensive survey. arXiv preprint arXiv:1702.05374, 2017. Ding, G. W., Wang, L., and Jin, X. AdverTorch v0.1: An adversarial robustness toolbox based on pytorch. arXiv preprint arXiv:1902.07623, 2019. Doersch, C., Gupta, A., and Efros, A. A. Unsupervised visual representation learning by context prediction. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1422â€“1430, 2015. Fei-Fei, L., Fergus, R., and Perona, P. One-shot learning of object categories. IEEE transactions on pattern analysis and machine intelligence, 28(4):594â€“611, 2006. Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta- learning for fast adaptation of deep networks. In Proceed- ings of the 34th International Conference on Machine Learning-Volume 70, pp. 1126â€“1135. JMLR. org, 2017. Gammerman, A., V ovk, V ., and Vapnik, V . Learning by transduction. In Proceedings of the Fourteenth conference on Uncertainty in artiï¬cial intelligence , pp. 148â€“155. Morgan Kaufmann Publishers Inc., 1998. Gan, C., Yang, T., and Gong, B. Learning attributes equals multi-source domain generalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 87â€“97, 2016. Ganin, Y ., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., and Lempitsky, V . Domain-adversarial training of neural networks. The Journal of Machine Learning Research, 17(1):2096â€“2030, 2016. Geirhos, R., Temme, C. R., Rauber, J., SchÂ¨utt, H. H., Bethge, M., and Wichmann, F. A. Generalisation in humans and deep neural networks. In Advances in Neural Information Processing Systems, pp. 7538â€“7550, 2018. Ghifary, M., Bastiaan Kleijn, W., Zhang, M., and Balduzzi, D. Domain generalization for object recognition with multi-task autoencoders. In Proceedings of the IEEE international conference on computer vision, pp. 2551â€“ 2559, 2015. Gidaris, S. and Komodakis, N. Dynamic few-shot visual learning without forgetting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4367â€“4375, 2018. Gidaris, S., Singh, P., and Komodakis, N. Unsupervised rep- resentation learning by predicting image rotations. arXiv preprint arXiv:1803.07728, 2018. Gong, B., Shi, Y ., Sha, F., and Grauman, K. Geodesic ï¬‚ow kernel for unsupervised domain adaptation. In2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2066â€“2073. IEEE, 2012.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Goodfellow, I. J., Shlens, J., and Szegedy, C. Explain- ing and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014. Guo, C., Rana, M., Cisse, M., and van der Maaten, L. Coun- tering adversarial images using input transformations. arXiv preprint arXiv:1711.00117, 2017. Hazan, E. et al. Introduction to online convex optimization. Foundations and TrendsÂ® in Optimization, 2(3-4):157â€“ 325, 2016. He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn- ing for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770â€“778, 2016a. He, K., Zhang, X., Ren, S., and Sun, J. Identity mappings in deep residual networks. In European conference on computer vision, pp. 630â€“645. Springer, 2016b. He, K., Girshick, R., and Doll Â´ar, P. Rethinking imagenet pre-training. arXiv preprint arXiv:1811.08883, 2018. Hendrycks, D. and Dietterich, T. Benchmarking neural network robustness to common corruptions and perturba- tions. arXiv preprint arXiv:1903.12261, 2019. Hendrycks, D. and Gimpel, K. A baseline for detecting misclassiï¬ed and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136, 2016. Hendrycks, D., Mazeika, M., Wilson, D., and Gimpel, K. Using trusted data to train deep networks on labels cor- rupted by severe noise. InAdvances in neural information processing systems, pp. 10456â€“10465, 2018. Hendrycks, D., Lee, K., and Mazeika, M. Using pre-training can improve model robustness and uncertainty. arXiv preprint arXiv:1901.09960, 2019a. Hendrycks, D., Mazeika, M., Kadavath, S., and Song, D. Improving model robustness and uncertainty estimates with self-supervised learning. arXiv preprint, 2019b. Hoffman, J., Kulis, B., Darrell, T., and Saenko, K. Discover- ing latent domains for multisource domain adaptation. In European Conference on Computer Vision, pp. 702â€“715. Springer, 2012. Hoffman, J., Darrell, T., and Saenko, K. Continuous man- ifold based adaptation for evolving visual domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 867â€“874, 2014. Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y ., Isola, P., Saenko, K., Efros, A. A., and Darrell, T. Cycada: Cycle- consistent adversarial domain adaptation. arXiv preprint arXiv:1711.03213, 2017. Hoffman, J., Mohri, M., and Zhang, N. Algorithms and theory for multiple-source adaptation. In Advances in Neural Information Processing Systems, pp. 8246â€“8256, 2018. Huang, G., Sun, Y ., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. In European conference on computer vision, pp. 646â€“661. Springer, 2016. Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. Jain, V . and Learned-Miller, E. Online domain adaptation of a pre-trained cascade of classiï¬ers. In CVPR 2011, pp. 577â€“584. IEEE, 2011. Kalal, Z., Mikolajczyk, K., and Matas, J. Tracking-learning- detection. IEEE transactions on pattern analysis and machine intelligence, 34(7):1409â€“1422, 2011. Kang, D., Sun, Y ., Brown, T., Hendrycks, D., and Steinhardt, J. Transfer of adversarial robustness between perturbation types. arXiv preprint arXiv:1905.01034, 2019. Kannan, H., Kurakin, A., and Goodfellow, I. Adversarial logit pairing. arXiv preprint arXiv:1803.06373, 2018. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Des- jardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521â€“3526, 2017. Krizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009. Larsson, G., Maire, M., and Shakhnarovich, G. Colorization as a proxy task for visual understanding. In CVPR, 2017. Li, D., Yang, Y ., Song, Y .-Z., and Hospedales, T. M. Deeper, broader and artier domain generalization. In Proceed- ings of the IEEE International Conference on Computer Vision, pp. 5542â€“5550, 2017a. Li, D., Zhang, J., Yang, Y ., Liu, C., Song, Y .-Z., and Hospedales, T. M. Episodic training for domain gen- eralization. arXiv preprint arXiv:1902.00113, 2019. Li, Y ., Tian, X., Gong, M., Liu, Y ., Liu, T., Zhang, K., and Tao, D. Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 624â€“639, 2018.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Li, Z. and Hoiem, D. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935â€“2947, 2017. Li, Z., Zhou, F., Chen, F., and Li, H. Meta-sgd: Learning to learn quickly for few-shot learning. arXiv preprint arXiv:1707.09835, 2017b. Liu, Z., Sun, M., Zhou, T., Huang, G., and Darrell, T. Re- thinking the value of network pruning. arXiv preprint arXiv:1810.05270, 2018. Long, M., Cao, Y ., Wang, J., and Jordan, M. I. Learn- ing transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015. Long, M., Zhu, H., Wang, J., and Jordan, M. I. Unsupervised domain adaptation with residual transfer networks. In Advances in Neural Information Processing Systems, pp. 136â€“144, 2016. Lopez-Paz, D. and Ranzato, M. Gradient episodic memory for continual learning. In Advances in Neural Information Processing Systems, pp. 6467â€“6476, 2017. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 , 2017. Motiian, S., Piccirilli, M., Adjeroh, D. A., and Doretto, G. Uniï¬ed deep supervised domain adaptation and gen- eralization. In Proceedings of the IEEE International Conference on Computer Vision, pp. 5715â€“5725, 2017. Muandet, K., Balduzzi, D., and Sch Â¨olkopf, B. Domain generalization via invariant feature representation. In International Conference on Machine Learning, pp. 10â€“ 18, 2013. Mullapudi, R. T., Chen, S., Zhang, K., Ramanan, D., and Fatahalian, K. Online model distillation for efï¬cient video inference. arXiv preprint arXiv:1812.02699, 2018. Noroozi, M. and Favaro, P. Unsupervised learning of visual representations by solving jigsaw puzzles. In European Conference on Computer Vision , pp. 69â€“84. Springer, 2016. Raghunathan, A., Steinhardt, J., and Liang, P. Certiï¬ed defenses against adversarial examples. arXiv preprint arXiv:1801.09344, 2018. Ravi, S. and Larochelle, H. Optimization as a model for few-shot learning. IEEE transactions on pattern analysis and machine intelligence, 2016. Recht, B., Roelofs, R., Schmidt, L., and Shankar, V . Do cifar-10 classiï¬ers generalize to cifar-10? arXiv preprint arXiv:1806.00451, 2018. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) , 115(3):211â€“252, 2015. doi: 10.1007/s11263-015-0816-y. Salman, H., Yang, G., Li, J., Zhang, P., Zhang, H., Razen- shteyn, I., and Bubeck, S. Provably robust deep learn- ing via adversarially trained smoothed classiï¬ers. arXiv preprint arXiv:1906.04584, 2019. Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., and Lillicrap, T. Meta-learning with memory-augmented neu- ral networks. In International conference on machine learning, pp. 1842â€“1850, 2016. Shalev-Shwartz, S. et al. Online learning and online con- vex optimization. Foundations and TrendsÂ® in Machine Learning, 4(2):107â€“194, 2012. Shankar, S., Piratla, V ., Chakrabarti, S., Chaudhuri, S., Jyothi, P., and Sarawagi, S. Generalizing across domains via cross-gradient training. arXiv preprint arXiv:1804.10745, 2018. Shankar, V ., Dave, A., Roelofs, R., Ramanan, D., Recht, B., and Schmidt, L. Do image classiï¬ers generalize across time? arXiv, 2019. Shocher, A., Cohen, N., and Irani, M. zero-shot super- resolution using deep internal learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3118â€“3126, 2018. Sinha, A., Namkoong, H., and Duchi, J. Certifying some dis- tributional robustness with principled adversarial training. arXiv preprint arXiv:1710.10571, 2017. Snell, J., Swersky, K., and Zemel, R. Prototypical networks for few-shot learning. In Advances in Neural Information Processing Systems, pp. 4077â€“4087, 2017. Song, Y ., Kim, T., Nowozin, S., Ermon, S., and Kushman, N. Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. arXiv preprint arXiv:1710.10766, 2017. Su, J.-C., Maji, S., and Hariharan, B. Boosting supervi- sion with self-supervision for few-shot learning. arXiv preprint arXiv:1906.07079, 2019. Sun, Y ., Tzeng, E., Darrell, T., and Efros, A. A. Unsuper- vised domain adaptation through self-supervision. arXiv preprint, 2019.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Tripuraneni, N. and Mackey, L. Debiasing linear prediction. arXiv preprint arXiv:1908.02341, 2019. Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A. Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018. Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T. Adver- sarial discriminative domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167â€“7176, 2017. Vapnik, V .The nature of statistical learning theory. Springer science & business media, 2013. Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. In Advances in neural information processing systems, pp. 3630â€“3638, 2016. Viola, P., Jones, M., et al. Rapid object detection using a boosted cascade of simple features. CVPR (1), 1(511- 518):3, 2001. Wong, E. and Kolter, J. Z. Provable defenses against adver- sarial examples via the convex outer adversarial polytope. arXiv preprint arXiv:1711.00851, 2017. Zhang, H., Yu, Y ., Jiao, J., Xing, E. P., Ghaoui, L. E., and Jor- dan, M. I. Theoretically principled trade-off between ro- bustness and accuracy. arXiv preprint arXiv:1901.08573, 2019. Zhang, R., Isola, P., and Efros, A. A. Colorful image col- orization. In European conference on computer vision, pp. 649â€“666. Springer, 2016. Zhu, W., Huang, Y ., Vannan, M. A., Liu, S., Xu, D., Fan, W., Qian, Z., and Xie, X. Neural multi-scale self-supervised registration for echocardiogram dense tracking. arXiv preprint arXiv:1906.07357, 2019.Appendix: Test-Time Training with Self-Supervision for Generalization under Distribution Shifts A1. Informal Discussion on Our Variable Decision Boundary In the introduction, we claim that in traditional supervised learning Î¸gives a ï¬xed decision boundary, while ourÎ¸gives a variable decision boundary. Here we informally discuss this claim. Denote the input space Xand output space Y. A decision boundary is simply a mapping f : X â†’Y. Let Î˜ be a model class e.g Rd. Now consider a family of parametrized functions gÎ¸ : Xâ†’Y , where Î¸âˆˆÎ˜. In the context of deep learning, gis the neural network architecture and Î¸contains the parameters. We say that f is a ï¬xed decision boundary w.r.t. g and Î˜ if there exists Î¸ âˆˆÎ˜ s.t. f(x) = gÎ¸(x) for every x âˆˆX , and a variable decision boundary if for every xâˆˆX, there exists Î¸âˆˆÎ˜ s.t. f(x) = gÎ¸(x). Note how selection of Î¸can depend on xfor a variable decision boundary, and cannot for a ï¬xed one. It is then trivial to verify that our claim is true under those deï¬nitions. A critical reader might say that with an arbitrarily large model class, canâ€™t every decision boundary be ï¬xed? Yes, but this is not the end of the story. Let d = dim( X) Ã— dim(Y), and consider the enormous model class Î˜â€²= Rd which is capable of representing all possible mappings be- tween Xand Y. Let gâ€² Î¸â€² simply be the mapping represented by Î¸â€² âˆˆÎ˜â€². A variable decision boundary w.r.t. g and Î˜ then indeed must be a ï¬xed decision boundary w.r.t. gâ€²and Î˜â€², but we would like to note two things. First, without any prior knowledge, generalization in Î˜â€²is impossible with any ï¬nite amount of training data; reasoning about gâ€²and Î˜â€²is most likely not productive from an algorithmic point of view, and the concept of a variable decision boundary is to avoid such reasoning. Second, selecting Î¸based on xfor a variable decision boundary can be thought of as â€œtrainingâ€ on all points x âˆˆRd; however, â€œtrainingâ€ only happens when necessary, for the xthat it actually encounters. Altogether, the concept of a variable decision boundary is different from what can be described by traditional learning theory. A formal discussion is beyond the scope of this paper and might be of interest to future work. A2. Computational Aspects of Our Method At test time, our method is 2 Ã— batch size Ã— number of iterations times slower than regular test- ing, which only performs a single forward pass for each sample. As the ï¬rst work on Test-Time Training, this paper is not as concerned about computational efï¬ciency as improving robustness, but here we provide two poten- tial solutions that might be useful, but have not been thor- oughly veriï¬ed. The ï¬rst is to use the thresholding trick on ls, introduced as a solution for the small batches prob- lem in the method section. For the models considered in our experiments, roughly 80% of the test instances fall below the threshold, so Test-Time Training can only be performed on the other 20% without much effect on per- formance, because those 20% contain most of the sam- ples with wrong predictions. The second is to reduce the number of iterations of test-time updates. For the online version, the number of iterations is al- ready 1, so there is nothing to do. For the standard ver- sion, we have done some preliminary experiments setting number of iterations to 1 (instead of 10) and learn- ing rate to 0.01 (instead of 0.001), and observing results almost as good as the standard hyper-parameter setting. A more in depth discussion on efï¬ciency is left for future works, which might, during training, explicitly make the model amenable to fast updates. A3. Proofs Here we prove the theoretical results in the main paper. A3.1. The Toy Problem The following setting applies to the two lemmas; this is simply the setting of our toy problem, reproduced here for ease of reference.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Consider a two layer linear network parametrized by Aâˆˆ RhÃ—d (shared) and v,w âˆˆRh (ï¬xed) for the two heads, respectively. Denote xâˆˆRd the input and y1,y2 âˆˆR the labels for the two tasks, respectively. For the main task loss lm(A; v) = 1 2 ( y1 âˆ’vâŠ¤Ax )2 , (12) and the self-supervised task loss ls(A; w) = 1 2 ( y2 âˆ’wâŠ¤Ax )2 , (13) Test-Time Training yields an updated matrix Aâ€²â†Aâˆ’Î· ( y2 âˆ’wâŠ¤Ax )( âˆ’wxâŠ¤) , (14) where Î·is the learning rate. Lemma 1. Following the exposition of the main paper, let Î·âˆ—= (y1 âˆ’vâŠ¤Ax) (y2 âˆ’wâŠ¤Ax)vâŠ¤wxâŠ¤x. (15) Assume Î·âˆ—âˆˆ[Ïµ,âˆž) for some Ïµ> 0. Then for any Î·âˆˆ(0,Ïµ], we are guaranteed an improvement on the main loss i.e. lm(Aâ€²) <lm(A). Proof. From the exposition of the main paper, we know that lm(Aâˆ’Î·âˆ—âˆ‡lsA)) = 0, which can also be derived from simple algebra. Then by convexity, we have lm(Aâˆ’Î·âˆ‡ls(A)) (16) = lm (( 1 âˆ’ Î· Î·âˆ— ) A+ Î· Î·âˆ—(Aâˆ’Î·âˆ—âˆ‡ls(A)) ) (17) â‰¤ ( 1 âˆ’ Î· Î·âˆ— ) lm(A) + 0 (18) â‰¤ ( 1 âˆ’Î· Ïµ ) lm(A) (19) <lm(A), (20) where the last inequality uses the assumption that lm(A) > 0, which holds because Î·âˆ—>0. Lemma 2. Deï¬ne âŸ¨U,VâŸ©= vec (U)âŠ¤vec (V) i.e. the Frobenious inner product, then sign (Î·âˆ—) = sign (âŸ¨âˆ‡lm(A),âˆ‡ls(A)âŸ©) . (21) Proof. By simple algebra, âŸ¨âˆ‡lm(A),âˆ‡ls(A)âŸ© = âŸ¨ ( y1 âˆ’vâŠ¤Ax )( âˆ’vxâŠ¤) , ( y2 âˆ’wâŠ¤Ax )( âˆ’wxâŠ¤) âŸ© = ( y1 âˆ’vâŠ¤Ax )( y2 âˆ’wâŠ¤Ax ) Tr ( xvâŠ¤wxâŠ¤) = ( y1 âˆ’vâŠ¤Ax )( y2 âˆ’wâŠ¤Ax ) vâŠ¤wxâŠ¤x, which has the same sign as Î·âˆ—. A3.2. Proof of Theorem 1 For any Î·, by smoothness and convexity, lm(x,y; Î¸(x)) = lm(x,y; Î¸âˆ’Î·âˆ‡ls(x; Î¸)) â‰¤lm(x,y; Î¸) + Î·âŸ¨âˆ‡lm(x,y; Î¸),âˆ‡ls(x,Î¸)âŸ© + Î·2Î² 2 âˆ¥âˆ‡ls(x; Î¸)âˆ¥2 . Denote Î·âˆ—= âŸ¨âˆ‡lm(x,y; Î¸),âˆ‡ls(x,Î¸)âŸ© Î²âˆ¥âˆ‡ls(x; Î¸)âˆ¥2 . Then Equation 22 becomes lm(x,y; Î¸âˆ’Î·âˆ—âˆ‡ls(x; Î¸)) (22) â‰¤lm(x,y; Î¸) âˆ’âŸ¨âˆ‡lm(x,y; Î¸),âˆ‡ls(x,Î¸)âŸ©2 2Î²âˆ¥âˆ‡ls(x; Î¸)âˆ¥2 . (23) And by our assumptions on the gradient norm and gradient inner product, lm(x,y; Î¸) âˆ’lm(x,y; Î¸âˆ’Î·âˆ—âˆ‡ls(x; Î¸)) â‰¥ Ïµ2 2Î²G2 . (24) Because we cannot observe Î·âˆ—in practice, we instead use a ï¬xed learning rate Î· = Ïµ Î²G2 , as stated in Theorem 1. Now we argue that this ï¬xed learning rate still improves performance on the main task. By our assumptions, Î·âˆ— â‰¥ Ïµ Î²G2 , so Î· âˆˆ(0,Î·âˆ—]. Denote g= âˆ‡ls(x; Î¸), then by convexity of lm, lm(x,y; Î¸(x)) = lm(x,y; Î¸âˆ’Î·g) (25) = lm ( x,y; ( 1 âˆ’ Î· Î·âˆ— ) Î¸+ Î· Î·âˆ—(Î¸âˆ’Î·âˆ—g) ) (26) â‰¤ ( 1 âˆ’ Î· Î·âˆ— ) lm(x,y; Î¸) + Î· Î·âˆ—lm(x,y; Î¸âˆ’Î·âˆ—g) (27) Combining with Equation 24, we have lm(x,y; Î¸(x)) â‰¤ ( 1 âˆ’ Î· Î·âˆ— ) lm(x,y; Î¸) + Î· Î·âˆ— ( lm(x,y; Î¸) âˆ’ Ïµ2 2Î²G2 ) = lm(x,y; Î¸) âˆ’ Î· Î·âˆ— Ïµ2 2Î²G2 Since Î·/Î·âˆ—>0, we have shown that lm(x,y; Î¸) âˆ’lm(x,y; Î¸(x)) >0. (28)Test-Time Training with Self-Supervision for Generalization under Distribution Shifts A4. Additional Results on the Common Corruptions Dataset For table aethetics, we use the following abbreviations: B for baseline, JT for joint training, TTT for Test-Time Train- ing standard version, and TTT-Online for online Test-Time Training i.e. the online version. We have abbreviated the names of the corruptions, in order: original test set, Gaussian noise, shot noise, impulse noise, defocus blur, glass blue, motion blur, zoom blur, snow, frost, fog, brightness, contrast, elastic transformation, pixelation, and JPEG compression. A4.1. Results Using Batch Normalization As discussed in the results section, Batch Normalization (BN) is ineffective for small batches, which are the inputs for Test-Time Training (both standard and online version) since there is only one sample available when forming each batch; therefore, our main results are based on a ResNet using Group Normalization (GN). Figure A2 and Table A1 show results of our method on CIFAR-10-C level 5, with a ResNet using Batch Normalization (BN). These results are only meant to be a point of reference for the curious readers. In the early stage of this project, we have experimented with two potential solutions to the small batches problem with BN. The naive solution is to ï¬x the BN layers during Test-Time Training. but this diminishes the performance gains since there are fewer shared parameters. The better solution, adopted for the results below, is hard example mining: instead of updating on all inputs, we only update on inputs that incur large self-supervised task loss ls, where the large improvements might counter the negative effects of inaccurate statistics. Test-Time Training (standard version) is still very effective with BN. In fact, some of the improvements are quite dra- matic, such as on contrast (34%), defocus blue (18%) and Gaussian noise (22% comparing to joint-training, and 16% comparing to the baseline). Performance on the original distribution is still almost the same, and the original error with BN is in fact slightly lower than with GN, and takes half as many epochs to converge. We did not further experiment with BN because of two rea- sons: 1) The online version does not work with BN, because the problem with inaccurate batch statistics is exacerbated when training online for many (e.g. 10000) steps. 2) The baseline error for almost every corruption type is signiï¬- cantly higher with BN than with GN. Although unrelated to the main idea of our paper, we make the interesting note that GN signiï¬cantly improves model robustness. A4.2. Additional Baseline: Adversarial Logit Pairing As discussed in the results section, Hendrycks & Dietterich (2019) point to Adversarial Logit Pairing (ALP) (Kannan et al., 2018) as an effective method for improving model robustness to corruptions and perturbations, even though it was designed to defend against adversarial attacks. We take ALP as an additional baseline on all benchmarks based on CIFAR-10 (using GN), following the training proce- dure in Kannan et al. (2018) and their recommended hyper- parameters. The implementation of the adversarial attack comes from the codebase of Ding et al. (2019). We did not run ALP on ImageNet because the two papers we reference for this method, Kannan et al. (2018) and Hendrycks & Di- etterich (2019), did not run on ImageNet or make any claim or recommendation. A4.3. Results on CIFAR-10-C and ImageNet-C, Level 5 Table A2 and Table A3 correspond to the bar plots in the results section. Two rows of Table A2 have been presented as Table 1 in the main text. A4.4. Results on CIFAR-10-C, Levels 1-4 The following bar plots and tables are on levels 1-4 of CIFAR-10-C. The original distribution is the same for all levels, so are our results on the original distribution. A4.5. Direct Comparison with Hendrycks et al. (2019a) The following comparison has been requested by an anony- mous reviewer for our ï¬nal version. Our joint training baseline is based on Hendrycks et al. (2019a), but also incor- porates some architectural changes (see below). We found these changes improved the robustness of our method, and felt that it was important to give the baseline the same ben- eï¬t. Note that our joint training baseline overall performs better than Hendrycks: Compare Table S2 to Figure 3 of Hendrycks et al. (2019a) (provided by the authors), our baseline has average error of 22.8% across all corruptions and levels, while their average error is 28.6%. Summary of architectural changes: 1) Group Normalization (GN) instead of Batch Normalization (BN). For complete- ness, the results with BN are provided in Table S1; c.f. GN results in Table S2 which signiï¬cantly improves robustness, with or without self-supervision. 2) We split after the sec- ond residual group, while they split after the third residual group right before the linear layer. This consistently gives about 0.5% - 1% improvement. 3) We use a ResNet-26, while they use a 40-2 Wide ResNet. But our baseline still performs better than their method even though our network is 4x smaller, due to the two tricks above.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Gaussian Noise  Shot Noise  Impulse Noise  Defocus Blur  Frosted Glass Blur Motion Blur  Zoom Blur  Snow  Frost  Fog Brightness  Contrast  Elastic  Pixelate  JPEG Figure A1.Sample images from the Common Corruptions Benchmark, taken from the original paper by Hendrycks & Dietterich (2019). originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 20 40 60Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT Figure A2.Test error (%) on CIFAR-10-C, level 5, ResNet-26 with Batch Normalization. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 7.9 63.9 58.8 64.3 46.3 54.6 41.6 45.9 31.9 44.0 37.5 13.0 69.2 33.8 61.4 31.7 JT 7.5 70.7 65.6 67.2 43.1 55.4 40.9 42.7 30.3 44.5 42.5 12.7 58.6 30.7 62.6 31.9 TTT 7.9 47.9 45.2 54.8 27.6 50.4 31.5 30.9 28.7 34.3 26.9 12.6 35.2 30.6 51.2 31.3 Table A1.Test error (%) on CIFAR-10-C, level 5, ResNet-26 with Batch Normalization. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 50.5 47.2 56.1 23.7 51.7 24.3 26.3 25.6 34.4 28.1 13.5 25.0 27.4 55.8 29.8 JT 8.1 49.4 45.3 53.4 24.2 48.5 24.8 26.4 25.0 32.5 27.5 12.6 25.3 24.0 51.6 28.7 TTT 7.9 45.6 41.8 50.0 21.8 46.1 23.0 23.9 23.9 30.0 25.1 12.2 23.9 22.6 47.2 27.2 TTT-Online 8.2 25.8 22.6 30.6 14.6 34.4 18.3 17.1 20.0 18.0 16.9 11.2 15.6 21.6 18.1 21.2 UDA-SS 9.0 28.2 26.5 20.8 15.6 43.7 24.5 23.8 25.0 24.9 17.2 12.7 11.6 22.1 20.3 22.6 ALP 16.5 22.7 22.9 28.3 25.0 25.6 27.4 23.1 25.2 27.2 64.8 21.7 73.6 23.0 20.2 18.9 Table A2.Test error (%) on CIFAR-10-C, level 5, ResNet-26. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 68.9 1.3 2.0 1.3 7.5 6.6 11.8 16.2 15.7 14.9 15.3 43.9 9.7 16.5 15.3 23.4 JT 69.1 2.1 3.1 2.1 8.7 6.7 12.3 16.0 15.3 15.8 17.0 45.3 11.0 18.4 19.7 22.9 TTT 69.0 3.1 4.5 3.5 10.1 6.8 13.5 18.5 17.1 17.9 20.0 47.0 14.4 20.9 22.8 25.3 TTT-Online 68.8 26.3 28.6 26.9 23.7 6.6 28.7 33.4 35.6 18.7 47.6 58.3 35.3 44.3 47.8 44.3 Table A3.Test accuracy (%) on ImageNet-C, level 5, ResNet-18.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40 50Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A3.Test error (%) on CIFAR-10-C, level 4. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 46.4 39.2 44.8 15.3 52.5 19.1 20.5 21.3 26.9 13.3 10.5 13.7 20.8 35.3 26.9 JT 8.1 45.0 38.3 42.2 16.4 50.2 20.7 20.5 21.1 25.4 14.1 10.0 14.7 19.0 33.2 25.1 TTT 7.9 41.5 35.4 39.8 15.0 47.8 19.1 18.4 20.1 24.0 13.5 10.0 14.1 17.7 29.4 24.5 TTT-Online 8.2 22.9 20.0 23.9 11.2 35.1 15.6 13.8 18.6 15.9 12.3 9.7 11.9 16.7 13.6 19.8 ALP 16.5 21.3 20.5 24.5 20.7 25.9 23.7 21.4 24.2 23.9 42.2 17.5 53.7 22.1 19.1 18.5 Table A4.Test error (%) on CIFAR-10-C, level 4, ResNet-26. originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A4.Test error (%) on CIFAR-10-C, level 3. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 42.2 35.1 30.7 12.2 41.7 18.6 17.5 19.0 25.3 10.8 9.7 11.6 15.3 21.7 24.6 JT 8.1 40.2 34.4 29.9 12.2 37.9 20.8 17.3 18.4 25.0 11.4 9.2 12.0 15.2 20.8 22.8 TTT 7.9 37.2 31.6 28.6 11.5 35.8 19.1 15.8 17.8 23.3 11.0 9.1 11.6 14.3 18.9 22.3 TTT-Online 8.2 21.3 17.7 17.9 9.0 23.4 15.3 12.5 16.4 15.8 10.9 9.0 10.7 12.8 12.2 18.7 ALP 16.5 20.0 19.3 20.5 19.2 21.2 24.0 20.5 20.9 24.2 30.1 16.6 39.6 20.9 17.8 18.0 Table A5.Test error (%) on CIFAR-10-C, level 3, ResNet-26.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A5.Test error (%) on CIFAR-10-C, level 2. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 31.7 22.6 24.3 9.9 42.6 14.9 14.7 21.7 18.4 9.8 9.1 10.0 13.1 17.1 22.4 JT 8.1 31.0 22.6 23.4 9.1 39.2 16.4 14.2 21.2 17.5 9.4 8.3 10.6 12.8 15.9 20.5 TTT 7.9 28.8 20.7 23.0 9.0 36.6 15.4 13.1 20.2 16.9 9.2 8.3 10.2 12.5 14.8 19.7 TTT-Online 8.2 16.8 13.8 15.5 8.5 23.4 13.3 11.5 16.8 12.7 9.4 8.4 9.7 12.4 11.5 17.0 ALP 16.5 18.0 17.2 19.0 17.8 20.7 21.2 19.3 19.0 20.1 22.4 16.3 29.2 20.3 17.4 17.8 Table A6.Test error (%) on CIFAR-10-C, level 2, ResNet-26. originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A6.Test error (%) on CIFAR-10-C, level 1. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 21.7 17.1 17.0 9.0 44.0 12.1 13.9 14.3 13.4 9.2 8.9 9.0 13.2 12.0 17.3 JT 8.1 20.4 16.6 16.9 8.2 40.5 12.2 13.0 13.1 12.3 8.4 8.1 8.5 12.9 11.3 15.9 TTT 7.9 19.1 15.8 16.5 8.0 37.9 11.7 12.2 12.8 11.9 8.2 8.0 8.3 12.6 11.1 15.5 TTT-Online 8.2 13.8 11.9 12.2 8.5 24.4 10.5 11.5 12.4 10.7 8.5 8.3 8.6 12.4 10.7 14.4 ALP 17.0 16.8 17.6 16.8 20.9 18.7 19.0 17.3 17.5 17.4 16.1 18.4 20.4 17.0 17.2 17.5 Table A7.Test error (%) on CIFAR-10-C, level 1, ResNet-26.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Figure A7.Sample Images from the VID-Robust dataset (Shankar et al., 2019) in the results section adapted to CIFAR-10. Each row shows eight sample images from one class. The seven classes shown are, in order: airplane, bird, car, dog, cat, horse, ship.",
      "meta_data": {
        "arxiv_id": "1909.13231v3",
        "authors": [
          "Yu Sun",
          "Xiaolong Wang",
          "Zhuang Liu",
          "John Miller",
          "Alexei A. Efros",
          "Moritz Hardt"
        ],
        "published_date": "2019-09-29T08:09:15Z",
        "pdf_url": "https://arxiv.org/pdf/1909.13231v3.pdf"
      }
    },
    {
      "title": "Improved Test-Time Adaptation for Domain Generalization",
      "abstract": "The main challenge in domain generalization (DG) is to handle the\ndistribution shift problem that lies between the training and test data. Recent\nstudies suggest that test-time training (TTT), which adapts the learned model\nwith test data, might be a promising solution to the problem. Generally, a TTT\nstrategy hinges its performance on two main factors: selecting an appropriate\nauxiliary TTT task for updating and identifying reliable parameters to update\nduring the test phase. Both previous arts and our experiments indicate that TTT\nmay not improve but be detrimental to the learned model if those two factors\nare not properly considered. This work addresses those two factors by proposing\nan Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically\ndefining an auxiliary objective, we propose a learnable consistency loss for\nthe TTT task, which contains learnable parameters that can be adjusted toward\nbetter alignment between our TTT task and the main prediction task. Second, we\nintroduce additional adaptive parameters for the trained model, and we suggest\nonly updating the adaptive parameters during the test phase. Through extensive\nexperiments, we show that the proposed two strategies are beneficial for the\nlearned model (see Figure 1), and ITTA could achieve superior performance to\nthe current state-of-the-art methods on several DG benchmarks. Code is\navailable at https://github.com/liangchen527/ITTA.",
      "full_text": "Improved Test-Time Adaptation for Domain Generalization Liang Chen1 Yong Zhang2* Yibing Song3 Ying Shan2 Lingqiao Liu1âˆ— 1 The University of Adelaide 2 Tencent AI Lab 3 AI3 Institute, Fudan University {liangchen527, zhangyong201303, yibingsong.cv}@gmail.com yingsshan@tencent.com lingqiao.liu@adelaide.edu.au Abstract The main challenge in domain generalization (DG) is to handle the distribution shift problem that lies between the training and test data. Recent studies suggest that test-time training (TTT), which adapts the learned model with test data, might be a promising solution to the problem. Gen- erally, a TTT strategy hinges its performance on two main factors: selecting an appropriate auxiliary TTT task for up- dating and identifying reliable parameters to update during the test phase. Both previous arts and our experiments in- dicate that TTT may not improve but be detrimental to the learned model if those two factors are not properly consid- ered. This work addresses those two factors by proposing an Improved Test-Time Adaptation (ITTA) method. First, in- stead of heuristically defining an auxiliary objective, we pro- pose a learnable consistency loss for the TTT task, which con- tains learnable parameters that can be adjusted toward bet- ter alignment between our TTT task and the main prediction task. Second, we introduce additional adaptive parameters for the trained model, and we suggest only updating the adap- tive parameters during the test phase. Through extensive ex- periments, we show that the proposed two strategies are ben- eficial for the learned model (see Figure 1), and ITTA could achieve superior performance to the current state-of-the-art methods on several DG benchmarks. Code is available at https://github.com/liangchen527/ITTA. 1. Introduction Recent years have witnessed the rapid development of deep learning models, which often assume the training and test data are from the same domain and follow the same distribution. However, this assumption does not always hold in real-world scenarios. Distribution shift among the source and target domains is ubiquitous in related areas [35], such as autonomous driving or object recognition tasks, resulting *Corresponding authors. This work is done when L. Chen is an intern in Tencent AI Lab. 0.5 1.1 0.5 1.2 0.5 0.5 0.5 1.4 0.4 0.4 0.4 0.3 art cartoon photo sketch 79.9 75.4 94.4 75.8 83.3 76.0 94.4 76.7 84.7 78.0 94.5 78.2 Figure 1. Performance improvements from the proposed two strate- gies (i.e. introducing a learnable consistency loss and including additional adaptive parameters to improve TTT) for the baseline model (i.e. ResNet18 [30] with existing augmentation strategy [75]). Experiments are conducted on the PACS dataset [37] with the leave- one-out setting. Following [27], we use 60 sets of random seeds and hyper-parameters for each target domain. The reported average accuracy and error bars verify the effectiveness of our method. in poor performances for delicately designed models and hindering the further application of deep learning techniques. Domain generalization (DG) [2,8,16,23,24,31,38 â€“40,40, 44, 47, 51, 52, 69], designed to generalize a learned model to unseen target domains, has attracted a great deal of attention in the research community. The problem can be traced back to a decade ago [7], and various approaches have been pro- posed to push the DG boundary ever since. Those efforts in- clude invariant representation learning [28,47,49,58], adver- sarial learning [23,40,44,69], augmentation [9,41,42,66,75], or meta-learning [2, 16, 38, 39]. Despite successes on certain occasions, a recent study [27] shows that, under a rigorous evaluation protocol, most of these arts are inferior to the baseline empirical risk minimization (ERM) method [61]. This finding is not surprising, as most current arts strive to decrease the distribution shift only through the training data while overlooking the contributions from test samples. Recently, the test-time training (TTT) technique [60] has been gaining momentum for easing the distribution shift problem. TTT lies its success in enabling dynamic tuning of the pretrained model with the test samples via an auxil- iary TTT task, which seems to be a promising effort when arXiv:2304.04494v2  [cs.CV]  16 Apr 2023confronting data from different domains. However, TTT is not guaranteed to improve the performance. Previous arts [46, 63] indicate that selecting an appropriate auxiliary TTT task is crucial, and an inappropriate one that does not align with the main loss may deteriorate instead of improv- ing the performance. Meanwhile, it is pointed out in [63] that identifying reliable parameters to update is also essential for generalization, which is in line with our experimental findings in Sec. 5.3. Both of these two tasks are non-trivial, and there are limited efforts made to address them. This paper aims to improve the TTT strategy for better DG. First, different from previous works that empirically define auxiliary objectives and assume they are aligned with the main task, our work does not make such assumptions. Instead, we suggest learning an appropriate auxiliary loss for test-time updating. Specifically, encouraged by recent successes in multi-view consistency learning [13,26,29], we propose to augment the consistency loss by adding learn- able parameters based on the original implementation, where the parameters can be adjusted to assure our TTT task can be more aligned with the main task and are updated by en- forcing the two tasks share the same optimization direction. Second, considering that identifying reliable parameters to update is an everlasting job given the growing size of current deep models, we suggest introducing new adaptive param- eters after each block during the test phase, and we only tune the new parameters by the learned consistency loss while leaving the original parameters unchanged. Through extensive evaluations on the current benchmark [27], we illustrate that the learnable consistency loss performs more effectively than the self-supervised TTT tasks adopted in previous arts [60, 63], and by tuning only the new adaptive parameters, our method is superior to existing strategies that update all the parameters or part of them. This work aims to ease the distribution shift problem by improving TTT, and the main contributions are three-fold: â€¢ We introduce a learnable consistency loss for test-time adaptation, which can be enforced to be more aligned with the main loss by tuning its learnable parameters. â€¢ We introduce new adaptive parameters for the trained model and only update them during the test phase. â€¢ We conduct experiments on various DG benchmarks and illustrate that our ITTA performs competitively against current arts under the rigorous setting [27] for both the multi-source and single-source DG tasks. 2. Related Works 2.1. Domain Generalization. Being able to generalize to new environments while de- ploying is a challenging and practical requirement for cur- rent deep models. Existing DG approaches can be roughly categorized into three types. (1) Invariant representation learning: The pioneering work [5] theoretically proves that if the features remain invariant across different domains, then they are general and transferable to different domains. Guided by this finding, [47] uses maximum mean discrep- ancy (MMD) to align the learned features, and [25] proposes to use a multi-domain reconstruction auto-encoder to obtain invariant features. More recently, [58] suggests maximiz- ing the inner product of gradients from different domains to enforce invariance, and a similar idea is proposed in [52] where these gradients are expected to be similar to their mean values. (2) Optimization algorithms: Among the different optimization techniques adopted in DG, prevail- ing approaches resort to adversarial learning [23, 40, 44, 69] and meta-learning [2, 16, 38, 39]. Adversarial training is often used to enforce the learned features to be agnostic about the domain information. In [23], a domain-adversarial neural network (DANN) is implemented by asking the main- stream feature to maximize the domain classification loss. This idea is also adopted in [44], where adversarial training and an MMD constraint are employed to update an auto- encoder. Meanwhile, the meta-learning technique is used to simulate the distribution shifts between seen and unseen environments [2, 16, 38, 39], and most of these works are developed based on the MAML framework [20]. (3) Aug- mentation: Most augmentation skills applied in the general- ization tasks are operated in the feature level [34, 41, 48, 75] except for [11,66,68] which mix images [68] or its phase [66] to synthesize new data. To enable contrastive learning, we incorporate an existing augmentation strategy [75] in our framework. This method originated from AdaIN [32], which synthesizes new domain information by mixing the statistics of the features. Similar ideas can be found in [42, 48]. 2.2. Test-Time Training and Adaptation Test-Time Training (TTT) is first introduced in [60]. The basic paradigm is to employ a test-time task besides the main task during the training phase and update the pre- trained model using the test data with only the test-time objective before the final prediction step. The idea is empir- ically proved effective [60] and further developed in other related areas [3, 10, 12, 14, 21, 22, 43, 56, 63, 65, 73, 74]. Most current works focus on finding auxiliary tasks for updat- ing during the test phase, and the efforts derive from self- supervion [3, 10, 21, 22, 43, 60], meta-learning [65, 73, 74], information entropy [63], pseudo-labeling [12, 14], to name a few. However, not all empirically selected test-time tasks are effective. A recent study [46] indicates that only when the auxiliary loss aligns with the main loss can TTT improve the trained model. Inspired by that, we propose a learnable consistency loss and enforce alignment between the two ob- jectives. Results show that our strategy can be beneficial for the trained model (see Figure 1).subtract Figure 2. Training process of ITTA. We use x from the source domain as input for the feature extractor fÎ¸(Â·) to obtain the repre- sentation z and its augmented version zâ€², where the augmentation skill from [75] is applied. The classifier fÏ•(Â·) and weight subnet- work fw(Â·) are used to compute the main loss Lmain and learnable consistency loss Lwcont. Please refer to our text for details. Meanwhile, [63] suggests that auxiliary loss is not the only factor that affects the performance. Selecting reliable parameters to update is also crucial within the TTT frame- work. Given the large size of current models, correctly iden- tifying these parameters may require tremendous amounts of effort. To this end, instead of heuristically selecting candi- dates, we propose to include new adaptive parameters for up- dating during the test phase. Experimental results show that the proposed method can obtain comparable performances against existing skills. 3. Methodology In the task of DG, we are often given access to data from S (S â‰¥ 1) source domains Ds = {D1, D2, ..., DS} and expect a model to make good prediction on unseen target domains Dt = {D1, D2, ..., DT } (T â‰¥ 1). Our method aims to improve the test-time training (TTT) strategy for better DG. The improvements are two-fold. First, we pro- pose a learnable consistency loss for the TTT task, which could be enforced to align with the main objective by tuning its learnable weights. Second, we suggest including addi- tional adaptive parameters and only updating these adaptive parameters during the test phase. 3.1. A Learnable Consistency Loss for TTT The TTT strategies have shown promising performances when dealing with distribution shift problems [43, 63]. How- ever, their successes are depended on the empirically selected auxiliary TTT tasks, which may deteriorate the performances if chosen improperly. Motivated by the recent successes in multi-view consistency learning [13, 26, 29], we suggest adopting a consistency loss in our TTT task. Note that the naive consistency loss is still not guaranteed to be effective as prior art [46] indicates that only when the auxiliary loss aligns with the main loss, can TTT improves the perfor- mance. To this end, we propose to augment the auxiliary loss with learnable parameters that could be adjusted toward a better alignment between the TTT and main tasks. In our case, we make the adopted consistency loss learnable by introducing a weight subnetwork that allows flexible ways Algorithm 1 Pseudo code of the training phase of ITTA in a PyTorch-like style. # fÎ¸, fÏ•, fw: feature extractor, classifier, weight subnetwork # Î±, 0: weight paramter, all zero tensor # training process for x, yin training loader: # load a minibatch with N samples def forward process(x, y): z, zâ€² = fÎ¸.forward(x) # computing losses Lmain = CrossEntropyLoss(fÏ•.forward(z), y) Lmain+ =CrossEntropyLoss(fÏ•.forward(zâ€²), y) Lwcont = MSELoss(fw.forward(z âˆ’ zâ€²), 0) return Lmain, Lwcont # SGD update: feature extractor and classifier Lmain, Lwcont = forward process(x, y) ([fÎ¸.params, fÏ•.params]).zero grad() (Lmain + Î±Lwcont).backward() update( \u0002 fÎ¸.params, fÏ•.params \u0003 ) # compute objectives for updating weight subnetwork Lmain, Lwcont = forward process(x, y) Lmain.backward() Ë†gmain = fÎ¸.params.grad.clone().normalize() fÎ¸.params.zero grad() Lwcont.backward() Ë†gwcont = fÎ¸.params.grad.clone().normalize() # SGD update: weight subnetwork MSELoss(Ë†gmain, Ë†gwcont).backward() fw.params.zero grad() update(fw.params) to measure the consistency between two views of the same instance. We first introduce the pipeline of our training framework. Given the D dimensional representation z âˆˆ RD1 and its corresponding augmented version zâ€² that are obtained from a feature extractor (i.e. {z, zâ€²} = fÎ¸(x), where x is an input image from Ds, and fÎ¸(Â·) is the feature extractor parame- terized by Î¸. In our implementation, we use the existing augmentation method [75] to obtain zâ€² by modifying the intermediate activation in fÎ¸(x). We show in our supplemen- tary material that our framework can also thrive with other augmentation strategies), our learnable consistency loss is given by, Lwcont = âˆ¥fw(z âˆ’ zâ€²)âˆ¥, (1) where âˆ¥ Â· âˆ¥denotes the L2 norm; fw(Â·) is the weight sub- network parameterized by w. To make the training process more stable and potentially achieve better performance, we apply a dimension-wise nonlinear function to map each di- mension of z âˆ’ zâ€² before calculating the L2 norm. That is, âˆ€h âˆˆ RD, fw(h) is implemented by stacking layers of a nonlinear function: ReLU(a âˆ— h + b), where a âˆˆ RD and b âˆˆ RD are the weight and bias from the nonlinear function, 1We omit the batch dimensions of the variables for simplicity.â€¦ â€¦ subtract Figure 3. Test adaptation process of ITTA. Different from that in the training stage, we include additional adaptive parameters fÎ˜ after each block of the feature extractor fÎ¸. For each test sample x, the intermediate representations zi and zâ€²i obtained from fi Î¸ are passed to fi Î˜ before going to the next block fi+1 Î¸ . We use the learnable consistency loss Lwcont as the objective to update fÎ˜. Please refer to our text for details. and different layers of a, bform the parameter w in fw. In effect, this creates a piecewise-linear mapping function for h: depending on the value of h, the output could be 0, a constant, or a scaling-and-shifted version of h. More studies about the design of fw are provided in our supplementary material. Compared to the naive consistency learning with- out fw, our Lwcont can be more flexible with an adjustable fw, which we show in the following is the key for learning an appropriate loss in the improved TTT framework. Combining Lwcont with the main loss Lmain which applies the cross-entropy loss (CE) for both the origi- nal and augmented inputs ( i.e. Lmain = CE(fÏ•(z), y) + CE(fÏ•(zâ€²), y), where fÏ• is the classifier parameterized by Ï•, and y is the corresponding label), the objective for the feature extractor and classifier can be formulated into, min{Î¸,Ï•} Lmain + Î±Lwcont, (2) where Î± is the weight parameter that balances the contri- butions from the two terms. A simple illustration of the workflow is shown in Figure 2. From Eq. (2), the expected gradients for the feature ex- tractor from Lmain and Lwcont can be represented as, \u001a gmain = âˆ‡Î¸(CE(fÏ•(z), y) + CE(fÏ•(zâ€²), y)), (3) gwcont = âˆ‡Î¸âˆ¥fw(z âˆ’ zâ€²)âˆ¥. (4) We observe that the direction of gwcont is also determined by the weight subnetwork fw(Â·), which should be close with gmain to ensure alignment between Lmain and Lwcont [46, 60]. To this end, we propose a straightforward solution by enforcing equality between the normalized versions of gmain and gwcont, and we use this term as the objective for updating fw(Â·), which gives, min w Lalign, s.t. Lalign = âˆ¥Ë†gmain âˆ’ Ë†gwcontâˆ¥, (5) where Ë†gmain = gmainâˆ’Egmain Ïƒgmain , and similar for Ë†gwcont. In our implementation, we update {Î¸, Ï•} and w in an alternative manner. Pseudo code of the training process are shown in Algorithm 1. Algorithm 2 Pseudo code of the test phase of ITTA in a PyTorch-like style. # fÎ¸, fÏ•: feature extractor, classifier # fw, fÎ˜: weight subnetwork, additional adaptive blocks # m, 0: total number of blocks in fÎ¸, all zero tensor # test process for x in test loader: # load a test batch def forward process(x): z1, zâ€²1 = f1 Î˜.forward((f1 Î¸ .forward(x))) # first blocks for i in range(2, m + 1): # the following m âˆ’ 1 blocks zi, zâ€²i = fi Î¸.forward(ziâˆ’1), fi Î¸.forward(zâ€²iâˆ’1) zi, zâ€²i = fi Î˜.forward(zi), fi Î˜.forward(zâ€²i) return zi, zâ€²i # test adaptation phase: SGD update additional adaptive parameters z, zâ€² = forward process(x) Lwcont = MSELoss(fw.forward(z âˆ’ zâ€²), 0) fÎ˜.params.zero grad() Lwcont.backward() update(fÎ˜.params) # final prediction z, = forward process(x) result = fÏ•.forward(z) 3.2. Including Additional Adaptive Parameters Selecting expressive and reliable parameters to update during the test phase is also essential in the TTT frame- work [63]. Some strategies decide to update all the parame- ters from the feature extractor [3, 43], while others use only the parameters from the specific layers for updating [63, 71]. Given the fact that the sizes of current deep models are often very large and still growing, exhaustively trying different combinations among the millions of candidates seems to be an everlasting job. As there are no consensuses on which parameter should be updated, we suggest another easy alter- native in this work. Specifically, assuming there are a total of m blocks in the pretrained feature extractor fÎ¸(Â·), and the i-th block can be denoted as fi Î¸(Â·). Then the intermediate representation zi from fi Î¸(Â·) can be formulated as, zi = fi Î¸(ziâˆ’1), s.t. z1 = f1 Î¸ (x). (6) We propose to include additional adaptive blockfÎ˜ that is parameterized by Î˜ after each block of fÎ¸ during the test- time adaptation phase, which reformulates Eq. (6) into, zi = fi Î˜(fi Î¸(ziâˆ’1)), s.t. z1 = f1 Î˜(f1 Î¸ (x)), (7) where fÎ˜(Â·) does not change the dimension and sizes of the intermediate representations. In our work, we use a structure similar to fw to implement fÎ˜. Note zm is simplified as z in this phase, and the same process is applied for obtaining zâ€². Then, in the test-time adaptation phase, we suggest only updating the new adaptive parameters via the learned con- sistency loss. The optimization process can be written as,Table 1. Multi sources domain generalization. Experiments are conducted on the DomainBed benchmark [27]. All methods are examined for 60 trials in each unseen domain. Top5 accumulates the number of datasets where a method achieves the top 5 performances. The score here accumulates the numbers of the dataset where a specific art obtains larger accuracy than ERM on account of the variance. Best results are colored as red. Among the 22 methods compared, less than a quarter outperforms ERM in most datasets (Score â‰¥ 3). PACS VLCS OfficeHome TerraInc DomainNet Avg. Top5â†‘ Scoreâ†‘ MMD [40] 81.3 Â± 0.8 74.9 Â± 0.5 59.9 Â± 0.4 42.0 Â± 1.0 7.9 Â± 6.2 53.2 1 2 RSC [33] 80.5 Â± 0.2 75.4 Â± 0.3 58.4 Â± 0.6 39.4 Â± 1.3 27.9 Â± 2.0 56.3 0 1 IRM [1] 80.9 Â± 0.5 75.1 Â± 0.1 58.0 Â± 0.1 38.4 Â± 0.9 30.4 Â± 1.0 56.6 0 1 ARM [72] 80.6 Â± 0.5 75.9 Â± 0.3 59.6 Â± 0.3 37.4 Â± 1.9 29.9 Â± 0.1 56.7 0 0 DANN [23] 79.2 Â± 0.3 76.3 Â± 0.2 59.5 Â± 0.5 37.9 Â± 0.9 31.5 Â± 0.1 56.9 1 1 GroupGRO [55] 80.7 Â± 0.4 75.4 Â± 1.0 60.6 Â± 0.3 41.5 Â± 2.0 27.5 Â± 0.1 57.1 0 1 CDANN [44] 80.3 Â± 0.5 76.0 Â± 0.5 59.3 Â± 0.4 38.6 Â± 2.3 31.8 Â± 0.2 57.2 0 0 VREx [36] 80.2 Â± 0.5 75.3 Â± 0.6 59.5 Â± 0.1 43.2 Â± 0.3 28.1 Â± 1.0 57.3 1 1 CAD [53] 81.9 Â± 0.3 75.2 Â± 0.6 60.5 Â± 0.3 40.5 Â± 0.4 31.0 Â± 0.8 57.8 1 2 CondCAD [53] 80.8 Â± 0.5 76.1 Â± 0.3 61.0 Â± 0.4 39.7 Â± 0.4 31.9 Â± 0.7 57.9 0 1 MTL [6] 80.1 Â± 0.8 75.2 Â± 0.3 59.9 Â± 0.5 40.4 Â± 1.0 35.0 Â± 0.0 58.1 0 0 ERM [61] 79.8 Â± 0.4 75.8 Â± 0.2 60.6 Â± 0.2 38.8 Â± 1.0 35.3 Â± 0.1 58.1 1 - MixStyle [75] 82.6 Â± 0.4 75.2 Â± 0.7 59.6 Â± 0.8 40.9 Â± 1.1 33.9 Â± 0.1 58.4 1 1 MLDG [38] 81.3 Â± 0.2 75.2 Â± 0.3 60.9 Â± 0.2 40.1 Â± 0.9 35.4 Â± 0.0 58.6 1 1 Mixup [68] 79.2 Â± 0.9 76.2 Â± 0.3 61.7 Â± 0.5 42.1 Â± 0.7 34.0 Â± 0.0 58.6 2 2 Fishr [52] 81.3 Â± 0.3 76.2 Â± 0.3 60.9 Â± 0.3 42.6 Â± 1.0 34.2 Â± 0.3 59.0 2 2 SagNet [48] 81.7 Â± 0.6 75.4 Â± 0.8 62.5 Â± 0.3 40.6 Â± 1.5 35.3 Â± 0.1 59.1 1 2 SelfReg [34] 81.8 Â± 0.3 76.4 Â± 0.7 62.4 Â± 0.1 41.3 Â± 0.3 34.7 Â± 0.2 59.3 2 3 Fish [58] 82.0 Â± 0.3 76.9 Â± 0.2 62.0 Â± 0.6 40.2 Â± 0.6 35.5 Â± 0.0 59.3 3 4 CORAL [59] 81.7 Â± 0.0 75.5 Â± 0.4 62.4 Â± 0.4 41.4 Â± 1.8 36.1 Â± 0.2 59.4 2 3 SD [51] 81.9 Â± 0.3 75.5 Â± 0.4 62.9 Â± 0.2 42.0 Â± 1.0 36.3 Â± 0.2 59.7 4 4 Ours 83.8 Â± 0.3 76.9 Â± 0.6 62.0 Â± 0.2 43.2 Â± 0.5 34.9 Â± 0.1 60.2 4 4 min Î˜ âˆ¥fw(z âˆ’ zâ€²)âˆ¥, s.t. {z, zâ€²} = fÎ˜(fÎ¸(x)). (8) Note that different from the training phase, x in this stage is from the target domain Dt, and we use the online setting in [60] for updating. A simple illustration of the test adaptation pipeline is shown in Figure 3. For the final step, we use the original representation ob- tained from the pretrained feature extractor and the adapted adaptive parameters for prediction. Pseudo code of the test stage are shown in Algorithm 2. 4. Experiments 4.1. Settings Datasets. We evalute ITTA on five benchmark datasets: PACS [37] which consists of 9,991 images from 7 cate- gories. This dataset is probably the most widely-used DG benchmark owing to its large distributional shift across 4 do- mains including art painting, cartoon, photo, and sketch; VLCS [18] contains 10,729 images of 5 classes from 4 different datasets (i.e. domains) including PASCAL VOC 2007 [17], LabelMe [54], Caltech [19], and Sun [64] where each dataset is considered a domain in DG;OfficeHome [62] is composed of 15,588 images from 65 classes in office and home environments, and those images can be categorized into 4 domains (i.e. artistic, clipart, product, and real world); TerraInc [4] has 24,788 images from 10 classes. Those images are wild animals taken from 4 different locations (i.e. domains) including L100, L38, L43, and L46; Domain- Net [50] which contains 586,575 images from 345 classes, and the images in it can be depicted in 6 styles (i.e. clipart, infograph, painting, quickdraw, real, and sketch). Implementation details. For all the experiments, we use the ImageNet [15] pretrained ResNet18 [30] backbone that with 4 blocks as the feature extractor fÎ¸, which could en- large the gaps in DG compared to larger models [70]. Corre- spondingly, we also include 4 blocks of additional adaptive parameters (i.e. fÎ˜), and each block is implemented with 5 layers of learnable parameters with weight initialized as all ones and bias initialized as all zeros. For the weight subnet- work fw, we use 10 layers of learnable parameters with the initialization skill similar to that of fÎ˜. The classifier fÏ• is an MLP layer provided by the Domainbed benchmark [27]. For the weight parameter Î± in Eq. (2), we set it to be 1 for all experiments (please refer to our supplementary material for analysis). The random seeds, learning rates, batch size, and augmentation skills are all dynamically set for all the compared arts according to [27].Table 2. Single source domain generalization. Experiments are conducted on the PACS dataset [37]. Here A, C, P, and S are the art, cartoon, photo, and sketch domains in PACS. Aâ†’C represents models trained on the art domain and tested on the cartoon domain, and similar for others. All methods are examined for 60 trials in each unseen domain. Best results are colored as red. Aâ†’C A â†’P A â†’S C â†’A C â†’P C â†’S P â†’A P â†’C P â†’S S â†’A S â†’C S â†’P Avg. RSC 66.3 Â±1.3 88.2Â±0.6 57.2Â±3.1 65.8Â±1.5 82.4Â±0.6 68.7Â±2.5 60.5Â±2.0 41.3Â±6.0 53.1Â±2.8 53.8Â±1.6 65.9Â±0.7 48.4Â±1.9 62.6 Fish 67.1 Â±0.5 89.2Â±1.8 57.0Â±0.2 66.7Â±1.0 85.6Â±0.4 64.5Â±3.6 55.1Â±2.1 33.9Â±2.3 51.2Â±4.2 59.1Â±3.2 67.1Â±0.9 58.4Â±1.2 62.9 CDANN 66.5Â±1.7 92.2Â±0.6 65.0Â±0.9 70.6Â±0.1 82.9Â±1.4 67.7Â±3.0 60.6Â±0.3 42.2Â±6.4 46.9Â±9.9 51.4Â±2.3 60.7Â±1.2 51.9Â±0.4 63.2 SelfReg 63.9Â±1.9 90.1Â±1.0 56.8Â±2.2 70.2Â±2.3 85.4Â±0.3 70.2Â±2.2 60.9Â±2.6 38.8Â±4.0 50.5Â±3.2 54.5Â±4.7 66.2Â±1.2 51.7Â±4.1 63.3 DANN 67.5 Â±1.6 91.2Â±1.3 67.5Â±1.3 70.6Â±1.0 81.4Â±0.4 66.6Â±1.1 54.1Â±2.3 33.5Â±2.7 52.8Â±2.3 53.8Â±1.7 64.4Â±0.7 58.9Â±0.8 63.5 CAD 67.1 Â±1.5 89.6Â±0.4 60.2Â±0.2 67.7Â±3.1 83.7Â±1.4 70.2Â±2.6 60.6Â±2.6 38.3Â±3.7 53.8Â±3.2 50.7Â±1.6 65.8Â±1.3 54.4Â±1.7 63.5 GroupGRO66.5Â±1.2 90.5Â±1.5 58.9Â±2.5 70.8Â±0.9 85.7Â±1.2 69.7Â±1.8 62.3Â±2.1 41.1Â±2.7 48.2Â±4.1 54.8Â±0.5 65.2Â±1.6 53.9Â±1.4 64.0 MTL 67.3 Â±1.0 90.1Â±1.0 58.9Â±0.7 70.2Â±1.8 84.2Â±2.2 71.9Â±0.7 58.3Â±2.7 38.5Â±2.7 52.8Â±1.5 55.4Â±3.1 66.1Â±1.3 55.2Â±2.6 64.1 IRM 67.5 Â±1.8 93.0Â±0.5 62.9Â±4.7 67.6Â±1.3 83.8Â±0.4 68.9Â±0.8 63.7Â±1.8 39.9Â±3.7 49.0Â±5.4 54.9Â±1.4 63.1Â±2.1 54.9Â±1.4 64.1 ARM 66.0 Â±2.4 91.2Â±0.7 58.7Â±6.9 70.6Â±0.8 84.2Â±1.0 69.1Â±0.9 59.2Â±1.8 42.1Â±5.6 52.1Â±3.0 60.0Â±0.6 62.9Â±3.3 53.8Â±2.0 64.2 Mixup 65.5 Â±0.8 87.8Â±0.3 57.2Â±1.0 71.4Â±1.1 83.1Â±1.8 68.0Â±3.0 59.6Â±1.7 37.2Â±2.7 56.5Â±3.8 55.0Â±2.2 66.2Â±1.5 62.7Â±4.2 64.2 CORAL 66.8Â±0.5 90.3Â±0.7 61.5Â±1.9 67.9Â±2.1 85.4Â±0.3 70.4Â±1.3 55.9Â±2.9 40.4Â±4.9 49.8Â±8.5 55.8Â±2.1 67.6Â±0.9 58.9Â±3.8 64.2 SD 67.1 Â±1.3 91.7Â±1.2 63.7Â±4.1 70.3Â±0.9 84.4Â±0.7 69.4Â±2.3 57.5Â±2.5 42.6Â±0.8 47.7Â±1.7 55.9Â±2.4 65.7Â±0.8 55.8Â±2.1 64.3 MMD 67.1 Â±1.4 88.0Â±0.8 63.6Â±1.6 70.0Â±1.1 83.6Â±0.2 70.2Â±1.0 58.8Â±2.6 40.3Â±1.0 52.3Â±2.4 57.4Â±1.9 68.7Â±0.9 52.7Â±3.7 64.4 MLDG 67.3Â±2.0 90.8Â±0.5 64.4Â±0.9 70.8Â±1.0 84.2Â±0.3 69.7Â±1.8 61.6Â±1.0 41.3Â±5.1 50.4Â±0.2 49.9Â±2.5 66.8Â±0.4 58.7Â±3.4 64.7 CondCAD66.9Â±1.4 92.3Â±0.7 60.8Â±4.5 71.0Â±0.6 84.7Â±1.1 72.6Â±0.5 61.2Â±1.5 40.7Â±3.6 55.7Â±1.6 52.3Â±1.7 64.2Â±0.4 55.3Â±1.2 64.8 ERM 67.3 Â±0.7 91.7Â±0.9 60.1Â±4.7 70.4Â±0.6 82.3Â±2.7 68.1Â±0.9 59.6Â±1.8 44.7Â±2.8 56.5Â±2.7 52.8Â±2.3 68.1Â±0.7 58.4Â±0.9 65.0 VREx 67.1 Â±1.5 91.0Â±1.0 62.6Â±3.5 71.1Â±2.4 84.1Â±0.9 71.7Â±1.3 62.4Â±3.1 37.7Â±3.3 53.6Â±2.3 60.6Â±1.6 66.7Â±0.8 57.5Â±1.4 65.5 Fishr 67.9 Â±1.9 92.7Â±0.3 62.4Â±4.7 71.2Â±0.5 83.4Â±0.6 70.2Â±1.1 60.0Â±2.3 42.7Â±3.2 57.1Â±3.9 55.7Â±3.7 68.4Â±1.0 62.0Â±3.1 66.1 SagNet 67.6Â±1.4 92.3Â±0.5 59.5Â±1.7 71.8Â±0.3 82.8Â±0.6 69.9Â±1.8 62.5Â±2.5 45.2Â±2.5 64.1Â±2.0 55.8Â±1.1 65.7Â±1.4 55.9Â±3.5 66.1 MixStyle 68.5Â±2.0 91.2Â±1.6 65.1Â±0.7 73.2Â±1.3 85.0Â±0.8 71.7Â±1.5 63.6Â±1.7 46.3Â±1.1 51.6Â±3.7 54.2Â±1.5 67.0Â±3.4 58.3Â±1.4 66.3 Ours 68.9 Â±0.6 92.4Â±0.1 62.5Â±0.6 75.3Â±0.4 85.9Â±0.3 70.2Â±1.4 66.5Â±1.1 52.2Â±2.7 63.8Â±1.1 57.6Â±3.7 68.0Â±1.3 57.9Â±2.0 68.4 Training and evaluation details. For all the compared methods, we conduct 60 trials on each source domain, and each with 5,000 iteration steps. During the training stage, we split the examples from training domains to 8:2 (train:val) where the training and validation samples are dynamically selected among different training trials. During test, we select the model that performs the best in the validation samples and test it on the target domains. The strategy is referred to as the â€œtraining-domain validate setâ€ model selec- tion method in [27]. For each domain in different datasets, the final performance is the average accuracy from the 60 trials. 4.2. Multi-Source Generalization In these experiments, all five benchmark datasets afore- mentioned are used for evaluation, and the leave-one-out strategy is adopted for training (i.e. with S = |Ds âˆªDt|2 âˆ’1, and T = 1). Results are shown in Table 1. We note that ERM method obtains favorable performance against existing arts. In fact, as a strong baseline, ERM is superior to half of the methods in the term of average accuracy, and only 5 arts (i.e. SelfReg [34], Fish [58], CORAL [59], SD [51], and ours) among the compared 22 methods outperforms ERM in most datasets (i.e. with Score â‰¥ 3). In comparison, the proposed ITTA is more effective than all other models on average. In particular, ITTA achieves the best performances in 3 out of the 5 benchmarks (i.e. PACS, VLCS, and TerraInc datasets) and 4 in the top 5. Note that although our method does not obtain the best performances in the OfficeHome and DomainNet benchmarks, it still outperforms more than half 2We use | Â· |to denote the number of domains in the environment. of the existing models. The results validate the effectiveness of our method when tested in the multi-source setting. We present results of average accuracy in each domain from different datasets in the supplementary material. Please refer to it for details. 4.3. Single-Source Generalization In these experiments, we adopt the widely-used PACS [37] benchmark for evaluation, and the models are trained on one domain while tested on the remaining three (i.e. with S = 1, and T = 3). Although some approaches, such as MLDG [38] and Fishr [52], may require more than one domain information for their trainings, we can simu- late multi-domain information using only the source domain, and thus the experimental settings are still feasible for them. Compared to the multi-source generalization task, the single- source generalization is considered more difficult due to the limited domain information during the training phase. Evalu- ation results are presented in Table 2. We note that the ERM method outperforms most state-of-the-art models, and only 5 models, including VREx [36], Fishr [52], SagNet [48], MixStyle [75], and the proposed ITTA, can obtain better re- sults than ERM in the term of average accuracy. Meanwhile, our method achieves the best performances when trained in 5 out of the 12 source domain, and it obtains the best perfor- mance on average, leading more than 2% than the second best (i.e. MixStyle [75]) and 3% the ERM method. In line with the findings in [27], we notice that the naive ERM method [61] can indeed perform favorably against most existing models under rigorous evaluation protocol. As a matter of fact, the proposed method is the only one that consistently outperforms ERM in both the multi-sourceTable 3. Evaluations of different TTT-based models in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch Baseline 79.9 Â±0.5 75.4Â±1.1 94.4Â±0.5 75.8Â±1.2 81.4Â±0.5 TTT [60] 81.5Â±0.8 77.6Â±0.6 94.3Â±0.2 78.4Â±0.7 83.0Â±0.2 MT3 [3] 82.0 Â±1.0 76.5Â±1.0 94.1Â±0.2 77.7Â±1.3 82.6Â±0.6 TENT [63] 80.2Â±0.9 77.2Â±0.8 94.4Â±0.2 77.4Â±0.1 82.3Â±0.5 Ours 84.7 Â±0.4 78.0Â±0.4 94.5Â±0.4 78.2Â±0.3 83.8Â±0.3 and single-source settings. These results indicate that DG remains challenging for current efforts that aim to ease the distribution shift only through training data, and using the proposed improved TTT strategy may be a promising direc- tion for solving DG. 5. Analysis All experiments in this section are conducted on the widely-used PACS benchmark [37] with the leave-one-out strategy. The experimental settings are the same as that illus- trated in Sec. 4.1. Please refer to our supplementary material for more analysis. 5.1. Compared with Other TTT-Based Models Using test-time adaptation to ease the distribution shift problem has been explored in previous works, such as the original TTT method [60] and MT3 [3]. Their differences lie in that TTT uses a rotation estimation task for the test-time objective, and MT3 adopts a contrastive loss for the task and implements the overall framework using MAML [20]. There is also a recently proposed TENT [63] that aims to minimize the entropy of the final results by tuning the parameters from the batch normalization (BN) layers. To analyze the overall effectiveness of our method, we compare ITTA with these arts using the same baseline (i.e. ResNet18 [30] backbone with the existing augmentation skill [75]). Results are shown in Table 3. We observe that all the com- pared TTT-based methods can improve the baseline model in almost all target domains except for the â€œPhotoâ€ domain, which might be due to the ImageNet pretraining [67]. This phenomenon demonstrates that the TTT strategy may be a promising effort for easing the distribution shift problem. Meanwhile, we observe that the proposed ITTA is superior to all other approaches in most target domains and leads in the term of average accuracy. The main reason is that compared to the empirically designed TTT tasks adopted in previous works, the proposed learnable consistency loss is enforced to be more aligned with the main loss, thus more suitable for the test-time adaptation task [46]. Meanwhile, compared to the strategies that update the original param- eters from the trained model, the adaptation of the newly included parameters is also more effective for the overall (a) Input (b) Ours w/o fw (c) Ours (d) Main Figure 4. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels from the four target do- mains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). Ours w/o fw is the naive consis- tency loss with fw disabled in Eq. (1). The proposed learnable consistency loss can align well with the main classification task. TTT framework. In the following, we provide more analysis to support these claims. 5.2. Effectiveness of the Learnable Consistency Loss To examine the effectiveness of our learnable consistency loss, we conduct ablation studies by comparing our method with the following variants. (1) Ours w/o fw: we disable fw when computing the learnable consistency loss in Eq. (1), which uses the naive consistency loss for the auxiliary TTT task. (2) Ours w/ Ent.: after training the model using the baseline settings (i.e. ResNet18 with the augmentation strat- egy [75]), we use the entropy minimization task in [63] for the TTT task. (3) Ours w/ Rot.: we use the rotation estimation task in [60] for the TTT task. To ensure fair com- parisons, we use the same baseline settings and include the same additional adaptive parameters for all the variants. Results are shown in the 4th to 6th rows Table 4. We find that the results from the naive consistency loss ( i.e. Ours w/o fw) are slightly better than that from the other two specially-designed objectives (i.e. Ours w/ Ent. and Ours w/ Rot.) on average. Besides the possibility of deteriorating the performance [46], our results indicate that empirically select- ing a TTT task may also be far from optimal. Meanwhile, we observe that when enabling fw, the proposed learnable consistency loss is superior to that withoutfw in all target do-Table 4. Comparison between different TTT tasks and parameter selecting strategies in the unseen domain from the PACS benchmark [37]. Here the â€œEnt.â€, â€œRot.â€, and â€œLwcontâ€ denotes the entropy minimization task in [63], the rotation estimation task in [60], and the proposed learnable consistency objective, the â€œAllâ€, â€œBNâ€, and â€œAda.â€ are the strategies that update all the parameters, parameters from the batch normalization layer, and the proposed strategy that updates only the new additional adaptive parameters. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model TTT tasks Param selectings Target domain Avg.Ent. Rot. Lwcont All BN Ada. Art Cartoon Photo Sketch Ours âˆ’ âˆ’ âœ“ âˆ’ âˆ’ âœ“ 84.7Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 Ours w/ofw âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âœ“ 83.1Â±0.4 74.6 Â±0.6 94.0 Â±0.5 78.0 Â±0.8 82.5 Â±0.1 Ours w/ Ent. âœ“ âˆ’ âˆ’ âˆ’ âˆ’ âœ“ 79.9Â±2.4 77.3 Â±0.3 94.8 Â±0.8 77.6 Â±0.4 82.4 Â±0.8 Ours w/ Rot. âˆ’ âœ“ âˆ’ âˆ’ âˆ’ âœ“ 81.1Â±1.0 75.2 Â±0.5 94.9 Â±0.3 77.3 Â±0.6 82.1 Â±0.3 Ours w/o TTT âˆ’ âˆ’ âœ“ âˆ’ âˆ’ âˆ’ 83.3Â±0.5 76.0 Â±0.5 94.4 Â±0.5 76.7 Â±1.4 82.8 Â±0.3 Ours w/ All âˆ’ âˆ’ âœ“ âœ“ âˆ’ âˆ’ 83.0Â±0.7 77.0 Â±1.4 94.5 Â±0.7 77.4 Â±0.9 83.0 Â±0.2 Ours w/ BN âˆ’ âˆ’ âœ“ âˆ’ âœ“ âˆ’ 81.8Â±0.5 75.6 Â±0.3 94.4 Â±0.3 77.9 Â±1.1 82.4 Â±0.5 mains, and it leads in the term of average accuracy among the variants compared, illustrating its advantage against other adopted TTT tasks. These results are not surprising. By comparing the Grad-CAM [57] visualizations from the main classification task with the learnable and naive consistency losses in Figure 4, we find that the proposed learnable objec- tive can well align with the main loss when fw is enabled as the hot zones activated by these two tasks are similar, which guarantees the improvement for the test-time adapta- tion [46, 60]. Please refer to our supplementary material for more visualizations. 5.3. Effectiveness of the Adaptive Parameters We compare ITTA with three variants to demonstrate the effectiveness of the proposed additional adaptive parameters. (1) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model. (2) Ours w/ ALL: similar to the updating strategy in the original TTT method [60], we update all the parameters from the feature extractor during the test phase. (3) Ours w/ BN: following the suggestion from TENT [63], only parameters from the BN layers of the feature extractor are updated. Note the same pretrained model is shared for all variants in these experiments, and the objectives during the test adaptation phase are to minimize the same learned consistency loss. We list the results in the last three rows in Table 4. We observe that when only updating parameters from the BN layers, the performance is inferior to the strategy without test-time adaptation, and updating all the parameters does not ensure improvements in all target domains. The observations are in line with the findings in [63] that selecting reliable parameters to update is essential in the TTT system and may also interact with the choice of the TTT task. In comparison, when including additional adaptive parameters for updating, the pretrained model can be boosted in all environments. The results validate that our adaptive parameters are more effective than that selected with existing strategies [60, 63] when applied with the proposed learnable test-time objective. 5.4. Limitation Although the proposed learned loss can bring satisfaction improvements, we are aware that the lunch is not free. When the weight subnetwork fw is disabled, updating the joint loss in Eq. (2) only costs 1 forward and 1 backward. However, in order to update fw, we have to compute the second-order derivative in Eq. (5), which will require 1 more forward and 3 more backward processes, bringing extra burden to the system. Our future efforts aim to simplify the overall optimization process and reduce the cost for ITTA. 6. Conclusion In this paper, we aim to improve the current TTT strategy for alleviating the distribution shift problem in DG. First, given that the auxiliary TTT task plays a vital role in the over- all framework, and an empirically selecting one that does not align with the main task may potentially deteriorate instead of improving the performance, we propose a learnable con- sistency loss that can be enforced to be more aligned with the main loss by adjusting its learnable parameters. This strategy is ensured to improve the model and shows favorable perfor- mance against some specially-designed objectives. Second, considering that selecting reliable and effective parameters to update during the test phase is also essential while exhaus- tively trying different combinations may require tremendous effort, we propose a new alternative by including new ad- ditional adaptive parameters for adaptation during the test phase. This alternative is shown to outperform some pre- vious parameter selecting strategies via our experimental findings. By conducting extensive experiments under a rig- orous evaluation protocol, we show that our method can achieve superior performance against existing arts in both the multi-source and single-source DG tasks. Acknowledgements. Liang Chen is supported by the ChinaScholarship Council (CSC Student ID 202008440331). References [1] Martin Arjovsky, LÂ´eon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019. 5, 15, 16, 17 [2] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. In NeurIPS, 2018. 1, 2, 14, 15 [3] Alexander Bartler, Andre BÂ¨uhler, Felix Wiewel, Mario DÂ¨obler, and Bin Yang. Mt3: Meta test-time training for self- supervised test-time adaption. In AISTATS, 2022. 2, 4, 7 [4] Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In ECCV, 2018. 5, 17 [5] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In NeurIPS, 2006. 2 [6] Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton Scott. Domain generalization by marginal transfer learning. arXiv preprint arXiv:1711.07910, 2017. 5, 15, 16, 17 [7] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generaliz- ing from several related classification tasks to a new unlabeled sample. In NeurIPS, 2011. 1 [8] Chaoqi Chen, Jiongcheng Li, Xiaoguang Han, Xiaoqing Liu, and Yizhou Yu. Compound domain generalization via meta- knowledge encoding. In CVPR, 2022. 1 [9] Chaoqi Chen, Luyao Tang, Feng Liu, Gangming Zhao, Yue Huang, and Yizhou Yu. Mix and reason: Reasoning over se- mantic topology with data mixing for domain generalization. In NeurIPS, 2022. 1 [10] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022. 2 [11] Liang Chen, Yong Zhang, Yibing Song, Lingqiao Liu, and Jue Wang. Self-supervised learning of adversarial example: Towards good generalizations for deepfake detection. In CVPR, 2022. 2 [12] Liang Chen, Yong Zhang, Yibing Song, Jue Wang, and Lingqiao Liu. Ost: Improving generalization of deepfake detection via one-shot test-time training. In NeurIPS, 2022. 2, 12 [13] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geof- frey Hinton. A simple framework for contrastive learning of visual representations. In ICML, 2020. 2, 3 [14] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, 2022. 2 [15] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 5 [16] Qi Dou, Daniel Coelho de Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via model-agnostic learning of semantic features. In NeurIPS, 2019. 1, 2 [17] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303â€“338, 2010. 5 [18] Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In ICCV, 2013. 5, 16 [19] Li Fei-Fei, Rob Fergus, and Pietro Perona. Learning gener- ative visual models from few training examples: An incre- mental bayesian approach tested on 101 object categories. In CVPR worksho, 2004. 5 [20] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model- agnostic meta-learning for fast adaptation of deep networks. In ICML, 2017. 2, 7 [21] Francois Fleuret et al. Uncertainty reduction for model adap- tation in semantic segmentation. In CVPR, 2021. 2 [22] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 2 [23] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc Â¸ois Laviolette, Mario Marc- hand, and Victor Lempitsky. Domain-adversarial training of neural networks. JMLR, 17(1):2096â€“2030, 2016. 1, 2, 5, 15, 16, 17 [24] Muhammad Ghifary, David Balduzzi, W Bastiaan Kleijn, and Mengjie Zhang. Scatter component analysis: A unified framework for domain adaptation and domain generalization. IEEE TPAMI, 39(7):1414â€“1430, 2016. 1 [25] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generalization for object recognition with multi-task autoencoders. In ICCV, 2015. 2 [26] Jean-Bastien Grill, Florian Strub, Florent Altch Â´e, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doer- sch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Ghesh- laghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. In NeurIPS, 2020. 2, 3 [27] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In ICLR, 2021. 1, 2, 5, 6, 14, 15, 16, 17 [28] Sivan Harary, Eli Schwartz, Assaf Arbelle, Peter Staar, Shady Abu-Hussein, Elad Amrani, Roei Herzig, Amit Alfassy, Raja Giryes, Hilde Kuehne, et al. Unsupervised domain general- ization by learning a bridge across domains. In CVPR, 2022. 1 [29] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual repre- sentation learning. In CVPR, 2020. 2, 3 [30] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 5, 7, 14 [31] Shoubo Hu, Kun Zhang, Zhitang Chen, and Laiwan Chan. Domain generalization via multidomain discriminant analysis. In UAI, 2020. 1 [32] Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In ICCV, 2017. 2 [33] Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain generalization. In ECCV, 2020. 5, 15, 16, 17[34] Daehee Kim, Youngjun Yoo, Seunghyun Park, Jinkyu Kim, and Jaekoo Lee. Selfreg: Self-supervised contrastive regular- ization for domain generalization. In ICCV, 2021. 2, 5, 6, 15, 16, 17 [35] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribu- tion shifts. In ICML, 2021. 1 [36] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In ICML, 2021. 5, 6, 15, 16, 17 [37] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In ICCV, 2017. 1, 5, 6, 7, 8, 12, 13, 14, 15 [38] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, 2018. 1, 2, 5, 6, 15, 16, 17 [39] Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and Timothy M Hospedales. Episodic training for domain generalization. In ICCV, 2019. 1, 2 [40] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adversarial feature learning. In CVPR, 2018. 1, 2, 5, 15, 16, 17 [41] Pan Li, Da Li, Wei Li, Shaogang Gong, Yanwei Fu, and Timothy M Hospedales. A simple feature augmentation for domain generalization. In ICCV, 2021. 1, 2, 12, 14 [42] Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan, and Ling-Yu Duan. Uncertainty modeling for out- of-distribution generalization. In ICLR, 2022. 1, 2 [43] Yizhuo Li, Miao Hao, Zonglin Di, Nitesh Bharadwaj Gun- davarapu, and Xiaolong Wang. Test-time personalization with a transformer for human pose estimation. In NeurIPS, 2021. 2, 3, 4 [44] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep domain generaliza- tion via conditional invariant adversarial networks. In ECCV, 2018. 1, 2, 5, 15, 16, 17 [45] Yiying Li, Yongxin Yang, Wei Zhou, and Timothy Hospedales. Feature-critic networks for heterogeneous do- main generalization. In ICML, 2019. 14, 15 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In NeurIPS, 2021. 2, 3, 4, 7, 8, 12, 14, 15 [47] Krikamol Muandet, David Balduzzi, and Bernhard SchÂ¨olkopf. Domain generalization via invariant feature representation. In ICML, 2013. 1, 2 [48] Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing domain gap by reducing style bias. In CVPR, 2021. 2, 5, 6, 15, 16, 17 [49] Prashant Pandey, Mrigank Raman, Sumanth Varambally, and Prathosh Ap. Generalization on unseen domains via inference- time label-preserving target projections. In CVPR, 2021. 1 [50] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, 2019. 5, 17 [51] Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and Guillaume Lajoie. Gradient star- vation: A learning proclivity in neural networks. In NeurIPS, 2021. 1, 5, 6, 15, 16, 17 [52] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for out-of-distribution gen- eralization. In ICML, 2022. 1, 2, 5, 6, 15, 16, 17 [53] Yangjun Ruan, Yann Dubois, and Chris J Maddison. Optimal representations for covariate shift. In ICLR, 2022. 5, 15, 16, 17 [54] Bryan C Russell, Antonio Torralba, Kevin P Murphy, and William T Freeman. Labelme: a database and web-based tool for image annotation. IJCV, 77(1):157â€“173, 2008. 5 [55] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst- case generalization. In ICLR, 2020. 5, 15, 16, 17 [56] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. 2 [57] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad- cam: Visual explanations from deep networks via gradient- based localization. In ICCV, 2017. 7, 8, 11, 13 [58] Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In ICLR, 2021. 1, 2, 5, 6, 15, 16, 17 [59] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In ECCV, 2016. 5, 6, 15, 16, 17 [60] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, 2020. 1, 2, 4, 5, 7, 8, 11, 12, 13 [61] Vladimir Vapnik. The nature of statistical learning theory . Springer science & business media, 1999. 1, 5, 6, 15, 16, 17 [62] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017. 5, 16 [63] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 2, 3, 4, 7, 8, 11, 12, 13 [64] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Large-scale scene recog- nition from abbey to zoo. In CVPR, 2010. 5 [65] Zehao Xiao, Xiantong Zhen, Ling Shao, and Cees GM Snoek. Learning to generalize across domains on single test samples. In ICLR, 2022. 2 [66] Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. A fourier-based framework for domain generaliza- tion. In CVPR, 2021. 1, 2 [67] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 7[68] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020. 2, 5, 15, 16, 17 [69] Fu-En Yang, Yuan-Chia Cheng, Zu-Yun Shiau, and Yu- Chiang Frank Wang. Adversarial teacher-student representa- tion learning for domain generalization. In NeurIPS, 2021. 1, 2 [70] Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and Jun Zhu. Ood-bench: Quantifying and understanding two dimensions of out-of- distribution generalization. In CVPR, 2022. 5 [71] Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. 4 [72] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: A meta-learning approach for tackling group distri- bution shift. arXiv preprint arXiv:2007.02931, 2020. 5, 15, 16, 17 [73] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: Learning to adapt to domain shift. NeurIPS, 2021. 2 [74] Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu, and Jin Tang. Meta-dmoe: Adapting to domain shift by meta- distillation from mixture-of-experts. In NeurIPS, 2022. 2 [75] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 1, 2, 3, 5, 6, 7, 12, 15, 16, 17 Appendix In this supplementary material, we provide, 1. Resource usage for ITTA in Section 7. 2. Grad-CAM visualizations of different loss terms in Section 8. 3. Parameter analysis of ITTA in Section 9; 4. Using a different augmentation skill for ITTA in Sec- tion 10. 5. Using different updating steps or a strategy for ITTA during the test phase in Section 11. 6. Using different network structures for the learnable consistency loss and adaptive parameters in Section 12. 7. Comparisons with other related methods in Section 13. 8. Detailed experimental results in the DomainBed bench- mark in Section 14. 7. Resource Usage Comparisons Between ITTA and the Baseline Model Requiring extra resources for our ITTA is a common lim- itation for existing test-time-based arts. To further evaluate our method, in this section, we compare FLOPS, model size, and inference time in Table 5. We compare only with ERM as most existing methods utilize the same network during in- ferences. We note that compare to the baseline model, ITTA requires extra Flops and processing time, this is because the adaptation process uses extra forward and backward steps during the test phase. While the parameters between the two models are similar because the newly included adaptive blocks are much smaller in size compared to the original model. Table 5. Resource comparisons during testing. Here inc. and exc. columns in ITTA indicate to include and exclude the TTA phase. Model Flops (G) Params (M) Time (s) Baseline 1.82 11.18 0.004 ITTA (inc.| exc.) 6.12 | 1.83 14.95 | 14.94 0.021 | 0.005 8. Grad-CAM Visualizations of Different Self- Supervised Objectives In Section 5 of the manuscript, we provide Grad-CAM [57] visualizations of our learnable consistency and the main losses to illustrate their alignment. To further show the differences between several TTT tasks [60, 63], we present more visual examples in this section. Results are shown in Figure 5. We observe that the entropy minimization [63] and rotation estimation [60] objectives do not activate the same regions as the main loss. As shown in the first row, for the class label of giraffe, both the main loss and our learned loss can correctly locate the two giraffes in the image, while the rotation estimation task can only locate one target, the same observation can be found when the learned weightsare disabled in our loss term. Meanwhile, although the two objects can be found for the entropy minimization task, the corresponding hot region does not align with that of the main loss. Similar phenomena can be observed in other samples. These visual examples demonstrate that our learned objective can better align with the main task than the TTT tasks adopted in previous works [60, 63], explaining why using the proposed learnable consistency loss can better improve TTT. 9. Parameter Analysis In this section, we analyze the hyper-parameter used in ITTA. We use the weight parameterÎ± to balance the contri- butions from the main loss and weighted consistency loss (i.e. Lmain + Î±Lwcont in Eq. (2) of our manuscript). To analyze the sensitivity of ITTA regarding different values of Î±, we conduct ablation studies in the PACS benchmark [37]. Results are listed in Table 6. We observe that the proposed ITTA can obtain favorable performances when Î± is in the range of 0.1 to 10, and it performs the best on average when setting as 1. We thus fix the parameter as 1 in all experi- ments. 10. A Different Augmentation Skill for ITTA In our manuscript, we use the existing augmentation strat- egy from [75] to obtain the augmented feature. In this sec- tion, we replace this implementation with that from [41] to further verify if our ITTA can still thrive with another aug- mentation skill. Different from [75] that mixes the statics of the feature to synthesize new information, [41] uses an affine transformation to create new features, where the weight for the transformation is sampled from a normal distribution with the mean value of one and standard value of zero, and the bias for the transformation is sampled from a normal distribution with the mean and standard values both zero. Experiments are conducted on the PACS benchmark [37] with the leave-one-out strategy. We compare ITTA with several different variants. (1) Ours w/o fw & TTT: this variant is the baseline model which uses the naive consistency loss for training and does not include TTT during the test phase. (2) Ours w/o fw: we disable the fw in our consistency loss, which uses the naive consistency loss for the test-time updating. (3) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model when replacing the augmentation strategy. We also compare these variants with the ERM method to show their effectivenesses. Results are listed in Table 7. We observe that ERM per- forms favorably against the baseline model, indicating that this augmentation strategy may not be beneficial for the training process. Meanwhile, we observe that when fw is disabled, the performances seem to decrease in 3 out of 4 target domains, and the average accuracy is also inferior to the baseline (i.e. Ours w/o fw & TTT). This result is in line with the finding in [46] that an inappropriate TTT task may deteriorate the performance. In comparison, we note that the performances are both improved when fw is enabled (i.e. Ours w/o TTT and Ours), which once again demonstrates that the proposed learnable consistency loss can improve the trained model. Moreover, we can also observe that when combining fw and TTT, our model is superior to other vari- ants and the ERM method. These results demonstrate that the proposed two strategies can improve the current TTT framework despite a less effective augmentation strategy. 11. Different Updating Steps or Strategies for ITTA In the manuscript, we use one TTT step for ITTA before during the testing step. In this section, we conduct experi- ments to evaluate the performances of ITTA with different TTT steps. Experiments are conducted on the PACS bench- mark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper- parameter settings. Results are listed in Table 8. We observe that the average accuracies of using more TTT steps are not improved greatly while the computational times are propor- tional to the TTT steps. To this end, we use one TTT step for ITTA as a compromise between accuracy and efficiency. We use the online setting from TTT [60] for all arts, which assumes test samples arrive sequentially and updates the adaptive blocks based on the states optimized from a previous sample. In this section, we also test ITTA in an episodic manner (i.e. Epi) [12]. Results in Table 8 suggest that while the episodic updating strategy performs slightly worse than the current scheme, and it still outperforms the baseline. 12. Different Network Structures for the Learnable Consistency Loss and Adaptive Parameters In our implementation, we use 10 layers of learnable pa- rameters for fw, and we use 5 layers of learnable parameters for fÎ˜ after each block. In this section, we evaluate our ITTA with different network structures for these two mod- ules. Specifically, we compare the original implementation with the variants that use 1, 5, and 15 layers for fw and 1, 10, and 15 layers for fÎ˜ to evaluate the performances of dif- ferent structures. Similarly, we conduct experiments on the PACS benchmark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper-parameter settings. Evaluation results are listed in Table 9. We observe that their differences in the average accuracy are rather subtle on account of the variances. To(a) Input (b) Entropy (c) Rotation (d) Ours w/o fw (e) Ours (f) Main Figure 5. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels (i.e. giraffe, elephant, house, and horse from top to bottom) from the four target domains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). â€œEntropyâ€ and â€œRotationâ€ here denote the entropy minimization and rotation estimation tasks in [63] and [60]. Ours w/o fw is the learnable consistency loss in Eq. (1) in the manuscript (i.e. âˆ¥fw(z âˆ’ zâ€²)âˆ¥) when fw is disabled. The proposed learnable consistency loss can align well with the main classification task. Table 6. Sensitivity analysis of ITTA regarding different values ofÎ± in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Values Target domain Avg.Art Cartoon Photo Sketch Î± = 0.1 83.9 Â± 0.7 76.2 Â± 1.1 94.8 Â± 0.2 78.8 Â± 0.8 83.4 Â± 0.2 Î± = 1 (Ours) 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 Î± = 10 83.9 Â± 0.5 77.4 Â± 0.6 94.2 Â± 0.7 77.3 Â± 0.8 83.2 Â± 0.3 Î± = 100 81.5 Â± 1.2 77.0 Â± 0.6 92.6 Â± 0.7 78.9 Â± 2.1 82.5 Â± 0.9 this end, we use the original implementation with 10 layers of learnable parameters for fw and 5 layers of learnable pa- rameters for fÎ˜, which performs relatively better than other variants. Since the adaptive blocks fÎ˜ are attached after each layer of the network, one may wonder how the varying locations of the adaptive blocks affect the performance of ITTA. To answer this question, we further conduct experiments by adding the adaptive blocks after different layers of the orig- inal network. Denoting as Loc = lan given the n layers in the original network, we note that the model performs less effectively when the adaptive block is placed after the 1st layer of the network, and using all four adaptive blocks (i.e. ours) is more effective than other alternatives. 13. Comparisons with Other Related Methods Apart from the proposed ITTA, some other works also propose to include learnable parameters in their auxiliaryTable 7. Performances of our method with another augmentation strategy from [41] in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch ERM 78.0 Â± 1.3 73.4 Â± 0.8 94.1 Â± 0.4 73.6 Â± 2.2 79.8 Â± 0.4 Ours w/o fw & TTT 74.9 Â± 0.4 74.1 Â± 0.8 90.6 Â± 0.3 79.7 Â± 0.7 79.8 Â± 0.4 Ours w/o fw 77.1 Â± 1.0 73.6 Â± 1.1 89.9 Â± 0.4 78.4 Â± 0.8 79.7 Â± 0.2 Ours w/o TTT 77.5 Â± 0.3 73.2 Â± 0.6 92.4 Â± 0.4 78.0 Â± 1.0 80.3 Â± 0.3 Ours (w/ fw & TTT) 79.2 Â± 0.8 74.9 Â± 1.1 92.2 Â± 0.3 76.9 Â± 0.7 80.8 Â± 0.4 Table 8. Evaluations of ITTA in the unseen domain from PACS [37] with different TTT steps and updating strategies during the testing phase. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. The time consumption (TC) is computed using one image with the size of 224 Ã— 224. Epi. denotes updating ITTA in an episodic manner. Steps Target domain Avg. TCArt Cartoon Photo Sketch 1 step (Ours) 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 2.4 ms 2 step 84.2 Â± 0.9 77.5 Â± 0.6 94.4 Â± 0.4 79.1 Â± 1.0 83.8 Â± 0.1 4.2 ms 3 step 84.5 Â± 1.2 77.6 Â± 0.6 94.0 Â± 0.6 79.3 Â± 0.1 83.9 Â± 0.3 6.1 ms Epi. 83.6 Â± 0.7 77.9 Â± 0.5 95.2 Â± 0.1 76.6 Â± 0.5 83.3 Â± 0.4 losses. Examples include MetaReg [2] and Feature-Critic [45] which both suggest using meta-learning to produce more general models. The main difference between these arts and ITTA is that parameters in the auxiliary loss from [2,45] are gradually refined by episode training, and they are updated via a gradient alignment step in ITTA (see Sec. 3.1 in the manuscript), which is much simpler. In this sec- tion, we compare ITTA with these two arts in the PACS dataset [37] using the same settings aforementioned. Be- cause MetaReg [2] does not release codes, we thus directly cite the data from their paper in the comparison. Different from others, the results in [2] are averaged by 5 trials accord- ing to their paper, which is much less than our experimental settings. Meanwhile, we also compare with TTT++ [46] which suggests storing the momentum of the features from the source domain and enforcing the similarity between mo- mentums of features from the source and target domains. We use the same setting in Section 5.1 from the manuscript to evaluate TTT++. Results are listed in Table 10. We observe that our method consistently outperforms that from [2,45,46] for both the cases with and without TTT, indicating that the proposed learnable consistency loss and updating method is not only simpler but also more effective than the losses in [2, 45]. 14. Detailed Results in the DomainBed Bench- mark [27] this section presents the average accuracy in each domain from different datasets. As shown in Table 11, 12, 13, 14, and 15, these results are detailed illustrations of the results in Table 2 in our manuscript. For all the experiments, we use the â€œtraining-domain validate setâ€ as the model selection method. A total of 22 methods are examined for 60 trials in each unseen domain, and all methods are trained with the leave-one-out strategy using the ResNet18 [30] backbones.Table 9. Performances of our method with different network structures for the consistency loss (i.e. fw) and adaptive parameters (i.e. fÎ˜) in the unseen domain from PACS [37]. Here â€˜Loc=lanâ€™ locates the adaptive block after the n-th layer of the model (â€˜la4â€™ is the last layer). The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Structures Target domain Avg.Art Cartoon Photo Sketch Structures offw 1 layer 83.5 Â±1.2 76.0 Â±1.0 95.3 Â±0.2 78.7 Â±1.5 83.4 Â±0.4 5 layers 83.7 Â±0.6 76.8 Â±0.9 94.6 Â±0.3 78.8 Â±0.3 83.5 Â±0.3 10 layers (Ours) 84.7 Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 15 layers 84.1 Â±0.4 75.8 Â±0.2 94.3 Â±0.3 79.5 Â±0.4 83.4 Â±0.2 Structures offÎ˜ 1 layer 84.0 Â±0.6 77.4 Â±0.5 94.4 Â±0.5 78.3 Â±0.4 83.5 Â±0.3 5 layers (Ours) 84.7 Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 10 layers 84.8 Â±0.3 76.0 Â±0.6 94.1 Â±0.5 78.3 Â±0.1 83.3 Â±0.3 15 layers 83.9 Â±0.8 76.0 Â±0.5 93.8 Â±0.4 78.7 Â±1.4 83.1 Â±0.6 Locations offÎ˜ Loc=la1 83.4Â±0.7 76.8 Â±0.3 94.4 Â±0.3 77.8 Â±0.3 83.1 Â±0.3 Loc=la2 83.4Â±0.6 77.7 Â±0.6 94.2 Â±0.5 78.0 Â±0.5 83.3 Â±0.3 Loc=la3 84.0Â±0.4 77.5 Â±0.3 94.4 Â±0.1 77.8 Â±0.1 83.4 Â±0.2 Loc=la4 84.1Â±0.7 77.8 Â±0.5 94.8 Â±0.2 76.9 Â±1.5 83.4 Â±0.4 Table 10. Compare with learnable losses in [2, 45] in the unseen domain from PACS [37]. The reported accuracies ( %) and standard deviations are computed from 60 trials in each target domain except for [2] where the numbers are directly cited from their paper. Model Target domain Avg.Art Cartoon Photo Sketch MetaReg [2] 83.7 Â± 0.2 77.2 Â± 0.3 95.5 Â± 0.2 70.3 Â± 0.3 81.7 Feture-Critic [45] 78.4 Â± 1.6 75.4 Â± 1.2 92.6 Â± 0.5 73.3 Â± 1.4 80.0 Â± 0.3 TTT++ [46] 84.3 Â± 0.1 78.4 Â± 0.5 93.8 Â± 1.3 73.2 Â± 3.2 82.4 Â± 1.1 Ours w/o TTT 83.3 Â± 0.5 76.0 Â± 0.5 94.4 Â± 0.5 76.7 Â± 1.4 82.8 Â± 0.3 Ours 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 Table 11. Average accuracies on the PACS [37] datasets using the default hyper-parameter settings in DomainBed [27]. art cartoon photo sketch Average ERM [61] 78.0 Â± 1.3 73.4 Â± 0.8 94.1 Â± 0.4 73.6 Â± 2.2 79.8 Â± 0.4 IRM [1] 76.9 Â± 2.6 75.1 Â± 0.7 94.3 Â± 0.4 77.4 Â± 0.4 80.9 Â± 0.5 GroupGRO [55] 77.7 Â± 2.6 76.4 Â± 0.3 94.0 Â± 0.3 74.8 Â± 1.3 80.7 Â± 0.4 Mixup [68] 79.3 Â± 1.1 74.2 Â± 0.3 94.9 Â± 0.3 68.3 Â± 2.7 79.2 Â± 0.9 MLDG [38] 78.4 Â± 0.7 75.1 Â± 0.5 94.8 Â± 0.4 76.7 Â± 0.8 81.3 Â± 0.2 CORAL [59] 81.5 Â± 0.5 75.4 Â± 0.7 95.2 Â± 0.5 74.8 Â± 0.4 81.7 Â± 0.0 MMD [40] 81.3 Â± 0.6 75.5 Â± 1.0 94.0 Â± 0.5 74.3 Â± 1.5 81.3 Â± 0.8 DANN [23] 79.0 Â± 0.6 72.5 Â± 0.7 94.4 Â± 0.5 70.8 Â± 3.0 79.2 Â± 0.3 CDANN [44] 80.4 Â± 0.8 73.7 Â± 0.3 93.1 Â± 0.6 74.2 Â± 1.7 80.3 Â± 0.5 MTL [6] 78.7 Â± 0.6 73.4 Â± 1.0 94.1 Â± 0.6 74.4 Â± 3.0 80.1 Â± 0.8 SagNet [48] 82.9 Â± 0.4 73.2 Â± 1.1 94.6 Â± 0.5 76.1 Â± 1.8 81.7 Â± 0.6 ARM [72] 79.4 Â± 0.6 75.0 Â± 0.7 94.3 Â± 0.6 73.8 Â± 0.6 80.6 Â± 0.5 VREx [36] 74.4 Â± 0.7 75.0 Â± 0.4 93.3 Â± 0.3 78.1 Â± 0.9 80.2 Â± 0.5 RSC [33] 78.5 Â± 1.1 73.3 Â± 0.9 93.6 Â± 0.6 76.5 Â± 1.4 80.5 Â± 0.2 SelfReg [34] 82.5 Â± 0.8 74.4 Â± 1.5 95.4 Â± 0.5 74.9 Â± 1.3 81.8 Â± 0.3 MixStyle [75] 82.6 Â± 1.2 76.3 Â± 0.4 94.2 Â± 0.3 77.5 Â± 1.3 82.6 Â± 0.4 Fish [58] 80.9 Â± 1.0 75.9 Â± 0.4 95.0 Â± 0.4 76.2 Â± 1.0 82.0 Â± 0.3 SD [51] 83.2 Â± 0.6 74.6 Â± 0.3 94.6 Â± 0.1 75.1 Â± 1.6 81.9 Â± 0.3 CAD [53] 83.9 Â± 0.8 74.2 Â± 0.4 94.6 Â± 0.4 75.0 Â± 1.2 81.9 Â± 0.3 CondCAD [53] 79.7 Â± 1.0 74.2 Â± 0.9 94.6 Â± 0.4 74.8 Â± 1.4 80.8 Â± 0.5 Fishr [52] 81.2 Â± 0.4 75.8 Â± 0.8 94.3 Â± 0.3 73.8 Â± 0.6 81.3 Â± 0.3 Ours 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3Table 12. Average accuracies on the VLCS [18] datasets using the default hyper-parameter settings in DomainBed [27]. Caltech LabelMe Sun VOC Average ERM [61] 97.7 Â± 0.3 62.1 Â± 0.9 70.3 Â± 0.9 73.2 Â± 0.7 75.8 Â± 0.2 IRM [1] 96.1 Â± 0.8 62.5 Â± 0.3 69.9 Â± 0.7 72.0 Â± 1.4 75.1 Â± 0.1 GroupGRO [55] 96.7 Â± 0.6 61.7 Â± 1.5 70.2 Â± 1.8 72.9 Â± 0.6 75.4 Â± 1.0 Mixup [68] 95.6 Â± 1.5 62.7 Â± 0.4 71.3 Â± 0.3 75.4 Â± 0.2 76.2 Â± 0.3 MLDG [38] 95.8 Â± 0.5 63.3 Â± 0.8 68.5 Â± 0.5 73.1 Â± 0.8 75.2 Â± 0.3 CORAL [59] 96.5 Â± 0.3 62.8 Â± 0.1 69.1 Â± 0.6 73.8 Â± 1.0 75.5 Â± 0.4 MMD [40] 96.0 Â± 0.8 64.3 Â± 0.6 68.5 Â± 0.6 70.8 Â± 0.1 74.9 Â± 0.5 DANN [23] 97.2 Â± 0.1 63.3 Â± 0.6 70.2 Â± 0.9 74.4 Â± 0.2 76.3 Â± 0.2 CDANN [44] 95.4 Â± 1.2 62.6 Â± 0.6 69.9 Â± 1.3 76.2 Â± 0.5 76.0 Â± 0.5 MTL [6] 94.4 Â± 2.3 65.0 Â± 0.6 69.6 Â± 0.6 71.7 Â± 1.3 75.2 Â± 0.3 SagNet [48] 94.9 Â± 0.7 61.9 Â± 0.7 69.6 Â± 1.3 75.2 Â± 0.6 75.4 Â± 0.8 ARM [72] 96.9 Â± 0.5 61.9 Â± 0.4 71.6 Â± 0.1 73.3 Â± 0.4 75.9 Â± 0.3 VREx [36] 96.2 Â± 0.0 62.5 Â± 1.3 69.3 Â± 0.9 73.1 Â± 1.2 75.3 Â± 0.6 RSC [33] 96.2 Â± 0.0 63.6 Â± 1.3 69.8 Â± 1.0 72.0 Â± 0.4 75.4 Â± 0.3 SelfReg [34] 95.8 Â± 0.6 63.4 Â± 1.1 71.1 Â± 0.6 75.3 Â± 0.6 76.4 Â± 0.7 MixStyle [75] 97.3 Â± 0.3 61.6 Â± 0.1 70.4 Â± 0.7 71.3 Â± 1.9 75.2 Â± 0.7 Fish [58] 97.4 Â± 0.2 63.4 Â± 0.1 71.5 Â± 0.4 75.2 Â± 0.7 76.9 Â± 0.2 SD [51] 96.5 Â± 0.4 62.2 Â± 0.0 69.7 Â± 0.9 73.6 Â± 0.4 75.5 Â± 0.4 CAD [53] 94.5 Â± 0.9 63.5 Â± 0.6 70.4 Â± 1.2 72.4 Â± 1.3 75.2 Â± 0.6 CondCAD [53] 96.5 Â± 0.8 62.6 Â± 0.4 69.1 Â± 0.2 76.0 Â± 0.2 76.1 Â± 0.3 Fishr [52] 97.2 Â± 0.6 63.3 Â± 0.7 70.4 Â± 0.6 74.0 Â± 0.8 76.2 Â± 0.3 Ours 96.9 Â± 1.2 63.7 Â± 1.1 72.0 Â± 0.3 74.9 Â± 0.8 76.9 Â± 0.6 Table 13. Average accuracies on the OfficeHome [62] datasets using the default hyper-parameter settings in DomainBed [27]. art clipart product real Average ERM [61] 52.2 Â± 0.2 48.7 Â± 0.5 69.9 Â± 0.5 71.7 Â± 0.5 60.6 Â± 0.2 IRM [1] 49.7 Â± 0.2 46.8 Â± 0.5 67.5 Â± 0.4 68.1 Â± 0.6 58.0 Â± 0.1 GroupGRO [55] 52.6 Â± 1.1 48.2 Â± 0.9 69.9 Â± 0.4 71.5 Â± 0.8 60.6 Â± 0.3 Mixup [68] 54.0 Â± 0.7 49.3 Â± 0.7 70.7 Â± 0.7 72.6 Â± 0.3 61.7 Â± 0.5 MLDG [38] 53.1 Â± 0.3 48.4 Â± 0.3 70.5 Â± 0.7 71.7 Â± 0.4 60.9 Â± 0.2 CORAL [59] 55.1 Â± 0.7 49.7 Â± 0.9 71.8 Â± 0.2 73.1 Â± 0.5 62.4 Â± 0.4 MMD [40] 50.9 Â± 1.0 48.7 Â± 0.3 69.3 Â± 0.7 70.7 Â± 1.3 59.9 Â± 0.4 DANN [23] 51.8 Â± 0.5 47.1 Â± 0.1 69.1 Â± 0.7 70.2 Â± 0.7 59.5 Â± 0.5 CDANN [44] 51.4 Â± 0.5 46.9 Â± 0.6 68.4 Â± 0.5 70.4 Â± 0.4 59.3 Â± 0.4 MTL [6] 51.6 Â± 1.5 47.7 Â± 0.5 69.1 Â± 0.3 71.0 Â± 0.6 59.9 Â± 0.5 SagNet [48] 55.3 Â± 0.4 49.6 Â± 0.2 72.1 Â± 0.4 73.2 Â± 0.4 62.5 Â± 0.3 ARM [72] 51.3 Â± 0.9 48.5 Â± 0.4 68.0 Â± 0.3 70.6 Â± 0.1 59.6 Â± 0.3 VREx [36] 51.1 Â± 0.3 47.4 Â± 0.6 69.0 Â± 0.4 70.5 Â± 0.4 59.5 Â± 0.1 RSC [33] 49.0 Â± 0.1 46.2 Â± 1.5 67.8 Â± 0.7 70.6 Â± 0.3 58.4 Â± 0.6 SelfReg [34] 55.1 Â± 0.8 49.2 Â± 0.6 72.2 Â± 0.3 73.0 Â± 0.3 62.4 Â± 0.1 MixStyle [75] 50.8 Â± 0.6 51.4 Â± 1.1 67.6 Â± 1.3 68.8 Â± 0.5 59.6 Â± 0.8 Fish [58] 54.6 Â± 1.0 49.6 Â± 1.0 71.3 Â± 0.6 72.4 Â± 0.2 62.0 Â± 0.6 SD [51] 55.0 Â± 0.4 51.3 Â± 0.5 72.5 Â± 0.2 72.7 Â± 0.3 62.9 Â± 0.2 CAD [53] 52.1 Â± 0.6 48.3 Â± 0.5 69.7 Â± 0.3 71.9 Â± 0.4 60.5 Â± 0.3 CondCAD [53] 53.3 Â± 0.6 48.4 Â± 0.2 69.8 Â± 0.9 72.6 Â± 0.1 61.0 Â± 0.4 Fishr [52] 52.6 Â± 0.9 48.6 Â± 0.3 69.9 Â± 0.6 72.4 Â± 0.4 60.9 Â± 0.3 Ours 54.4 Â± 0.2 52.3 Â± 0.8 69.5 Â± 0.3 71.7 Â± 0.2 62.0 Â± 0.2Table 14. Average accuracies on the TerraInc [4] datasets using the default hyper-parameter settings in DomainBed [27]. L100 L38 L43 L46 Average ERM [61] 42.1 Â± 2.5 30.1 Â± 1.2 48.9 Â± 0.6 34.0 Â± 1.1 38.8 Â± 1.0 IRM [1] 41.8 Â± 1.8 29.0 Â± 3.6 49.6 Â± 2.1 33.1 Â± 1.5 38.4 Â± 0.9 GroupGRO [55] 45.3 Â± 4.6 36.1 Â± 4.4 51.0 Â± 0.8 33.7 Â± 0.9 41.5 Â± 2.0 Mixup [68] 49.4 Â± 2.0 35.9 Â± 1.8 53.0 Â± 0.7 30.0 Â± 0.9 42.1 Â± 0.7 MLDG [38] 39.6 Â± 2.3 33.2 Â± 2.7 52.4 Â± 0.5 35.1 Â± 1.5 40.1 Â± 0.9 CORAL [59] 46.7 Â± 3.2 36.9 Â± 4.3 49.5 Â± 1.9 32.5 Â± 0.7 41.4 Â± 1.8 MMD [40] 49.1 Â± 1.2 36.4 Â± 4.8 50.4 Â± 2.1 32.3 Â± 1.5 42.0 Â± 1.0 DANN [23] 44.3 Â± 3.6 28.0 Â± 1.5 47.9 Â± 1.0 31.3 Â± 0.6 37.9 Â± 0.9 CDANN [44] 36.9 Â± 6.4 32.7 Â± 6.2 51.1 Â± 1.3 33.5 Â± 0.5 38.6 Â± 2.3 MTL [6] 45.2 Â± 2.6 31.0 Â± 1.6 50.6 Â± 1.1 34.9 Â± 0.4 40.4 Â± 1.0 SagNet [48] 36.3 Â± 4.7 40.3 Â± 2.0 52.5 Â± 0.6 33.3 Â± 1.3 40.6 Â± 1.5 ARM [72] 41.5 Â± 4.5 27.7 Â± 2.4 50.9 Â± 1.0 29.6 Â± 1.5 37.4 Â± 1.9 VREx [36] 48.0 Â± 1.7 41.1 Â± 1.5 51.8 Â± 1.5 32.0 Â± 1.2 43.2 Â± 0.3 RSC [33] 42.8 Â± 2.4 32.2 Â± 3.8 49.6 Â± 0.9 32.9 Â± 1.2 39.4 Â± 1.3 SelfReg [34] 46.1 Â± 1.5 34.5 Â± 1.6 49.8 Â± 0.3 34.7 Â± 1.5 41.3 Â± 0.3 MixStyle [75] 50.6 Â± 1.9 28.0 Â± 4.5 52.1 Â± 0.7 33.0 Â± 0.2 40.9 Â± 1.1 Fish [58] 46.3 Â± 3.0 29.0 Â± 1.1 52.7 Â± 1.2 32.8 Â± 1.0 40.2 Â± 0.6 SD [51] 45.5 Â± 1.9 33.2 Â± 3.1 52.9 Â± 0.7 36.4 Â± 0.8 42.0 Â± 1.0 CAD [53] 43.1 Â± 2.6 31.1 Â± 1.9 53.1 Â± 1.6 34.7 Â± 1.3 40.5 Â± 0.4 CondCAD [53] 44.4 Â± 2.9 32.9 Â± 2.5 50.5 Â± 1.3 30.8 Â± 0.5 39.7 Â± 0.4 Fishr [52] 49.9 Â± 3.3 36.6 Â± 0.9 49.8 Â± 0.2 34.2 Â± 1.3 42.6 Â± 1.0 Ours 51.7 Â± 2.4 37.6 Â± 0.6 49.9 Â± 0.6 33.6 Â± 0.6 43.2 Â± 0.5 Table 15. Average accuracies on the DomainNet [50] datasets using the default hyper-parameter settings in DomainBed [27]. clip info paint quick real sketch Average ERM [61] 50.4 Â± 0.2 14.0 Â± 0.2 40.3 Â± 0.5 11.7 Â± 0.2 52.0 Â± 0.2 43.2 Â± 0.3 35.3 Â± 0.1 IRM [1] 43.2 Â± 0.9 12.6 Â± 0.3 35.0 Â± 1.4 9.9 Â± 0.4 43.4 Â± 3.0 38.4 Â± 0.4 30.4 Â± 1.0 GroupGRO [55] 38.2 Â± 0.5 13.0 Â± 0.3 28.7 Â± 0.3 8.2 Â± 0.1 43.4 Â± 0.5 33.7 Â± 0.0 27.5 Â± 0.1 Mixup [68] 48.9 Â± 0.3 13.6 Â± 0.3 39.5 Â± 0.5 10.9 Â± 0.4 49.9 Â± 0.2 41.2 Â± 0.2 34.0 Â± 0.0 MLDG [38] 51.1 Â± 0.3 14.1 Â± 0.3 40.7 Â± 0.3 11.7 Â± 0.1 52.3 Â± 0.3 42.7 Â± 0.2 35.4 Â± 0.0 CORAL [59] 51.2 Â± 0.2 15.4 Â± 0.2 42.0 Â± 0.2 12.7 Â± 0.1 52.0 Â± 0.3 43.4 Â± 0.0 36.1 Â± 0.2 MMD [40] 16.6 Â± 13.3 0.3 Â± 0.0 12.8 Â± 10.4 0.3 Â± 0.0 17.1 Â± 13.7 0.4 Â± 0.0 7.9 Â± 6.2 DANN [23] 45.0 Â± 0.2 12.8 Â± 0.2 36.0 Â± 0.2 10.4 Â± 0.3 46.7 Â± 0.3 38.0 Â± 0.3 31.5 Â± 0.1 CDANN [44] 45.3 Â± 0.2 12.6 Â± 0.2 36.6 Â± 0.2 10.3 Â± 0.4 47.5 Â± 0.1 38.9 Â± 0.4 31.8 Â± 0.2 MTL [6] 50.6 Â± 0.2 14.0 Â± 0.4 39.6 Â± 0.3 12.0 Â± 0.3 52.1 Â± 0.1 41.5 Â± 0.0 35.0 Â± 0.0 SagNet [48] 51.0 Â± 0.1 14.6 Â± 0.1 40.2 Â± 0.2 12.1 Â± 0.2 51.5 Â± 0.3 42.4 Â± 0.1 35.3 Â± 0.1 ARM [72] 43.0 Â± 0.2 11.7 Â± 0.2 34.6 Â± 0.1 9.8 Â± 0.4 43.2 Â± 0.3 37.0 Â± 0.3 29.9 Â± 0.1 VREx [36] 39.2 Â± 1.6 11.9 Â± 0.4 31.2 Â± 1.3 10.2 Â± 0.4 41.5 Â± 1.8 34.8 Â± 0.8 28.1 Â± 1.0 RSC [33] 39.5 Â± 3.7 11.4 Â± 0.8 30.5 Â± 3.1 10.2 Â± 0.8 41.0 Â± 1.4 34.7 Â± 2.6 27.9 Â± 2.0 SelfReg [34] 47.9 Â± 0.3 15.1 Â± 0.3 41.2 Â± 0.2 11.7 Â± 0.3 48.8 Â± 0.0 43.8 Â± 0.3 34.7 Â± 0.2 MixStyle [75] 49.1 Â± 0.4 13.4 Â± 0.0 39.3 Â± 0.0 11.4 Â± 0.4 47.7 Â± 0.3 42.7 Â± 0.1 33.9 Â± 0.1 Fish [58] 51.5 Â± 0.3 14.5 Â± 0.2 40.4 Â± 0.3 11.7 Â± 0.5 52.6 Â± 0.2 42.1 Â± 0.1 35.5 Â± 0.0 SD [51] 51.3 Â± 0.3 15.5 Â± 0.1 41.5 Â± 0.3 12.6 Â± 0.2 52.9 Â± 0.2 44.0 Â± 0.4 36.3 Â± 0.2 CAD [53] 45.4 Â± 1.0 12.1 Â± 0.5 34.9 Â± 1.1 10.2 Â± 0.6 45.1 Â± 1.6 38.5 Â± 0.6 31.0 Â± 0.8 CondCAD [53] 46.1 Â± 1.0 13.3 Â± 0.4 36.1 Â± 1.4 10.7 Â± 0.2 46.8 Â± 1.3 38.7 Â± 0.7 31.9 Â± 0.7 Fishr [52] 47.8 Â± 0.7 14.6 Â± 0.2 40.0 Â± 0.3 11.9 Â± 0.2 49.2 Â± 0.7 41.7 Â± 0.1 34.2 Â± 0.3 Ours 50.7 Â± 0.7 13.9 Â± 0.4 39.4 Â± 0.5 11.9 Â± 0.2 50.2 Â± 0.3 43.5 Â± 0.1 34.9 Â± 0.1",
      "meta_data": {
        "arxiv_id": "2304.04494v2",
        "authors": [
          "Liang Chen",
          "Yong Zhang",
          "Yibing Song",
          "Ying Shan",
          "Lingqiao Liu"
        ],
        "published_date": "2023-04-10T10:12:38Z",
        "pdf_url": "https://arxiv.org/pdf/2304.04494v2.pdf"
      }
    },
    {
      "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
      "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
      "full_text": "Published as a conference paper at ICLR 2024 ACTIVE TEST-TIME ADAPTATION : T HEORETICAL ANALYSES AND AN ALGORITHM Shurui Guiâˆ— Texas A&M University College Station, TX 77843 shurui.gui@tamu.edu Xiner Li* Texas A&M University College Station, TX 77843 lxe@tamu.edu Shuiwang Ji Texas A&M University College Station, TX 77843 sji@tamu.edu ABSTRACT Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies. To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting. We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA. 1 I NTRODUCTION Deep learning has achieved remarkable success across various fields, attaining high accuracy in numerous applications (Krizhevsky et al., 2017; Simonyan and Zisserman, 2014). Nonetheless, When training and test data follow distinct distributions, models often experience significant performance degradation during test. This phenomenon, known as the distribution shift or out-of-distribution (OOD) problem, is extensively studied within the context of both domain generalization (DG) (Gulra- jani and Lopez-Paz, 2020; Koh et al., 2021; Gui et al., 2022) and domain adaptation (DA) (Ganin et al., 2016; Sun and Saenko, 2016). While these studies involve intensive training of models with considerable generalization abilities towards target domains, they overlook an important application property; namely, continuous adaptivity to real-time streaming data under privacy, resource, and efficiency constraints. This gap leads to the emergence of test-time adaptation (TTA) tasks, targeting on-the-fly adaptation to continuous new domains during the test phase or application deployment. The study of TTA encompasses two main categories; namely test-time training (TTT) methods (Sun et al., 2020; Liu et al., 2021c) and fully test-time adaptation (FTTA) (Niu et al., 2023; Wang et al., 2021). The TTT pipeline incorporates retraining on the source data, whereas FTTA methods adapt arbitrary pre-trained models to the given test mini-batch by conducting entropy minimization, without access to the source data. Nevertheless, most TTA methods can only handle corrupted distribution shifts (Hendrycks and Dietterich, 2019b) (e.g., Gaussian noise,) and rely heavily on human intuition or empirical studies. To bridge this gap, our paper focuses on tackling significant domain distribution shifts in real time with theoretical insights. We investigate FTTA, which is more general and adaptable than TTT, particularly under data ac- cessibility, privacy, and efficiency constraints. Traditional FTTA aims at adapting a pre-trained model to streaming test-time data from diverse domains under unsupervised settings. However, recent works (Lin et al., 2022; Pearl, 2009) prove that it is theoretically infeasible to achieve OOD generalization without extra information such as environment partitions. Since utilizing environment partitions requires heavy pretraining, contradicting the nature of TTA, we are motivated to incorporate extra information in a different way,i.e., integrating a limited number of labeled test-time samples to alleviate distribution shifts, following the active learning (AL) paradigm (Settles, 2009). To this end, we propose the novel problem setting of active test-time adaptation (ATTA) by incorporating âˆ—Equal contributions 1 arXiv:2404.05094v1  [cs.LG]  7 Apr 2024Published as a conference paper at ICLR 2024 AL within FTTA. ATTA faces two major challenges; namely, catastrophic forgetting (CF) (Kemker et al., 2018; Li and Hoiem, 2017) and real-time active sample selection. CF problem arises when a model continually trained on a sequence of domains experiences a significant performance drop on previously learned domains, due to the inaccessibility of the source data and previous test data. Real-time active sample selection requires AL algorithms to select informative samples from a small buffer of streaming test data for annotation, without a complete view of the test distribution. In this paper, we first formally define the ATTA setting. We then provide its foundational analysis under the learning theoryâ€™s paradigm to guarantee the mitigation of distribution shifts and avoid CF. Aligned with our empirical validations, while the widely used entropy minimization (Wang et al., 2021; Grandvalet and Bengio, 2004) can cause CF, it can conversely become the key to preventing CF problems with our sample selection and balancing techniques. Building on the analyses, we then introduce a simple yet effective ATTA algorithm, SimATTA, incorporating balanced sample selections and incremental clustering. Finally, we conducted a comprehensive experimental study to evaluate the proposed ATTA settings with three different settings in the order of low to high requirement restrictiveness, i.e., TTA, Enhanced TTA, and Active Domain Adaptation (ADA). Intensive experiments indicate that ATTA jointly equips with the efficiency of TTA and the effectiveness of ADA, rendering an uncompromising real-time distribution adaptation direction. Comparison to related studies. Compared to TTA methods, ATTA requires extra active labels, but the failure of TTA methods (Sec. 5.1) and the theoretical proof of Lin et al. (2022); Pearl (2009) justify its necessity and rationality. Compared to active online learning, ATTA focuses on lightweight real-time fine-tuning without round-wise re-trainings as Saran et al. (2023) and emphasizes the importance of CF avoidance instead of resetting models and losing learned distributions. In fact, active online learning is partially similar to our enhanced TTA setting (Sec. 5.2. Compared to ADA methods (Prabhu et al., 2021; Ning et al., 2021), ATTA does not presuppose access to source data, model parameters, or pre-collected target samples. Furthermore, without this information, ATTA can still perform on par with ADA methods (Sec. 5.3). The recent source-free active domain adaptation (SFADA) method SALAD (Kothandaraman et al., 2023) still requires access to model parameter gradients, pre-collected target data, and training of additional networks. Our ATTA, in contrast, with non-regrettable active sample selection on streaming data, is a much lighter and more realistic approach distinct from ADA and SFADA. More related-work discussions are provided in Appx. C. 2 T HE ACTIVE TEST-TIME ADAPTATION FORMULATION TTA methods aim to solve distribution shifts by dynamically optimizing a pre-trained model based on streaming test data. We introduce the novel problem setting of Active Test-Time Adaptation (ATTA), which incorporates active learning during the test phase. In ATTA, the model continuously selects the most informative instances from the test batch to be labeled by an explicit or implicit oracle (e.g., human annotations, self-supervised signals) and subsequently learned by the model, aiming to improve future adaptations. Considering the labeling costs in real-world applications, a â€œbudgetâ€ is established for labeled test instances. The model must effectively manage this budget distribution and ensure that the total number of label requests throughout the test phase does not surpass the budget. We now present a formal definition of the ATTA problem. Consider a pre-trained modelf(x; Ï•) with parameters Ï• trained on the source dataset DS = (x, y)|DS|, with each data sample x âˆˆ Xand a label y âˆˆ Y. We aim to adapt model parameters Î¸, initialized as Ï•, to an unlabeled test-time data stream. The streaming test data exhibit distribution shifts from the source data and varies continuously with time, forming multiple domains to which we must continuously adapt. The test phase commences at time step t = 1 and the streaming test data is formulated in batches. The samples are then actively selected, labeled (by the oracle) and collected as Dte(t) = ActAlg(Ute(t)), where ActAlg(Â·) denotes an active selection/labeling algorithm. The labeled samples Dte(t) are subsequently incorporated into the ATTA training setDtr(t). Finally, we conclude time step t by performing ATTA training, updating model parameters Î¸(t) using Dtr(t), with Î¸(t) initialized as the previous final state Î¸(t âˆ’ 1). Definition 1 (The ATTA problem). Given a model f(x; Î¸), with parameters Î¸, initialized with parameters Î¸(0) = Ï• obtained by pre-training on source domain data, and streaming test data batches Ute(t) continually changing over time, the ATTA task aims to optimize the model at any time stept (with test phase commencing at t = 1) as Î¸(t)âˆ— := argmin Î¸(t) (E(x,y,t)âˆˆDtr(t)[â„“CE (f(x; Î¸(t)), y)] + E(x,t)âˆˆUte(t)[â„“U (f(x; Î¸(t)))]), (1) 2Published as a conference paper at ICLR 2024 where Dtr(t) = ( âˆ…, t = 0 Dtr(t âˆ’ 1) âˆª Dte(t), t â‰¥ 1, s.t. |Dtr(t)| â‰¤ B, (2) Dte(t) = ActAlg(Ute(t)) is actively selected and labeled, â„“CE is the cross entropy loss, â„“U is an unsupervised learning loss, and B is the budget. 3 T HEORETICAL STUDIES In this section, we conduct an in-depth theoretical analysis of TTA based on learning theories. We mainly explore two questions: How can significant distribution shifts be effectively addressed under the TTA setting? How can we simultaneously combat the issue of CF? Sec. 3.1 provides a solution with theoretical guarantees to the first question, namely, active TTA (ATTA), along with the conditions under which distribution shifts can be well addressed. Sec. 3.2 answers the second question with an underexplored technique, i.e., selective entropy minimization, building upon the learning bounds established in Sec. 3.1. We further validate these theoretical findings through experimental analysis. Collectively, we present a theoretically supported ATTA solution that effectively tackles both distribution shift and CF. 3.1 A LLEVIATING DISTRIBUTION SHIFTS THROUGH ACTIVE TEST-TIME ADAPTATION Traditional TTA is performed in unsupervised or self-supervised context. In contrast, ATTA introduces supervision into the adaptation setting. In this subsection, we delve into learning bounds and establish generalization bounds to gauge the efficacy of ATTA in solving distribution shifts. We scrutinize the influence of active learning and evidence that the inclusion of labeled test instances markedly enhances overall performances across incremental test domains. Following Kifer et al. (2004), we examine statistical guarantees for binary classification. A hypothesis is a function h : X â†’ {0, 1}, which can serve as the prediction function within this context. In the ATTA setting, the mapping ofh varies with time as h(x, t). We use Hâˆ†H-distance following Ben- David et al. (2010), which essentially provides a measure to quantify the distribution shift between two distributions D1 and D2, and can also be applied between datasets. The probability that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} according to distribution D is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source data is inaccessible under ATTA settings, we consider the existence of source dataset DS for accurate theoretical analysis. Thus, we initialize Dtr as Dtr(0) = DS. For every time step t, the test and training data can be expressed asUte(t) and Dtr(t) = DS âˆªDte(1) âˆªDte(2) âˆªÂ·Â·Â·âˆª Dte(t). Building upon two lemmas (provided in Appx. D), we establish bounds on domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesish at time t. Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Â·Â·Â· , Ute(t), Â·Â·Â· , Si are unlabeled samples of sizem sampled from each of thet+1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î» = (Î»0, Â·Â·Â· , Î»t). If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w = (w0, Â·Â·Â· , wt) on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. The adaptation performance on a test domain is majorly bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. Further theoretical analysis are in Appx. D. 3Published as a conference paper at ICLR 2024 Figure 1: (a) Empirical validation of Thm. 1. We train a series of models on N = 2000 samples from the PACS (Li et al., 2017) dataset given differentÎ»0 and w0 and display the test domain loss of each model. Red points are the test loss minimums given a fixed Î»0. The orange line is the reference where w0 = Î»0. We observe that w0 with loss minimums are located closed to the orange line but slightly smaller than Î»0, which validates our findings in Eq. (4). (b) Empirical analysis with an uncertainty balancing. Given source pre-trained models, we fine-tune the models on 500 samples with different Î»0 and w0, and display the combined error surface of test and source error. Although a small Î»0 is good for test domain error, it can lead to non-trivial source error exacerbation. Therefore, we can observe that the global loss minimum (green X) locates in a relatively high-Î»0 region. If we consider the multiple test data distributions as a single test domain,i.e., St i=1 Ute(i), Thm. 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . Given the optimal test/source hypothesis hâˆ— T (t) = arg minhâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), we have |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (3.a), with approximatelyB = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (4) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. The following theorem offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (5) Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. All proofs are provided in Appx. E. Finally, we support the theoretical findings with experimental analysis and show the numerical results of applying the principles on real-world datasets, as shown in Fig. 1. For rigorous analysis, note that our theoretical results rest on the underlying condition that N should at least be of the same scale as d, according to the principles of VC-dimension theory. The empirical alignment of our experiments with the theoretical framework can be attributed to the assumption that fine-tuning a model is roughly equivalent to learning a model with a relatively small d. Experiment details and other validations can be found in Appx. H. 4Published as a conference paper at ICLR 2024 3.2 M ITIGATING CATASTROPHIC FORGETTING WITH BALANCED ENTROPY MINIMIZATION Catastrophic forgetting (CF), within the realm of Test-Time Adaptation (TTA), principally manifests as significant declines in overall performance, most notably in the source domain. Despite the lack of well-developed learning theories for analyzing training with series data, empirical studies have convincingly illustrated the crucial role of data sequential arrangement in model learning, thereby accounting for the phenomenon of CF. Traditionally, the mitigation of CF in adaptation tasks involves intricate utilization of source domain data. However, under FTTA settings, access to the source dataset is unavailable, leaving the problem of CF largely unexplored in the data-centric view. Table 1: Correlation analysis of high/low en- tropy samples and domains. We use a source pre-trained model to select samples with low- est/highest entropy, and 1.retrain the model on 2000 samples; 2.fine-tune the model on 300 sam- ples. We report losses on source/test domains for each setting, showing that low-entropy samples form distributions close to the source domain. Sample type Retrain Fine-tune ÏµS ÏµT ÏµS ÏµT Low entropy 0.5641 0.8022 0.0619 1.8838 High entropy 2.5117 0.3414 0.8539 0.7725 To overcome this challenge of source dataset ab- sence, we explore the acquisition of â€œsource-likeâ€ data. In TTA scenarios, it is generally assumed that the amount of source data is considerably large. We also maintain this assumption in ATTA, practically assuming the volume of source data greatly surpasses the test-time budget. As a re- sult, we can safely assume that the pre-trained model is well-trained on abundant source do- main data DS. Given this adequately trained source model, we can treat it as a â€œtrueâ€ source data labeling function f(x; Ï•). The model es- sentially describes a distribution, DÏ•,S(X, Y) = {(x, Ë†y) âˆˆ (X, Y) | Ë†y = f(x; Ï•), xâˆˆ DS}. The entropy of the model prediction is defined as H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc), Ë†y = f(x; Ï•), where c denotes the class. Lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction, which can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model recognizes the sample as being similar to those it was trained on. Thus entropy can be used as an indicator of how closely a sample x aligns with the model distribution DÏ•,S. Since the model distribution is approximately the source distribution, selecting (and labeling) low-entropy samples using f(x; Ï•) essentially provides an estimate of sampling from the source dataset. Therefore, in place of the inaccessible DS, we can feasibly include the source-like dataset into the ATTA training data at each time stept: DÏ•,S(t) = {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el}, (6) where el is the entropy threshold. The assumption that DÏ•,S(t) is an approximation of DS can be empirically validated, as shown by the numerical results on PACS in Tab. 1. In contrast, high-entropy test samples typically deviate more from the source data, from which we select Dte(t) for active labeling. Following the notations in Thm. 1, we are practically minimizing the empirical weighted error of hypothesis h(t) as Ë†Ïµâ€² w(h(t)) = tX j=0 wjË†Ïµj(h(t)) = w0 Î»0N X xâˆˆDÏ•,S(t) |h(x, t) âˆ’ f(x; Ï•)| + tX j=1 wj Î»jN X x,yâˆˆDte(j) |h(x, t) âˆ’ y|. (7) By substituting DS with DÏ•,S(t) in Thm. 1, the bounds of Thm. 1 continue to hold for the test domains. In the corollary below, we bound the source error for practical ATTA at each time stept. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Thm. 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Thm. 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Further analysis and proofs are in Appx. D and E. The following corollary provides direct theoretical support that our strategy conditionally reduces the error bound on the source domain. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Thm. 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight 5Published as a conference paper at ICLR 2024 <latexit sha1_base64=\"NxhXSyFABPQk4q8627/odirDspg=\">AAAB9XicbVDLSgMxFM34rPVVdekmWARXZab4WhbcuKzYF7S1ZNI7bWgmMyR3lDL0P9y4UMSt/+LOvzHTdqGtBwKHc87l3hw/lsKg6347K6tr6xubua389s7u3n7h4LBhokRzqPNIRrrlMwNSKKijQAmtWAMLfQlNf3ST+c1H0EZEqobjGLohGygRCM7QSg/3mIWFGtAaGOwVim7JnYIuE29OimSOaq/w1elHPAlBIZfMmLbnxthNmUbBJUzyncRAzPiIDaBtqWIhmG46vXpCT63Sp0Gk7VNIp+rviZSFxoxD3yZDhkOz6GXif147weC6mwoVJwiKzxYFiaQY0awC2hcaOMqxJYxrYW+lfMg042iLytsSvMUvL5NGueRdli7uysXK+byOHDkmJ+SMeOSKVMgtqZI64USTZ/JK3pwn58V5dz5m0RVnPnNE/sD5/AFnsJJq</latexit> Streaming Test <latexit sha1_base64=\"a41BOKrutEYSWO9+8CjkPZKHvb8=\">AAAB73icbVBNS8NAEJ3Ur1q/qh69BIvgqSTiR48FLx4r2A9oQ9lsN+3SzSbuToQQ+ie8eFDEq3/Hm//GTZuDtj4YeLw3w8w8PxZco+N8W6W19Y3NrfJ2ZWd3b/+genjU0VGiKGvTSESq5xPNBJesjRwF68WKkdAXrOtPb3O/+8SU5pF8wDRmXkjGkgecEjRSbzAhmKWzyrBac+rOHPYqcQtSgwKtYfVrMIpoEjKJVBCt+64To5cRhZwKNqsMEs1iQqdkzPqGShIy7WXze2f2mVFGdhApUxLtufp7IiOh1mnom86Q4EQve7n4n9dPMGh4GZdxgkzSxaIgETZGdv68PeKKURSpIYQqbm616YQoQtFElIfgLr+8SjoXdfe6fnV/WWs2ijjKcAKncA4u3EAT7qAFbaAg4Ble4c16tF6sd+tj0Vqyiplj+APr8wfpIY/e</latexit> Ë†y <latexit sha1_base64=\"SJEOE2ZYxLL1SU/QahOlMH6fop4=\">AAAB8HicbVBNSwMxEM3Wr1q/qh69BItQL2VX/Oix4MVjBbettEvJptk2NMkuyaxQlv4KLx4U8erP8ea/MW33oK0PBh7vzTAzL0wEN+C6305hbX1jc6u4XdrZ3ds/KB8etUycasp8GotYd0JimOCK+cBBsE6iGZGhYO1wfDvz209MGx6rB5gkLJBkqHjEKQErPfr9DNi0Cuf9csWtuXPgVeLlpIJyNPvlr94gpqlkCqggxnQ9N4EgIxo4FWxa6qWGJYSOyZB1LVVEMhNk84On+MwqAxzF2pYCPFd/T2REGjORoe2UBEZm2ZuJ/3ndFKJ6kHGVpMAUXSyKUoEhxrPv8YBrRkFMLCFUc3srpiOiCQWbUcmG4C2/vEpaFzXvunZ1f1lp1PM4iugEnaIq8tANaqA71EQ+okiiZ/SK3hztvDjvzseiteDkM8foD5zPH2KnkB4=</latexit> U te ( t ) <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model SimATTA <latexit sha1_base64=\"bhVea6W/pzUPuDRNfs2xbDF7qAk=\">AAAB73icbVC7SgNBFL3rM8ZX1NJmMAhWYTf4KgM2FhYRzAOSJcxOZpMhs7PrzF0hhPyEjYUitv6OnX/jbLKFJh4YOJxzD3PvCRIpDLrut7Oyura+sVnYKm7v7O7tlw4OmyZONeMNFstYtwNquBSKN1Cg5O1EcxoFkreC0U3mt564NiJWDzhOuB/RgRKhYBSt1L6jQRYd9Eplt+LOQJaJl5My5Kj3Sl/dfszSiCtkkhrT8dwE/QnVKJjk02I3NTyhbEQHvGOpohE3/mS275ScWqVPwljbp5DM1N+JCY2MGUeBnYwoDs2il4n/eZ0Uw2t/IlSSIlds/lGYSoIxyY4nfaE5Qzm2hDIt7K6EDammDG1FRVuCt3jyMmlWK95l5eK+Wq6d53UU4BhO4Aw8uIIa3EIdGsBAwjO8wpvz6Lw4787HfHTFyTNH8AfO5w/1SI/i</latexit> Labeling <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"ipQ+JKlINPDcPjrbUYUkqyyzp40=\">AAAB+nicbVC7TsMwFHXKq5RXCiOLRYXEQpVUvMZKLIxF0IfURpXj3LRWHSeyHVBV+iksDCDEypew8Te4aQZoOZKlo3Puy8dPOFPacb6twsrq2vpGcbO0tb2zu2eX91sqTiWFJo15LDs+UcCZgKZmmkMnkUAin0PbH13P/PYDSMVica/HCXgRGQgWMkq0kfp2+S6bdNqQoCUxQ4K+XXGqTga8TNycVFCORt/+6gUxTSMQmnKiVNd1Eu1NiNSMcpiWeqmChNARGUDXUEEiUN4kO32Kj40S4DCW5gmNM/V3x4RESo0j31RGRA/VojcT//O6qQ6vvAkTSapB0PmiMOVYx3iWAw6YBKr52BBCJTO3YjokklBt0iqZENzFLy+TVq3qXlTPb2uV+lkeRxEdoiN0glx0ieroBjVQE1H0iJ7RK3qznqwX6936mJcWrLznAP2B9fkDSAyT+w==</latexit> Source-Pretrained <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model <latexit sha1_base64=\"5LNAmmVR/AN9Lc2T+FRV/is2yz8=\">AAAB8nicbVDLSgNBEJyNrxhfUY9eBoPgKewGX8eACB48RDAP2CxhdjKbDJmdWWZ6lbDkM7x4UMSrX+PNv3GS7EETCxqKqm66u8JEcAOu++0UVlbX1jeKm6Wt7Z3dvfL+QcuoVFPWpEoo3QmJYYJL1gQOgnUSzUgcCtYOR9dTv/3ItOFKPsA4YUFMBpJHnBKwkn+nnvCNBK2Sca9ccavuDHiZeDmpoByNXvmr21c0jZkEKogxvucmEGREA6eCTUrd1LCE0BEZMN9SSWJmgmx28gSfWKWPI6VtScAz9fdERmJjxnFoO2MCQ7PoTcX/PD+F6CrIuExSYJLOF0WpwKDw9H/c55pREGNLCNXc3orpkGhCwaZUsiF4iy8vk1at6l1Uz+9rlfpZHkcRHaFjdIo8dInq6BY1UBNRpNAzekVvDjgvzrvzMW8tOPnMIfoD5/MHKbiRJQ==</latexit> Low Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"wuZucU3JbeEJSquG2WgqGdYMCR8=\">AAAB83icbVDLSgMxFL3js9ZX1aWbYBFclZnia1kQocsK9gHtUDJppg3NJCHJCGXob7hxoYhbf8adf2PazkJbD1w4nHMv994TKc6M9f1vb219Y3Nru7BT3N3bPzgsHR23jEw1oU0iudSdCBvKmaBNyyynHaUpTiJO29H4bua3n6g2TIpHO1E0TPBQsJgRbJ3Uq7PhCN0Lq6Wa9Etlv+LPgVZJkJMy5Gj0S1+9gSRpQoUlHBvTDXxlwwxrywin02IvNVRhMsZD2nVU4ISaMJvfPEXnThmgWGpXwqK5+nsiw4kxkyRynQm2I7PszcT/vG5q49swY0KllgqyWBSnHFmJZgGgAdOUWD5xBBPN3K2IjLDGxLqYii6EYPnlVdKqVoLrytVDtVy7zOMowCmcwQUEcAM1qEMDmkBAwTO8wpuXei/eu/exaF3z8pkT+APv8wfIYpF9</latexit> High Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"1BO6D/gzkeZNQ7HNIaph5NqELCI=\">AAAB8nicbVDLSgMxFM3UV62vqks3wSK4KjPF17LgRncV7AOmQ8mkd9rQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3kHtPmHCmjet+O6W19Y3NrfJ2ZWd3b/+genjU0TJVFNpUcql6IdHAmYC2YYZDL1FA4pBDN5zc5n73CZRmUjyaaQJBTEaCRYwSYyX/XlAFMQhD+KBac+vuHHiVeAWpoQKtQfWrP5Q0zdOUE619z01MkBFlGOUwq/RTDQmhEzIC31JBYtBBNl95hs+sMsSRVPYJg+fq70RGYq2ncWgnY2LGetnLxf88PzXRTZAxkaQGBF18FKUcG4nz+/GQKaCGTy0hVDG7K6Zjogg1tqWKLcFbPnmVdBp176p++dCoNS+KOsroBJ2ic+Sha9REd6iF2ogiiZ7RK3pzjPPivDsfi9GSU2SO0R84nz9y2ZFU</latexit> Incremental <latexit sha1_base64=\"Jmobmj50NeE6y3ftB4xt5xZD5Eg=\">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8dALh4jmAcmS5id9CZDZmeXmVkhLP6FFw+KePVvvPk3TpI9aGJBQ1HVTXdXkAiujet+O4W19Y3NreJ2aWd3b/+gfHjU1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfM7j6g0j+W9mSboR3QkecgZNVZ6aIhUG1Rcjgblilt15yCrxMtJBXI0B+Wv/jBmaYTSMEG17nluYvyMKsOZwKdSP9WYUDahI+xZKmmE2s/mFz+RM6sMSRgrW9KQufp7IqOR1tMosJ0RNWO97M3E/7xeasIbP+MySQ1KtlgUpoKYmMzeJ0OukBkxtYQyxe2thI2posymoEs2BG/55VXSrlW9q+rlXa1Sv8jjKMIJnMI5eHANdbiFJrSAgYRneIU3RzsvzrvzsWgtOPnMMfyB8/kDzgaQ+A==</latexit> Clustering <latexit sha1_base64=\"c4xrXg0yZYBSSDLHCxlf45OWNzg=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBA8hd2Aj2PAi8eI5gHJEmYnnWTIzOwyMyuEJR/hxYMiXv0eb/6Nk2QPmljQUFR1090VJYIb6/vf3tr6xubWdmGnuLu3f3BYOjpumjjVDBssFrFuR9Sg4AoblluB7UQjlZHAVjS+nfmtJ9SGx+rRThIMJR0qPuCMWie1HqhMBJpeqexX/DnIKglyUoYc9V7pq9uPWSpRWSaoMZ3AT2yYUW05EzgtdlODCWVjOsSOo4pKNGE2P3dKzp3SJ4NYu1KWzNXfExmVxkxk5DoltSOz7M3E/7xOagc3YcZVklpUbLFokApiYzL7nfS5RmbFxBHKNHe3EjaimjLrEiq6EILll1dJs1oJriqX99VyrZrHUYBTOIMLCOAaanAHdWgAgzE8wyu8eYn34r17H4vWNS+fOYE/8D5/AF7Wj40=</latexit> Samples <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"KzBZ8R84UC9mpPFQBWeRHFxcqjw=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKVI8FLx4rmLbQhrLZbNq1m92wuxFK6H/w4kERr/4fb/4bt20O2vpg4PHeDDPzwpQzbVz32yltbG5t75R3K3v7B4dH1eOTjpaZItQnkkvVC7GmnAnqG2Y47aWK4iTktBtObud+94kqzaR4MNOUBgkeCRYzgo2VOn4aYUOH1ZpbdxdA68QrSA0KtIfVr0EkSZZQYQjHWvc9NzVBjpVhhNNZZZBpmmIywSPat1TghOogX1w7QxdWiVAslS1h0EL9PZHjROtpEtrOBJuxXvXm4n9ePzPxTZAzkWaGCrJcFGccGYnmr6OIKUoMn1qCiWL2VkTGWGFibEAVG4K3+vI66TTqXrPevG/UWldFHGU4g3O4BA+uoQV30AYfCDzCM7zCmyOdF+fd+Vi2lpxi5hT+wPn8AYuwjxQ=</latexit> Update <latexit sha1_base64=\"y2NH6tDs2GygUDqZYglGwvR4SpA=\">AAAB+nicbVBNSwMxEJ2tX7V+bfXoJVgEQSi7PVSPFS8eK9oPaEvJptk2NMkuSVYpa3+KFw+KePWXePPfmLZ70NYHA4/3ZpiZF8ScaeN5305ubX1jcyu/XdjZ3ds/cIuHTR0litAGiXik2gHWlDNJG4YZTtuxolgEnLaC8fXMbz1QpVkk780kpj2Bh5KFjGBjpb5bvMMi5lSjc3QlyShSuu+WvLI3B1olfkZKkKHed7+6g4gkgkpDONa643ux6aVYGUY4nRa6iaYxJmM8pB1LJRZU99L56VN0apUBCiNlSxo0V39PpFhoPRGB7RTYjPSyNxP/8zqJCS97KZNxYqgki0VhwpGJ0CwHNGCKEsMnlmCimL0VkRFWmBibVsGG4C+/vEqalbJfLVdvK6Wal8WRh2M4gTPw4QJqcAN1aACBR3iGV3hznpwX5935WLTmnGzmCP7A+fwBUnKTWg==</latexit> Samples + Anchors <latexit sha1_base64=\"u0BDOcH87PXd3DsT+o414+7cHnI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBsAq7FjGdARvLBMwFkhBmZ2eTMbMzy8ysEJaU9jYWitj6Cql8CDufwZdwcik0+sPAx/+fw5xz/JgzbVz308msrK6tb2Q3c1vbO7t7+f2DhpaJIrROJJeq5WNNORO0bpjhtBUriiOf06Y/vJrmzTuqNJPixoxi2o1wX7CQEWys1eiQQBrdyxfcojsT+gveAgqX75Pa1/3xpNrLf3QCSZKICkM41rrtubHpplgZRjgd5zqJpjEmQ9ynbYsCR1R309m0Y3RqnQCFUtknDJq5PztSHGk9inxbGWEz0MvZ1PwvaycmLHdTJuLEUEHmH4UJR0ai6eooYIoSw0cWMFHMzorIACtMjD1Qzh7BW175LzTOi16pWKq5hUoZ5srCEZzAGXhwARW4hirUgcAtPMATPDvSeXRenNd5acZZ9BzCLzlv33Yvk3g=</latexit> Â·Â·Â· <latexit sha1_base64=\"+7L/8ObZcl+JIZaSFhVO3t+lUUE=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2bvizjWb9YcituBrJMvDkp1Y6CDPV+8as7iFgScoVMUmM6nhtjL6UaBZN8UugmhseUPdIh71iqaMhNL82unZBTqwxIEGlbCkmm/p5IaWjMOPRtZ0hxZBa9qfif10kwuOqlQsUJcsVmi4JEEozI9HUyEJozlGNLKNPC3krYiGrK0AZUsCF4iy8vk+Z5xatWqnc2jQuYIQ/HcAJl8OASanALdWgAgwd4hld4cyLnxXl3PmatOWc+cwh/4Hz+AFjYkTs=</latexit> D l ( t ) <latexit sha1_base64=\"9C0bB8PYImk9DX0HLfGvGd44PFA=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2b/qiMZ/1iya24Gcgy8eakVDsKMtT7xa/uIGJJyBUySY3peG6MvZRqFEzySaGbGB5T9kiHvGOpoiE3vTS7dkJOrTIgQaRtKSSZ+nsipaEx49C3nSHFkVn0puJ/XifB4KqXChUnyBWbLQoSSTAi09fJQGjOUI4toUwLeythI6opQxtQwYbgLb68TJrnFa9aqd7ZNC5ghjwcwwmUwYNLqMEt1KEBDB7gGV7hzYmcF+fd+Zi15pz5zCH8gfP5A1K8kTc=</latexit> D h ( t ) <latexit sha1_base64=\"eNrtnhPGeU8n4BRDMStm5cjQ4ts=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDbbTbt0s4m7E6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSKQw6Lrfzsbm1vbObmGvuH9weHRcOjltmzjVjLdYLGPdDajhUijeQoGSdxPNaRRI3gkmjbnfeeLaiFg94DThfkRHSoSCUbRS1zNIGlTKQansVtwFyDrxclKGHM1B6as/jFkacYVMUmN6npugn1GNgkk+K/ZTwxPKJnTEe5YqGnHjZ4t7Z+TSKkMSxtqWQrJQf09kNDJmGgW2M6I4NqveXPzP66UY3vqZUEmKXLHlojCVBGMyf54MheYM5dQSyrSwtxI2ppoytBEVbQje6svrpF2teLVK7b5arl/ncRTgHC7gCjy4gTrcQRNawEDCM7zCm/PovDjvzseydcPJZ87gD5zPH1Naj3k=</latexit> 1st Call <latexit sha1_base64=\"mxsL+XuWb2hqFND+pzTctrB1rcY=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDababt0s4m7G6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSATXxnW/nY3Nre2d3cJecf/g8Oi4dHLa1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfc7T6g0j+WDmSboR3Qk+ZAzaqzUrcqQNKgQg1LZrbgLkHXi5aQMOZqD0lc/jFkaoTRMUK17npsYP6PKcCZwVuynGhPKJnSEPUsljVD72eLeGbm0SkiGsbIlDVmovycyGmk9jQLbGVEz1qveXPzP66VmeOtnXCapQcmWi4apICYm8+dJyBUyI6aWUKa4vZWwMVWUGRtR0Ybgrb68TtrViler1O6r5fp1HkcBzuECrsCDG6jDHTShBQwEPMMrvDmPzovz7nwsWzecfOYM/sD5/AE0o49l</latexit> 2nd Call <latexit sha1_base64=\"oSA1OFmXXL9y3PJtqoVxTIG9mto=\">AAAB8HicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaElCY2UwkQ8DF7K3zMGGvb3L7p6REH6FjYXG2Ppz7Pw3LnCFgi+Z5OW9mczMCxLBtXHdbye3sbm1vZPfLeztHxweFY9PWjpOFcMmi0WsOgHVKLjEpuFGYCdRSKNAYDsY1+d++xGV5rG8N5ME/YgOJQ85o8ZKD7f4ZEidCtEvltyyuwBZJ15GSpCh0S9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50cfCMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia89qdcJqlByZaLwlQQE5P592TAFTIjJpZQpri9lbARVZQZm1HBhuCtvrxOWpWyVy1X7yqlWiWLIw9ncA6X4MEV1OAGGtAEBhE8wyu8Ocp5cd6dj2VrzslmTuEPnM8fSFeQCA==</latexit> Next Call Figure 2: Overview of the SimATTA framework. and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (8) Corollary 4 validates that the selected low-entropy samples can mitigate the CF problem under the assumption that these samples are source-like, which is also empirically validated in Fig. 1. Note that our strategy employs entropy minimization in a selective manner, aiming to solve CF rather than the main adaptation issue. While many FTTA works use entropy minimization to adapt across domains without guarantees, our use is more theoretically-sound. 4 A N ATTA ALGORITHM Building on our theoretical findings, we introduce a simple yet effective ATTA method, known as SimATTA, that innovatively integrates incremental clustering and selective entropy minimization techniques, as illustrated in Fig. 2. We start with an overview of our methodology, including the learning framework and the comprehensive sample selection strategies. We then proceed to discuss the details of the incremental clustering technique designed for real-time sample selections. 4.1 A LGORITHM OVERVIEW Let (x, y) be a labeled sample and f(Â·; Î¸) be our neural network, where Ë†y = f(x; Î¸) and Î¸ represents the parameters. We have a model pre-trained on source domains with the pre-trained parameters Ï•. We initialize model parameters as Î¸(0) = Ï• and aim to adapt the model f(Â·; Î¸) in real-time. During the test phase, the model continuously predicts labels for streaming-in test data and concurrently gets fine-tuned. We perform sample selection to enable active learning. As discussed in Sec. 3.2, we empirically consider informative high-entropy samples for addressing distribution shifts and source-like low-entropy samples to mitigate CF. As shown in Alg. 1, at each time step t, we first partition unlabeled test samples Ute(t) into high entropy and low entropy datasets, Uh(t) and Ul(t), using an entropy threshold. The source-pretrained model f(Â·; Ï•) is frozen to predict pseudo labels for low entropy data. We obtain labeled low-entropy data Dl(t) by labeling Ul(t) with f(Â·; Ï•) and combining it with Dl(t âˆ’ 1). In contrast, the selection of high-entropy samples for active labeling is less straightforward. Since the complete test dataset is inaccessible for analyzing the target domain distribution, real-time sample selection is required. We design an incremental clustering sample selection technique to reduce sample redundancy and increase distribution coverage, detailed in Sec. 4.2. The incremental clustering algorithm outputs the labeled test samples Dh(t), also referred to as anchors, given Dh(t âˆ’1) and Uh(t). After sample selection, the model undergoes test-time training using the labeled test anchors Dh(t) and pseudo-labeled source-like anchors Dl(t). Following the analyses in Sec. 3.1, the training weights and sample numbers should satisfy w(t) â‰ˆ Î»(t) for Dh(t) and Dl(t) for optimal results. The analyses and results in Sec. 3.2 further indicate that balancing the source and target ratio is the key to mitigating CF. However, when source-like samples significantly outnumber test samples, the optimal w(t) for test domains can deviate from Î»(t) according to Eq. (4). 4.2 I NCREMENTAL CLUSTERING We propose incremental clustering, a novel continual clustering technique designed to select informa- tive samples in unsupervised settings under the ATTA framework. The primary goal of this strategy is to store representative samples for distributions seen so far. Intuitively, we apply clusters to cover all seen distributions while adding new clusters to cover newly seen distributions. During this process with new clusters added, old clusters may be merged due to the limit of the cluster budget. Since 6Published as a conference paper at ICLR 2024 Algorithm 1 SIMATTA: A SIMPLE ATTA ALGORITHM Require: A fixed source pre-trained model f(Â·; Ï•) and a real-time adapting model f(Â·; Î¸(t)) with Î¸(0) = Ï•. Streaming test data Ute(t) at time step t. Entropy of predictions H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc). Low entropy and high entropy thresholds el and eh. The number of cluster centroid budget NC (t) at time step t. Centroid increase number k. Learning step size Î·. 1: for t = 1, . . . , Tdo 2: Model inference on Ute(t) using f(Â·; Î¸(t âˆ’ 1)). 3: Dl(t) â† Dl(t âˆ’ 1) âˆª {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el} 4: Uh(t) â† {x|x âˆˆ Ute(t), H(f(x; Î¸)) > eh} 5: Dh(t) â† Dh(t âˆ’ 1) âˆª {(x, y)|âˆ€x âˆˆ IC(Dh(t âˆ’ 1), Uh(t), NC(t)), y= Oracle(x)} 6: Î»(t) â† |Dl(t)|/(|Dl(t)| + |Dh(t)|), |Dh(t)|/(|Dl(t)| + |Dh(t)|) 7: w(t) â† GetW(Î»(t)) â–· Generally, GetW(Î»(t)) = Î»(t) is a fair choice. 8: Î¸(t) â† Î¸(t âˆ’ 1) 9: for (xl, yl) in Dl and (xh, yh) in Dh do 10: Î¸(t) â† Î¸(t) âˆ’ Î·w0âˆ‡â„“CE (f(xl; Î¸(t)), yl) âˆ’ Î·(1 âˆ’ w0)âˆ‡â„“CE (f(xh; Î¸(t)), yh) 11: end for 12: NC (t + 1) â† UpdateCentroidNum(NC (t)) â–· Naive choice: NC (t + 1) â† NC (t) + k. 13: end for clusters cannot be stored efficiently, we store the representative samples of clusters, named anchors, instead. In this work, we adopt weighted K-means (Krishna and Murty, 1999) as our base clustering method due to its popularity and suitability for new setting explorations. When we apply clustering with new samples, a previously selected anchor should not weigh the same as new samples since the anchor is a representation of a cluster,i.e., a representation of many samples. Instead, the anchor should be considered as a barycenter with a weight of the sum of its clusterâ€™s sample weights. For a newly added cluster, its new anchor has the weight of the whole cluster. For clusters containing multiple old anchors, i.e., old clusters, the increased weights are distributed equally among these anchors. These increased weights are contributed by new samples that are close to these old anchors. Intuitively, this process of clustering is analogous to the process of planet formation. Where there are no planets, new planets (anchors) will be formed by the aggregation of the surrounding material (samples). Where there are planets, the matter is absorbed by the surrounding planets. This example is only for better understanding without specific technical meanings. Specifically, we provide the detailed Alg. 2 for incremental clustering. In each iteration, we apply weighted K-Means for previously selected anchors Danc and the new streaming-in unlabeled data Unew. We first extract all sample features using the model from the previous step f(Â·; Î¸(t âˆ’ 1)), and then cluster these weighted features. The initial weights of the new unlabeled samples are 1, while anchors inherit weights from previous iterations. After clustering, clusters including old anchors are old clusters, while clusters only containing new samples are newly formed ones. For each new cluster, we select the centroid-closest sample as the new anchor to store. As shown in line 10 of Alg. 2, for both old and new clusters, we distribute the sample weights in this cluster as its anchorsâ€™ weights. With incremental clustering, although we can control the number of clusters in each iteration, we cannot control the number of new clusters/new anchors. This indirect control makes the increase of new anchors adaptive to the change of distributions, but it also leads to indirect budget control. Therefore, in experimental studies, we set the budget limit, but the actual anchor budget will not reach this limit. The overall extra storage requirement is O(B) since the number of saved unlabeled samples is proportional to the number of saved labeled samples (anchors). 5 E XPERIMENTAL STUDIES In this study, we aim to validate the effectiveness of our proposed method, as well as explore the various facets of the ATTA setting. Specifically, we design experiments around the following research questions: RQ1: Can TTA methods address domain distribution shifts? RQ2: Is ATTA as efficient as TTA? RQ3: How do the components of SimATTA perform? RQ4: Can ATTA perform on par with stronger Active Domain Adaptation (ADA) methods? We compare ATTA with three settings, TTA (Tab. 2), enhanced TTA (Tab. 3 and 5), and ADA (Tab. 4). Datasets. To assess the OOD performance of the TTA methods, we benchmark them using datasets from DomainBed (Gulrajani and Lopez-Paz, 2020) and Hendrycks and Dietterich (2019a). We employ PACS (Li et al., 2017), VLCS (Fang et al., 2013), Office-Home (Venkateswara et al., 2017), and Tiny-ImageNet-C datasets for our evaluations. For each dataset, we designate one domain as 7Published as a conference paper at ICLR 2024 Table 2: TTA comparisons on PACS and VLCS.This table includes the two data stream mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. PACS Domain-wise data stream Post-adaptation Random data stream Post-adaptation P â†’Aâ†’ â†’Câ†’ â†’S P A C S â†’1â†’ â†’2â†’ â†’3â†’ â†’4 P A C S BN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 Tent (steps=1) N/A 67.29 64.59 44.67 97.60 66.85 64.08 42.58 56.35 54.09 51.83 48.58 97.19 63.53 60.75 41.56Tent (steps=10) N/A 67.38 57.85 20.23 62.63 34.52 40.57 13.59 47.36 31.01 22.84 20.33 50.78 23.68 20.95 19.62EATA N/A 67.04 64.72 50.27 98.62 66.50 62.46 48.18 57.31 56.06 58.17 59.78 98.62 69.63 65.70 54.26CoTTA N/A 65.48 62.12 53.17 98.62 65.48 63.10 53.78 56.06 54.33 57.16 57.42 98.62 65.97 62.97 54.62SAR (steps=1) N/A 66.75 63.82 49.58 98.32 66.94 62.93 45.74 56.78 56.35 56.68 56.70 98.44 68.16 64.38 52.53SAR (steps=10) N/A 69.38 68.26 49.02 96.47 62.16 56.19 54.62 53.51 51.15 51.78 45.60 94.13 56.64 56.02 36.37 SimATTA (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00SimATTA (B â‰¤500) N/A 77.93 76.02 76.30 98.62 88.33 83.49 83.74 68.46 78.22 80.91 85.49 99.16 86.67 84.77 87.71 VLCS Domain-wise data stream Post-adaptation Random data stream Post-adaptation C â†’Lâ†’ â†’Sâ†’ â†’V C L S V â†’1â†’ â†’2â†’ â†’3â†’ â†’4 C L S V BN w/o adapt 100.00 33.55 41.10 49.05 100.00 33.55 41.10 49.05 41.23 41.23 41.23 41.23 100.00 33.55 41.10 49.05BN w/ adapt 85.16 37.31 33.27 52.16 85.16 37.31 33.27 52.16 40.91 40.91 40.91 40.91 85.16 37.31 33.27 52.16 Tent (steps=1) N/A 38.55 34.40 53.88 84.73 43.86 33.61 53.11 44.85 44.29 47.38 44.98 85.30 43.49 37.81 53.35Tent (steps=10) N/A 45.41 31.44 32.32 42.54 37.65 27.79 33.12 46.13 42.31 43.51 39.48 52.01 40.32 33.64 40.37EATA N/A 37.24 33.15 52.58 84.10 37.69 32.39 52.49 43.77 42.48 43.34 41.55 83.32 36.67 31.47 52.55CoTTA N/A 37.39 32.54 52.25 82.12 37.65 33.12 52.90 43.69 42.14 43.21 42.32 81.98 37.99 33.52 53.23SAR (steps=1) N/A 36.18 34.43 52.46 83.96 39.72 36.53 52.37 43.64 43.04 44.20 41.93 85.09 40.70 36.44 53.02SAR (steps=10) N/A 35.32 34.10 51.66 82.12 41.49 33.94 53.08 43.56 42.05 42.53 41.16 85.09 37.58 33.12 52.01 SimATTA (B â‰¤300) N/A 62.61 65.08 74.38 99.93 69.50 66.67 77.34 62.33 69.33 73.20 71.93 99.93 69.43 72.46 80.39SimATTA (B â‰¤500) N/A 63.52 68.01 76.13 99.51 70.56 73.10 78.35 62.29 70.45 73.50 72.02 99.43 70.29 72.55 80.18 the source domain and arrange the samples from the other domains to form the test data stream. For DomainBed datasets, we adopt two stream order strategies. The first order uses a domain-wise data stream, i.e., we finish streaming samples from one domain before starting streaming another domain. The second order is random, where we shuffle samples from all target domains and partition them into four splits 1, 2, 3, and 4, as shown in Tab. 2. More dataset details are provided in Appx. G.1. Baselines. For baseline models, we start with the common source-only models, which either utilize pre-calculated batch statistics (BN w/o adapt) or test batch statistics (BN w/ adapt). For comparison with other TTA methods, we consider four state-of-the-art TTA methods: Tent (Wang et al., 2021), EATA (Niu et al., 2022), CoTTA (Wang et al., 2022a), and SAR (Niu et al., 2023). The three of them except Tent provide extra design to avoid CF. To compare with ADA methods, we select algorithms that are partially comparable with our method, i.e., they should be efficient (e.g., uncertainty-based) without the requirements of additional networks. Therefore, we adopt random, entropy (Wang and Shang, 2014), k-means (Krishna and Murty, 1999), and CLUE (Prabhu et al., 2021) for comparisons. Settings. For TTA, we compare with general TTA baselines in streaming adaptation using the two aforementioned data streaming orders, domain-wise and random. We choose P in PACS and C in VLCS as source domains. For domain-wise data stream, we use order A â†’ C â†’ S for PACS and L â†’ S â†’ V for VLCS. We report the real-time adaptation accuracy results for each split of the data stream, as well as the accuracy on each domain after all adaptations through the data stream (under â€œpost-adaptationâ€ columns). Enhanced TTA is built on TTA with access to extra random sample labels. TTA baselines are further fine-tuned with these random samples. To further improve enhanced TTA, we use long-term label storage and larger unlabeled sample pools. To its extreme where the model can access the whole test set samples, the setting becomes similar to ADA, thus we also use ADA methods for comparisons. ADA baselines have access to all samples in the pre-collected target datasets but not source domain data, whereas our method can only access the streaming test data. 5.1 T HE FAILURE OF TEST-TIME ADAPTATION The failure of TTA methods on domain distribution shifts is one of the main motivations of the ATTA setting. As shown in Tab. 2, TTA methods cannot consistently outperform eventhe simplest baseline \"BN w/ adapt\" which uses test time batch statistics to make predictions, evidencing that current TTA methods cannot solve domain distribution shifts (RQ1). Additionally, Tent (step=10) exhibits significant CF issues, where \"step=10\" indicates 10 test-time training updates, i.e., 10 gradient backpropagation iterations. This failure of TTA methods necessitates the position of ATTA. In contrast, SimATTA, with a budget B less than 300, outperforms all TTA methods on both source and target domains by substantial margins. Moreover, compared to the source-only baselines, our method improves the target domain performances significantly with negligible source performance loss, showing that ATTA is a more practically effective setting for real-world distribution shifts. 5.2 E FFICIENCY & ENHANCED TTA SETTING COMPARISONS To validate the efficiency of ATTA and broaden the dataset choice, we conduct this study on Tiny- ImageNet-C which, though does not focus on domain shifts, is much larger than PACS and VLCS. we 8Published as a conference paper at ICLR 2024 Table 3: Comparisons with Enhanced TTA on Tiny-ImageNet-C (severity level 5). Tiny-ImageNet-C Time (sec)Noise Blur Weather Digital Gauss. Shot Impul. Defoc. Glass Motion Zoom Snow Frost Fog Contr. Elastic Pixel JPEG Avg. Tent (step=1) 68.83 9.32 11.97 8.86 10.43 7.00 12.20 14.34 13.58 15.46 13.55 3.99 13.31 17.79 18.61 12.17Tent (step=10) 426.90 0.86 0.63 0.52 0.52 0.55 0.54 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.54EATA 93.14 3.98 3.33 2.18 4.80 2.37 11.02 11.41 14.06 15.26 9.65 1.36 9.88 14.24 12.12 8.26CoTTA 538.78 5.63 7.12 6.31 8.05 5.74 9.68 10.55 11.75 12.00 11.15 4.17 5.35 7.82 8.90 8.16SAR (step=1) 113.76 8.90 3.11 1.67 1.55 1.47 1.35 1.19 1.03 1.04 0.93 0.83 1.00 0.74 0.77 1.83SAR (step=10) 774.11 2.67 3.26 2.38 1.64 1.85 2.49 3.16 3.81 2.72 3.12 0.81 3.47 4.04 1.76 2.66 SimATTA (step=10) 736.289.68 19.40 12.14 30.28 17.03 42.36 43.10 31.96 40.08 29.243.21 34.56 45.24 45.74 28.86 enhance the TTA setting by fine-tuning baselines on randomly selected labeled samples. Specifically, the classifier of ResNet18-BN is pre-adapted to the brightness corruption (source domain) before test-time adapting. SimATTAâ€™s label budget is around 4,000, while all other TTA methods have budget 4,500 for randomly selected labeled samples. The data stream order is shown in Tab. 3. Time is measured across all corrupted images in the Noise and Blur noise types, and the values represent the average time cost for adapting 10,000 images. The results clearly evidence the efficiency of ATTA (RQ2), while substantially outperforming all enhanced TTA baselines. Simply accessing labeled samples cannot benefit TTA methods to match ATTA. With 10 training updates (step=10) for each batch, FTTA methods would suffer from severe CF problem. In contrast, ATTA covers a statistically significant distribution, achieving stronger performances with 10 training updates or even more steps till approximate convergences. In fact, longer training on Tent (step=10) leads to worse results (compared to step=1), which further motivates the design of the ATTA setting. The reason for higher absolute time cost in Tab. 3 is due to differences in training steps. In this experiment, SimATTA has a training step of 10, and similar time cost as SAR per step. Note that if the enhanced TTA setting is further improved to maintain distributions with a balanced CF mitigation strategy and an incremental clustering design, the design approaches ATTA. Specifically, we compare SimATTA with its variants as the ablation study (RQ3) in Appx. I.2. 5.3 C OMPARISONS TO A STRONGER SETTING : ACTIVE DOMAIN ADAPTATION Table 4: Comparisons to ADA baselines. Source domains are denoted as \"(S)\". Results are average accuracies (with standard deviations). PACS P (S) A C S Random (B= 300) 96.21 (0.80) 81.19 (0.48) 80.75 (1.27) 84.34 (0.18)Entropy (B= 300) 96.31 (0.64)88.00 (1.46)82.48 (1.71) 80.55 (1.01)Kmeans (B= 300) 93.71 (1.50) 79.31 (4.01) 79.64 (1.44) 83.92 (0.65)CLUE (B= 300) 96.69 (0.17)83.97 (0.57)84.77 (0.88) 86.91 (0.26) SimATTA (B â‰¤300) 98.89 (0.09)84.69 (0.22)83.09 (0.83)83.76 (2.24) VLCS C (S) L S V Random (B= 300) 96.21 (1.65) 66.67 (1.70) 70.72 (0.30) 72.14 (1.71)Entropy (B= 300) 97.74 (1.56) 69.29 (2.26)69.25 (4.77) 75.26 (3.07)Kmeans (B= 300) 98.61 (0.27)67.57 (1.64)70.77 (0.01)74.49 (0.97)CLUE (B= 300) 85.70 (10.09) 65.29 (1.49) 69.42 (2.64) 69.09 (6.05) SimATTA (B â‰¤300) 99.93 (0.00) 69.47 (0.03)69.57 (2.90)78.87 (1.53) In addtion to the above comparisons with (en- hanced) TTA, which necessitate the requirement of extra information in the ATTA setting, we com- pare ATTA with a stronger setting Active Domain Adaptation (ADA) to demonstrate another supe- riority of ATTA, i.e., weaker requirements for comparable performances (RQ4). ADA baselines are able to choose the global best active samples, while ATTA has to choose samples from a small sample buffer (e.g., a size of 100) and discard the rest. Tab. 4 presents the post-adaptation model per- formance results. All ADA results are averaged from 3 random runs, while ATTA results are the post-adaptation performances averaged from the two data stream orders. As can be observed, despite the lack of a pre-collected target dataset, SimATTA produces better or competitive results against ADA methods. Moreover, without source data access, SimATTAâ€™s design for CF allows it to maintain superior source domain performances over ADA methods. Further experimental studies including the Office-Home dataset are provided in Appx. I. In conclusion, the significant improvement compared to weaker settings (TTA, enhanced TTA) and the comparable performance with the stronger setting, ADA, rendering ATTA a setting that is as efficient as TTA and as effective as ADA. This implies its potential is worthy of future explorations. 6 C ONCLUSION AND DISCUSSION Thereâ€™s no denying that OOD generalization can be extremely challenging without certain information, often relying on various assumptions easily compromised by different circumstances. Thus, itâ€™s prudent to seek methods to achieve significant improvements with minimal cost, e.g., DG methods leveraging environment partitions and ATTA methods using budgeted annotations. As justified in our theoretical and experimental studies, ATTA stands as a robust approach to achieve real-time OOD generalization. Although SimATTA sets a strong baseline for ATTA, thereâ€™s considerable scope for further investigation within the ATTA setting. One potential direction involves developing alternatives to prevent CF in ATTA scenarios. While selective entropy minimization on low-entropy samples has prove to be empirically effective, it relies on the quality of the pre-trained model and training on incorrectly predicted low-entropy samples may reinforce the errors. It might not be cost-effective to expend annotation budgets on low-entropy samples, but correcting them could be a viable alternative solution. We anticipate that our work will spur numerous further explorations in this field. 9Published as a conference paper at ICLR 2024 ACKNOWLEDGMENTS This work was supported in part by National Science Foundation grant IIS-2006861 and National Institutes of Health grant U01AG070112. REFERENCES Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, and Mario Marchand. Domain- adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014. Lucas Baier, Tim SchlÃ¶r, Jakob SchÃ¶ffer, and Niklas KÃ¼hl. Detecting concept drift with neural network model uncertainty. In Hawaii International Conference on System Sciences, 2021. URL https://api.semanticscholar.org/CorpusID:235731947. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79:151â€“175, 2010. Davide Cacciarelli and Murat Kulahci. A survey on online active learning, 2023. Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, and Pheng-Ann Heng. Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part V 24, pages 225â€“235. Springer, 2021. Li Chen, Tutian Tang, Zhitian Cai, Yang Li, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, and Yu Qiao. Level 2 autonomous driving on a single device: Diving into the devils of openpilot. arXiv preprint arXiv:2206.08176, 2022a. Weijie Chen, Luojun Lin, Shicai Yang, Di Xie, Shiliang Pu, and Yueting Zhuang. Self-supervised noisy label learning for source-free unsupervised domain adaptation. In 2022 IEEE/RSJ In- ternational Conference on Intelligent Robots and Systems (IROS) , pages 10185â€“10192. IEEE, 2022b. Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. Advances in Neural Information Processing Systems, 33:21061â€“21071, 2020. David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models. Journal of artificial intelligence research, 4:129â€“145, 1996. Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, AleÅ¡ Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366â€“3385, 2021. Yuhe Ding, Lijun Sheng, Jian Liang, Aihua Zheng, and Ran He. Proxymix: Proxy-based mixup training with label refinery for source-free domain adaptation. arXiv preprint arXiv:2205.14566, 2022. Cian Eastwood, Ian Mason, Christopher KI Williams, and Bernhard SchÃ¶lkopf. Source-free adaptation to measurement shift via bottom-up feature restoration. arXiv preprint arXiv:2107.05446, 2021. Jiahao Fan, Hangyu Zhu, Xinyu Jiang, Long Meng, Chen Chen, Cong Fu, Huan Yu, Chenyun Dai, and Wei Chen. Unsupervised domain adaptation by statistics alignment for deep sleep staging networks. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30:205â€“216, 2022. Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision, pages 1657â€“1664, 2013. Yuqi Fang, Pew-Thian Yap, Weili Lin, Hongtu Zhu, and Mingxia Liu. Source-free unsupervised domain adaptation: A survey. arXiv preprint arXiv:2301.00265, 2022. Francois Fleuret et al. Uncertainty reduction for model adaptation in semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9613â€“9623, 2021. 10Published as a conference paper at ICLR 2024 Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180â€“1189. PMLR, 2015. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096â€“2030, 2016. Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004. Shurui Gui, Chaoyue Wang, Qihua Chen, and Dacheng Tao. Featureflow: Robust video interpolation via structure-to-texture generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14004â€“14013, 2020. Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL https://openreview.net/forum?id=8hHg-zs_p-h. Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770â€“778, 2016. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. March 2019a. doi: 10.48550/ARXIV .1903.12261. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019b. Steven CH Hoi, Rong Jin, Jianke Zhu, and Michael R Lyu. Semisupervised svm batch mode active learning with applications to image retrieval. ACM Transactions on Information Systems (TOIS), 27(3):1â€“29, 2009. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 17853â€“17862, 2023. Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. Model adaptation: Historical contrastive learning for unsupervised domain adaptation without source data. Advances in Neural Information Processing Systems, 34:3635â€“3649, 2021. Masato Ishii and Masashi Sugiyama. Source-free domain adaptation via distributional alignment by matching batch normalization statistics. arXiv preprint arXiv:2101.10842, 2021. Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. Advances in Neural Information Processing Systems, 34:2427â€“2440, 2021. Suyog Dutt Jain and Kristen Grauman. Active image segmentation propagation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2864â€“2873, 2016. Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. Contrastive adaptation network for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4893â€“4902, 2019. Ashish Kapoor, Kristen Grauman, Raquel Urtasun, and Trevor Darrell. Active learning with gaussian processes for object categorization. In 2007 IEEE 11th international conference on computer vision, pages 1â€“8. IEEE, 2007. Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu. Test-time adaptable neural networks for robust medical image segmentation. Medical Image Analysis, 68:101907, 2021. 11Published as a conference paper at ICLR 2024 Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and Christopher Kanan. Measuring catastrophic forgetting in neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018. Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In VLDB, volume 4, pages 180â€“191. Toronto, Canada, 2004. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114 (13):3521â€“3526, 2017. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal- subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637â€“5664. PMLR, 2021. Divya Kothandaraman, Sumit Shekhar, Abhilasha Sancheti, Manoj Ghuhan, Tripti Shukla, and Dinesh Manocha. Salad: Source-free active label-agnostic domain adaptation for classification, segmentation and detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 382â€“391, 2023. K Krishna and M Narasimha Murty. Genetic k-means algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29(3):433â€“439, 1999. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu- tional neural networks. Communications of the ACM, 60(6):84â€“90, 2017. David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrap- olation (REx). In International Conference on Machine Learning , pages 5815â€“5826. PMLR, 2021. Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In Proceedings of the IEEE/CVF winter conference on applications of computer vision, pages 615â€“625, 2021. David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine learning proceedings 1994, pages 148â€“156. Elsevier, 1994. Aodong Li, Alex Boyd, Padhraic Smyth, and Stephan Mandt. Detecting and adapting to irregular distribution shifts in bayesian online learning. Advances in neural information processing systems, 34:6816â€“6828, 2021a. Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542â€“5550, 2017. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9641â€“9650, 2020. Xianfeng Li, Weijie Chen, Di Xie, Shicai Yang, Peng Yuan, Shiliang Pu, and Yueting Zhuang. A free lunch for unsupervised domain adaptive object detection without source data. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 8474â€“8481, 2021b. Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935â€“2947, 2017. Jian Liang, Dapeng Hu, Ran He, and Jiashi Feng. Distill and fine-tune: Effective adaptation from a black-box source model. arXiv preprint arXiv:2104.01539, 1(3), 2021. Jian Liang, Dapeng Hu, Jiashi Feng, and Ran He. Dine: Domain adaptation from single and multiple black-box predictors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8003â€“8013, 2022. 12Published as a conference paper at ICLR 2024 Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without environment partition? Advances in Neural Information Processing Systems, 35:24529â€“24542, 2022. Xiaofeng Liu, Fangxu Xing, Chao Yang, Georges El Fakhri, and Jonghye Woo. Adapting off-the- shelf source segmenter for target medical image segmentation. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part II 24, pages 549â€“559. Springer, 2021a. Xinyu Liu and Yixuan Yuan. A source-free domain adaptive polyp detection framework with style diversification flow. IEEE Transactions on Medical Imaging, 41(7):1897â€“1908, 2022. Yuang Liu, Wei Zhang, Jun Wang, and Jianyong Wang. Data-free knowledge transfer: A survey. arXiv preprint arXiv:2112.15278, 2021b. Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems, 34:21808â€“21820, 2021c. Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97â€“105. PMLR, 2015. David Lopez-Paz and Marcâ€™Aurelio Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017. Chaochao Lu, Yuhuai Wu, JosÃ© Miguel HernÃ¡ndez-Lobato, and Bernhard SchÃ¶lkopf. Invariant causal representation learning for out-of-distribution generalization. In International Conference on Learning Representations, 2021. Xinhong Ma, Junyu Gao, and Changsheng Xu. Active universal domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8968â€“8977, 2021. Haitao Mao, Lun Du, Yujia Zheng, Qiang Fu, Zelin Li, Xu Chen, Shi Han, and Dongmei Zhang. Source free unsupervised graph domain adaptation. arXiv preprint arXiv:2112.00955, 2021. Christoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, and Jean Oh. Core challenges of social robot navigation: A survey. ACM Transactions on Human-Robot Interaction, 12(3):1â€“39, 2023. Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Munan Ning, Donghuan Lu, Dong Wei, Cheng Bian, Chenglang Yuan, Shuang Yu, Kai Ma, and Yefeng Zheng. Multi-anchor active domain adaptation for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9112â€“9122, 2021. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In International conference on machine learning, pages 16888â€“16905. PMLR, 2022. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. InThe Eleventh International Con- ference on Learning Representations, 2023. URL https://openreview.net/forum?id=g2YraF75Tj. Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE transactions on neural networks, 22(2):199â€“210, 2010. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019. 13Published as a conference paper at ICLR 2024 Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53â€“69, 2015. Judea Pearl. Causality. Cambridge university press, 2009. Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal of machine Learning research, 12:2825â€“2830, 2011. Jonas Peters, Peter BÃ¼hlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947â€“1012, 2016. Jonas Peters, Dominik Janzing, and Bernhard SchÃ¶lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017. Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, and Judy Hoffman. Active domain adaptation via clustering uncertainty-weighted embeddings. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8505â€“8514, 2021. Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. arXiv preprint arXiv:2010.05761, 2020. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019. Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normal- ization help optimization? Advances in neural information processing systems, 31, 2018. Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford, and Jordan T. Ash. Streaming active learning with deep neural networks. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 30005â€“30021. PMLR, 23â€“29 Jul 2023. URL https://proceedings.mlr. press/v202/saran23a.html. Harald Schafer, Eder Santana, Andrew Haden, and Riccardo Biasini. A commute in data: The comma2k19 dataset, 2018. Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for informa- tion extraction. In Advances in Intelligent Data Analysis: 4th International Conference, IDA 2001 Cascais, Portugal, September 13â€“15, 2001 Proceedings 4, pages 309â€“318. Springer, 2001. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539â€“11551, 2020. Burr Settles. Active learning literature survey. 2009. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji, and Manmohan Chandraker. Active adversarial domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 739â€“748, 2020. Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443â€“450. Springer, 2016. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229â€“9248. PMLR, 2020. 14Published as a conference paper at ICLR 2024 Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472â€“7481, 2018. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE international conference on computer vision, pages 4068â€“4076, 2015. Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7167â€“7176, 2017. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018â€“5027, 2017. Sudheendra Vijayanarasimhan and Ashish Kapoor. Visual recognition and detection under bounded computational resources. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 1006â€“1013. IEEE, 2010. Dan Wang and Yi Shang. A new active labeling method for deep learning. In 2014 International joint conference on neural networks (IJCNN), pages 112â€“119. IEEE, 2014. Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test- time adaptation by entropy minimization. InInternational Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c. Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing, 312: 135â€“153, 2018. Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201â€“7211, 2022a. Rui Wang, Zuxuan Wu, Zejia Weng, Jingjing Chen, Guo-Jun Qi, and Yu-Gang Jiang. Cross-domain contrastive learning for unsupervised domain adaptation. IEEE Transactions on Multimedia , 2022b. Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):1â€“46, 2020. Binhui Xie, Longhui Yuan, Shuang Li, Chi Harold Liu, Xinjing Cheng, and Guoren Wang. Active learning for domain adaptation: An energy-based approach. InProceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8708â€“8716, 2022. Zhao Xu, Kai Yu, V olker Tresp, Xiaowei Xu, and Jizhi Wang. Representative sampling for text classification using support vector machines. In Advances in Information Retrieval: 25th European Conference on IR Research, ECIR 2003, Pisa, Italy, April 14â€“16, 2003. Proceedings 25, pages 393â€“407. Springer, 2003. Baoyao Yang, Hao-Wei Yeh, Tatsuya Harada, and Pong C Yuen. Model-induced generalization error bound for information-theoretic representation learning in source-data-free unsupervised domain adaptation. IEEE Transactions on Image Processing, 31:419â€“432, 2021a. Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu Sebe, and Elisa Ricci. Transformer-based source-free domain adaptation. arXiv preprint arXiv:2105.14138, 2021b. Jianfei Yang, Xiangyu Peng, Kai Wang, Zheng Zhu, Jiashi Feng, Lihua Xie, and Yang You. Divide to adapt: Mitigating confirmation bias for domain adaptation of black-box predictors. arXiv preprint arXiv:2205.14467, 2022. H Yao, Yuhong Guo, and Chunsheng Yang. Source-free unsupervised domain adaptation with surrogate data generation. In Proceedings of NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021. 15Published as a conference paper at ICLR 2024 Hao-Wei Yeh, Baoyao Yang, Pong C Yuen, and Tatsuya Harada. Sofa: Source-data-free feature alignment for unsupervised domain adaptation. InProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 474â€“483, 2021. Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. Hu Yu, Jie Huang, Yajing Liu, Qi Zhu, Man Zhou, and Feng Zhao. Source-free domain adaptation for real-world image dehazing. In Proceedings of the 30th ACM International Conference on Multimedia, pages 6645â€“6654, 2022. Haojian Zhang, Yabin Zhang, Kui Jia, and Lei Zhang. Unsupervised domain adaptation of black-box source models. arXiv preprint arXiv:2101.02839, 2021. Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. Advances in Neural Information Processing Systems, 35:38629â€“38642, 2022a. Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan. Adanpc: Exploring non-parametric classifier for test-time adaptation. In International Conference on Machine Learning, pages 41647â€“41676. PMLR, 2023. Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2339â€“2348, 2022b. Bowen Zhao, Chen Chen, and Shu-Tao Xia. Delta: degradation-free fully test-time adaptation. arXiv preprint arXiv:2301.13018, 2023a. Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023b. Chunting Zhou, Xuezhe Ma, Paul Michel, and Graham Neubig. Examining and combating spurious features under distribution shift. In International Conference on Machine Learning, pages 12857â€“ 12867. PMLR, 2021. 16Published as a conference paper at ICLR 2024 Active Test-Time Adaptation: Foundational Analyses and An Algorithm Supplementary Material A B ROADER IMPACTS The field of domain generalization primarily concentrates on enhancing a modelâ€™s generalization abilities by preparing it thoroughly before deployment. However, it is equally important for deep learning applications to have the capacity for real-time adaptation, as no amount of preparation can account for all possible scenarios. Consequently, domain generalization and test-time adaptation are complementary strategies: the former is more weighty and extensive, while the latter is more agile, lightweight and privacy-friendly. This work delves into the development of a real-time model adaptation strategy that can be applied to any pre-trained models, including large language models, to enhance their adaptive capabilities. Our research does not involve any human subjects or dataset releases, nor does it raise any ethical concerns. Since this work does not directly tie to specific applications, we do not foresee any immediate negative societal impacts. Nonetheless, we acknowledge that any technological advancement may carry potential risks, and we encourage the continued assessment of the broader impacts of real-time adaptation methodologies in various contexts. B FAQ & D ISCUSSIONS To facilitate the reviewing process, we summarize the answers to the questions that arose during the discussion of an earlier version of this paper. The major updates of this version are reorganized theoretical studies, incremental clustering details, experimental reorganization, and additional datasets and settings . We include more related field comparisons to distinguish different settings. We also cover the position of this paper in literature and the main claims of this paper. Finally, we will frankly acknowledge the limitations of this paper, explain and justify the scope of coverage, and provide possible future directions. Q1: What is the relationship between the proposed ATTA protocol and stream based active learning (Saran et al., 2023)? A: We would like to discuss the difference between our work and the referenced work. 1. Real-time Training Distinction: Saran et al. (2023) doesnâ€™t operate in real-time capacity. This is evident from their experiments, where their model is trained only after completing a round. In contrast, our work involves training the model post each batch. This positions Saran et al. (2023)â€™s work as an intrinsic active learning technique, while our approach leans towards TTA methods. 2. Continual Training Nuance: Following the point above, Saran et al. (2023) stands out of the scope of continual training. As they mentioned â€˜each time new data are acquired, the ResNet is reset to the ImageNet pre-trained weights before being updatedâ€˜, Saran et al. (2023) starts afresh with each iteration and is out of scope for CF discussions. Contrarily, our model is continuously trained on varying distributions, compelling us to address the CF issue while preserving advantages derived from various stored distributions. 3. Comparative Complexity: Given the aforementioned distinctions, itâ€™s evident that our task presents a greater challenge compared to theirs. In addition, we have included comparisons with stronger active learning settings in Sec. 5.3. Q2: What are the insights from the theoretically foundational analysis? A: 1. It sets a well-defined formulation and grounded theoretical framework for the ATTA setting. 2. While entropy minimizations can cause CF, balancing the learning rate and number of high/low entropy samples is conversely the key solution to both distribution shifts and 17Published as a conference paper at ICLR 2024 CF by corresponding benefits. Though adding low-entropy data is intuitive, it is crucial in that this simple operation can make methods either too conservative or too aggressive without the correct balancing conditions. 3. The studies in Sec. 3.1 directly present a feasible and guaranteed solution for imple- menting ATTA to tackle shifts while avoiding CF. The aligned empirical validations of Sec. 3.2 also instruct the implementation of SimATTA. Q3: In test-time adaptation, one important issue is that the number of testing samples in a batch may be small, which means the sample size m will also be very small. May it affect the theorem and make them become very loose? A: We consider this issue jointly from theoretical and empirical validations. 1. It is true that the theoretical bounds can be loose given a small size of m unlabeled test samples. This situation of the error bound is mathematically ascribed to the quotient between the VC-dimension d of the hypothesis class and m. Under the VC-dimension theory, the ResNet18 model we adopt should have d â‰« m. However, practically we perform fine-tuning on pre-trained models instead of training from scratch, which significantly reduces the scale of parameter update. In this case, an assumption can be established that fine-tuning a model is roughly equivalent to learning a model with a relatively small d (Appx. H). This assumption is potentially underpinned by the empirical alignment of our validation experiments with the theoretical framework (Fig. 1). To this end, experiments indicate thatd and m are practically of similar scale for our settings. This prevents our theoretical bounds from being very loose and meaningless in reality. 2. Regarding cases that our assumption does not apply, this issue would appear inevitable, since it is rigorously inherent in the estimation error of our streaming and varying test distributions. The distribution of a test stream can be hardly monitored when only a limited batch is allowed, which we consider as a limitation of TTA settings. Moreover, this issue directly implies the necessity of using a buffer for unlabeled samples. A good practice is to maintain a relatively comparable sample buffer scale. Q4: What distribution shifts can ATTA solve? A: We would like to follow (but not limited to) the work (Zhao et al., 2023b) to discuss the distribution shifts ATTA can solve. 1. As elucidated in Sec. 3.1 and Sec. 5, ATTA can solve domain generalization shifts. Domain generalization shifts include complex shifts on the joint data distribution P(X, Y), given X as the covariates and Y as the label variable. Since P(X, Y) = P(X)P(Y |X), ATTA can handle covariate shift (P(X)), label shift (P(Y )), and conditional shift (P(Y |X)). The shifts on both covariate and conditional distributions can cover the shift on labels, but they (covariate + conditional shifts) are more complicated than pure label shifts, where only the marginal label distribution changes while the conditional distribution remains. Note that the conditional shifts are generally caused by spurious correlations, where the independent causal mechanism assumption (Pearl, 2009) holds or no concept drifts exist. 2. In our framework, the distribution support of X at different time steps can be different, but we donâ€™t cover the situation where the support of Y changes, i.e., class-incremental problems. Q5: It is unclear how many samples are selected in each minibatch of testing samples. How the total budget is distributed across the whole testing data stream? A: The number of selected samples for each minibatch is decided jointly by the incremental clustering and the cluster centroid number NC (t). Intuitively, this sample selection is a dynamic process, with NC (t) restricting the budget and incremental clustering performing sample selection. For each batch, we increase applicable clustering centroids as a maximum limit, while the exact number of the selected samples is given by the incremental clustering by how many clusters are located in the scope of new distributions. e.g., if the incoming batch does not introduce new data distributions, then we select zero samples even with increased NC (t). In contrast, if the incoming batch contains data located in multiple new distributions, the incremental clustering tends to select more samples than the NC (t) limit, thus forcing to merging of multiple previous clusters into one new cluster. 18Published as a conference paper at ICLR 2024 The incremental clustering is detailed in Sec. 4.2, and NC (t) is naively increased by a constant hyper-parameter k. Therefore, the budget is adaptively distributed according to the data streaming distribution with budgets controlled by k, which is also the reason why we compare methods under a budget limit. Q6: Could compared methods have access to a few ground-truth labels as well? Making other algorithms be able to use the same amount of ground-truth labels randomly will produce fairer comparisons. A: 1. The enhanced TTA setting is exactly the setup we provide to produce fairer comparisons. See Tab. 3 and Tab. 5 for comparison results. 2. ATTA also compares to a stronger setting ADA which can access the whole test datasets multiple times. Table 5: The table demonstrates the comparisons on PACS where all enhanced TTA baselines have 300 budgets to randomly select labeled samples. The training steps of these labeled samples are the same as the original TTA method training steps. For accumulated sample selection, please refer to our ablation studies. Method Domain-wise data stream A VG Random data stream A VG Pâ†’ â†’Aâ†’ â†’Câ†’ â†’S P A C S 1 2 3 4 P A C S Source onlyBN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 TTA Tent (steps=1) N/A 70.07 68.43 64.42 97.72 74.17 72.61 68.92 61.20 62.36 66.59 67.32 98.14 74.37 70.26 66.07Tent (steps=10) N/A 76.27 63.78 49.35 59.46 38.62 48.46 55.03 56.20 53.22 52.55 55.55 58.32 47.56 60.75 58.00EATA N/A 69.53 66.94 61.42 98.56 69.38 66.60 64.83 60.34 59.81 64.38 65.02 98.68 73.78 68.30 59.74CoTTA N/A 66.55 63.14 59.91 90.12 61.67 66.68 67.68 57.26 57.36 63.46 65.64 92.22 71.53 70.44 62.41SAR (steps=1) N/A 66.60 63.78 50.34 98.38 67.87 64.04 49.48 57.21 56.06 56.78 57.14 98.38 68.80 64.59 53.02SAR (steps=10) N/A 69.09 66.55 49.07 96.23 62.50 59.34 46.53 49.76 52.74 48.51 49.06 95.39 57.13 54.61 38.76 Ours (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00 Q7: What is the position of ATTA? A: Comparisons with different settings are challenging. In this work, the design of our experiments (Sec. 5) is to overcome this challenge by comparing both weaker settings and stronger settings. While the significant performance over weaker settings renders the necessity of extra information, the comparable performance with stronger settings provides the potential to relax restricted requirements. Intuitively, ATTA is the most cost-effective option in the consideration of both efficiency and effectiveness. We further provide the following ATTA summary: ATTA, which incorporates active learning in FTTA, is the light, real-time, source-free, widely applicable setting to achieve high generalization performances for test-time adaptation. 1. Necessity: From the causality perspective, new information is necessary (Lin et al., 2022; Pearl, 2009; Peters et al., 2017) to attain generalizable over distribution shifts which are insurmountable within the current TTA framework. 2. Effectiveness: Compared to FTTA methods, ATTA produces substantially better perfor- mances, on-par with the costly active domain adaptation (ADA) methods as shown in Table 3 in the paper. 3. Efficiency: Relative to ADA methods, ATTA possesses superior efficiency, similar to general FTTA methods, as shown in Tab. 3. 4. Applicability: ATTA is a model-agnostic setting. (1) Compared to domain generalization methods, ATTA do not require re-training and has the potential to apply to any pre-trained models. One interesting future direction is designing ATTA methods for large language models (LLMs), where re-trainings are extremely expensive and source data may be in- accessible. (2) Compared to FTTA methods, ATTA can protect model parameters from corrupting while learning new distributions by fine-tuning pre-trained models, rendering it more feasible and practical. In comparison with existing works, ATTA is motivated to mitigate the limitations of previous settings: 1. FTTA: Limited generalization performance. 19Published as a conference paper at ICLR 2024 2. TTT: Not source-free; limited generalization performance. 3. ADA & domain adaptation/generalization: Expensive re-trainings; limited applicability to pre-trained models. 4. Online active learning: It does not maintain and protect adaptation performances for multiple distributions in one model and does not consider the CF problem. Q8: What is the potential practical utility of ATTA? A: 1. Empirically, our method can generally finish a round of sample selection/training of 100 frames in 5s, i.e., 20 frames per sec, which is more than enough to handle multiple practical situations. Experiments on time complexity are provided in Tab. 3, where SimATTA has comparable time efficiency. 2. As a case analysis, the autopilot system (Hu et al., 2023; Chen et al., 2022a) presents an application scenario requiring high-speed low-latency adaptations, while these adaptations are largely underexplored. When entering an unknown environment, e.g., a construction section, a system of ATTA setting can require the driver to take over the wheel. During the period of manual operation when the driver is handling the wheel, steering signals are generated, and the in-car system quickly adaptations. The system doesnâ€™t need to record 60 frames per second, since only the key steering operations and the corresponding dash cam frames are necessary, which can be handled by ATTA algorithms processing at 20 frames per sec. In this case, the human annotations are necessary and indirect. ATTA makes use of this information and adapts in the short term instead of collecting videos and having a long-round fine-tuning (Schafer et al., 2018). 3. In addition, many scenarios applicable for ATTA are less speed-demanding than the case above. One example is a personalized chatbot that subtly prompts and gathers user labels during user interaction. In a home decoration setting, applications can request that users scan a few crucial areas to ensure effective adaptation. Social robots (Mavrogiannis et al., 2023), e.g., vacuum robots, often require users to label critical obstacles theyâ€™ve encountered. 4. Compared with ADA, ATTA stands out as the tailored solution for the above scenarios. It does not require intensive retraining or server-dependent fine-tuning, offering both speed and computational efficiency. Meanwhile, akin to other TTA methods, ATTA also ensures user privacy. While it might marginally exceed the cost of standard TTA methods, the superior generalization ability makes it a compelling choice and justifies the additional expense. Q9: What can be covered by this paper? A: This paper endeavors to establish the foundational framework for a novel setting referred to as ATTA. We target (1) positioning the ATTA setting, (2) solving the two major and basic challenges of ATTA,i.e., the mitigation of distribution shifts and the avoidance of catastrophic forgetting (CF). We achieve the first goal by building the problem formulation and analyses, and further providing extensive qualitative and well-organized experimental comparisons with TTA, enhanced TTA, and ADA settings. These efforts position ATTA as the most cost-effective option between TTA and ADA, where ATTA inherits the efficiency of TTA and the effectiveness of ADA. With our theoretical analyses and the consistent algorithm design, we validate the success of our second goal through significant empirical performances. Q10: What are not covered by this paper? A: Constructing a new setting involves multifaceted complexities. Although there are various potential applications discussed above including scaling this setting up for large models and datasets, we cannot cover them in this single piece of work. There are three main reasons. First, the topics covered by a single paper are limited. Formally establishing ATTA setting and addressing its major challenges of ATTA takes precedence over exploring practical applications. Secondly, given the interrelations between ATTA and other settings, our experimental investigations are predominantly comparative, utilizing the most representative datasets from TTA and domain adaptation to showcase persuasive results. Thirdly, many practical applications necessitate task-specific configurations, rendering them unsuitable for establishing a universal learning setting. While the current focus is on laying down the foundational aspects of ATTA, the exploration of more specialized applications remains a prospective avenue for future work in the ATTA domain. 20Published as a conference paper at ICLR 2024 C R ELATED WORKS The development of deep learning witnesses various applications (He et al., 2016; Gui et al., 2020). To tackle OOD problem, various domain generalization works emerge (Krueger et al., 2021; Sagawa et al., 2019). C.1 U NSUPERVISED DOMAIN ADAPTATION Unsupervised Domain Adaptation (UDA) (Pan et al., 2010; Patel et al., 2015; Wilson and Cook, 2020; Wang and Deng, 2018) aims at mitigating distribution shifts between a source domain and a target domain, given labeled source domain samples and unlabeled target samples. UDA methods generally rely on feature alignment techniques to eliminate distribution shifts by aligning feature distributions between source and target domains. Typical feature alignment techniques include discrepancy minimization (Long et al., 2015; Sun and Saenko, 2016; Kang et al., 2019) and adversarial training (Ganin and Lempitsky, 2015; Tsai et al., 2018; Ajakan et al., 2014; Ganin et al., 2016; Tzeng et al., 2015; 2017). Nevertheless, alignments are normally not guaranteed to be correct, leading to the alignment distortion problem as noted by Ning et al. (2021). Source-free Unsupervised Domain Adaptation (SFUDA) (Fang et al., 2022; Liu et al., 2021b) algorithms aim to adapt a pre-trained model to unlabeled target domain samples without access to source samples. Based on whether the algorithm can access model parameters, these algorithms are categorized into white-box and black-box methods. White-box SFUDA typically considers data recovery (generation) and fine-tuning methods. The former focuses on recovering source- like data (Ding et al., 2022; Yao et al., 2021), e.g., training a Generative Adversarial Network (GAN) (Kurmi et al., 2021; Li et al., 2020), while the latter employs various techniques (Mao et al., 2021), such as knowledge distillation (Chen et al., 2022b; Liu and Yuan, 2022; Yang et al., 2021b; Yu et al., 2022), statistics-based domain alignment (Ishii and Sugiyama, 2021; Liu et al., 2021a; Fan et al., 2022; Eastwood et al., 2021), contrastive learning (Huang et al., 2021; Wang et al., 2022b), and uncertainty-based adaptation (Gawlikowski et al., 2021; Fleuret et al., 2021; Chen et al., 2021; Li et al., 2021b). Black-box SFUDA cannot access model parameters and often relies on self-supervised knowledge distillation (Liang et al., 2022; 2021), pseudo-label denoising (Zhang et al., 2021; Yang et al., 2022), or generative distribution alignment (Yeh et al., 2021; Yang et al., 2021a). C.2 T EST-TIME ADAPTATION Test-time Adaptation (TTA), especially Fully Test-time Adaptation (FTTA) algorithms (Wang et al., 2021; Iwasawa and Matsuo, 2021; Karani et al., 2021; Nado et al., 2020; Schneider et al., 2020; Wang et al., 2022a; Zhao et al., 2023a; Niu et al., 2022; Zhang et al., 2022a; Niu et al., 2023; You et al., 2021; Zhang et al., 2022b), can be considered as realistic and lightweight methods for domain adaptation. Built upon black-box SFUDA, FTTA algorithms eliminate the requirement of a pre-collected target dataset and the corresponding training phase. Instead, they can only access an unlabeled data stream and apply real-time adaptation and training. In addition to FTTA, Test-time Training (TTT) (Sun et al., 2020; Liu et al., 2021c) often relies on appending the original network with a self-supervised task. TTT methods require retraining on the source dataset to transfer information through the self-supervised task. Although they do not access the source dataset during the test-time adaptation phase, TTT algorithms are not off-the-shelf source-free methods. TTA is a promising and critical direction for real-world applications, but current entropy minimization-based methods can be primarily considered as feature calibrations that require high-quality pseudo-labels. This requirement, however, can be easily violated under larger distribution shifts. Current TTA algorithms, inheriting UDA drawbacks, cannot promise good feature calibration results, which can be detrimental in real-world deployments. For instance, entropy minimization on wrongly predicted target domain samples with relatively low entropy can only exacerbate spurious correla- tions (Chen et al., 2020). Without extra information, this problem may be analogous to applying causal inference without intervened distributions, which is intrinsically unsolvable (Peters et al., 2016; Pearl, 2009). This paper aims to mitigate this issue with minimal labeled target domain samples. To minimize the cost, we tailor active learning techniques for TTA settings. It is worth noting that a recent work AdaNPC (Zhang et al., 2023) is essentially a domain gener- alization method with a TTA phase attached, while our ATTA is built based on the FTTA setting. Specifically, Current FTTA methods and our work cannot access the source domain. In contrast, 21Published as a conference paper at ICLR 2024 AdaNPC accesses source data to build its memory bank, circumventing the catastrophic forgetting problem. Furthermore, AdaNPC requires multiple source domains and training before performing TTA. Thus AdaNPC uses additional information on domain labels and retraining resources for its memory bank, undermining the merits of FTTA. Regarding theoretical bounds, their target domain is bounded by source domain error and model estimations (in big-O expression), while we consider active sample learning and time variables for varying test distributions. C.3 C ONTINUAL DOMAIN ADAPTATION Many domain adaptation methods focus on improving target domain performance, neglecting the performance on the source domain, which leads to the CF problem (Kemker et al., 2018; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lopez-Paz and Ranzato, 2017; De Lange et al., 2021; Wang et al., 2022a; Niu et al., 2022). This issue arises when a neural network, after being trained on a sequence of domains, experiences a significant degradation in its performance on previously learned domains as it continues to learn new domains. Continual learning, also known as lifelong learning, addresses this problem. Recent continual domain adaptation methods have made significant progress by employing gradient regularization, random parameter restoration, buffer sample mixture, and more. Although the CF problem is proposed in the continual learning field, it can occur in any source-free OOD settings since the degradation caused by CF is attributed to the networkâ€™s parameters being updated to optimize performance on new domains, which may interfere with the representations learned for previous domains. C.4 A CTIVE DOMAIN ADAPTATION Active Domain Adaptation (ADA) (Prabhu et al., 2021; Ning et al., 2021; Su et al., 2020; Ma et al., 2021; Xie et al., 2022) extends semi-supervised domain adaptation with active learning strate- gies (Cohn et al., 1996; Settles, 2009), aiming to maximize target domain performance with a limited annotation budget. Therefore, the key challenge of active learning algorithms is selecting the most informative unlabeled data in target domains (Kapoor et al., 2007). Sample selection strategies are of- ten based on uncertainty (Lewis and Catlett, 1994; Scheffer et al., 2001), diversity (Jain and Grauman, 2016; Hoi et al., 2009), representativeness (Xu et al., 2003), expected error minimization (Vijaya- narasimhan and Kapoor, 2010), etc. Among these methods, uncertainty and diversity-based methods are simple and computationally efficient, making them the most suitable choices to tailor for TTA settings. Adapting these strategies is non-trivial because, compared to typical active domain adaptation, our proposed Active Test-time Adaptation (ATTA) setting does not provide access to source data, model parameters, or pre-collected target samples. This requirement demands that our active sample selection algorithm select samples for annotation during data streaming. Consequently, this active sampling selection process is non-regrettable, i.e., we can only meet every sample once in a short period. To avoid possible confusion, compared to the recent Source-free Active Domain Adaptation (SFADA) method SALAD (Kothandaraman et al., 2023), we do not require access to model parameter gradients, training additional neural networks, or pre-collected target datasets. Therefore, our ATTA setting is quite different, much lighter, and more realistic than ADA and SFADA. C.5 A CTIVE ONLINE LEARNING The most related branch of active online learning (AOL) (Cacciarelli and Kulahci, 2023) is active online learning on drifting data stream (Zhou et al., 2021; Baier et al., 2021; Li et al., 2021a). Generally, these methods include two components, namely, detection and adaptation. Compared with ATTA, there are several distinctions. First, this line of studies largely focuses on the distribution shift detection problem, while ATTA focuses on multi-domain adaptations. Second, AOL on drifting data stream aims to detect and adapt to one current distribution in the stream, without considering preserving the adaptation abilities of multiple past distributions by maintaining and fine-tuning the original pre-trained models. In contrast, ATTAâ€™s goal is to achieve the OOD generalization optimums adaptable across multiple source and target distributions, leading to the consideration of CF problems. Third, while AOL requires one-by-one data input and discard, ATTA maintains a buffer for incoming data before selection decisions. This is because ATTA targets maintaining the original model without corrupting and replacing it, such that making statistically meaningful and high-quality decisions is 22Published as a conference paper at ICLR 2024 critical for ATTA. In contrast, AOL allows resetting and retraining new models, whose target is more lean to cost saving and one-by-one manner. D F URTHER THEORETICAL STUDIES In this section, we refine the theoretical studies with supplement analysis and further results. We use the H-divergence and Hâˆ†H-distance definitions following (Ben-David et al., 2010). Definition 2 (H-divergence). For a function class H and two distributions D1 and D2 over a domain X, the H-divergence between D1 and D2 is defined as dH(D1, D2) = sup hâˆˆH |Pxâˆ¼D1 [h(x) = 1] âˆ’ Pxâˆ¼D2 [h(x) = 1]|. The Hâˆ†H-distance is defined base on H-divergence. We use the Hâˆ†H-distance definition follow- ing (Ben-David et al., 2010). Definition 3 (Hâˆ†H-distance). For two distributions D1 and D2 over a domain X and a hypothesis class H, the Hâˆ†H-distance between D1 and D2 w.r.t. H is defined as dHâˆ†H(D1, D2) = sup h,hâ€²âˆˆH Pxâˆ¼D1 [h(x) Ì¸= hâ€²(x)] + Pxâˆ¼D2 [h(x) Ì¸= hâ€²(x)]. (9) The Hâˆ†H-distance essentially provides a measure to quantify the distribution shift between two distributions. It measures the maximum difference of the disagreement between two hypotheses in H for two distributions, providing a metrics to quantify the distribution shift between D1 and D2. H-divergence and Hâˆ†H-distance have the advantage that they can be applied between datasets, i.e., estimated from finite samples. Specifically, let S1, S2 be unlabeled samples of size m sampled from D1 and D2; then we have estimated Hâˆ†H-distance Ë†dH(S1, S2). This estimation can be bounded based on Theorem 3.4 of Kifer et al. (2004), which we state here for completeness. Theorem 5. Let A be a collection of subsets of some domain measure space, and assume that the VC-dimension is some finite d. Let P1 and P2 be probability distributions over that domain and S1, S2 finite samples of sizes m1, m2 drawn i.i.d. according P1, P2 respectively. Then Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16, (10) where Pm1+m2 is the m1 + m2â€™th power of P - the probability that P induces over the choice of samples. Theorem 5 bounds the probability for relativized discrepancy, and its applications in below lemmas and Theorem 1 help us bound the quantified distribution shifts between domains. The probability, according to a distribution D, that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source domain dataset is inaccessible under ATTA settings, we consider the existence of the source dataset DS for the purpose of accurate theoretical analysis. Thus, we initialize Dtr(0) as DS, i.e., Dtr(0) = DS. For every time step t, the test and training data can be expressed as Ute(t) and Dtr(t) = DS âˆª Dte(1) âˆª Dte(2) âˆª Â·Â·Â· âˆªDte(t). (11) We use N to denote the total number of samples in Dtr(t) and Î» = (Î»0, Î»1, Â·Â·Â· , Î»t) to represent the ratio of sample numbers in each component subset. In particular, we have |DS| |Dtr(t)| = Î»0, |Dte(1)| |Dtr(t)| = Î»1, Â·Â·Â· , |Dte(t)| |Dtr(t)| = Î»t, (12) where Pt i=0 Î»i = 1. Therefore, at time step t, the model has been trained on labeled data Dtr(t), which contains t + 1 components consisting of a combination of data from the source domain and multiple test-time domains. For each domain the model encounters, DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), let Ïµj(h(t)) denote the error of hypothesis h at time t on the jth domain. Specifically, Ïµ0(h(t)) = ÏµS(h(t)) represents the error of h(t) on the source data DS, and Ïµj(h(t)) for j â‰¥ 1 denotes the error of h(t) on test data Ute(j). Our optimization minimizes a convex combination of training error over the labeled samples from all domains. Formally, given the vector w = (w0, w1, Â·Â·Â· , wt) of domain error 23Published as a conference paper at ICLR 2024 weights with Pt j=0 wj = 1 and the sample number from each component Nj = Î»jN, we minimize the empirical weighted error of h(t) as Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Nj X Nj |h(x, t) âˆ’ g(x)|. (13) Note that w, Î» and N are also functions of t, which we omit for simplicity. We now establish two lemmas as the preliminary for Theorem 1. In the following lemma, we bound the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)). Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. In the following lemma, we provide an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. The proofs for both lemmas are provided in Appx. E. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Lemma 6 bounds the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)), which is majorly influenced by the estimatedHâˆ†H-distance and the quality of discrepancy estimation. During the ATTA process, the streaming test data can form multiple domains and distributions. However, if we consider all data during the test phase as a single test domain,i.e., St i=1 Ute(i), we can simplify Lemma 6 to obtain an upper bound for the test error ÏµT as |Ïµw(h(t)) âˆ’ ÏµT (h(t))| â‰¤w0 ï£« ï£­1 2 Ë†dHâˆ†H(S0, ST ) + 2 s 2d log(2m) + log 2 Î´ m + Î³ ï£¶ ï£¸, (14) where Î³ = min hâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}, and ST is sampled from St i=1 Ute(i). To understand Lamma 7, we need to understand Hoeffdingâ€™s Inequality, which we state below as a Proposition for completeness. Proposition 8 (Hoeffdingâ€™s Inequality). Let X be a set, D1, . . . , Dt be probability distributions on X, and f1, . . . , ft be real-valued functions on X such that fi : X â†’ [ai, bi] for i = 1, . . . , t. Then for any Ïµ >0, P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! (15) where E[fi(x)] is the expected value of fi(x). Lamma 7 provides an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Theorem 1 essentially bounds the performance of ATTA on the source and each test domains. The adaptation performance on a test domain is majorly 24Published as a conference paper at ICLR 2024 bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. If we consider the multiple data distributions during the test phase as a single test domain, i.e., St i=1 Ute(i), Theorem 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . With the optimal test/source hypothesis hâˆ— T (t) = arg min hâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (16.a), with approximately B = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (17) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. When the budget is sufficiently large or the source data amount is not sufficiently large compared to the distribution shift A, the optimal wâˆ— 0 for the test error bound is wâˆ— 0 = 0, i.e., using no source data since possible error reduction from the data addition is always less than the error increase caused by large divergence between the source data and the test data. Theorem 2 offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Following Theorem 1, when no active learning is included during TTA,i.e., w0 = Î»0 = 1, the upper boundw0A+ q w2 0 Î»0 + (1âˆ’w0)2 1âˆ’Î»0 B â‰¥ A+B; when enabling ATTA, withw0 = Î»0 Ì¸= 1, we can easily achieve an upper bound w0A + B < A+ B. Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. Entropy quantifies the amount of information contained in a probability distribution. In the context of a classification model, lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction. When a model assigns low entropy to a sample, this high confidence can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model â€œrecognizesâ€ the sample as being similar to those it was trained on, hence the high confidence in its prediction. While entropy is not a direct measure of distributional distance, it can be used as an indicator of how closely a sample aligns with the modelâ€™s learned distribution. This interpretation is more about model confidence and the implied proximity rather than a strict mathematical measure of distributional distance. The pre-trained model is well-trained on abundant source domain data, and thus the model distribution is approximately the source distribution. Selecting low-entropy samples using essentially provides an estimate of sampling from the source dataset. Thus, DÏ•,S(t), based on well-aligned with the modelâ€™s learned distribution is an approximation of DS. When we consider the CF problem and feasibly include the source-like dataset DÏ•,S(t) into the ATTA training data in place of the inaccessible DS in Eq. (11), we can also derive bounds on the domain errors under this practical ATTA setting when minimizing the empirical weighted errorÏµâ€² w(h(t)) using the hypothesis h at time t, similar to Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domainsDÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is 25Published as a conference paper at ICLR 2024 N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµâ€² w(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Other derived results following Theorem 1 also apply for this practical ATTA setting. Further empirical validations for our theoretical results are provided in Appx. H. E P ROOFS This section presents comprehensive proofs for all the lemmas, theorems, and corollaries mentioned in this paper, along with the derivation of key intermediate results. Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Proof. First we prove that given unlabeled samples of size m S1, S2 sampled from two distributions D1 and D2, we have dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (18) We start with Theorem 3.4 of Kifer et al. (2004): Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16. (19) In Eq. 19, â€™dâ€™ is the VC-dimension of a collection of subsets of some domain measure space A, while in our case, d is the VC-dimension of hypothesis space H. Following (Ben-David et al., 2010), the Hâˆ†H space is the set of disagreements between every two hypotheses inH, which can be represented as a linear threshold network of depth 2 with 2 hidden units. Therefore, the VC-dimension of Hâˆ†H is at most twice the VC-dimension of H, and the VC-dimension of our domain measure space is 2d for Eq. 19 to hold. Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2m)2deâˆ’m1Ïµ2/16 + (2m)2deâˆ’m2Ïµ2/16. We rewrite the inequality as Î´ (2m)2d = eâˆ’m1Ïµ2/16 + eâˆ’m2Ïµ2/16; taking the logarithm of both sides, we get log Î´ (2m)2d = âˆ’m1 Ïµ2 16 + log(1 +eâˆ’(m1âˆ’m2) Ïµ2 16 ). 26Published as a conference paper at ICLR 2024 Assuming m1 = m2 = m and defining a = Ïµ2 16 , we have log Î´ (2m)2d = âˆ’ma + log 2; rearranging the equation, we then get ma + log(Î´/2) = 2d log(2m). Now, we can solve for a: a = 2d log(2m) + log 2 Î´ m . Recall that a = Ïµ2 16 , so we get: Ïµ = 4âˆša Ïµ = 4 s 2d log(2m) + log 2 Î´ m . With probability of at least 1 âˆ’ Î´, we have |Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| â‰¤4 s 2d log(2m) + log 2 Î´ m ; therefore, dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (20) Now we prove Lemma 6. We use the triangle inequality for classification error in the derivation. For the domain error of hypothesis h at time t on the jth domain Ïµj(h(t)), given the definition of Ïµw(h(t)), |Ïµw(h(t)) âˆ’ Ïµj(h(t))| = | tX i=0 wiÏµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi|Ïµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(|Ïµi(h(t)) âˆ’ Ïµi(h(t), hâˆ— i (t))| + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + |Ïµj(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t))|) â‰¤ tX i=0 wi(Ïµi(hâˆ— i (t)) + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + Ïµj(hâˆ— i (t))) â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|), where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. By the definition of Hâˆ†H-distance and our proved Eq. 20, |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| â‰¤sup h,hâ€²âˆˆH |Ïµi(h(t), hâ€²(t)) âˆ’ Ïµj(h(t), hâ€²(t))| = sup h,hâ€²âˆˆH Pxâˆ¼Di[h(x) Ì¸= hâ€²(x)] + Pxâˆ¼Dj [h(x) Ì¸= hâ€²(x)] = 1 2dHâˆ†H(Di, Dj) â‰¤ 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m , 27Published as a conference paper at ICLR 2024 where Di, Dj denote the ith and jth domain. Therefore, |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|) â‰¤ tX i=0 wi(Î³i + 1 2dHâˆ†H(Di, Dj)) â‰¤ tX i=0 wi(Î³i + 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m ). Since Ïµi(h(t)) âˆ’ Ïµj(h(t)) = 0 when i = j, we derive |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. This completes the proof. Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Proof. We apply Hoeffdingâ€™s Inequality in our proof: P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! . (21) In the jth domain, there are Î»jN samples. With the true labeling function g(x), for each of the Î»jN samples x, let there be a real-valued function fi(x) fi(x) = wj Î»j |h(x, t) âˆ’ g(x)|, where fi(x) âˆˆ [0, wj Î»j ]. Incorporating all the domains, we get Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Î»jN X Î»jN |h(x, t) âˆ’ g(x)| = 1 N tX j=0 Î»jNX i=1 fi(x), which corresponds to the 1 t Pt i=1 fi(x) part in Hoeffdingâ€™s Inequality. Due to the linearity of expectations, we can calculate the sum of expectations as 1 N tX j=0 Î»jNX i=1 E[fi(x)] = 1 N ( tX j=0 Î»jN wj Î»j Ïµj(h(t))) = tX j=0 wjÏµj(h(t)) = Ïµw(h(t)), which corresponds to the 1 t Pt i=1 Exâˆ¼Di[fi(x)] part in Hoeffdingâ€™s Inequality. Therefore, we can apply Hoeffdingâ€™s Inequality as P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2N2Ïµ2/( NX i=0 range2(fi(x))) ! = 2 exp   âˆ’2N2Ïµ2/( tX j=0 Î»jN(wj Î»j )2) ! = 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . This completes the proof. 28Published as a conference paper at ICLR 2024 Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. Proof. First we prove that for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (22) We apply Theorem 3.2 of Kifer et al. (2004) and Lemma 7, P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . We rewrite the inequality as Î´ (2N)d = e âˆ’2NÏµ2/(Pt j=0 w2 j Î»j ) , taking the logarithm of both sides, we get log Î´ (2N)d = âˆ’2NÏµ2/( tX j=0 w2 j Î»j ). Rearranging the equation, we then get Ïµ2 = ( tX j=0 w2 j Î»j )d log(2N) âˆ’ log(Î´) 2N . Therefore, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (23) 29Published as a conference paper at ICLR 2024 Based on Eq. 23, we now prove Theorem 1. For the empirical domain error of hypothesis h at time t on the jth domain Ïµj(Ë†h(t)), applying Lemma 6, Eq. 23, and the definition of hâˆ— j (t), we get Ïµj(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— j (t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµj(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k where k > 0, we have the assumption that kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H(D(kâ€²), Ute(t + k)) â‰¤ Î´D. Here, we slightly abuse the notation D(kâ€²) to represent Ds if kâ€² = 0 and Ute(kâ€²) if kâ€² > 0. Then we get Ïµt+k(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, St+k) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2( Ë†dHâˆ†H(Si, Skâ€² ) + Ë†dHâˆ†H(Skâ€² , St+k)) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 30Published as a conference paper at ICLR 2024 â‰¤ Ë†Ïµw(hâˆ— t+k(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµt+k(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. with probability of at least 1âˆ’Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 , Î³i = minhâˆˆH{Ïµi(h(t))+ Ïµt+k(h(t))}, and 0 â‰¤ Î´D â‰ª +âˆž. This completes the proof. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (24) Proof. From Theorem 1, we can derive the bound for the test error where the test-time data are considered as a single test domain: |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t) = w0( Ë†dHâˆ†H(S0, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N ; and we simplify the above equation as |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (25) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Since we have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (26) 31Published as a conference paper at ICLR 2024 where Formula 26 obtains the minimum value if and only if w0 = Î»0; when enabling ATTA with any Î»0 Ì¸= 1, we can get EBT (w, Î», N, t) = w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¥ w0A + B, (27) where the minimum value EBT (w, Î», N, t)min = w0A + B can be obtained with condition w0 = Î»0 Ì¸= 1. When no active learning is included, i.e., for weight and sample ratio vectors wâ€² and Î»â€², wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, we have EBT (wâ€², Î»â€², N, t) = wâ€² 0A + s wâ€²2 0 Î»â€² 0 + (1 âˆ’ wâ€² 0)2 1 âˆ’ Î»â€² 0 B = A + B. (28) Since for EBT (w, Î», N, t)min = w0A + B, w0 < 1 and A, B >0 hold, we derive EBT (w, Î», N, t)min = w0A + B < A+ B = EBT (wâ€², Î»â€², N, t). (29) This completes the proof. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Theorem 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Theorem 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Proof. For the empirical source error on DS of hypothesis h at time t, similar to Theorem 1, we apply Lemma 6, Eq. 23 to get ÏµS(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— S(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ ÏµS(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 32Published as a conference paper at ICLR 2024 = ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. This completes the proof. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Theorem 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (30) Proof. From Theorem 1, considering the test-time data as a single test domain, we can derive the bound for the source error on DS: |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N , where ST is sampled fromSt i=1 Ute(i), Î³ = minhâˆˆH{Ïµ0(h(t))+ÏµS(h(t))}, and Î³â€² = minhâˆˆH{ÏµT (h(t))+ ÏµS(h(t))}. We have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (31) where the equality and the minimum value are obtained if and only if w0 = Î»0. When DÏ•,S(t) is not included,i.e., with the weight and sample ratio vectorswâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0, using the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , we have EBS(wâ€², Î»â€², N, t) = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B. When DÏ•,S(t) is included with Î»0 Ì¸= 0, EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¤ w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B, 33Published as a conference paper at ICLR 2024 Algorithm 2 INCREMENTAL CLUSTERING (IC) Require: Given previously selected anchors, new unlabeled samples, and the cluster budget as Danc, Unew, and NC . Global anchor weights wanc = (wanc 1 , . . . , wanc |Danc|)âŠ¤. 1: For simplicity, we consider anchor weights wanc as a global vector. 2: function IC(Danc, Unew, NC ) 3: wsp â† Concat(wanc, 1âŠ¤ |Unew|) â–· Assign all new samples with weight 1. 4: Î¦ â† Extract the features from the penultimate layer of model f on x âˆˆ Danc âˆª Unew in order. 5: clusters â† Weighted-K-Means(Î¦, wsp, NC) 6: new_clusters â† {clusteri | âˆ€clusteri âˆˆ clusters, âˆ€x âˆˆ Danc, x /âˆˆ clustersi} 7: Xnew_anchors â† {the closest sample x to the centroid of clusteri | âˆ€clusteri âˆˆ new_clusters} 8: Xanchors â† {x âˆˆ Danc} âˆªXnew_anchors 9: wanc â† Concat(wanc, 0âŠ¤ |Xnew_anchors|) â–· Initialize new anchor weights. 10: for wanc i âˆˆ wanc, wanc i â† wanc i + # sample of clusterj # anchor in clusterj , wanc i âˆˆ clusterj â–· Weight accumulation. 11: Return Xanchors 12: end function where the minimum value can be obtained with condition w0 = Î»0 Ì¸= 0. In practical learning scenarios, we generally assume adaptation tasks are solvable; therefore, there should be a prediction function that performs well on two distinct domains. In this case, Î³ and Î³â€² should be relatively small, so we can assume Î³ â‰ˆ Î³â€². If Ë†dHâˆ†H(S0, SS) < Ë†dHâˆ†H(SS, ST ), then we have EBS(w, Î», N, t)min = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B < Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B = EBS(wâ€², Î»â€², N, t). Therefore, we derive EBS(w, Î», N, t)min < EBS(wâ€², Î»â€², N, t). (32) This completes the proof. F I NCREMENTAL CLUSTERING F.1 A LGORITHM DETAILS We provide the detailed algorithm for incremental clustering as Alg. 2. F.2 V ISUALIZATION To better illustrate the incremental clustering algorithm, we provide visualization results on PACS to demonstrate the process. As shown in Fig. 3, the initial step of IC is a normal K-Means clustering step, and ten anchors denoted as \"X\" are selected. The weights of all samples in a clusters is aggregated into the corresponding anchorâ€™s weight. Therefore, these ten samples (anchors) are given larger sizes visually (i.e., larger weights) than that of other new test samples in the first IC step (Fig. 4). During the first IC step, several distributions are far away from the existed anchors and form clusters 1,7,9 and 10, which leads to 4 new selected anchors. While the number of cluster centroid is only increased by 1, 4 of the existing anchors are clustered into the same cluster 8 (purple). Thus IC produces 4 new anchors instead of 1. Similarly, in the second IC step (Fig. 5), the new streaming-in test samples introduce a new distribution; IC produces 3 new clusters (4, 8, and 11) and the corresponding number of anchors to cover them. The number of centroid is only increased by 1, which implies that there are two original-cluster-merging events. More IC step visualization results are provided in Fig. 6 and 7. 34Published as a conference paper at ICLR 2024 Figure 3: Initial IC step: normal clustering. Left: Clustering results. Right: Selecting new anchors. Figure 4: The first IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 5: The second IC step. Left: Weighted clustering results. Right: Selecting new anchors. 35Published as a conference paper at ICLR 2024 Figure 6: The third IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 7: The fourth IC step. Left: Weighted clustering results. Right: Selecting new anchors. 36Published as a conference paper at ICLR 2024 G E XPERIMENT DETAILS In this section, we provide more experimental details including the details of the datasets and training settings. G.1 D ETAILS ABOUT THE DATASETS We adopt datasets PACS, VLCS, and Office-Home from DomainBed (Gulrajani and Lopez-Paz, 2020) with the same domain splits. All available licenses are mentioned below. â€¢ PACS (Li et al., 2017) includes four domains: art, cartoons, photos, and sketches. PACS is a 7-class classification dataset with 9,991 images of dimension (3, 224, 224). â€¢ VLCS (Fang et al., 2013) contains photographic domains: Caltech101, LabelMe, SUN09, and VOC2007. This dataset includes 10,729 images of dimension (3, 224, 224) with 5 classes. â€¢ Office-Home (Venkateswara et al., 2017) is a 65-class dataset, including domains: art, clipart, product, and real. VLCS includes 10,729 images of dimension (3, 224, 244). (License) â€¢ Tiny-ImageNet-C is a 200-class dataset, including 15 corrupt types. Tiny-ImageNet-C includes 150,000 images of dimension (3, 224, 244). Since the class number 200 is less than ImageNet (1000), the modelâ€™s last layer classifier needs to be adapted. In this work, we use the brightness corruption domain to adapt. In the source pretraining phase, we adopt the most ImageNet-like domain as our source domain. For PACS and Office-Home, we use domains \"photos\" and \"real\" as the source domains, respectively, while for VLCS, Caltech101 is assigned to apply the source pretraining. We freeze the random seeds to generate the sample indices order for the two test data streams, namely, the domain-wise data stream and the random data stream. For PACS, the domain-wise data stream inputs samples from domain art, cartoons, to sketches, while we shuffle all samples from these three domains in the random data stream. For VLCS, we stream the domains in the order: LabelMe, SUN09, and VOC2007, as the domain-wise data stream. For Office-Home, the domain-wise data stream order becomes art, clipart, and product. G.2 T RAINING AND OPTIMIZATION SETTINGS In this section, we extensively discuss the model architectures, optimization settings, and method settings. G.2.1 A RCHITECTURES PACS & VLCS. We adopt ResNet-18 as our model encoder followed by a linear classifier. The initial parameters of ResNet-18 are ImageNet pre-trained weights. In our experiment, we remove the Dropout layer since we empirically found that using the Dropout layer might degrade the optimization process when the sample number is small. The specific implementation of the network is closely aligned with the implementation in DomainBed (Gulrajani and Lopez-Paz, 2020). Office-Home. We employ ResNet-50 as our model encoder for Office-Home. Except for the architecture, the other model settings are aligned with the ResNet-18. Tiny-ImageNet-C ResNet-18 is adapted from ImageNet to Tiny-ImageNet-C by training the last linear layer. G.2.2 T RAINING & OPTIMIZATION In this section, we describe the training configurations for both the source domain pre-training and test-time adaptation procedures. Source domain pre-training. For the PACS and VLCS datasets, models are fine-tuned on the selected source domains for 3,000 iterations. The Adam optimizer is utilized with a learning rate 37Published as a conference paper at ICLR 2024 of 10âˆ’4. In contrast, for the Office-Home dataset, the model is fine-tuned for a longer duration of 10,000 iterations with a slightly adjusted learning rate of 5 Ã— 10âˆ’5. Test-time adaptation. For test-time adaptation across PACS and VLCS, the pre-trained source model is further fine-tuned using the SGD optimizer with a learning rate of 10âˆ’3. While on Office-Home and Tiny-ImageNet-C, a learning rate of 10âˆ’4 is adopted. For all TTA baselines, barring specific exceptions, we faithfully adhere to the original implementation settings. A noteworthy exception is the EATA method, which requires a cosine similarity threshold. The default threshold of the original EATA implementation was not suitable for the three datasets used in our study, necessitating an adjustment. We empirically set this threshold to 0.5 for training. Unlike Tent and SAR, which only require the optimization of batch normalization layers (Santurkar et al., 2018), SimATTA allows the training of all parameters in the networks. In experiments, we use a tolerance count (tol) to control the training process. SimATTA will stop updating once the loss does not descrease for more than 5 steps. However, for Tiny-ImageNet-C, SimATTA uses â€˜steps=10â€˜ for time comparisons since other methods apply at most 10 steps. G.2.3 M ETHOD SETTINGS Tent. In our experiments, we apply the official implementation of Tent1. Specifically, we evaluate Tent with 1 test-time training step and 10 steps, respectively. EATA.Our EATA implementation follows its official code2. In our experiments, EATA has 2000 fisher training samples, E0 = 0.4 Ã— log(# class), Ïµ <0.5. CoTTA. For CoTTA, we strictly follow all the code and settings from its official implementation3. SAR. With SARâ€™s official implementation4, we set E0 = 0 .4 Ã— log(# class) and e0 = 0 .1 in our experiments. ADA baselines. For ADA baselines, we follow the architecture of the official implementation of CLUE (Prabhu et al., 2021)5. SimATTA Implementation. Our implementation largely involves straightforward hyperparameter settings. The higher entropy bound eh = 10âˆ’2 should exceed the lower entropy bound el, but equal values are acceptable. Empirically, the lower entropy bound el can be set to 10âˆ’3 for VLCS and Office-Home, or 10âˆ’4 for PACS. The choice of el is largely dependent on the number of source-like samples obtained. A lower el may yield higher-accuracy low-entropy samples, but this could lead to unstable training due to sample scarcity. Though experimentation with different hyperparameters is encouraged, our findings suggest that maintaining a non-trivial number of low-entropy samples and setting an appropriateÎ»0 are of primary importance. If Î»0 < 0.5, CF may ensue, which may negate any potential improvement. Regarding the management of budgets, numerous strategies can be adopted. In our experiments, we utilized a simple hyperparameter k, varying from 1 to 3, to regulate the increasing rate of budget consumption. This strategy is fairly elementary and can be substituted by any adaptive techniques. G.3 S OFTWARE AND HARDWARE We conduct our experiments with PyTorch (Paszke et al., 2019) and scikit-learn (Pedregosa et al., 2011) on Ubuntu 20.04. The Ubuntu server includes 112 Intel(R) Xeon(R) Gold 6258R CPU @2.70GHz, 1.47TB memory, and NVIDIA A100 80GB PCIe graphics cards. The training process costs graphics memory less than 10GB, and it requires CPU computational resources for scikit-learn K-Means clustering calculations. Our implementation also includes a GPU-based PyTorch K-Means method for transferring calculation loads from CPUs to GPUs. However, for consistency, the results of our experiments are obtained with the original scikit-learn K-Means implementation. 1https://github.com/DequanWang/tent 2https://github.com/mr-eggplant/EATA 3https://github.com/qinenergy/cotta 4https://github.com/mr-eggplant/SAR 5https://github.com/virajprabhu/CLUE 38Published as a conference paper at ICLR 2024 Figure 8: Target loss surface on 2000 samples without source pre-training. The red points denote the loss minimum for a fixed Î»0. The orange line denote the place where w0 = Î»0. Figure 9: Target loss surface on 2000 samples with source pre-training. H E MPIRICAL VALIDATIONS FOR THEORETICAL ANALYSIS In this section, we undertake empirical validation of our learning theory, which encompasses multiple facets awaiting verification. In contemporary computer vision fields, pre-trained models play a pivotal role, and performance would significantly decline without the use of pre-trained features. The learning theory suggests that given the vast VC-dimension of complete ResNets, without substantial data samples, the training error cannot be theoretically tight-bounded. However, we show empirically in the following experiments that fine-tuning pre-trained models is behaviorally akin to training a model with a low VC-dimension. Training on 2000 Samples Without Source Domain Pre-training. For an ImageNet pre-trained ResNet-18 model, we trained it using 2000 samples from the PACS dataset. To ascertain the optimal value wâˆ— 0 in Equation 4, we trained multiple models for different w0 and Î»0 pairings. For each pair, we derived the target domain loss (from art, cartoons, and sketches) post-training and plotted this loss on the z-axis. With w0 and Î»0 serving as the xy-axes, we drafted the target domain loss ÏµT surface in Figure 8. As the results show, given a Î»0, the optimal wâˆ— 0 typically aligns with the line Î»0 = w0, with a slight downward shift, which aligns with Equation 4. 39Published as a conference paper at ICLR 2024 Figure 10: Target loss surface on 500 samples with source pre-training. Figure 11: Source loss surface on 500 samples with source pre-training. 40Published as a conference paper at ICLR 2024 Figure 12: Target and source loss surface on 500 samples with source pre-training. Table 6: TTA comparisons on Office-Home. This table includes the two data stream settings mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. Office-Home Domain-wise data stream Post-adaptation Random data stream Post-adaptation R â†’Aâ†’ â†’Câ†’ â†’P R A C P 1 2 3 4 R A C P BN w/o adapt 93.78 42.93 37.62 59.90 93.78 42.93 37.62 59.90 46.82 46.82 46.82 46.82 93.78 42.93 37.62 59.90BN w/ adapt 92.38 49.69 39.43 63.53 92.38 49.69 39.43 63.53 50.88 50.88 50.88 50.88 92.38 49.69 39.43 63.53 Tent (steps=1) N/A 49.61 39.31 63.87 92.47 49.57 39.89 63.89 49.95 50.27 50.23 52.06 92.40 49.24 39.68 63.98Tent (steps=10) N/A 49.61 39.04 61.41 87.08 44.79 38.37 60.49 50.05 49.31 48.74 47.79 85.31 42.85 37.89 58.71EATA N/A 49.65 39.04 63.53 91.60 49.61 38.65 63.48 49.73 50.27 49.45 51.07 91.05 49.11 38.26 62.99CoTTA N/A 49.61 38.76 61.84 87.81 44.95 35.92 59.04 49.84 49.84 48.95 50.43 86.99 43.68 34.73 57.56SAR (steps=1) N/A 49.65 39.24 63.53 92.45 49.73 39.36 63.69 49.84 50.05 49.91 51.67 92.38 49.57 39.50 63.87SAR (steps=10) N/A 49.53 38.81 61.50 88.94 46.15 37.04 59.41 50.09 50.30 49.77 49.22 89.14 46.23 36.31 59.45 SimATTA (B â‰¤300) N/A 56.20 48.38 71.66 95.75 60.07 52.62 74.70 58.57 60.88 62.91 63.67 95.89 62.01 54.98 74.70SimATTA (B â‰¤500) N/A 58.71 51.11 74.36 96.03 62.05 57.41 76.98 58.85 62.63 63.41 64.31 95.91 63.78 57.87 77.09 Training on 2000 Samples with Source Domain Pre-training. To further assess the effects of source pre-training, we repeated the same experiment on a source pre-trained ResNet-18. The results are depicted in Figure 9. This experiment provides empirical guidance on selecting w0 in source domain pre-trained situations. The findings suggest that the optimal wâˆ— 0 non-trivially shifts away from the line Î»0 = w0 towards lower-value regions. Considering the source pre-training process as using a greater quantity of source domain samples, it implies that when the number of source samples greatly exceeds target samples, a lower w0 can enhance target domain results. Training on 500 Samples with Source Domain Pre-training. We proceed to fine-tune the source domain pre-trained ResNet-18 using only 500 samples, thereby simulating active TTA settings. We train models with various w0 and Î»0 pairings, then graph the target domain losses, source domain losses, and the combined losses. As shown in Figure 10, the target losses still comply with our theoretical deductions where the local minima are close to the line Î»0 = w0 and marginally shift towards lower values. Considering the challenge of CF, the source domain results in Figure 11 suggest a reverse trend compared to the target domain, where lower Î»0 and w0 values yield superior target domain results but inferior source domain results. Thus, to curb CF, the primary strategy is to maintain a relatively higher Î»0. When considering both target and source domains, a balance emerges as depicted in Figure 12. The global minimum is located in the middle region, demonstrating the trade-off between the target domain and source domain performance. I A DDITIONAL EXPERIMENT RESULTS In this section, we provide additional experiment results. The Office-Home results and ablation studies will be presented in a similar way as the main paper. In the full results Sec. I.3, we will post more detailed experimental results with specific budget numbers and intermediate performance during the test-time adaptation. 41Published as a conference paper at ICLR 2024 Table 7: Comparisons to ADA baselines on Office-Home. The source domain is denoted as \"(S)\" in the table. Results are average accuracies with standard deviations). Office-Home R (S) A C P Random (B = 300) 95.04 (0.20) 57.54 (1.16) 53.43 (1.17) 73.46 (0.97) Entropy (B = 300) 94.39 (0.49) 61.21 (0.71) 56.53 (0.71) 72.31 (0.28) Kmeans (B = 300) 95.09 (0.14) 57.37 (0.90) 51.74 (1.34) 71.81 (0.39) CLUE (B = 300) 95.20 (0.23) 60.18 (0.98) 58.05 (0.43) 73.72 (0.70) Ours (B â‰¤300) 95.82 (0.07) 61.04 (0.97) 53.80 (1.18) 74.70 (0.00) I.1 R ESULTS ON OFFICE -HOME We conduct experiments on Office-Home and get the test-time performances and post-adaptation performances for two data streams. As shown in Tab. 6, SimATTA can outperform all TTA baselines with huge margins. Compared to ADA baselines under the source-free settings, as shown in Tab. 7, SimATTA obtains comparable results. I.2 A BLATION STUDIES Figure 13: Ablation study on PACS and VLCS.\"IC=0\" denotes removing incremental clustering (IC) selection. \"LE=0\" denotes removing the low-entropy (LE) sample training. Domain-wise stream and random stream are applied on first and second rows, respectively. The accuracy values are averaged across all splits/domains. In this section, we explore three variations of our method to examine the individual impacts of its components. The first variant replaces the incremental clustering selection with entropy selection, 42Published as a conference paper at ICLR 2024 where only the samples with the highest entropy are chosen. The second variant eliminates low- entropy sample training. The third variation combines the first and second variants. We perform this ablation study on the PACS and VLCS as outlined in Fig. 13. We denote the use of incremental clustering (IC) and low-entropy training (LE) respectively as IC=1 and LE=1. The experiments essentially reveals the effectiveness of incremental clustering and low-entropy- sample training. As we have detailed in Sec. 3.2, these techniques are designed to to select informative samples, increase distribution coverage, and mitigate catastrophic forgetting. These designs appositely serve the ATTA setting where the oracle has costs and the budget is limited. Therefore, their effectiveness is prominent particularly when the budget is small. As the results show, when the budget B â‰¤100 or B â‰¤300, removing the components observably impairs performances. When B gets large, more active samples cover a larger distribution; thus the performance gap from random selection and informative selection gets smaller. In the extreme case where B â†’ âˆž, all samples are selected and thus the superiority of our meticulously-designed techniques are not manifested. Specifically, our analysis yields several insights. First, SimATTA (LE=1, IC=1) comprehensively outperforms other variants on both datasets, different streams, and different budgets. Second, variants without low-entropy training (LE=0, IC=0/1) easily fail to produce stable results (e.g., domain-wise stream in VLCS). Third, SimATTAâ€™s performance surpasses this variant on PACSâ€™s domain-wise stream clearly especially when the budgets are low. This indicates these variants fail to retrieve the most informative style shift (PACSâ€™s shifts) samples, which implies the advantage of incremental clustering when the budget is tight. In addition, these results show that IC has its unique advantage on domain-wise streams where distributions change abruptly instead of random streams. Therefore, compared to PACSâ€™s domain- wise stream results, the reason for the smaller performance improvement of SimATTA over the variant (LE=1, IC=0) on VLCSâ€™s domain-wise stream is that images in VLCS are all photos that do not include those severe style shifts in PACS (i.e., art, cartoons, and sketches). That is, when the shift is not severe, we donâ€™t need IC to cover very different distributions, and selecting samples using entropy can produce good results. In brief, IC is extraordinary for severe distribution shifts and quick adaptation. It is worth mentioning that low budget comparison is essential to show the informative sample retrieval ability, since as the budget increases, all AL techniques will tend to perform closely. I.3 C OMPLETE EXPERIMENT RESULTS We provide complete experimental results in this section. As shown in Tab. 8, we present the full results for two data streams. The test-time adaptation accuracies are shown in the \"Current domain\" row, while the \"Budgets\" row denotes the used budget by the end of the domain. The rest four rows denote the four domain test results by the end of the real-time adaptation of the current domain, where the first column results are the test accuracy before the test-time adaptation phase. N/A represents \"do not apply\". Table 8: Tent (steps=1) on PACS. Tent (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.29 64.59 44.67 56.35 54.09 51.83 48.58 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.38 97.60 98.56 98.08 97.72 97.19 A 59.38 69.09 68.95 66.85 68.07 67.33 65.58 63.53 C 28.03 64.04 65.19 64.08 64.85 65.19 62.97 60.75 S 42.91 53.65 47.39 42.58 54.57 49.83 44.13 41.56 J C HALLENGES AND PERSPECTIVES Despite advancements, test-time adaptation continues to pose considerable challenges. As previously discussed, without supplementary information and assumptions, the ability to guarantee model generalization capabilities is limited. However, this is not unexpected given that recent progress 43Published as a conference paper at ICLR 2024 Table 9: Tent (steps=10) on PACS. Tent (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.38 57.85 20.23 47.36 31.01 22.84 20.33 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 95.45 87.43 62.63 93.83 81.32 65.39 50.78 A 59.38 64.94 55.03 34.52 55.32 40.28 28.27 23.68 C 28.03 55.89 56.70 40.57 54.52 39.68 27.22 20.95 S 42.91 36.96 26.27 13.59 32.25 23.16 20.95 19.62 Table 10: EATA on PACS. EATA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.04 64.72 50.27 57.31 56.06 58.17 59.78 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.62 98.50 98.62 98.68 98.62 98.50 98.62 A 59.38 68.90 68.16 66.50 68.65 68.95 69.34 69.63 C 28.03 63.74 65.36 62.46 65.19 66.00 65.57 65.70 S 42.91 54.01 52.89 48.18 55.71 55.64 54.09 54.26 Table 11: CoTTA on PACS. CoTTA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 65.48 62.12 53.17 56.06 54.33 57.16 57.42 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.62 98.62 98.62 98.62 98.56 98.62 A 59.38 65.82 65.87 65.48 66.02 65.87 66.31 65.97 C 28.03 62.63 63.05 63.10 63.01 62.88 63.01 62.97 S 42.91 53.88 54.03 53.78 54.67 55.31 55.10 54.62 Table 12: SAR (steps=1) on PACS. SAR (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 66.75 63.82 49.58 56.78 56.35 56.68 56.70 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.50 98.32 98.74 98.56 98.50 98.44 A 59.38 68.02 68.07 66.94 67.87 68.65 68.55 68.16 C 28.03 62.84 64.97 62.93 63.82 64.89 64.46 64.38 S 42.91 53.47 52.07 45.74 54.92 55.46 53.68 52.53 Table 13: SAR (steps=10) on PACS. SAR (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 69.38 68.26 49.02 53.51 51.15 51.78 45.60 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.20 95.39 96.47 97.13 97.78 97.72 94.13 A 59.38 72.36 66.60 62.16 62.74 64.94 66.11 56.64 C 28.03 63.44 68.30 56.19 59.77 61.73 62.03 56.02 S 42.91 53.37 44.59 54.62 41.00 49.66 48.79 36.37 44Published as a conference paper at ICLR 2024 Table 14: SimATTA (B â‰¤300) on PACS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 76.86 70.90 75.39 69.47 76.49 82.45 82.22 Budgets N/A 75 145 223 66 142 203 267 P 99.70 98.44 98.86 98.80 97.96 98.68 99.04 98.98 A 59.38 80.71 82.32 84.47 73.97 80.52 81.10 84.91 C 28.03 48.12 82.00 82.25 72.35 81.06 83.36 83.92 S 42.91 32.78 56.25 81.52 79.49 83.10 84.78 86.00 Table 15: SimATTA (B â‰¤500) on PACS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 77.93 76.02 76.30 68.46 78.22 80.91 85.49 Budgets N/A 121 230 358 102 221 343 425 P 99.70 98.92 98.86 98.62 98.20 99.46 99.10 99.16 A 59.38 87.01 87.60 88.33 73.39 79.20 84.91 86.67 C 28.03 54.78 83.96 83.49 68.43 74.40 84.22 84.77 S 42.91 46.37 63.53 83.74 81.34 81.04 86.66 87.71 Table 16: Tent (steps=1) on VLCS. Tent (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 38.55 34.40 53.88 44.85 44.29 47.38 44.98 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.81 85.44 84.73 84.95 85.16 85.80 85.30 L 33.55 40.02 43.11 43.86 39.68 41.98 43.11 43.49 S 41.10 33.39 35.41 33.61 36.29 37.90 38.27 37.81 V 49.08 53.20 54.06 53.11 53.76 54.18 53.76 53.35 Table 17: Tent (steps=10) on VLCS. Tent (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 45.41 31.44 32.32 46.13 42.31 43.51 39.48 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 73.07 48.34 42.54 74.13 62.19 56.54 52.01 L 33.55 46.61 38.44 37.65 44.88 45.93 43.41 40.32 S 41.10 31.75 28.82 27.79 35.37 36.14 35.28 33.64 V 49.08 48.05 40.14 33.12 50.50 44.49 42.48 40.37 Table 18: EATA on VLCS. EATA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.24 33.15 52.58 43.77 42.48 43.34 41.55 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 85.16 85.02 84.10 84.73 84.52 84.10 83.32 L 33.55 37.16 37.24 37.69 37.09 36.78 36.90 36.67 S 41.10 33.39 33.49 32.39 33.33 32.54 31.84 31.47 V 49.08 51.87 52.16 52.49 52.07 52.43 52.64 52.55 45Published as a conference paper at ICLR 2024 Table 19: CoTTA on VLCS. CoTTA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.39 32.54 52.25 43.69 42.14 43.21 42.32 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 81.55 81.98 82.12 82.61 82.47 82.12 81.98 L 33.55 37.20 37.91 37.65 38.48 38.22 38.40 37.99 S 41.10 30.71 32.78 33.12 34.00 33.70 33.97 33.52 V 49.08 52.01 52.64 52.90 53.64 53.14 53.08 53.23 Table 20: SAR (steps=1) on VLCS. SAR (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 36.18 34.43 52.46 43.64 43.04 44.20 41.93 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.31 84.17 83.96 85.09 85.23 85.23 85.09 L 33.55 35.62 38.29 39.72 38.55 39.34 40.21 40.70 S 41.10 33.24 36.41 36.53 34.37 35.62 36.29 36.44 V 49.08 51.75 52.61 52.37 52.90 52.75 53.05 53.02 Table 21: SAR (steps=10) on VLCS. SAR (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 35.32 34.10 51.66 43.56 42.05 42.53 41.16 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 83.96 83.04 82.12 84.03 84.24 85.23 85.09 L 33.55 34.07 35.92 41.49 39.53 38.37 37.65 37.58 S 41.10 31.93 34.89 33.94 35.19 32.94 33.88 33.12 V 49.08 51.33 51.51 53.08 52.78 52.34 51.78 52.01 Table 22: SimATTA (B â‰¤300) on VLCS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 62.61 65.08 74.38 62.33 69.33 73.20 71.93 Budgets N/A 79 175 272 71 135 208 262 C 100.00 99.51 98.52 99.93 99.86 99.79 100.00 99.93 L 33.55 68.11 69.92 69.50 62.61 66.64 68.45 69.43 S 41.10 55.24 68.89 66.67 65.54 69.29 71.79 72.46 V 49.08 66.08 70.94 77.34 73.79 76.87 78.82 80.39 Table 23: SimATTA (B â‰¤500) on VLCS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 63.52 68.01 76.13 62.29 70.45 73.50 72.02 Budgets N/A 113 266 446 107 203 283 356 C 100.00 99.29 98.59 99.51 99.93 99.86 99.86 99.43 L 33.55 62.95 70.63 70.56 66.57 67.09 67.24 70.29 S 41.10 51.31 73.83 73.10 65.33 71.79 72.91 72.55 V 49.08 59.36 71.65 78.35 73.58 77.84 80.01 80.18 46Published as a conference paper at ICLR 2024 Table 24: Tent (steps=1) on Office-Home. Tent (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.31 63.87 49.95 50.27 50.23 52.06 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.33 92.36 92.47 92.38 92.45 92.45 92.40 A 57.07 49.73 49.73 49.57 49.69 49.73 49.57 49.24 C 44.97 39.27 39.54 39.89 39.45 39.68 39.73 39.68 P 73.15 63.60 63.66 63.89 63.60 63.82 63.93 63.98 Table 25: Tent (steps=10) on Office-Home. Tent (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.04 61.41 50.05 49.31 48.74 47.79 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 91.99 89.14 87.08 92.08 90.80 88.59 85.31 A 57.07 49.94 46.77 44.79 49.44 48.21 45.69 42.85 C 44.97 38.58 39.11 38.37 40.18 40.02 38.63 37.89 P 73.15 63.28 61.03 60.49 64.36 63.64 61.12 58.71 Table 26: EATA on Office-Home. EATA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.04 63.53 49.73 50.27 49.45 51.07 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.36 92.17 91.60 92.38 92.22 91.71 91.05 A 57.07 49.57 49.53 49.61 49.69 49.40 49.36 49.11 C 44.97 39.08 39.01 38.65 39.27 39.01 38.42 38.26 P 73.15 63.42 63.42 63.48 63.51 63.37 63.33 62.99 Table 27: CoTTA on Office-Home. CoTTA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 38.76 61.84 49.84 49.84 48.95 50.43 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 90.38 88.02 87.81 90.48 89.37 88.00 86.99 A 57.07 48.58 45.53 44.95 47.34 46.35 44.62 43.68 C 44.97 36.66 35.58 35.92 37.55 36.40 35.44 34.73 P 73.15 60.40 57.74 59.04 61.12 59.63 58.35 57.56 Table 28: SAR (steps=1) on Office-Home. SAR (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.24 63.53 49.84 50.05 49.91 51.67 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.38 92.31 92.45 92.40 92.36 92.36 92.38 A 57.07 49.65 49.57 49.73 49.69 49.61 49.57 49.57 C 44.97 39.34 39.22 39.36 39.34 39.56 39.47 39.50 P 73.15 63.51 63.51 63.69 63.60 63.71 63.71 63.87 47Published as a conference paper at ICLR 2024 Table 29: SAR (steps=10) on Office-Home. SAR (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.53 38.81 61.50 50.09 50.30 49.77 49.22 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.20 92.06 88.94 92.40 92.47 91.53 89.14 A 57.07 49.40 49.77 46.15 49.81 50.02 48.91 46.23 C 44.97 39.20 38.63 37.04 39.50 39.29 38.65 36.31 P 73.15 63.53 62.69 59.41 64.18 64.18 62.83 59.45 Table 30: SimATTA (B â‰¤300) on Office-Home. SimATTA (B â‰¤300) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 56.20 48.38 71.66 58.57 60.88 62.91 63.67 Budgets N/A 75 187 277 79 147 216 278 R 96.44 95.43 95.43 95.75 95.91 95.96 96.01 95.89 A 57.07 57.56 59.50 60.07 58.34 59.91 61.15 62.01 C 44.97 42.25 52.46 52.62 51.66 52.30 54.75 54.98 P 73.15 68.84 70.13 74.70 72.45 73.10 74.50 74.70 Table 31: SimATTA (B â‰¤500) on Office-Home. SimATTA (B â‰¤500) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 58.71 51.11 74.36 58.85 62.63 63.41 64.31 Budgets N/A 107 284 440 126 248 361 467 R 96.44 95.69 95.71 96.03 96.26 96.19 95.87 95.91 A 57.07 61.43 61.43 62.05 58.18 61.15 61.52 63.78 C 44.97 46.41 57.73 57.41 53.17 55.14 56.79 57.87 P 73.15 70.74 71.98 76.98 73.51 74.18 75.78 77.09 48Published as a conference paper at ICLR 2024 in deep learning heavily relies on large-scale data. Consequently, two promising paths emerge: establishing credible assumptions and leveraging additional information. Firstly, developing credible assumptions can lead to comprehensive comparisons across various stud- ies. Given that theoretical guarantees highlight the inherent differences between methods primarily based on the application limits of their assumptions, comparing these assumptions becomes critical. Without such comparative studies, empirical evaluations may lack precise guidance and explanation. Secondly, while we acknowledge the value of real-world data (observations), discussions surrounding the use of extra information remain pertinent. Considerations include the strategies to acquire this supplementary information and the nature of the additional data needed. Despite the myriad of works on domain generalization, domain adaptation, and test-time adaptation, a comprehensive survey or benchmark encapsulating the aforementioned comparisons remains an unmet need. Moreover, potential future directions for out-of-distribution generalization extend beyond domain generalization and test-time adaptation. One promising avenue is bridging the gap between causal inference and deep learning, for instance, through causal representation learning. In conclusion, our hope is that this work not only offers a novel practical setting and algorithm but also illuminates meaningful future directions and research methodologies that can benefit the broader scientific community. 49",
      "meta_data": {
        "arxiv_id": "2404.05094v1",
        "authors": [
          "Shurui Gui",
          "Xiner Li",
          "Shuiwang Ji"
        ],
        "published_date": "2024-04-07T22:31:34Z",
        "pdf_url": "https://arxiv.org/pdf/2404.05094v1.pdf"
      }
    },
    {
      "title": "Test Time Adaptation via Conjugate Pseudo-labels",
      "abstract": "Test-time adaptation (TTA) refers to adapting neural networks to distribution\nshifts, with access to only the unlabeled test samples from the new domain at\ntest-time. Prior TTA methods optimize over unsupervised objectives such as the\nentropy of model predictions in TENT [Wang et al., 2021], but it is unclear\nwhat exactly makes a good TTA loss. In this paper, we start by presenting a\nsurprising phenomenon: if we attempt to meta-learn the best possible TTA loss\nover a wide class of functions, then we recover a function that is remarkably\nsimilar to (a temperature-scaled version of) the softmax-entropy employed by\nTENT. This only holds, however, if the classifier we are adapting is trained\nvia cross-entropy; if trained via squared loss, a different best TTA loss\nemerges. To explain this phenomenon, we analyze TTA through the lens of the\ntraining losses's convex conjugate. We show that under natural conditions, this\n(unsupervised) conjugate function can be viewed as a good local approximation\nto the original supervised loss and indeed, it recovers the best losses found\nby meta-learning. This leads to a generic recipe that can be used to find a\ngood TTA loss for any given supervised training loss function of a general\nclass. Empirically, our approach consistently dominates other baselines over a\nwide range of benchmarks. Our approach is particularly of interest when applied\nto classifiers trained with novel loss functions, e.g., the recently-proposed\nPolyLoss, where it differs substantially from (and outperforms) an\nentropy-based loss. Further, we show that our approach can also be interpreted\nas a kind of self-training using a very specific soft label, which we refer to\nas the conjugate pseudolabel. Overall, our method provides a broad framework\nfor better understanding and improving test-time adaptation. Code is available\nat https://github.com/locuslab/tta_conjugate.",
      "full_text": "Test-Time Adaptation via Conjugate Pseudo-labels Sachin Goyalâ‹†1 Mingjie Sunâ‹†1 Aditi Raghunathan1 Zico Kolter1,2 1Carnegie Mellon University, 2Bosch Center for AI {sachingo, mingjies, raditi, zkolter}@cs.cmu.edu Abstract Test-time adaptation (TTA) refers to adapting neural networks to distribution shifts, with access to only the unlabeled test samples from the new domain at test-time. Prior TTA methods optimize over unsupervised objectives such as the entropy of model predictions in TENT [50], but it is unclear what exactly makes a good TTA loss. In this paper, we start by presenting a surprising phenomenon: if we attempt to meta-learn the â€œbestâ€ possible TTA loss over a wide class of functions, then we recover a function that isremarkably similar to (a temperature-scaled version of) the softmax-entropy employed by TENT. This only holds, however, if the classiï¬er we are adapting is trained via cross-entropy loss; if the classiï¬er is trained via squared loss, a different â€œbestâ€ TTA loss emerges. To explain this phenomenon, we analyze test-time adaptation through the lens of the training lossesâ€™sconvex conjugate. We show that under natural conditions, this (unsupervised) conjugate function can be viewed as a good local approximation to the original supervised loss and indeed, it recovers the â€œbestâ€ losses found by meta-learning. This leads to a generic recipe that can be used to ï¬nd a good TTA loss for any given supervised training loss function of a general class. Empirically, our approach consistently dominates other TTA alternatives over a wide range of domain adaptation benchmarks. Our approach is particularly of interest when applied to classiï¬ers trained with novel loss functions, e.g., the recently-proposed PolyLoss [25] function, where it differs substantially from (and outperforms) an entropy-based loss. Further, we show that our conjugate based approach can also be interpreted as a kind of self-training using a very speciï¬c soft label, which we refer to as the conjugate pseudo-label. Overall, our method provides a broad framework for better understanding and improving test-time adaptation. Code is available at https://github.com/locuslab/ tta_conjugate. 1 Introduction Modern deep networks perform exceeding well on new test inputs that are close to the training distribution. However, this performance dramatically decreases on test inputs drawn from a different distribution. While there is a large body of work on improving the robustness of models, most robust training methods are highly specialized to the setting they cater to. For e.g., they assume pre-speciï¬ed perturbations, subpopulations, and spurious correlations, or access to unlabeled data from the target distribution, and most methods offer close to no improvement on general distribution shifts beyond what they were trained for [12, 21]. In practice, it is often cumbersome (or even impossible) to precisely characterize all possible distri- bution shifts a model could encounter and then train accordingly. Instead, a model already trained on some source data must be able to adapt at test-time to new inputs from a different domain. This setting of test-time adaptation (TTA) has gained interest in recent years [ 6, 47, 50, 54]. TTA is typically accomplished by updating the source model parameters via a few steps of optimization on an unsupervised objective involving the new test sample from the target distribution. The choice â‹† Equal Contribution 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv:2207.09640v2  [cs.LG]  23 Nov 2022of this unsupervised objective, which we call the TTA loss, dictates the success of the adaptation procedure. [47] uses a self-supervised objective on the test sample, [50] uses the entropy of model predictions, and several follow-ups have proposed variants or alternatives [ 40, 54]. However, it remains unclear as to how to choose or guide the selection of this TTA loss, and thus far the choice of these losses has remained largely heuristic in nature. In this work, we begin by presenting a set of intriguing experiments where we attempt to learn the â€œbestâ€ TTA loss for a given source classiï¬er and distribution shift. We parameterize the TTA loss by another neural network whose parameters are learnt via meta-learning [ 3, 9] where we differentiate through the adaptation process to ï¬nd the TTA loss that achieves the best adaptation on distribution shifts. Surprisingly, we ultimately learn a TTA loss that looksremarkably similar to (a temperature-scaled version of) the softmax-entropy loss, which was already proposed by [50]. Why did we recover the commonly used softmax-entropy loss despite the fact that the procedure is capable of learning a very general class of losses and the meta-learning process could potentially specialize to both the source classiï¬er and the distribution shift of interest? Furthermore, we ï¬nd that this pattern only holds when the loss used to train the source classiï¬er is cross-entropy loss; when a different loss such as squared loss is used instead, the meta-learning procedure recovers a TTA loss that itself looks more like a negative squared error, and is very different from the softmax-entropy loss (Section 3). In order to explain this phenomenon, we propose to consider TTA through the lens of the convex conjugate function. Speciï¬cally, given a hypothesis function h(x) and label y, several common losses (cross-entropy and the squared loss amongst them, but not limited to these) can be written in the form L(h(x),y) = f(h(x)) âˆ’yTh(x) for some function f. In these cases, we show that â€œnaturalâ€ TTA loss for such classiï¬ers is precisely the (negation of) the convex conjugate evaluated at the gradient of h, LTTA(x) = âˆ’fâˆ—(âˆ‡f(h(x)), where fâˆ—is the convex conjugate of f. This framework not only recovers the results of our meta-learning experiments, but also justiï¬es why some speciï¬c choices of TTA loss in the previous literature work well (e.g., this framework recovers TENTâ€™s choice of softmax-entropy for cross-entropy-trained classiï¬er). Moreover, it also provides a broad framework for what the TTA loss should be when the source model is trained using various different loss functions (for example the recently-proposed PolyLoss [25, 29]) as is becoming increasingly common in machine learning. Further, we show that our proposed conjugate adaptation loss is in fact a kind of self-training with pseudo-labels [42], a classic approach in machine learning. Various formulations of the pseudo-label have been proposed in the literature, and our conjugate analysis provides a general recipe for the â€œcorrectâ€ choice of soft pseudo-labels given byË†y(x) = âˆ‡f(h(x)). We thus refer to these as conjugate pseudo-labels (Conjugate PLâ€™s), and believe our work provides a broad framework for understanding adaptation with unlabeled data in general. Finally, we empirically verify the effectiveness of our proposed conjugate adaptation loss across several datasets and training losses, such as cross-entropy and squared loss, along with the recently- proposed PolyLoss [ 25] (which itself has shown higher standard test accuracy on a wide range of vision tasks). Over all models, datasets and training losses, we ï¬nd our proposed conjugate pseudo-labeling consistently outperforms prior TTA losses and improves TTA performance over the current state of the art. 2 Background and preliminaries. Test-time adaptation. We are interested in mapping an input xâˆˆRd to a label yâˆˆY. We learn a model hÎ¸ : Rd â†¦â†’R|Y|parameterized by Î¸that maps an input xto predictions hÎ¸(x). We assume access to a trained source model and adapt at test-time over the test input, before making the ï¬nal prediction. This is the standard test-time adaptation (TTA) setting [47, 50]. During TTA, we update the model parameters on an unsupervised objective L(x,hÎ¸). For example, in TENT [50], this loss is the entropy of the softmax-normalized predictions of the model. At each time step of adaptation, we observe a batch of test inputs and we take a gradient step towards optimizing the TTA loss on this test batch. As is standard, we measure the average online performance of models across all steps (number of test batch inputs seen) in the adaptation process. Meta learning the loss function. In order to explore the existence of different TTA losses, we employ the meta-learning procedure where we attempt to learn the TTA loss. We use a similar procedure as prior work on meta-learning loss functions [3, 37] and parameterize the loss function via a neural network mÏ† : R|Y| â†¦â†’R that takes in the model predictions/logits and outputs a loss value. We want to learn parameter Ï†such that when we update Î¸via the loss function mÏ†, our ï¬nal 2performance is optimal. In order to do so, let xbe the unlabeled test samples to adapt to, and ybe the corresponding labels. We update Î¸and Ï†alternatively as follows. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t , Ï†t+1 â†Ï†t âˆ’Î²âˆ‚L(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , (1) where Lis some supervised surrogate loss function such as cross-entropy. Please refer to Appendix A3 for further details regarding meta-learning setup. Note that the meta-learning process above assumes access to labels yof test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We discuss our ï¬ndings from this exploration in the next section. 3 Test-time Adaptation via Meta-Learnt Losses The objective used in TENT is the softmax-entropy of the model predictions which essentially makes the classiï¬er more conï¬dent in its current predictions. The same can be achieved by various other loss formulations such as those mentioned in [40]. With so many possible choices for the loss function, what should we use for TTA? In this section, we attempt to answer this empirically and present some intriguing observations. (a)  (b) Figure 1: Visualization of meta loss (blue) by varying one input prediction score. (a) For cross-entropy loss trained model, the learnt meta loss can be approximated with a scaled softmax-entropy function (dashed red). (b) When the source model is trained with a squared loss for classiï¬cation, the learnt meta loss (blue) can be ï¬tted closely with a quadratic function (dashed red), shown in Figure 1b. The range (max/min) of the prediction score (logit) in x-axis is chosen to cover the empirical range of the predicted logits. Experiment 1. We learn the TTA loss parameterized by a neural network via meta-learning as described in Section 2. Our source classiï¬er is a ResNet-26 trained on CIFAR-10 and we adapt to distribution shifts in CIFAR-10-C. We use the 4 labeled validation noises in CIFAR-10-C to learn the meta-loss network parameters and we denote the resulting learnt loss function by meta-TTA loss. We then adapt the source classiï¬er to the test set of 15 corruptions by optimizing the meta-TTA loss. Observations. First, we ï¬nd that TTA using meta-TTA loss performs better than TENT (12.35% vs 13.14%), suggesting that there are better TTA losses than previous losses based on softmax-entropy. However, on examining this meta-TTA loss, we ï¬nd a surprising observation. Figure 1a (blue curve) visualizes the learnt meta-loss over model predictions as we vary a single class prediction with the rest ï¬xed. Qualitatively, the learnt meta-loss looks very similar to softmax-entropy in one dimension. In fact, we can ï¬t it closely with a scaled softmax-entropy function (dashed red curve): Î±Â·H(softmax(hÎ¸(x)/T)), where Î±is a magnitude parameter and T is a temperature scaler. We want to test if the meta-loss is basically learning the softmax-entropy function. Hence, we perform test-time adaptation with the ï¬tted softmax-entropy function instead (dashed red curve) and achieve an error of 12.32%, essentially recovering the performance of meta-TTA. 3Despite the ability to represent many different loss functions and potentially specialize to the CIFAR- 10-C setting, the meta-loss procedure gave back the standard entropy objective.Do we always recover a loss that looks like softmax-entropy? Experiment 2. In an attempt to isolate when we get back the entropy objective, we vary several things. We tried different architectures for the source classiï¬er, different lossesLduring the meta- learning process (1) and different training losses for the source classiï¬er. Results. We observed that we consistently recovered the temperature scaled softmax-entropy function in all cases except when we varied the training loss for the source classiï¬er (Appendix A.10). On using the squared loss function [18], a strikingly different meta-TTA loss emerges. Figure 1b (blue curve) shows the learnt meta-loss (13.48% error) for this network. Here again, the meta-TTA loss outperforms entropy (14.57%) but it is not simply due to a scaling factor. The loss now looks like the negative squared error (red curve). Like previously, we tried ï¬tting a quadratic loss directly to the meta loss in Figure 1b, and this time we even slightly outperformed the meta-TTA loss. To summarize, we used a meta-learning procedure to search for the â€œbestâ€ TTA loss, where the loss itself was parameterized by a neural network that could potentially represent arbitrarily complex loss functions. However, we ended up with loss functions displaying remarkable structure: across different architectures and different variants of meta-learning, for a classiï¬er trained with cross-entropy, the meta-TTA loss was temperature scaled softmax-entropy and for a classiï¬er trained with squared loss, the meta-TTA loss was a negative squared loss. This is interesting from both a practical and conceptual standpoint where the â€œbestâ€ TTA loss depends on the loss used to train the source classiï¬er in a clean fashion. We attempt to understand and explain this phenomenon in the next section. 4 Conjugate Pseudo Labels Results in the previous section raise an obvious question: why does softmax-entropy as used in TENT seem to be the â€œbestâ€ possible test time adaptation loss for classiï¬ers trained via cross-entropy (at least, best in the sense that meta-learning consistently recovers something which essentially mimics softmax-entropy, even though meta-loss is parameterized by a neural network and hence could learn much more complex functions speciï¬c to the model and the particular shift)? And why, alternatively, does a quadratic TTA loss seem to perform best when the classiï¬er is trained via squared loss? In this section, we offer an explanation of this phenomenon via the construct of the convex conjugate function [1]. As we will see, our method recovers softmax-entropy and quadratic loss as the â€œnaturalâ€ objectives for classiï¬ers trained via cross-entropy and squared loss respectively. Furthermore, for classiï¬ers trained via other loss functions, as is becoming increasingly common in deep learning, our approach naturally suggests corresponding test-time adaptation losses, which we show in the next section to comparatively outperform alternatives. Thus, we argue that our framework overall provides a compelling recipe for specifying the â€œcorrectâ€ method for TTA for a large class of possible losses. 4.1 Losses and the convex conjugate We begin by formally considering loss functions between a hypothesis outputhÎ¸(x) (e.g., the logit outputs of a classiï¬er, or the direct prediction of a regressor) and targetythat take the following form L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yThÎ¸(x) (2) for some function f; when there is no risk of confusion, we will use hin place of hÎ¸(x) for simplicity of notation. While not every loss can be expressed in such a form, this captures a wide variety of common losses (possibly scaled by a constant value). For example, cross-entropy loss corresponds to the choice f(h) = log âˆ‘ iexp(hi) and where y denotes a one-hot encoding of the class label; similarly, squared loss corresponds to the choice f(h) = 1 2 âˆ¥hâˆ¥2 2. When training an over-parameterized classiï¬er, we can roughly view the training process as (approxi- mately) attaining the minimum over hypotheses hfor each training example min Î¸ 1 t tâˆ‘ i=1 L(hÎ¸(xi),yi) â‰ˆ1 t tâˆ‘ i=1 min h L(h,yi) (3) 4where t is the number of training samples. However, in the case of losses in the form (2), the minimization over hin this form represents a very speciï¬c and well-known optimization problem: it is known as the convex conjugate [1] of the function f min h L(h,y) = min h {f(h) âˆ’yTh}= âˆ’fâ‹†(y) (4) where fâ‹† denotes the convex conjugate of f. fâ‹† is a convex function in y(and indeed, is convex regardless of whether or not f is convex). Furthermore, for the case that f is convex differentiable, the optimality condition of this minimization problem is given by âˆ‡f(hopt) = y, so we also have that fâ‹†(y) = fâ‹†(âˆ‡f(hopt)) (5) where hopt refers to the optimal classiï¬er (used interchangeably with hÎ¸opt ). Putting this all together, we can state (admittedly, in a rather informal manner) that under the assumption that Î¸opt is chosen so as to approximately minimize the empirical loss on the source data in the over-parameterized setting, we have that for tinputs 1 t tâˆ‘ i=1 L(hÎ¸opt (xi),yi) â‰ˆ1 t tâˆ‘ i=1 âˆ’fâ‹†(âˆ‡f(hÎ¸opt (xi))) (6) i.e., the empirical loss can be approximated by the (negative) conjugate applied to the gradient of the f, at least in a region close to the optimal Î¸opt that minimizes the empirical loss. But the later expression has the notable beneï¬t that it does not require any label yi in order to compute the loss, and thus can be used as a basis for TTA on target domain of the hypothesis function hÎ¸opt . Deï¬nition 1 (conjugate adaptation loss) Consider a loss function that takes the form given in 2, used for training a hypothesis hÎ¸ in the over-parameterized regime. We deï¬ne the conjugate adaptation loss Lconj(hÎ¸(x)) : R|Y|â†¦â†’R as follows. Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))âŠ¤hÎ¸(x). (7) 4.2 Recovery of existing test-time adaptation strategies Cross-entropy The interesting aspect to this formalism is that when applied to classiï¬ers trained with cross-entropy, it recovers exactly the TENT approach to TTA : minimizing the softmax-entropy of hÎ¸(x). And indeed, this loss was also recovered when using meta-learning to learn the â€œoptimalâ€ test-time adaptation loss. To see this, note that for cross-entropy, we have thatf(h) = log âˆ‘ iexp(hi), giving the optimality condition y= âˆ‡f(hopt) = exp(hopt)âˆ‘ iexp(hopt i ) and the conjugate function fâ‹†(y) = { âˆ‘ iyilog yi if âˆ‘ iyi = 1 âˆž otherwise . (8) In other words, Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (9) i.e. softmax-entropy of the model prediction, which is exactly the TTA loss that TENT uses. Squared loss For the squared loss, we have thatf(h) = 1 2 âˆ¥hâˆ¥2 2, leading to the optimality condition y = hand conjugate function fâ‹†(y) = 1 2 âˆ¥yâˆ¥2 2. Hence, the adaptation loss in this case would be simply given by Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’1 2 âˆ¥hâˆ¥2 2 which is also what we observed in the meta-learning experiments discussed in Section 3. 4.3 Conjugate pseudo-labels We now emphasize that by the nature of our approximations, there is an additional simple interpre- tation of the conjugate loss: it is also equal to the original loss (2) applied to the â€œpsuedo-labelsâ€ ËœyCPL Î¸ (x) = âˆ‡f(hÎ¸(x)), where CPL refers to conjugate pseudo-labels, i.e., Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))ThÎ¸(x) = L(hÎ¸(x),âˆ‡f(hÎ¸(x))). (10) 5This property is known as the Fenchel-Young inequality, that isf(x) + fâ‹†(u) â‰¥xTuholding with equality when u = âˆ‡f(x). In other words, our conjugate adaptation loss is precisely equivalent to self-training under the speciï¬c soft pseudo-labels given by ËœyCPL = âˆ‡f(hÎ¸(x)). And indeed, for many cases, this may be a more convenient form to compute than explicitly computing the conjugate function at all. For this reason, we refer to our method as that of conjugate pseudo-labels. In the case of cross-entropy loss, this approach then corresponds exactly to self-training using labels given by the softmax applied to the current hypothesis. We must emphasize, however, that while our conjugate formulation indeed has this â€œsimpleâ€ form for the case of cross-entropy loss, the real advantage comes in that it provides the â€œcorrectâ€pseudo-label for use with other losses, which may result in pseudo-labels different from the â€œcommonâ€ softmax operation. Example: conjugate pseudo-labels for PolyLoss. PolyLoss [25] is a recently-proposed simple alternative to cross-entropy loss than has been shown to improve performance across a wide variety of compute tasks. This loss is given by the form Lpoly(hÎ¸(x),y) = Lce(hÎ¸(x),y) + ÏµÂ·yT(1 âˆ’softmax(hÎ¸(x))) (11) We note that this can be put exactly into our conjugate form (equation 2) by writing the loss in a slightly more involved fashion, which we refer to as the expanded conjugate form Lpoly(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yTg(hÎ¸(x)). (12) where f is the log-sum-exp function as before, and g(h) = hâˆ’Ïµ(1 âˆ’softmax(h)). In order to formally put this into the form of the previous loss function (equation 2), we can simply deï¬ne an alternative hypothesis as the function hâ€² Î¸(x) = g(hÎ¸(x)), and then deï¬ne PolyLoss in the conjugate form as Lpoly(hâ€² Î¸(x),y) = f(gâˆ’1(hâ€² Î¸(x))) âˆ’yThâ€² Î¸(x). (13) Typically, however, it is easier to simply operate on the expanded conjugate form, which yields the optimality condition for the pseudo-label âˆ‡f(hopt) = Dg(hopt)ËœyCPL Î¸ (x), where D is the Jacobian operator. For the case of PolyLoss, this leads to the conjugate pseudo-label of the following form: ËœyCPL Î¸ (x) = (I+ Ïµdiag(z) âˆ’ÏµzzT)âˆ’1z, z â‰¡softmax(hÎ¸(x)). Test-time adaptation. Finally, we note that the above discussion doesnâ€™t actually address any topics related to test-time adaptation to OOD data, but merely provides a generic characterization of a self- training procedure for generic loss functions of the form(2). However, the application toTTA on OOD data is fairly straightforward: as long as the learnt source parameters Î¸is a reasonable approximation to the true optimal Î¸opt on the shifted domain, self-training with the conjugate pseudo-labels provides a reasonable proxy for ï¬ne-tuning the network on the true OOD loss. We emphasize that, common to most approaches for TTA , there are still some amount of design decisions that must be put in place; these are detailed in Section 5.1. In practice, we observe OOD generalization typically beneï¬ts (across all baselines) from an additional â€œtemperatureâ€ scaling, i.e., applying the TTA loss to hÎ¸(x)/T for some ï¬xed temperature T, although it requires a held-out validation dataset for tuningT. However, we should emphasize that truly unsupervisedTTA would require making an informed guess for the value of these hyper-parameters. The full procedure for test time adaptation via conjugate pseudo-labels is shown in Algorithm 1. Algorithm 1 Conjugate pseudo-labeling (Conjugate PL) Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’hÎ¸(x)âŠ¤y. N batches of test data Dtest = [x1,x2,...,x N] Hyperparams: learning rate Î·and temperature T. Let Â¯hÎ¸(x) def = hÎ¸(x)/T be the temperature scaled predictor. Let ËœyCPL Î¸ (x) denote the conjugate pseudo-label function ËœyCPL Î¸ (x) = âˆ‡(f(Â¯hÎ¸(x))). for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡L ( Â¯hÎ¸(xn),ËœyCPL Î¸ (xn) ) [Self-training with conjugate pseudo-labels] 65 Experiments In this section, we empirically evaluate the effectiveness and generality of the proposed conjugate pseudo-labeling procedure (Algorithm 1) for test-time adaptation on a variety of datasets. 5.1 Setup Datasets. We evaluate on the three common corruption benchmarks: adapting a classiï¬er trained on CIFAR-10 to CIFAR-10-C, CIFAR-100 to CIFAR-100-C and ImageNet to ImageNet-C [ 15]. Following the previous works [47, 50], we report the error averaged across corruptions at the highest severity for CIFAR-10/100-C and averaged across corruptions and severity level for ImageNet-C. We also evaluate on three domain adaptation datasets: adapting a classiï¬er trained on SVHN to MNIST, an ImageNet classiï¬er to ImageNet-R [16] and adapting from synthetic to real data in VISDA-C [38]. Models and Training losses. Following previous works on TTA[47, 50], we use ResNet-26 [14] as the source classiï¬er architecture for CIFAR-10/100 experiments, ResNet-18 for SVHN to MNIST and a ResNet-50 for ImageNet and source synthetic data on VisDA-C. We consider source classiï¬ers trained via the following loss functions: the de-facto cross-entropy, recently proposed polyloss [25] and squared loss [18]. Baselines. Our proposed conjugate pseudo-label is the classic approach of self-training with a speciï¬c form of pseudo-labels. In self-training, we replace the label ywith a pseudo-label Ëœy(x) and adapt by optimizing the loss function L(hÎ¸(x),Ëœy(x)). Note that we could either instantaneously update the pseudo-labels using the current classiï¬er, or generate pseudo-labels once with just the source classiï¬er. Instantaneous updates have been shown to work better for domain adaptation [7, 40], and we perform instantaneous updates for all methods. While we propose using ËœyCPL(x) = âˆ‡f(hÎ¸(x)) (See Section 4.3), we compare to the standard pseudo-labels used in the literature: â€¢ (i) the â€œhardâ€ pseudo-label (hard PL) where Ëœy(x) = arg maxi ( hÎ¸(x) ) i is the most likely class as predicted by hÎ¸. As is common in the self-training literature, we perform conï¬dence thresholding. â€¢ (ii) The â€œsoftâ€ pseudo-label (soft PL) where Ëœy(x) is obtained by applying a softmax function to the model predictions hÎ¸(x). We also compare with the following recently proposed test-time adaptation methods. â€¢ Entropy Minimization (ENT) [50] minimizes the entropy of model predictions. â€¢ Robust Pseudo-Label [40] where we minimize a robust classiï¬cation loss, Lrpl = qâˆ’1(1 âˆ’p(i|x)q) where i= argmaxjp(j|x) and qâˆˆ[0,1]. â€¢ MEMO [54] minimizes entropy of a modelâ€™s outputs across different augmentations of a test input. We implement a batch version, where we see multiple test points at once, for fair comparisons. TTA methodology. Following [ 50] and [40], we ï¬ne-tune by updating the learnable scale and shift parameters of the batch normalization layers across all adaptation losses. For each batch, batch normalization statistics is also updated, as suggested in [41]. We report performance at the end of one round of test-time adaptation over the entire test set. We tune the learning rate (LR) and temperature (T) on the validation noises in the corruption benchmark by grid-search. LR is selected from {1eâˆ’1,1eâˆ’2,... 1eâˆ’4}and T from {1,2 ... 5}. All the experiments have been performed on A6000 GPUâ€™s. On domain adaptation benchmarks, where there is no held-out target domain, we set T to be 1 and use the LR suggested by [ 6, 50]. We use the same hyperparameter tuning protocol across all methods. We single out temperature as a very important hyperparameter, as we discuss in the results below. 5.2 Results on classiï¬ers trained with cross-entropy We study the effectiveness of our proposed conjugate pseudo-labels when the source classiï¬er is trained via cross-entropy loss. In this case, baselines Softmax PL and ENT are the same as Conjugate PL. Thus we omit them in our results. Table 1, reports the performance of various TTA methods. When the source classiï¬er is trained via cross-entropy, our conjugate pseudo-label algorithm exactly corresponds to entropy minimization with an additional temperature scaling. Entropy minimization as 7Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 13.95 (Â±0.06) 13.97 ( Â±0.04) 12.60(Â±0.04) 13.07 (Â±0.05) \u0013 13.95 (Â±0.06) 12.85 ( Â±0.04) 12.51(Â±0.01) 12.51(Â±0.03) CIFAR-100-C \u0017 45.22 (Â±0.4) 39.80 ( Â±0.18) 38.52(Â±0.16) 41.15 (Â±0.25) \u0013 45.22 (Â±0.4) 36.37 ( Â±0.10) 37.38 ( Â±0.06) 36.10(Â±0.07) ImageNet-C \u0017 45.43(Â±0.05) 45.68 ( Â±0.01) 48.91( Â±0.03) 45.82(Â±0.01) \u0013 45.43 (Â±0.05) 45.61 ( Â±0.01) 48.91( Â±0.04) 45.36(Â±0.01) Table 1: Mean errors when adapting to corruptions using a source classiï¬er trained via cross- entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. With the right temperature scaling, softmax-entropy minimization matches or outperforms other approaches. Prior reported gains of other methods over softmax-entropy minimization disappear when we use temperature scaling. For additional context, the source classiï¬er errors without adaptation are: CIFAR-10-C (29.54%), CIFAR-100-C (62.26%), ImageNet-C (61.89%) proposed in prior work [50] does not tune the temperature parameter, and some newer objectives such as robust PL or MEMO outperform vanilla entropy minimization. For example, on CIFAR-100-C, vanilla ENT obtaines 41.15% average error, while robust PL improves this to39.80% and MEMO to 38.52%. However, with the right temperature scaling, entropy minimization obtains 36.10% error which outperforms the newer objectives (with and without temperature scaling). A similar observation holds for CIFAR-10-C and ImageNet-C as well. Essentially, the gains over vanilla entropy minimization vanish when we do temperature scaling, and entropy minimization (i.e. conjugate pseudo-labeling corresponding to cross-entropy) turns out to be the best objective after all. 5.3 Results on classiï¬ers trained with polyloss and squared loss In the case of cross-entropy, conjugate pseudo-labeling reduces to the familiar notion of entropy minimization. We now explore the performance of our method on different loss functions where the conjugate pseudo-labels differ substantially from entropy minimization (section 4.3). Table 2 presents the results on the corruption benchmarks and Table 3 presents the results on the other domain adaptation datasets for source classiï¬ers trained with PolyLoss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C \u0017 13.81(Â±0.12) 14.23(Â±0.02) 13.46(Â±0.06) 13.23(Â±0.07) 14.64(Â±0.11) 13.02(Â±0.09) \u0013 13.81(Â±0.12) 12.45(Â±0.05) 12.23(Â±0.06) 12.33(Â±0.04) 12.26(Â±0.04) 12.08(Â±0.05) CIFAR-100-C\u0017 40.47(Â±0.05) 42.86(Â±0.11) 40.12(Â±0.08) 39.90(Â±0.05) 41.00(Â±0.11) 38.17(Â±0.17) \u0013 40.47(Â±0.05) 39.80(Â±0.08) 38.23(Â±0.05) 39.23(Â±0.04) 37.04(Â±0.06) 36.83(Â±0.08) ImageNet-C \u0017 45.44(Â±0.21) 46.27(Â±0.03) 46.10(Â±0.03) 48.21(Â±0.05) 44.63(Â±0.03) 44.01(Â±0.01) \u0013 45.44(Â±0.21) 46.27(Â±0.03) 45.50(Â±0.02) 48.21(Â±0.04) 44.45(Â±0.03) 44.01(Â±0.01) Table 2: Mean errors when adapting to corruptions using a source classiï¬er trained via recently proposed Poly-1 Loss [ 25]. Conjugate pseudo-labeling consistently outperforms all previous ap- proaches. For additional context, source classiï¬er errors without adaptation : CIFAR-10-C (30.22%), CIFAR-100-C (63.91%) and ImageNet-C (62.18%). First, we note that, across all datasets in Table 2 and Table 3, our conjugate PL approach outperforms all other TTA losses. With polyloss classiï¬ers, entropy minimization is no longer the best methodâ€”on CIFAR-100-C, entropy minimization achieves38.23% error while our conjugate PL achieves36.83%. We see similar consistent gains on CIFAR-10-C, ImageNet-C, ImageNet-R and VisDA-C. On digit adaptation tasks from SVHN to MNIST/USPS/MNISTM, where there is a larger shift between source and target, the gains are especially pronounced. Figure 2 compares how the task loss (polyloss Ïµ= 6) on the test data decreases as we adapt the model through conjugate PL and other baselines. We use CIFAR-10-C as an example. Observe that our proposed conjugate PL indeed reduces the task loss the most among other baselines. 8Dataset Source Error Hard PL Robust PL EntropySoftmax PL Conjugate PL Ours SVHNâ†’MNIST 28.33 20.21 19.73 14.28 16.54 10.73 SVHNâ†’USPS 31.58 23.32 26.12 23.12 24.07 21.62 SVHNâ†’MNISTM61.69 50.73 51.35 49.33 50.47 47.59 ImageNet-R 64.19 58.52 59.46 58.25 56.62 55.63 VisDA-C 58.13 40.43 45.44 44.11 39.63 38.42 Table 3: Target error when adapting models trained via polyloss on source domains across different domain adaptation bench- marks. Conjugate pseudo-labeling offers consistent and substan- tial gains over previous approaches across three datasets. Figure 2: Task Loss (PolyLoss Ïµ= 6) evaluated on CIFAR-10-C test data during test-time adaptation. Furthermore, on CIFAR-10-C and ImageNet-C, we ï¬nd that adapting polyloss classiï¬ers via conjugate PL improves the performance over all methods applied to cross-entropy trained source classiï¬ers. For e.g., on ImageNet-C, the performance improves from 45.34% to 44.01%. However, this is only true when using the proposed conjugate PL. If we just did softmax-entropy minimization (even with temperature scaling), the ï¬nal adapted performance of a polyloss classiï¬er (45.5%) is in fact worse than that of a cross-entropy classiï¬er (45.34%). Our results suggest that as we develop new training losses that improve the source classiï¬ers, it is important to adapt via conjugate pseudo-labeling to reap the maximum gains. Similarly, we experiment with the case when the source classiï¬er is trained using squared loss on the CIFAR-10 and CIFAR-100 datasets, and observe consistent gains using the proposed conjugate pseudo-labels over the baselines. For example, on CIFAR-10-C, TTA using conjugate PL gives and error of 12.87%, outperforming baselines like ENT (13.24%) and Softmax PL (31.81%). Table 5 in Appendix A.7 shows the detailed results. Comparing Table 1 and Table 2, we see that the relative ordering between the various baselines differs. This is further evidence that the adaptation loss has to depend on the training loss, and we believe our conjugate pseudo-label approach captures this appropriately by offering consistent gains across the various settings we experimented with. 6 Related Works Test-time adaptation methods. In recent years, the setting of test-time adaptation has gained a lot of interest with a host of different approaches proposed in the literature. One family of TTA approaches update the source classiï¬er by minimizing an unsupervised loss on the target distribution [4, 6, 20, 22, 35, 36, 40, 43, 44, 50, 51, 54]. TENT [ 50] proposes to minimize the entropy of model predictions at test time. Several follow ups like [ 6, 35, 40, 44, 54] propose alternative TTA objectives, e.g. robust pseudo-labelling [40], likelihood ratio loss [35], entropy of marginal probability averaged across augmentations [54] and self-supervised contrastive losses [6, 49]. However, most of these objectives are heuristically designed or chosen. In this paper, we provide a principled approach of designing unsupervised objectives for TTA . Another family of approaches for test-time adaptation such as [ 2, 8, 13, 31, 34, 47] leverage an auxiliary self-supervised task (e.g. rotation prediction [ 47], masked autoencoders [10]) to update model parameters on each test sample. Crucially, these methods require modifying the source model training by augmenting the supervised training objective with an auxiliary self-supervised loss. Hence it cannot be applied to typical standard classiï¬ers that are trained by minimizing a supervised loss on the source data. Source-free domain adaptation. A very related setting to test-time adaptation is source-free domain adaptation, where a trained source classiï¬er must be adapted to a target distribution of interest, although the entire target unlabeled data is available at once. SHOT [28] proposes to optimize the source hypothesis (i.e. feature extractor) with a combination of entropy minimization, diversity and self-training on pseudo-labels on the unlabeled target data. [53] promotes feature clustering on features from target distributions. [24, 26] use generative modeling to estimate the underlying source distributions for enforcing feature invariance. Such approaches typically require multiple epochs over the target data and cannot be easily adopted to work in an online fashion. 9Unsupervised domain adaptation. The most canonical setting of domain adaptation involves access to labeled source data and unlabeled target data, all during training. The availability of source and target data during training lends itself to approaches that â€œalignâ€ the source and target representations in some way: [ 32, 33, 45, 48] match distribution statistics, [ 11] uses a discriminator, [ 46] uses self-supervised learning. However, such approaches require access to source data which might not always be feasible due to data privacy and efï¬ciency issues. Pseudo-labels and self-training. Self-training is a classic idea for leveraging unlabeled data, devel- oped ï¬rst for the semi-supervised setting. Self-training generates pseudo-labels on the unlabeled data, allowing us to use any â€œsupervisedâ€ loss on this pseudo-labeled data. Self-training has shown promising results in various settings like semi-supervised learning [ 19] and improving adversarial robustness [ 5]. Self-training has also been gaining attention in the setting of unsupervised domain adaptation [28, 39], where pseudo-labels generated on the unlabeled data from target domain is used to supervise the adaptation process. [ 7, 23, 52] provide theoretical insights into how self-training with pseudo-labels can help under distribution shift. TENT [50] (i.e entropy minimization) can be viewed as a form of self-training with instantaneous softmax pseudo-labels. Our work provides a general framework for the choice of soft pseudo-labels based on the conjugate analysis of the source training objective. Some prior works like [7, 17, 27, 30, 55, 56] have documented the improvement in performance when using instantaneous pseudo-labels over pre-computed pseudo-labels, and thus lend further support to the beneï¬ts of our proposed conjugate pseudo-labeling approach. The ex- periment results presented in this work supporting conjugate pseudo-labels suggest that conjugate pseudo-labels is a promising direction of pseudo-labeling in a broader context. 7 Conclusion, Limitations and Future Directions In this work, we proposed a general test-time adaptation loss, based on the convex conjugate formulation which in turn was motivated by the intriguing meta learning experiments. The fact that meta-learning recovers the proposed loss hints at some kind of optimality of the loss. In Section 4, we prove that for a broad set of loss functions, the proposed (unsupervised) conjugate loss is close to the oracle supervised loss. However, this still does not completely answer what the optimal test-time adaptation loss is and why. The meta-learning framework in this work was constrained to learn functions over the logits of each individual input. It can be expanded to more involved setups, where we consider functions over the intermediate representations too and also consider learning functions over a batch of input while accounting for their interactions. Beyond the choice of the adaptation loss itself, achieving good test-time adaptation generally involves several heuristics like updating only the batch norm parameters [50]. While our work was motivated by the loss function, via the meta-learning experiments, we discovered that temperature scaling is another important hyper-parameter that improves the performance of all previous baselines as well. At a high level, test-time adaptation has to be appropriately regularized to prevent the updates over batches from taking the model too far: updating only a few batch norm parameters is one way to do that, and perhaps temperature scaling provides a similar beneï¬cial regularization effect by making the network predictions on unlabeled inputs less conï¬dent. Understanding the role of these heuristics more concretely is an interesting direction for future work. It also remains an open problem to understand under what sort of real-world distribution shifts would self-training based approaches would help. Finally, it is also worth extending and applying the conjugate pseudo-labeling to other settings like semi-supervised learning. 8 Acknowledgments We thank Shubhang Bhatnagar and Asher Trockman for helping with running the ImageNet experi- ments. We thank Zhili Feng for useful feedback. Sachin Goyal and Mingjie Sun were supported by funding from the Bosch Center for Artiï¬cial Intelligence. Aditi Raghunathan was supported by an Open Philanthropy AI Fellowship. 10References [1] https://en.wikipedia.org/wiki/Convex_conjugate. [2] Pratyay Banerjee, Tejas Gokhale, and Chitta Baral. Self-supervised test-time learning for reading comprehension. In Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2021. [3] Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette, Ludovic Righetti, Gaurav Sukhatme, and Franziska Meier. Meta-learning via learned loss. arXiv preprint arXiv:1906.05374, 2019. [4] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [5] Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Un- labeled data improves adversarial robustness. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÃ©-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips. cc/paper/2019/file/32e0bd1497aa43e02a42f47d9d6515ad-Paper.pdf. [6] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [7] Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. In Advances in Neural Information Processing Systems, 2020. [8] Mohammad Zalbagi Darestani, Jiayu Liu, and Reinhard Heckel. Test-time training can close the natural distribution shift performance gap in deep learning based compressed sensing. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [9] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adap- tation of deep networks. In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017. [10] Yossi Gandelsaman, Yu Sun, Xinlei Chen, and Alexei A. Efros. Test-time training with masked autoencoders. In Advances in Neural Information Processing Systems, 2022. [11] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1â€“35, 2016. [12] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. InInternational Conference on Learning Representations, 2021. [13] Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Alenya, Pieter Abbeel, Alexei A. Efros, Lerrel Pinto, and Xiaolong Wang. Self-supervised policy adaptation during deployment. In International Conference on Learning Representations, 2021. [14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [15] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019. [16] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In In IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [17] Yosuke Higuchi, Niko Moritz, Jonathan Le Roux, and Takaaki Hori. Advancing momentum pseudo-labeling with conformer and initialization strategy. In IEEE International Conference on Acoustics, Speech and Signal Processing, 2022. 11[18] Like Hui and Mikhail Belkin. Evaluation of neural architectures trained with square loss vs cross-entropy in classiï¬cation tasks. In International Conference on Learning Representations, 2021. [19] Dong hyun Lee. Pseudo-label: The simple and efï¬cient semi-supervised learning method for deep neural networks. [20] Yusuke Iwasawa and Yutaka Matsuo. Test-time classiï¬er adjustment module for model-agnostic domain generalization. In Advances in Neural Information Processing Systems, 2021. [21] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton A. Earnshaw, Imran S. Haque, Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. Wilds: A benchmark of in-the-wild distribution shifts. In Proceedings of the 38th International Conference on Machine Learning (ICML), 2021. [22] Takeshi Kojima, Yutaka Matsuo, and Yusuke Iwasawa. Robustifying vision transformer without retraining from scratch by test-time class-conditional feature alignment. In International Joint Conference on Artiï¬cial Intelligence, 2022. [23] Ananya Kumar, Tengyu Ma, and Percy Liang. Understanding self-training for gradual domain adaptation. In Proceedings of the 37 th International Conference on Machine Learning (ICML), 2020. [24] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In IEEE Winter Conference on Applications of Computer Vision (WACV), 2021. [25] Zhaoqi Leng, Mingxing Tan, Chenxi Liu, Ekin Dogus Cubuk, Jay Shi, Shuyang Cheng, and Dragomir Anguelov. Polyloss: A polynomial expansion perspective of classiï¬cation loss functions. In International Conference on Learning Representations, 2022. [26] Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsuper- vised domain adaptation without source data. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [27] Xinzhe Li, Qianru Sun, Yaoyao Liu, Qin Zhou, Shibao Zheng, Tat-Seng Chua, and Bernt Schiele. Learning to self-train for semi-supervised few-shot classiï¬cation. In Advances in Neural Information Processing Systems, 2019. [28] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. InProceedings of the 37th International Conference on Machine Learning (ICML), 2020. [29] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r. Focal loss for dense object detection. In IEEE/CVF International Conference on Computer Vision (ICCV), 2017. [30] Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training for domain adaptation. In Advances in Neural Information Processing Systems, 2021. [31] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In Advances in Neural Information Processing Systems, 2021. [32] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S. Yu. Transfer feature learning with joint distribution adaptation. In IEEE/CVF International Conference on Computer Vision (ICCV), 2013. [33] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. Learning transferable features with deep adaptation networks. In Proceedings of the 32nd International Conference on Machine Learning, 2015. [34] Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf. Consistent video depth estimation. In SIGGRAPH, 2020. 12[35] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and Jan Hendrik Metzen. Test-Time Adaptation to Distribution Shift by Conï¬dence Maximization and Input Transformation. arXiv preprint arXiv: 2106.14999, 2021. [36] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efï¬cient test-time model adaptation without forgetting. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [37] Junhyuk Oh, Matteo Hessel, Wojciech M. Czarnecki, Zhongwen Xu, Hado P van Hasselt, Satinder Singh, and David Silver. Discovering reinforcement learning algorithms. In Advances in Neural Information Processing Systems, 2020. [38] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. Visda: The visual domain adaptation challenge, 2017. [39] Viraj Prabhu, Shivam Khare, Deeksha Kartik, and Judy Hoffman. Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [40] Evgenia Rusak, Steffen Schneider, George Pachitariu, Luisa Eck, Peter Vincent Gehler, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. If your data distribution shifts, use self- learning, 2022. URL https://openreview.net/forum?id=1oEvY1a67c1. [41] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In Advances in Neural Information Processing Systems, 2020. [42] H. Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transac- tions on Information Theory, 1965. [43] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test-time prompt tuning for zero-shot generalization in vision-language models. In Advances in Neural Information Processing Systems, 2022. [44] Prabhu Teja Sivaprasad and FranÃ§ois Fleuret. Test time adaptation through perturbation robust- ness. arXiv preprint arXiv: 2110.10232, 2021. [45] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment for unsupervised domain adaptation. arXiv preprint arXiv: 1612.01939, 2016. [46] Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A. Efros. Unsupervised domain adaptation through self-supervision. arXiv preprint arXiv:1909.11825, 2019. [47] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Proceedings of the 36th International Conference on Machine Learning (ICML), 2019. [48] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014. [49] Dequan Wang, Shaoteng Liu, Sayna Ebrahimi, Evan Shelhamer, and Trevor Darrell. On-target adaptation. arXiv preprint arXiv: 2109.01087, 2021. [50] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. [51] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [52] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. In-n-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness. In International Conference on Learning Representations, 2021. 13[53] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [54] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In Advances in Neural Information Processing Systems, 2022. [55] Yang Zou, Zhiding Yu, B. V . K. Vijaya Kumar, and Jinsong Wang. Domain adaptation for semantic segmentation via class-balanced self-training. European Conference on Computer Vision, 2018. [56] Yang Zou, Zhiding Yu, Xiaofeng Liu, B. V . K. Vijaya Kumar, and Jinsong Wang. Conï¬dence regularized self-training. In IEEE/CVF International Conference on Computer Vision (ICCV), 2019. 14A Appendix A.1 Conjugate Derivations Cross-Entropy Loss : L(h,y) = âˆ’ câˆ‘ i=1 yilog exp(hi)âˆ‘c j=1 exp(hj) = âˆ’ câˆ‘ i=1 yi âˆ—hi + log câˆ‘ j=1 exp(hj) = f(h) âˆ’yâŠ¤h, (14) where f(h) is log âˆ‘c j=1 exp(hj) and the constraint that âˆ‘c i=1 yi = 1. Now, the conjugate fâ‹†(y) is given by : fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {log câˆ‘ j=1 exp(hj) âˆ’yTh} (15) with the constraint âˆ‘c i=1 yi = 1. At the optimality, yi = (âˆ‡f(h))i = exp(hi)âˆ‘ jexp(hj) (16) Then, fâ‹†(y) = âˆ’log câˆ‘ j=1 exp(hj) + câˆ‘ i=1 hi exp(hi)âˆ‘ jexp(hj) = âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj), (17) if the constraint âˆ‘c i=1 yi = 1 is satisï¬ed, otherwise fâ‹†(y) = âˆžby duality. This in turn gives, the conjugate loss for cross-entropy (when the constraint is satisï¬ed) : Lconj(h) = âˆ’fâ‹†(y) = âˆ’fâ‹†(âˆ‡f(h)) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (18) Squared Loss : L(h,y) = 1 2||hâˆ’y||2 2 â‰ˆ1 2||h||2 2 âˆ’yâŠ¤h [ignoring the constant term] = f(h) âˆ’yâŠ¤h, (19) Now, the conjugate fâ‹†(y) is given by: fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {1 2||h||2 2 âˆ’yTh} = âˆ’1 2||h||2 2 (20) A.2 Experiments on Binary Classiï¬cation with Exponential Loss Here we present the results on a binary classiï¬cation task over a synthetic dataset of 100 dimensional gaussian clusters. 15Dataset Creation For the binary classiï¬cation task, we create a synthetic dataset similar to [23]. Speciï¬cally, let the data X âˆ¼ N(Âµ,Î£) âˆˆ R100 and labels Y âˆˆ {âˆ’1,+1}. We sample Âµ âˆ¼ N(k,I100). For Î£, similar to [ 23], we sample a diagonal matrix D, where each entry is sampled uniformly from a speciï¬ed range, and a rotation matrix U from a HAAR distribution, giving Î£ = UDUT. For the source data, we sample Âµâˆ’1 s ,Âµ+1 s ,Î£âˆ’1 s ,Î£+1 s as speciï¬ed above with k= 0. Now to create a distribution shifted data of various severity, we sampleÂµâˆ’1 t ,Âµ+1 t ,Î£âˆ’1 t ,Î£+1 t as speciï¬ed above with k= 1, which are then used to sample the shifted data as follows : Âµ1 Î» = Î»Âµ1 t + (1 âˆ’Î»)Âµ1 s Âµâˆ’1 Î» = Î»Âµâˆ’1 t + (1 âˆ’Î»)Âµâˆ’1 s Î£1 Î» = Î»Î£1 t + (1 âˆ’Î»)Î£1 s Î£âˆ’1 Î» = Î»Î£âˆ’1 t + (1 âˆ’Î»)Î£âˆ’1 s XÎ» âˆ¼N(ÂµÎ»,Î£Î») In the following experiments, easy shift refers to Î»= 0.6, moderate shift to Î»= 0.65 and hard shift to Î»= 0.7. Exponential Loss for Binary Classiï¬cation Let zbe the classiï¬cation score hÎ¸(x). For logistic training loss, conjugate adaptation loss would default to entropy with sigmoid probability. Thus, here we experiment with a different but also commonly used surrogate loss to 0/1 loss: exponential loss, which is deï¬ned as: Lexp(z,y) = exp(âˆ’yz) (21) where yâˆˆ{âˆ’1,+1}. It can be rewritten in the expanded conjugate form of: Lexp(z,y) = 1 2 Â· ( ez + eâˆ’z) âˆ’1 2 Â·yÂ· ( ez âˆ’eâˆ’z) (22) For exponential loss, the conjugate pseudo-label function and the conjugate pseudo-label loss are: yCPL exp (z) = ez âˆ’eâˆ’z ez + eâˆ’z, LCPL exp (z) = 2 ez + eâˆ’z (23) The model is adapted on shifted gaussian clusters and we compare the conjugate loss with two baseline approaches: 1) Hard pseudo-labelling exp(âˆ’yhard pl Â·z); 2) Entropy applied to sigmoid probability P(y= +1) = Ïƒ(z). The losses are compared on three degrees of shift (easy, moderate and hard), which is controlled by the drifted distance of Gaussian clusters. The results are shown in Figure 3, where we plot the accuracy curve with respect to adaptation iterations. With easy and moderate shift, conjugate loss (green) generalizes faster to shifted test data; with hard shift, only conjugate loss improves model accuracy on shifted test data while entropy (blue) deteriorates model performance. Figure 3: Test-time adaptation result on synthetic data with three shift levels ranging from easy, moderate and hard (detailed in section A.2). The source model is a linear classiï¬er trained with exponential loss Lexp = eâˆ’yhÎ¸(x). Adaptation with the conjugate loss generalizes better compared to baseline losses. 16A.3 Meta Learning Experiment Details In section 3 we talked about learning the meta-loss function parameterized by a neural network mÏ† : R|Y|â†¦â†’R, that takes in the model predictions/logits and outputs a loss value. Here we discuss the architecture chosen and the implementation details. Further, in Appendix A.4 we empirically show that the learnt meta-loss is not affected by the choice of task loss / surrogate loss used in meta learning (Lin Equation 1). Note that the task loss / surrogate loss function is used to update the meta-loss mÏ† during meta-learning. The surrogate loss is calculated on updated source modelâ€™s predictions on labeled samples from test domain. The surrogate loss tries to update the meta-loss in the outer loop such that when meta-loss is later used to update the source model in the inner loop, the source model generalizes better to the test domain. Architecture and Implementation Details Figure 4 gives an overall schema for meta-learning the loss function and algorithm 2 gives the pseudo-code for meta-learning the loss function. Below we describe this in further detail. We use a transformer (denoted by T) with a MLP (denoted by P) over the output of transformer as the architecture for mÏ†, i.e. mÏ†(x) = P(T(x)). Speciï¬cally, for a given source trained model hÎ¸ and input xâˆ¼Dtest : 1. Let hÎ¸(x) âˆˆR|Y|be the model predictions/logits, where |Y|denotes the number of classes. 2. Let hj Î¸(x) âˆˆR,âˆ€j âˆˆ|Y| be the prediction corresponding to class j. 3. The input to transformer is then given by z âˆˆR|Y|Ã—(1+e), where zj âˆˆR1+e,âˆ€j âˆˆ|Y| is the concatenation of hj Î¸(x) and the learnable positional embedding pej âˆˆRe. 4. The transformer output is given by w= T(z) âˆˆRd, where ddenotes the feed-forward dimension of the transformer. 5. The transformer output wis ï¬nally passed through a MLP to get the meta-loss valuemÏ†(hÎ¸(x)) = P(w) âˆˆR 6. The source model is updated by optimizing over the meta-loss. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t (24) 7. The updated source model is then used to update the meta-loss by optimizing over some supervised loss function Ltask. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , where (xâ€²,yâ€²) âˆ¼Dtest (25) Note that the last step assumes access to labels of test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We select the trasformer input embedding dimension (1 + e) from {16,32,64}and transformer feed-forward dimension dfrom {32,64,128}. The number of transformer layers and the hidden layers in MLP are selected from {1,2}. We use Adam optimizer with a learning rate of 1eâˆ’3 for learning the meta-loss (i.e. the transformer + MLP). We train the meta-loss for 100 epochs with a batch size of 200. A.4 Effect of Task Loss in Meta Learning In section 3, we show that the meta losses learned on different source classiï¬ers differ substantially if the source classiï¬ers are trained using different source loss functions. Here we further empirically verify that the learnt meta loss is not affected by the task loss used in meta learning (Lin Equation 1). Thus the learnt meta loss is determined by the source model. In Figure 5, we show the meta loss learnt on a ResNet-26 trained with Cross Entropy loss for two meta task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. We plot the meta loss as a function over one of its input prediction scores, while keeping other ï¬xed. We can see that the task loss barely affects the learnt meta loss. Similar observations can be made for the classiï¬er trained with squared loss Figure 6. 17Meta-Loss  Backpropogate  Figure 4: Meta-Loss learning procedure : The model predictions hÎ¸t(x) are passed through the parameterized loss function mÏ†t, which outputs a loss value. We optimize Ï† such that when optimizing the source model over the loss mÏ†t(hÎ¸t(x)), the updated Î¸t+1 has a better performance on the test domain. To do this, we take one gradient step over the meta-loss to get the update source model parameters Î¸t+1, and then update Ï†by evaluating Î¸t+1 on the labeled validation data using some task loss Ltask. Algorithm 2 Learning the Meta-Loss Input: Source trained classiï¬er hÎ¸0 . Randomly initialized meta-loss mÏ†0 . Task loss / Surrogate loss Ltask like cross-entropy or squared loss for meta learning N batches of test data Dtest = [(x1,y1),..., (xN,yN)] Hyperparams: learning rates Î±and Î². for epoch= 0,1,2,... do for n= 0,1,...N âˆ’1 do Î¸t+1 â†Î¸t âˆ’Î± âˆ‚mÏ†t(hÎ¸t(xn)) âˆ‚Î¸t Sample (xr,yr) âˆ¼Dtest. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xr),yr) âˆ‚Ï†t A.5 Test-Time Adaptation Detail For completeness, we also give the test-time adaptation setup in Algorithm 3. A.6 ImageNet results on each severity level In continuation with results shown in Table 2 in Section 5.3, Table 4 shows the mean errors averaged across the 15 corruption types for each of the severity level on ImageNet-C, for a source classiï¬er trained with PolyLoss (Ïµ= 8). A.7 Square Loss Trained Source Classiï¬er In Section 5.3, we brieï¬‚y discussed that similar to the other source training losses like cross-entropy and polyloss, our proposed conjugate loss outperforms the baselines when the source classiï¬er is 18(a)  (b) Figure 5: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Cross Entropy. Here we show meta loss trained by two different task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. (a)  (b) Figure 6: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Squared Loss. Here we show meta loss trained by two different task losses: Cross Entropy Figure 6a and Squared Loss Figure 6b. Algorithm 3 Test-Time Adaptation Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y), An unsupervised loss function for test-time adaptation Ltta(x), N batches of test data Dtest = [x1,...,x N] Hyperparams: learning rate Î·. for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡Ltta(xn) Ë†yn = hÎ¸n+1 (xn) [Predictions for the nth batch] 19Corrution Severity Temperature Robust PL Entropy MEMO Softmax PL Conjugate 1 \u0017 34.27 33.17 34.39 32.49 32.26 \u0013 34.27 32.84 34.39 32.70 32.26 2 \u0017 41.25 39.04 40.38 37.78 37.40 \u0013 41.25 38.50 40.38 37.75 37.40 3 \u0017 47.37 44.04 45.67 42.30 41.72 \u0013 47.37 43.33 45.67 42.14 41.72 4 \u0017 56.63 51.88 54.49 49.61 48.84 \u0013 56.63 51.03 54.49 49.39 48.84 5 \u0017 67.11 62.53 66.13 60.94 59.90 \u0013 67.11 61.80 66.13 60.30 59.90 Mean \u0017 49.32 46.13 48.21 44.62 44.02 \u0013 49.32 45.50 48.21 44.45 44.02 Table 4: Mean Errors across the 15 noises for various severity level on the ImageNet-C dataset, with source model trained using Poly-1 Loss. Note that Temperature scaling helped only in the case of Entropy and Softmax PL. trained using a squared loss. Table 5 shows a detailed comparison with the baselines. We note that for the conjugate of squared loss, the temperature scaling can be wrapped into the learning rate as shown in Section 4.2. Further, on the CIFAR-10-C dataset we observe temperature scaling doesnâ€™t help any of the other baselines too, hence we do not include the temperature row in CIFAR-10-C. Dataset Temperature Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL CIFAR-10-C \u0017 13.71 (Â±0.07) 13.06 (Â±0.05) 13.24 (Â±0.02) 13.22 (Â±0.04) 14.85 (Â±0.08)12.99(Â±0.04) CIFAR-100-C \u0017 50.82 (Â±0.31) 44.53 (Â±0.13) 43.55 (Â±0.12) 51.35 (Â±0.04) 51.99 (Â±0.03)43.39(Â±0.11) \u0013 50.82 (Â±0.31) 43.99 (Â±0.15)43.21(Â±0.08) 51.35 (Â±0.04) 51.99 (Â±0.03) 43.39 (Â±0.11) Table 5: Mean Errors on the common corruptions datasets for source classiï¬er trained using squared loss. We note that temperature scaling didnâ€™t help on the CIFAR-10-C dataset. Source Classiï¬er Errors without adaptation : CIFAR-10-C (28.34%), CIFAR-100-C (68.79%) Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1 eâˆ’2, 2 SGD,5 eâˆ’3, 3 Adam,1eâˆ’3, 2 CIFAR-100-C \u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD,1eâˆ’2, 2 ImageNet-C \u0017 SGD,1eâˆ’2, 1 SGD,2.5 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1.5 SGD,1eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 Table 6: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 1, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using cross-entropy loss. A.8 Hyper-Parameters We share the exact hyper-parameters found using gridsearch over the 4 validation noises for the common corruptions dataset. 20Cross Entropy Classiï¬er Experiments In Section 5.2, Table 1 shows the results when adapting a cross entropy trained classiï¬er on various common corruptions dataset. Table 6 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. PolyLoss Classiï¬er Experiments In Section 5.3, Table 2 shows the results when adapting a polyloss trained classiï¬er on various common corruptions dataset. Table 7 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’3, 1 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1eâˆ’2, 3 SGD,1 eâˆ’2, 3 SGD,5 eâˆ’3, 3 SGD, 1eâˆ’3, 2 SGD, 1eâˆ’3, 1.5 CIFAR-100-C\u0017 SGD,1eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD, 1eâˆ’2, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 Adam,1eâˆ’3, 3 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD, 1eâˆ’2, 2.5 SGD, 1eâˆ’2, 1.5 ImageNet-C\u0017 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 2 SGD, 2.5eâˆ’3, 1 Table 7: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 2, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using poly-loss. Squared Loss Classiï¬er Experiments In Section 5.3, we brieï¬‚y discussed the results when adapt- ing a squared loss trained classiï¬er on various common corruptions dataset. Table 8 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss for the results in Table 5. Digit Adaptation Datasets For the experiments on digits adaptation tasks, we do not have any validation set. Hence, we donâ€™t use temperature scaling here (T = 1) and ï¬x the optimizer and LR as Adam and 1eâˆ’2 respectively for all the baselines. A.9 Additional Experiments on Digit Adaptation Datasets Similar to the setting of Table 1, we perform additional experiments on digit adaptation datasets when the source classiï¬er is trained using the cross-entropy loss. Note that when the source classiï¬er is trained using cross-entropy loss, the conjugate loss is equal to the softmax-entropy. In the absence of validation dataset in digit adaptation benchmarks, we used a ï¬xed learning rate of 0.01 for all the baselines, optimizer as Adam and an informed temperature scaling guess of T=2. Table 9 compares softmax-entropy minimization with various baselines. Here, again we observe that on SVHN â†’MNIST benchmark, without temperature scaling, MEMO (10.67% error) outperforms softmax-entropy (14.41% error). However, similar to the observations in Table 1, with temperature scaling, softmax-entropy minimization (9.26% error) is able to match the performance of MEMO (9.36% error). Further, on the SVHN â†’USPS benchmark, softmax-entropy (conjugate) and MEMO perform similar even without temperature scaling. A.10 Additional Meta Learning the TTA Loss Experiments In Section 3, we tried to learn a test-time adaptation (TTA) loss via meta-learning for adapting a CIFAR10 trained ResNet26 to distribution shifts on CIFAR10 corruptions. Figure 1 showed that the learnt meta-loss looks like a temperature scaled softmax-entropy. In this section, we show the learnt meta loss across a range of settings as described below : 1. Digit Adaptation: Figure 7a and 7b show the learnt meta-loss when adapting a SVHN trained ResNet26 to MNIST dataset and USPS dataset respectively. We observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 2. Various Noise Types: In Figure 8, we show the learnt meta-loss when adapting a ResNet26 trained on CIFAR10 dataset using cross-entropy loss, to various noise types like speckle, gaussian, saturate and spatter. The severity level is kept ï¬xed at the maximum i.e. 5. 21Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’4, 1 SGD,1eâˆ’2, 1 CIFAR-100-C\u0017 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam, 1eâˆ’4, 1 Adam, 1eâˆ’3, 1 \u0013 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 0.5 Adam,1eâˆ’3, 2 Adam,1eâˆ’3, 2 Adam, 1eâˆ’4, 2.5 Adam, 1eâˆ’3, 1 Table 8: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 5, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using squared loss. Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) SVHNâ†’MNIST \u0017 21.54 27.44 10.67 14.41 \u0013 21.54 13.26 9.36 9.26 SVHNâ†’USPS \u0017 26.06 26.81 22.72 22.57 \u0013 26.06 22.32 22.42 22.27 Table 9: Mean errors when adapting to digit adaptation benchmarks using a source classiï¬er trained via cross-entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. Again we observe that with the right temperature scaling, softmax-entropy minimization matches other approaches. For additional context, the source classiï¬er errors without adaptation are: SVHN â†’MNIST (34.17%), SVHN â†’USPS (31.84%). 20  10  0 10 20 prediction score 5 0 5 10loss value meta loss (error 10.44%) softmax entropy (error 14.41) fitted entropy (error 9.26) Meta Loss for SVHN -> MNIST (a) 20  10  0 10 20 prediction score 6 4 2 0 2 4 6 8 loss value meta loss (error 20.13%) softmax entropy (error 22.57) fitted entropy (error 22.22) Meta Loss for SVHN -> USPS adpatation (b) Figure 7: Visualizations of the learnt meta-loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with cross-entropy on the SVHN dataset. (a) The learnt meta-loss when adapting to the MNIST test dataset. (b) The learnt meta-loss when adapting to the USPS test dataset. 3. Various Severity Levels: In Figure 9, we vary the severity level of the noise, keeping the noise type ï¬xed. 4. Dataset and Architecture: In Figure 10, we compare the learnt meta-loss when adapting to speckle noise, for different source classiï¬er architectures (ResNet26 and ResNet50) and different source training dataset (CIFAR10 and CIFAR100). In all the cases, we again observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 5. Squared Loss : Finally, in Figure 11 we show the learnt meta-loss for classiï¬ers trained with squared loss function instead of cross-entropy. We observe that in this case, the learnt meta loss mimics a quadratic function as expected from the conjugate formulation. 22For each of the learnt meta losses, we also show the values (Î±,T,C ) we use to ï¬t the meta loss with softmax entropy function: Î±Â·H(softmax(x/T)) âˆ’C. Note that although the learnt meta-loss can be approximated by the conjugate, the parameters Î±,T,C differ across the settings. In the case of classiï¬ers trained with squared loss, we ï¬t the meta loss with a quadratic functionâˆ‘K i=1(AÂ·x2 i + C), where Kis the number of classes and xis the logit vector. Again, we also show the ï¬tted parameter value A,C. The meta loss follows the trend of a quadratic function. The ï¬tted quadratic function performs better or similar as the meta loss, while the parameters of the ï¬tted quadratic function remain different across the meta learning setup (base classiï¬er architectures and noise types). (a)  (b) (c)  (d) Figure 8: Visualization of meta loss (blue) learnt from various noise types in CIFAR-10-C validation set, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 23(a)  (b) (c)  (d) Figure 9: Visualization of meta loss (blue) learnt on speckle noise with different severity level for CIFAR-10-C, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 24(a)  (b) (c)  (d) Figure 10: Visualization of meta loss (blue) learnt across datasets (CIFAR-10-C/CIFAR-100-C) and base classiï¬er architectures (ResNet-26/ResNet-50), where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters ( Î±,T,C ) in the ï¬tted entropy. (a)  (b) Figure 11: Visualization of meta loss (blue), where base classiï¬er is trained with quadratic loss. We show the error of meta loss, softmax entropy and ï¬tted quadratic function for test-time adaptation on the corresponding noise types. We also show the parameters ( A,B,C ) in the ï¬tted quadratic function. 25",
      "meta_data": {
        "arxiv_id": "2207.09640v2",
        "authors": [
          "Sachin Goyal",
          "Mingjie Sun",
          "Aditi Raghunathan",
          "Zico Kolter"
        ],
        "published_date": "2022-07-20T04:02:19Z",
        "pdf_url": "https://arxiv.org/pdf/2207.09640v2.pdf"
      }
    },
    {
      "title": "AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation",
      "abstract": "Test-time adaptation (TTA) has emerged as a viable solution to adapt\npre-trained models to domain shifts using unlabeled test data. However, TTA\nfaces challenges of adaptation failures due to its reliance on blind adaptation\nto unknown test samples in dynamic scenarios. Traditional methods for\nout-of-distribution performance estimation are limited by unrealistic\nassumptions in the TTA context, such as requiring labeled data or re-training\nmodels. To address this issue, we propose AETTA, a label-free accuracy\nestimation algorithm for TTA. We propose the prediction disagreement as the\naccuracy estimate, calculated by comparing the target model prediction with\ndropout inferences. We then improve the prediction disagreement to extend the\napplicability of AETTA under adaptation failures. Our extensive evaluation with\nfour baselines and six TTA methods demonstrates that AETTA shows an average of\n19.8%p more accurate estimation compared with the baselines. We further\ndemonstrate the effectiveness of accuracy estimation with a model recovery case\nstudy, showcasing the practicality of our model recovery based on accuracy\nestimation. The source code is available at https://github.com/taeckyung/AETTA.",
      "full_text": "AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation Taeckyung Leeâ€  Sorn Chottananurakâ€  Taesik Gongâ€¡ Sung-Ju Leeâ€  â€ KAIST â€¡Nokia Bell Labs {taeckyung,sorn111930,profsj}@kaist.ac.kr, taesik.gong@nokia-bell-labs.com Abstract Test-time adaptation (TTA) has emerged as a viable solu- tion to adapt pre-trained models to domain shifts using unla- beled test data. However, TTA faces challenges of adaptation failures due to its reliance on blind adaptation to unknown test samples in dynamic scenarios. Traditional methods for out-of-distribution performance estimation are limited by unrealistic assumptions in the TTA context, such as requir- ing labeled data or re-training models. To address this issue, we propose AETTA, a label-free accuracy estimation algo- rithm for TTA. We propose the prediction disagreement as the accuracy estimate, calculated by comparing the target model prediction with dropout inferences. We then improve the prediction disagreement to extend the applicability of AETTA under adaptation failures. Our extensive evaluation with four baselines and six TTA methods demonstrates that AETTA shows an average of 19.8%p more accurate estima- tion compared with the baselines. We further demonstrate the effectiveness of accuracy estimation with a model recovery case study, showcasing the practicality of our model recovery based on accuracy estimation. The source code is available at https://github.com/taeckyung/AETTA. 1. Introduction The rise of deep learning has impacted various fields with remarkable achievements [4, 13, 17, 32, 33]. In real-world deep learning applications, the divergence between training and test data, known as domain shifts, often leads to poor accuracy. For instance, object detection models encountering previously unseen data ( e.g., variations of objects) or dis- tributional shifts (e.g., weather changes) might suffer from performance degradation. To overcome this challenge, Test- Time Adaptation (TTA) [2, 11, 12, 28, 29, 34â€“36] has been regarded as a promising solution recently and actively stud- ied. TTA aims to adapt pre-trained models to domain shifts on the fly with only unlabeled test data. Despite recent advances in TTA, significant challenges hinder its practical applications. The core issue is that TTAâ€™s Adapted Model Dropout  Inferences Prediction Disagreement Model A Model B A B Accuracy Estimation True acc. Estimated acc. Proposed Method Online Test Streams Figure 1. AETTA estimates the modelâ€™s accuracy after adaptation using unlabeled test data without needing source data or ground- truth labels. AETTA can be integrated into existing TTA methods to estimate their accuracy under various scenarios. reliance on unlabeled test-domain samples makes TTA sus- ceptible to adaptation failures, especially in dynamic envi- ronments where the domain continuously changes [29, 30]. Although recent TTA studies deal with dynamic test streams in TTA [ 11, 12, 29, 35, 36], the inherent risk of TTAâ€“ blind adaptation to unseen test samples without ground- truth labelsâ€“remains a critical vulnerability. Notably, the absence of ground-truth labels makes it difficult to moni- tor the correctness of the adaptation. While various out-of- distribution performance estimation approaches have been proposed [1, 5, 15, 27], such methods necessitate labeled train data for accuracy estimation, which is impractical for TTA scenarios. In light of these challenges, we propose AETTA (Accu- racy Estimation for Test-Time Adaptation), a novel accuracy estimation method designed for TTA without reliance on labeled data or source data access (Figure 1). AETTA lever- ages prediction disagreement with dropout inferences, where the prediction disagreement between the adapted model and dropout inferences serves as a basis for performance estima- tion. To enhance AETTAâ€™s robustness to adaptation failure scenarios, we propose robust disagreement equality that dy- namically adjust the accuracy estimates based on model 1 arXiv:2404.01351v1  [cs.LG]  1 Apr 2024failures. The key idea is to extend the well-calibration as- sumption (i.e., predicted probabilities of expected model predictions are neither over-/under-confident [21]) to cover over-confident models (e.g., adaptation failures) via adaptive scaling of the predicted probability. In addition, we provide theoretical analysis on how AETTA can estimate accuracy with unlabeled test data. We evaluate AETTA on three TTA benchmarks (CIFAR10-C, CIFAR100-C, and ImageNet-C [ 18]) with two scenarios of fully TTA ( i.e., adapting to each corrup- tion) [34] and continual TTA (i.e., continuously adapting to 15 corruptions) [35]. We evaluate the accuracy estimation of AETTA integrated with six state-of-the-art TTA algo- rithms [12, 28, 29, 34â€“36]. We compare AETTA with four baselines that could be applied in the TTA setting. The result illustrates that AETTA shows an average of 19.8%p more accurate estimation compared with the baselines in various TTA methods and evaluation scenarios. Furthermore, we explore the impact of performance es- timation in TTA through a case study where we avoided undesirable accuracy drops in TTA based on AETTA. We propose a simple model recovery algorithm, which resets the model when consecutive estimated accuracy degradation or sudden accuracy drop are observed. Our case study shows that our model recovery algorithm with accuracy estimation achieved 11.7%p performance improvement, outperforming the best baseline that knows when distribution changes by 3.0%p. The result shows an example where accuracy estima- tion could benefit TTA in practice. 2. Preliminaries 2.1. Test-Time Adaptation (TTA) Consider the source data distribution DS, and the target data distribution DT and its random variable (X, Y), where Y is typically unknown to the learning algorithm, and K is total number of classes. The covariate shift assump- tion [ 31] asserts a disparity between the source and tar- get data distributions, defined by DS(x) Ì¸= DT (x) while maintaining consistency in the conditional label distribution: DS(y|x) = DT (y|x). Let h âˆ¼ HA denote a hypothesis that predicts a single class for a single input and f denote a corresponding soft- max value before class prediction. We define the hypothesis space HA as a hypothesis space H induced by a stochastic training algorithm A [21]. The stochasticity could arise from a different random initialization or data ordering. Assuming an off-the-shelf model h0 âˆ¼ HA pre-trained on DS, the goal of (fully) test-time adaptation (TTA) [34] is to adapt h0 for the target distribution DT to produce h, using a batch of the unlabeled test set in an online manner. 2.2. Accuracy Estimation in TTA We adopt a common TTA setup where source data is unavail- able and target test data lacks labels [12, 28, 29, 34â€“36]. The objective of TTA accuracy estimation is to predict the test accuracy (or error) with unlabeled test streams. Given an adapted model h(Â·; Î˜)at time t, we denote the test error of model h(Â·; Î˜)by: ErrDT (h) â‰œ EDT [1(h(X) Ì¸= Y )]. (1) Note that we use the terms test accuracy and test error de- pending on the context, and the sum of them is 1. Given the temporal nature of TTA, we consider estimating the accuracy of the model h(Â·; Î˜)â€“which has been updated before time tâ€“with the test batch Xt. Following the estimation, the test batch Xt is used for adaptation. 3. Methodology 3.1. Disagreement Equality We introduce an approach for estimating the test error of a model that is adapted at test time. The key idea is to compare the modelâ€™s output against outputs generated through dropout inference. Remarkably, this estimation process does not rely on access to the original training or labeled test data, which contrasts with existing accuracy estimation methods [1, 5, 15, 21, 27]. For example, generalization disagreement equality (GDE) [21] proposes a theoretical ground for estimating model error by measuring the disagreement rate between two networks. However, GDE requires multiple pre-trained models from different training procedures to calculate the disagreement rate. Instead of multiple pre-trained models, our strategy uti- lizes dropout inference sampling, a technique where random parts of a modelâ€™s intermediate layer outputs are omitted dur- ing the inference process [9]. From a single adapted model, we simulate the behavior of independent and identically dis- tributed (i.i.d.) models by dropout inference sampling. Definition 3.1. The hypothesis space HA satisfies the dropout independence if for anyh âˆ¼ HA, h and its dropout inference samples are i.i.d. over HA. To estimate the accuracy of the model, we proposepre- diction disagreement with dropout inferences (PDD) that calculates a disagreement between the adapted modelh(Â·; Î˜) and the dropout inferences h(Â·; Î˜dropout) with respect to test samples as: PDDDT(h) â‰œ EDT ï£® ï£° 1 N NX i=1 1 \u0002 h(X; Î˜) Ì¸= h(X; Î˜dropouti) \u0003 ï£¹ ï£», (2) where N is the number of dropout inferences. 2We now provide the theoretical background to estimate test error with PDD. We first define the expectation function Ëœh [21] over hypothesis space HA, which produces proba- bility vector of size K. For k-th element Ëœhk(x), we define: Ëœhk(x) â‰œ Ehâˆ¼HA[1[h(x) = k]], (3) which indicates the probability of a sample x sampled from DT being classed as the class k. Note that the expectation function does not represent the modelâ€™s accuracy; it indicates the probability of the input being classified as a particular class, regardless of the ground truth labels. Then, we define a confidence-prediction calibration as- sumption, indicating that the value of Ëœh for a particular class equals the probability of the sample having the same ground- truth label [21]. Definition 3.2. The hypothesis space HA and correspond- ing expectation function Ëœh satisfies confidence-prediction calibration1 on DT if for any confidence value q âˆˆ [0, 1] and class k âˆˆ [1, Â·Â·Â· , K]: p(Y = k|Ëœhk(X) = q) = q. (4) With PDD and the assumption of dropout independence and confidence-prediction calibration, we are able to esti- mate the modelâ€™s prediction error h (Theorem 3.1). Detailed proof is provided in the Appendix A.1. Theorem 3.1 (Disagreement Equality). If the hypothesis space HA and corresponding expectation functionËœh satisfies dropout independence and confidence-prediction calibration, prediction disagreement with dropouts (PDD) approximates the test error over HA: Ehâˆ¼HA[ErrDT (h)] = Ehâˆ¼HA[PDDDT (h)]. (5) 3.2. Robust Disagreement Equality Adaptation failures in TTA are often coupled with over- confident incorrect predictions. Figure 2 shows an illustra- tive example of this case; as the expectation functionâ€™s ac- curacy drops, the confidence increases, and predictions are skewed towards a few classes2. This violates the confidence- prediction calibration, leading to a high misalignment be- tween test error and PDD (red lines in Figure 3). To tackle the issue, we propose a robust confidence- prediction calibration to provide the theoretical ground of accuracy estimation for both well-calibrated or over- confident expectation function Ëœh. 1We rename the term from class-wise calibration [21] to clearly state the purpose of the calibration. 2Using the probabilistic property of expectation of dropout infer- ences [9], we approximate Ëœh(X) as EHA[Edropout[h(X; Î˜dropout)]]. /uni00000012/uni00000013/uni00000012/uni00000012/uni00000012/uni00000014/uni00000012/uni00000012/uni00000012 /uni00000031/uni00000050/uni0000004e/uni0000004b/uni00000050/uni00000047/uni00000002/uni00000024/uni00000043/uni00000056/uni00000045/uni0000004a /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) (a) Test batch accuracy and confidence. 0 1000 2000 Online batch 0 25 50 75 100Predicted class  (b) Predicted class distribution. Figure 2. Batch-wise accuracy, confidence, and prediction distribu- tion when a model failed to adapt. TENT [34] is used on CIFAR100- C with continually changing domains. The model becomes over- confident, and predictions are skewed. Definition 3.3. The hypothesis space HA and correspond- ing expectation function Ëœh satisfies robust confidence- prediction calibration on DT if for any confidence value q âˆˆ [0, 1], any class k âˆˆ [1, Â·Â·Â· , K], and the over-confident class kâ€², there exists a weighting constant b â‰¥ 1 and corre- sponding 0 â‰¤ a â‰¤ 1 that satisfies: p(Y = kâ€²|Ëœhkâ€²(X) = q) = aq, (6) and p(Y = k|Ëœhk(X) = q) = bq for k Ì¸= kâ€². (7) Robust confidence-prediction calibration adjusts the over- confident expectation function Ëœh to have a lower probability on the misclassified class kâ€² via multiplying a â‰¤ 1. Note that we can easily expand Definition 3.3 for multiple over- confident classes. Then, we estimate the test error with The- orem 3.2 (detailed proof in the Appendix A.2). Theorem 3.2 (Robust Disagreement Equality) . If the hy- pothesis space HA and corresponding expectation function Ëœh satisfies dropout independence and robust confidence- prediction calibration with a weighting constant b, predic- tion disagreement with dropouts (PDD) approximates the test error over HA: Ehâˆ¼HA[ErrDT (h)] = b Ehâˆ¼HA[PDDDT (h)] âˆ’ C, (8) where C = Z qâˆˆ[0,1] (b âˆ’ a) q(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq. (9) 3.3. Accuracy Estimation for TTA With Theorem 3.2, we propose an empirical approach to estimate the single model test error. Our experiments show that a single modelâ€™s disagreement (and the test error) lies close to the robust disagreement equality. This aligns with the previous finding that a single pair of differently-trained modelsâ€™ disagreement rate (and the test error) lies close to 3/uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000036/uni00000027/uni00000030/uni00000036 /uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a /uni00000025/uni00000032/uni00000025 /uni00000034/uni00000025/uni00000032/uni00000025 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p /uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000027/uni00000023/uni00000036/uni00000023 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p /uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000035/uni00000023/uni00000034 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p /uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000025/uni00000051/uni00000036/uni00000036/uni00000023 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p /uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000034/uni00000051/uni00000036/uni00000036/uni00000023 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p /uni00000012/uni00000010/uni00000012/uni00000012/uni00000012/uni00000010/uni00000014/uni00000017/uni00000012/uni00000010/uni00000017/uni00000012/uni00000012/uni00000010/uni00000019/uni00000017/uni00000013/uni00000010/uni00000012/uni00000012 /uni00000025/uni00000051/uni00000050/uni00000048/uni0000004b/uni00000046/uni00000047/uni00000050/uni00000045/uni00000047/uni00000002hkâ€²(X) /uni00000012 /uni00000014/uni00000012 /uni00000016/uni00000012 /uni00000018/uni00000012 /uni0000001a/uni00000012 /uni00000013/uni00000012/uni00000012/uni00000029/uni00000054/uni00000051/uni00000057/uni00000050/uni00000046/uni0000000f/uni00000036/uni00000054/uni00000057/uni00000056/uni0000004a/uni00000002/uni00000023/uni00000045/uni00000045/uni00000057/uni00000054/uni00000043/uni00000045/uni0000005b/uni00000002/uni0000000a/uni00000007/uni0000000b /uni00000035/uni00000051/uni00000036/uni00000036/uni00000023 /uni00000012/uni00000010/uni00000012 /uni00000012/uni00000010/uni00000014 /uni00000012/uni00000010/uni00000016 /uni00000012/uni00000010/uni00000018 /uni00000012/uni00000010/uni0000001a /uni00000013/uni00000010/uni00000012 /uni00000032/uni00000054/uni00000051/uni00000044/uni00000043/uni00000044/uni0000004b/uni0000004e/uni0000004b/uni00000056/uni0000005b/uni00000002p Figure 3. Correlations between the confidence value of estimated expectation function Ëœh and (1) ground-truth accuracy (GroundTruth), (2) conditional probability p(Y = kâ€²|Ëœhkâ€²(X) =q) of confidence-prediction calibration (CPC), and (3) robust confidence-prediction calibration (RCPC). We used six TTA methods in CIFAR100-C with continual domain changes. We observed accuracy degradation in TENT and EATA and improvement in SAR, CoTTA, RoTTA, and SoTTA. When models failed to adapt, the original CPC misaligned with the ground truth. In contrast, our WCPC dynamically scaled the probability p, thus showing better alignment. the disagreement equality [21]. Therefore, we approximate a single model test error as: ErrDT (h) â‰ˆ b PDDDT (h), (10) where we omit C due to the insufficient information regard- ing the true value of p(Ëœhkâ€²(X) = q). Note that C â‰ˆ 0 for models with calibration. Now, we discuss selecting a proper weighting constant b. Note that a desirable b should dynamically suppress the over- confident expectation function depending on the context so that the confidence-prediction calibration assumption holds. To this end, we use the skewness of the predicted outputs as an indicator of model over-confidence. Out intuition is based on the observation that the predicted class distribution is highly skewed when the adaptation fails (Figure 2b), which aligns with the findings from prior studies [19, 24]. Specifi- cally, we estimate the skewness of predictions by calculating the entropy (Ent) of the batch-aggregated softmax values from the dropout inferences over a test batch Xt: Eavg = Ent ï£« ï£­ 1 N NX i=1 1 |Xt| X xâˆˆXt f(x; Î˜dropouti) ï£¶ ï£¸, (11) where Eavg would maximize as Emax = Ent(âƒ—1K/K) with uniform predictions among the batch (e.g., no failures); while the minimum value would be 0 when entire batch predicts a single class (e.g., adaptation failures). We then model b with Eavg as: b = \u0012Eavg Emax \u0013âˆ’Î± , (12) where Î± âˆˆ [0, âˆž) is a hyperparameter. If the adaptation does not fail, predictions are uniformly distributed as Eavg = Emax and b = 1. Note that a = b = 1 drives Theorem 3.2 to be equivalent to Theorem 3.1. We found that modelingb with the average batch-wise entropy effectively corrects the correlation between confidence and prediction probability, as illustrated in Figure 3 (blue dots). Finally, with Equation 10 and Equation 12, we propose Accuracy Estimation for TTA (AETTA): ErrDT (h) â‰ˆ \u0012Eavg Emax \u0013âˆ’Î± PDDDT (h). (13) Observe that Î± = 0 and âˆž result in ErrDT (h) = PDDDT (h) and ErrDT (h) = 1, respectively. Setting a small Î± would result in a lesser penalty with adaptation failures. On the other hand, choosing a high Î± would undesirably penalize model improvement cases. Our experiment found that accuracy estimation is not too sensitive to Î± (Figure 5b), and we chose Î± = 3 for the other experiments. Algorithm 1 AETTA: batchwise TTA accuracy estimation Input: Test batch Xt, model f, number of dropout infer- ences N PDD â† 0 Yavg â† âƒ—0 Ë†Y â† f(Xt; Î˜) for i âˆˆ {1, Â·Â·Â· , N} do Ë†Yd â† f(Xt; Î˜dropouti) Yavg â† Yavg + Avg( Ë†Yd) PDD â† PDD + Avg(1[arg max(Ë†Y) Ì¸= arg max(Ë†Yd)]) Yavg â† 1 N Yavg PDD â† 1 N PDD â–· Avg. over dropouts Eavg â† Ent(Yavg) â–· Entropy of avg. batch Err â† \u0010 Eavg Emax \u0011âˆ’Î± PDD â–· ErrDT (h) Acc â† 1 âˆ’ Err We summarize the accuracy estimation procedure in Algo- rithm 1. We first infer with the adapted model for the current test batch Xt. Then, we repeatedly perform dropout infer- ence sampling. WithN samples from dropout inferences, we estimate the entropy of the batch-aggregated softmax output Eavg. Finally, we calculated the expected error of the model by AETTA. We apply the exponential moving average to the final accuracy estimation for stable error estimation. 4Table 1. Mean absolute error (MAE) (%) of the accuracy estimation on fully TTA (adapting to each corruption type).Bold numbers are the lowest error. Averaged over three different random seeds for 15 types of corruption. TTA Method Dataset Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†“) SrcValid 18.37 Â± 0.29 14.37 Â± 0.33 21.28 Â± 0.27 18.43 Â± 0.16 20.35 Â± 1.31 13.13 Â± 0.85 17.66 Â± 0.24 SoftmaxScore [7] 6.26 Â± 0.49 4.78 Â± 0.12 5.21 Â± 0.22 10.96 Â± 0.28 6.01 Â± 0.23 4.97 Â± 0.50 6.37 Â± 0.10 GDE [21] 18.69 Â± 0.28 16.95 Â± 0.22 21.25 Â± 0.27 14.50 Â± 0.03 23.27 Â± 0.43 16.45 Â± 0.21 18.52 Â± 0.13 AdvPerturb [23] 23.06 Â± 1.17 24.97 Â± 1.00 21.89 Â± 0.95 18.00 Â± 0.82 19.35 Â± 0.99 23.68 Â± 0.85 21.83 Â± 0.92 Fully CIFAR10-C AETTA 4.00 Â± 0.03 3.87 Â± 0.14 3.89 Â± 0.07 6.83 Â± 0.47 6.44 Â± 1.35 5.28 Â± 0.87 5.05 Â± 0.46 SrcValid 38.96 Â± 0.22 10.71 Â± 0.31 42.68 Â± 0.21 44.58 Â± 0.30 23.50 Â± 0.51 19.34 Â± 0.63 29.96 Â± 0.09 SoftmaxScore [7] 17.34 Â± 0.10 27.86 Â± 1.11 24.56 Â± 0.25 34.50 Â± 0.35 24.18 Â± 0.19 23.98 Â± 0.21 25.40 Â± 0.23 GDE [21] 40.11 Â± 0.05 71.53 Â± 2.12 42.51 Â± 0.23 33.21 Â± 0.24 48.02 Â± 0.56 34.24 Â± 0.12 44.94 Â± 0.23 AdvPerturb [23] 24.17 Â± 0.41 8.22 Â± 0.56 22.91 Â± 0.60 20.53 Â± 0.14 17.84 Â± 0.65 25.77 Â± 0.47 19.91 Â± 0.26 Fully CIFAR100-C AETTA 6.89 Â± 0.15 20.15 Â± 1.70 6.54 Â± 0.15 6.05 Â± 0.12 6.88 Â± 0.10 5.29 Â± 0.18 8.63 Â± 0.24 SrcValid 39.13 Â± 0.89 35.89 Â± 0.79 29.77 Â± 0.94 41.09 Â± 0.53 10.28 Â± 0.28 16.00 Â± 0.33 28.69 Â± 0.54 SoftmaxScore [7] 20.67 Â± 0.01 21.06 Â± 0.03 24.42 Â± 0.08 19.62 Â± 0.02 21.03 Â± 0.04 23.60 Â± 0.07 21.73 Â± 0.03 GDE [21] 70.58 Â± 0.01 66.17 Â± 0.07 63.48 Â± 0.03 72.76 Â± 0.02 66.39 Â± 0.04 52.74 Â± 0.02 65.35 Â± 0.02 AdvPerturb [23] 12.56 Â± 0.03 14.52 Â± 0.01 18.76 Â± 0.06 11.05 Â± 0.02 12.93 Â± 0.04 22.90 Â± 0.02 15.45 Â± 0.02 Fully ImageNet-C AETTA 6.14 Â± 0.03 6.48 Â± 0.02 6.43 Â± 0.09 6.02 Â± 0.03 14.82 Â± 0.01 17.40 Â± 0.26 9.55 Â± 0.07 Table 2. Mean absolute error (MAE) (%) of the accuracy estimation on continual TTA (continuously adapting to 15 consecutive corruptions). Bold numbers are the lowest error. Averaged over three different random seeds for 15 types of corruption. TTA Method Dataset Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†“) SrcValid 10.84 Â± 1.83 11.06 Â± 0.11 21.29 Â± 0.26 18.30 Â± 0.25 13.37 Â± 0.89 9.40 Â± 0.85 14.04 Â± 0.58 SoftmaxScore [7] 41.10 Â± 11.66 15.40 Â± 4.73 5.21 Â± 0.22 12.96 Â± 0.37 12.57 Â± 0.43 4.37 Â± 0.09 15.27 Â± 2.51 GDE [21] 46.29 Â± 10.93 26.44 Â± 5.16 21.25 Â± 0.27 14.69 Â± 0.15 17.50 Â± 0.30 17.03 Â± 0.70 23.87 Â± 2.43 AdvPerturb [23] 15.56 Â± 1.53 20.93 Â± 2.83 21.88 Â± 0.93 17.79 Â± 0.74 22.95 Â± 0.82 23.63 Â± 0.78 20.45 Â± 1.17 Continual CIFAR10-C AETTA 9.05 Â± 1.02 7.13 Â± 3.33 3.89 Â± 0.06 5.82 Â± 0.30 5.36 Â± 1.22 4.73 Â± 0.34 6.00 Â± 0.35 SrcValid 11.00 Â± 0.58 1.68 Â± 0.18 38.20 Â± 0.22 46.09 Â± 0.38 19.43 Â± 1.17 17.16 Â± 1.57 22.32 Â± 0.52 SoftmaxScore [7] 58.29 Â± 1.82 76.58 Â± 0.71 24.05 Â± 0.29 36.27 Â± 0.68 27.19 Â± 0.12 21.89 Â± 0.35 40.71 Â± 0.43 GDE [21] 80.87 Â± 1.29 94.01 Â± 0.43 39.21 Â± 0.22 35.43 Â± 0.30 41.68 Â± 0.45 35.29 Â± 0.27 54.41 Â± 0.18 AdvPerturb [23] 10.12 Â± 0.24 1.97 Â± 0.33 24.93 Â± 0.57 19.62 Â± 0.15 21.18 Â± 0.71 25.12 Â± 0.39 17.16 Â± 0.32 Continual CIFAR100-C AETTA 5.85 Â± 0.36 4.18 Â± 0.82 6.67 Â± 0.12 6.55 Â± 0.17 5.86 Â± 0.10 5.32 Â± 0.18 5.74 Â± 0.13 SrcValid 33.30 Â± 0.93 36.42 Â± 0.76 22.30 Â± 0.55 41.06 Â± 0.54 9.56 Â± 0.26 14.28 Â± 0.28 26.15 Â± 0.53 SoftmaxScore [7] 19.34 Â± 0.02 20.16 Â± 0.05 21.91 Â± 0.16 19.63 Â± 0.01 17.56 Â± 0.08 19.67 Â± 0.50 19.71 Â± 0.53 GDE [21] 68.30 Â± 0.01 66.58 Â± 0.03 64.36 Â± 0.15 72.81 Â± 0.07 73.76 Â± 0.22 55.76 Â± 0.45 66.93 Â± 0.14 AdvPerturb [23] 14.82 Â± 0.02 14.15 Â± 0.06 19.17 Â± 0.14 11.06 Â± 0.02 11.05 Â± 0.05 20.83 Â± 0.39 15.18 Â± 0.09 Continual ImageNet-C AETTA 5.66 Â± 0.05 6.73 Â± 0.03 6.68 Â± 0.04 5.98 Â± 0.04 11.19 Â± 0.12 19.22 Â± 0.79 9.24 Â± 0.14 4. Experiments We describe our experimental setup and present the results. Please refer to the Appendix D for further details. Scenario. We consider both fully (non-continual) and contin- ual test-time adaptation scenarios. In the fully TTA setting, target domains are each corruption type [ 34], while in the continual setting, the target domain continually changes to 15 different corruptions [35]. During adaptation, we calcu- late the accuracy estimation for every batch and report the mean absolute error between the ground-truth batch-wise accuracy. We ran experiments with three random seeds (0, 1, 2) and reported the average values. We use the test batch size 64 for all TTA baselines, with a memory size 64 for RoTTA [36] and SoTTA [12]. We specify further details of the hyperparameters in the Appendix D.2. Datasets. We use three standard benchmarks for test-time adaptation: CIFAR10-C, CIFAR100-C, and ImageNet- C [18]. Each dataset contains 15 different corruptions with five levels of corruption, where we use corruption level 5. CIFAR10-C/CIFAR100-C/ImageNet-C contains 10/100/1,000 classes with 10,000/10,000/50,000 test data, respectively. We use pre-trained ResNet18 [17] as an adapta- tion target, following a recent study [12]. TTA Methods. We consider six state-of-the-art TTA meth- ods. TENT [34] updates BN parameters with entropy min- imization. EATA [28] utilizes entropy thresholding-based sample filtering and anti-forgetting regularization. SAR [29] also adapts sample filtering with sharpness minimization [8]. CoTTA [35] addresses the continual setting by augmenta- tions and stochastic restoration of model weights to avoid catastrophic forgetting. RoTTA [36] adapts with robust batch normalization and category-balanced sampling with timeli- ness and uncertainty. SoTTA [12] utilizes high-confidence uniform-sampling and entropy-sharpness minimization for robust adaptation in noisy data streams [8]. 50 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) TENT GroundTruth SrcValid SoftmaxScore GDE AdvPerturb AETTA (Ours) 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) EATA 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) SAR 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) CoTTA (a) CIFAR10-C. 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) TENT 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) EATA 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) SAR 0 1000 2000 Online Batch 0 20 40 60 80 100Accuracy (%) CoTTA (b) CIFAR100-C. 0 5000 10000 Online Batch 0 20 40 60 80 100Accuracy (%) TENT 0 5000 10000 Online Batch 0 20 40 60 80 100Accuracy (%) EATA 0 5000 10000 Online Batch 0 20 40 60 80 100Accuracy (%) SAR 0 5000 10000 Online Batch 0 20 40 60 80 100Accuracy (%) CoTTA (c) ImageNet-C. Figure 4. Qualitative results on continual CIFAR10-C, CIFAR100-C, and ImageNet-C. Accuracy Estimation Baselines. We evaluate four distinct accuracy estimation baselines that could be applied to TTA settings: SrcValid, SoftmaxScore, GDE, and AdvPerturb. â€¢ SrcValid is a widely used technique that validates per- formance by leveraging labeled source data. It computes the accuracy using a hold-out labeled source dataset to estimate the target performance. Importantly, the hold-out source data for validation were not used for training in other baselines to ensure they do not affect the model per- formance. Note that TTA usually assumes that source data are unavailable during test time; hence, this baseline is unrealistic in TTA. We nonetheless include SrcValid as one of our baselines to understand its performance when the source data are accessible. â€¢ SoftmaxScore [7] utilizes the confidence scores derived from the last softmax layer as the modelâ€™s accuracy, which is also a widely used baseline [5, 6]. It estimates the target domain accuracy by averaging softmax confidence scores computed from the current test batch. In addition, we apply temperature scaling [16] to improve the estimation performance [10]. â€¢ Generalization disagreement equality (GDE) [21] aims to estimate test accuracy by quantifying the (dis)agreement rate between predictions on a test batch generated by a pair of models. Since training multiple models is impractical, we compare the current adapted model and the previous model right before the adaptation. We also report a com- parison with the original GDE and multiple pre-trained models in Appendix B. â€¢ Adversarial perturbation ( AdvPerturb) [ 23] also aims to estimate the OOD accuracy by calculating the agree- ment between the domain-adapted model and the source model, where adversarial perturbations on a test batch are applied to penalize the unconfident samples near the de- cision boundary. We note that the original paper aims to predict the accuracy of the source model, while our goal is to predict the accuracy of the adapted model. Results. Table 1 and Table 2 show the results on the fully and continual TTA settings. We observe that none of the baselines could reliably predict the accuracy among different scenarios. On the other hand, AETTA achieves the lowest mean absolute error, including adaptation failure cases (e.g., TENT in continual CIFAR10/100-C). On average, AETTA outperforms baselines by 19.8%p, validating the effective- ness of our robust prediction disagreement in diverse scenar- ios. More details are in the Appendix F. 6TENT EATA SARCoTTARoTTASoTTA 0 2 4 6 8 10MAE (%) 5 10 15 (a) Number of dropout inferences N. TENTEATA SARCoTTARoTTASoTTA 0 20 40 60 80 100MAE (%) 0 (PDD) 1 2 3 4 5 (b) Scaling hyperparameter Î±. Figure 5. Impact of hyperparameters on the accuracy estimation performance. Qualitative Analysis. We qualitatively analyze the results of the baselines and AETTA to understand the behavior. Figure 4 visualizes the ground-truth accuracy and the estimated accuracy from the baselines and AETTA under adaptation failure and non-failure cases. The Gaussian filter is applied for visualization. We observe that AETTA generally shows a reliable estimation of the ground-truth accuracy in diverse scenarios (fully and continual) and datasets (CIFAR10/100-C and ImageNet-C). SrcValid cor- rectly estimated when model accuracy decreases; however, it consistently predicted high accuracy when the adaptation did not fail. This limitation might be due to the distributional gap between source and target data. SoftmaxScore [ 7] captures the trend of ground-truth accuracy in some cases, but it overestimates the accuracy when the model accuracy drops. This is mostly due to the over-confident predictions from the model. GDE [ 21] showed to constantly predict high values among different TTA methods. Note that GDE was originally designed to utilize various pre-trained models. To use GDE in TTA, we utilize adapted models sampled at different stages of adaptation. The result suggests that utilizing multiple models from the single stochastic learning process might not be sufficient to consist of independent and identically distributed (i.i.d.) ensembles, leading to inaccurate estimation. AdvPerturb [ 23] shows accuracy estimations when ground-truth accuracy decreases but shows high errors in other cases. We believe this happens because it aims to evaluate the performance of the source model, not the adapted model. We found similar patterns were observed with different TTA methods. Impact of Hyperparameter N. The number of dropout in- ferences, N, is a hyperparameter for calculating the test error. We conducted an ablation study in continual CIFAR100-C with varying N âˆˆ {5, 10, 15}. As shown in Figure 5a, we found the effect of hyperparameter N is negligible. We inter- pret this result as the effect of calculating prediction disagree- ment over sufficient batch size with dropout independence, which could reduce the probabilistic variances from dropout inference sampling. We adopt a single value of N = 10 for the other experiments. Impact of Hyperparameter Î±. We investigate the im- pact of Î±, a hyperparameter to control the strength of ro- bust confidence-prediction calibration. We conduct an ab- lation study in continual CIFAR100-C with varying Î± âˆˆ {0, . . . ,5}, where Î± = 0 indicates no weighting, thus Err = PDD. Figure 5b shows the result. Note that estima- tions are often inaccurate when Î± = 0 , which shows the importance of our robust equality. Setting a reasonable Î± is important to predict failed adaptation cases (TENT and EATA) properly, but it is generally robust after certain values. We adopt Î± = 3 for the other experiments. 5. Case Study: Model Recovery The deployment of TTA algorithms encounters a significant challenge when exposed to extreme test streams, such as continuously changing corruptions [ 35]. Several TTA algorithms (e.g., TENT [34]) were not designed to exhibit robustness under such extreme conditions. Consequently, the model weights are poorly updated, leading to perfor- mance degradation, even worse than the source model. Although recent studies attempt to manage dynamic test streams [11, 12, 35], TTA algorithms are still susceptible to adaptation failures [30]. To tackle the issue, we perform a case study of model recovery based on the accuracy estimation. Recovery Algorithm. We introduce a simple reset algorithm based on our accuracy estimation with AETTA. Our reset algorithm detects two cases: (1) consecutive low accuracies and (2) sudden accuracy drop. First, we reset the model if the five recent consecutive estimated accuracies ( e.g., t âˆ’ 4, Â·Â·Â· , t) are lower than the five previous consecutive estimations (e.g., t âˆ’ 9, Â·Â·Â· , tâˆ’ 5). This way, we can detect the gradual degradation of TTA accuracy. Second, we apply hard lower-bound thresholding, which resets the model if the estimated accuracy is below the threshold ( e.g., 0.2). This could prevent catastrophic failure of TTA algorithms. Baselines. Some TTA studies covered the model recov- ery/reset as a part of the TTA algorithm: Episodic resetting (Episodic) [37], where the model resets after every batch; Model Recovery Scheme (MRS) [29], where the model re- sets when the moving average of entropy loss falls below a certain threshold; Stochastic restoration (Stochastic) [35], where a small number of model weights are stochastically restored to the initial weight of the source model; and Fisher information based restoration (FisherStochastic) [3], which applies stochastic restoration for layer importance measured by Fisher information matrix. We also include a baseline (DistShift), which assumes that the model knows when the distribution changes and thus acts as an oracle. DistShift resets the model when the test data distribution (corruption) changes, which is not feasible in practice. 7Table 3. Average accuracy improvement (%p) with model recovery.Bold number is the highest improvement. Averaged over three different random seeds for 15 types of corruption. TTA Method Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†‘) Episodic [37] 33.58 Â± 1.04 51.28 Â± 0.52 -7.00 Â± 0.26 1.65 Â± 0.10 -22.57 Â± 0.85 -26.40 Â± 0.51 5.09 Â± 0.24 MRS [29] 24.12 Â± 2.11 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 -1.97 Â± 2.23 0.00 Â± 0.00 3.69 Â± 0.22 Stochastic [35] 35.93 Â± 0.78 -0.01 Â± 0.47 -2.00 Â± 0.48 0.00 Â± 0.00 -2.55 Â± 0.49 0.35 Â± 0.51 5.29 Â± 0.19 FisherStochastic [3] 40.27 Â± 1.29 0.12 Â± 1.16 -4.85 Â± 0.13 0.13 Â± 0.03 -2.89 Â± 0.13 -1.36 Â± 0.51 5.24 Â± 0.29 DistShift 38.93 Â± 1.15 22.17 Â± 2.38 -3.25 Â± 0.10 1.51 Â± 0.09 -7.63 Â± 0.23 0.68 Â± 0.19 8.74 Â± 0.55 AETTA 36.79 Â± 1.20 48.64 Â± 0.74 -5.66 Â± 0.20 1.64 Â± 0.11 -6.03 Â± 0.89 -4.97 Â± 1.58 11.73 Â± 0.34 0 50 100 150 200 Online Batch 0 20 40 60 80 100Accuracy (%) AETTA Acc. w\\o Recovery Acc. w\\ Recovery Reset 0 50 100 150 200 Online Batch 0 20 40 60 80 100Accuracy (%) DistShift Figure 6. An example of model recovery compared with DistShift. Reset points are marked over the x-axis. Results. Our simple recovery algorithm outperforms the baselines, including DistShift, which relies on an impractical assumption of knowing when the corruption changes. Episodic [37] showed high accuracy improvements under adaptation failures; however, it prevents continuous adaptation, even without adaptation failures. MRS [ 29] fails to recover among various TTA methods due to the hard-coded threshold of loss value. Stochastic [ 35] and FisherStochastic [ 3] show marginal improvements while failing to recover EATA. Our proposed reset algorithm successfully recovers from adaptation failures while minimizing the negative effect on TTA without failures. Qualitative Analysis. Figure 6 shows an example of our model recovery compared with DistShift. Notably, our re- covery algorithm resets only when an accuracy degradation trend is detected. On the other hand, DistShift failed to re- cover in the early steps since it resets the model only on distribution shifts. This implies that estimating performance degradation is more beneficial than knowing when the do- main changes to improve TTA performance. 6. Related Work Test-Time Adaptation. Recent progress in the field of test-time adaptation (TTA) has focused on improving model robustness [2, 11, 12, 28, 29, 35, 36] and addressing novel forms of domain shifts [11, 12, 35]. On the other hand, an analysis [30] pointed out the conventional TTA approaches remain prone to adaptation failures and demonstrated the importance of model recovery. In alignment with this insight, our work not only showcases the feasibility of accuracy estimation for TTA but also investigates a promising model recovery solution to enhance the robustness of TTA. Accuracy Estimation. Existing accuracy estimation ap- proaches mainly focus on the ensemble of multiple pre- trained models [1, 5, 15, 21, 27]. Accuracy-on-the-line [27] and Agreement-on-the-line [1] have demonstrated a notable linear relationship between performances in a wide range of models and distribution shifts, relying on the consistency of model predictions between in-distribution (ID) and out- of-distribution (OOD) data. The Difference of Confidence (DoC) [15] leverages differences in the modelâ€™s confidence between ID and OOD data to estimate the accuracy gap under distribution shifts for calculating the final OOD accu- racy. Self-training ensemble [5] estimates the accuracy of the pre-trained classifier by iteratively learning an ensemble of models with a training dataset, unlabeled test dataset, and wrongly classified samples. All these methods require la- beled ID data to estimate OOD accuracy. To our knowledge, no existing studies target the accuracy estimation in TTA where source data and labels are unavailable. 7. Conclusion We proposed a label-free TTA performance estimation method without access to source data and target labels. Based on the dropout inference sampling, we proposed calculating the prediction disagreement to estimate the TTA accuracy. We further improved the method with robust disagreement equality by utilizing the batch-aggregated distribution to pe- nalize skewed predictions. Our method outperformed the baselines in diverse scenarios and datasets. Finally, our case study of model recovery showed the practicality of accuracy estimation. Our findings suggest that accuracy estimation is not only feasible but also a valuable tool in advancing the field of TTA without the need for labeled data. Acknowledgements This work was supported by the Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2022-0- 00495, On-Device V oice Phishing Call Detection). 8References [1] Christina Baek, Yiding Jiang, Aditi Raghunathan, and J. Zico Kolter. Agreement-on-the-line: Predicting the performance of neural networks under distribution shift. In Advances in Neural Information Processing Systems, pages 19274â€“19289. Curran Associates, Inc., 2022. 1, 2, 8 [2] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8344â€“8353, 2022. 1, 8 [3] Dhanajit Brahma and Piyush Rai. A probabilistic frame- work for lifelong test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 3582â€“3591, 2023. 7, 8, 17, 24 [4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub- biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakan- tan, Pranav Shyam, Girish Sastry, Amanda Askell, Sand- hini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jef- frey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few- shot learners. In Advances in Neural Information Processing Systems, pages 1877â€“1901. Curran Associates, Inc., 2020. 1 [5] Jiefeng Chen, Frederick Liu, Besim Avci, Xi Wu, Yingyu Liang, and Somesh Jha. Detecting errors and estimating accuracy on unlabeled data with self-training ensembles. In Advances in Neural Information Processing Systems, pages 14980â€“14992. Curran Associates, Inc., 2021. 1, 2, 6, 8 [6] Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka. Estimating generalization under distribution shifts via domain- invariant representations. In Proceedings of the 37th Interna- tional Conference on Machine Learning, pages 1984â€“1994. PMLR, 2020. 6 [7] Hady Elsahar and Matthias GallÂ´e. To annotate or not? predict- ing performance drop under domain shift. In Proceedings of the 2019 Conference on Empirical Methods in Natural Lan- guage Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2163â€“2173, 2019. 5, 6, 7, 14, 15, 18, 19, 20, 21, 22, 23 [8] Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. In International Conference on Learning Representations, 2021. 5, 16 [9] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learn- ing. In Proceedings of The 33rd International Conference on Machine Learning, pages 1050â€“1059, New York, New York, USA, 2016. PMLR. 2, 3 [10] Saurabh Garg, Sivaraman Balakrishnan, Zachary Chase Lip- ton, Behnam Neyshabur, and Hanie Sedghi. Leveraging un- labeled data to predict out-of-distribution performance. In International Conference on Learning Representations, 2022. 6 [11] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. NOTE: Robust continual test- time adaptation against temporal correlation. In Advances in Neural Information Processing Systems, 2022. 1, 7, 8, 16 [12] Taesik Gong, Yewon Kim, Taeckyung Lee, Sorn Chottananu- rak, and Sung-Ju Lee. SoTTA: Robust test-time adaptation on noisy data streams. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. 1, 2, 5, 7, 8, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24 [13] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Commun. ACM, 63(11):139â€“144, 2020. 1 [14] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014. 15 [15] Devin Guillory, Vaishaal Shankar, Sayna Ebrahimi, Trevor Darrell, and Ludwig Schmidt. Predicting with confidence on unseen distributions. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 1134â€“1144, 2021. 1, 2, 8 [16] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning, pages 1321â€“1330. PMLR, 2017. 6, 15 [17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. 1, 5, 15, 16 [18] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations , 2019. 2, 5, 16 [19] Dan Hendrycks and Kevin Gimpel. A baseline for detect- ing misclassified and out-of-distribution examples in neural networks. In International Conference on Learning Repre- sentations, 2017. 4 [20] Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, and Michael Spranger. MECTA: Memory-economic continual test-time model adaptation. In The Eleventh International Conference on Learning Representations, 2023. 15 [21] Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, and J Zico Kolter. Assessing generalization of sgd via disagree- ment. In International Conference on Learning Representa- tions, 2021. 2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23 [22] Diederick P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. 16 [23] JoonHo Lee, Jae Oh Woo, Hankyu Moon, and Kwonho Lee. Unsupervised accuracy estimation of deep visual models us- ing domain-adaptive adversarial perturbation without source samples. In Proceedings of the IEEE/CVF International Con- ference on Computer Vision (ICCV) , pages 16443â€“16452, 2023. 5, 6, 7, 14, 15, 18, 19, 20, 21, 22, 23 [24] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. In Advances in 9Neural Information Processing Systems, pages 21464â€“21475. Curran Associates, Inc., 2020. 4 [25] Ilya Loshchilov and Frank Hutter. SGDR: Stochastic gradient descent with warm restarts. In International Conference on Learning Representations (ICLR), 2017. 16 [26] TorchVision maintainers and contributors. Torchvision: Py- torchâ€™s computer vision library. https://github.com/ pytorch/vision, 2016. 16 [27] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in- distribution generalization. In Proceedings of the 38th Inter- national Conference on Machine Learning, pages 7721â€“7735. PMLR, 2021. 1, 2, 8 [28] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In Proceedings of the 39th International Conference on Machine Learning, pages 16888â€“16905. PMLR, 2022. 1, 2, 5, 8, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24 [29] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In The Eleventh International Conference on Learning Representations, 2023. 1, 2, 5, 7, 8, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24 [30] Ori Press, Steffen Schneider, Matthias K Â¨ummerer, and Matthias Bethge. Rdumb: A simple approach that questions our progress in continual test-time adaptation. In Thirty- seventh Conference on Neural Information Processing Sys- tems, 2023. 1, 7, 8 [31] Joaquin Qui Ëœnonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in ma- chine learning. Mit Press, 2008. 2 [32] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U- net: Convolutional networks for biomedical image segmenta- tion. In Medical Image Computing and Computer-Assisted Intervention â€“ MICCAI 2015, pages 234â€“241, Cham, 2015. Springer International Publishing. 1 [33] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- reit, Llion Jones, Aidan N Gomez, Å ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neu- ral Information Processing Systems. Curran Associates, Inc., 2017. 1 [34] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. 1, 2, 3, 5, 7, 8, 14, 16, 18, 19, 20, 21, 22, 23, 24 [35] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 7201â€“7211, 2022. 1, 2, 5, 7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24 [36] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test- time adaptation in dynamic scenarios. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 15922â€“15932, 2023. 1, 2, 5, 8, 14, 16, 18, 19, 20, 21, 22, 23, 24 [37] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In Advances in Neural Information Processing Systems, pages 38629â€“38642. Curran Associates, Inc., 2022. 7, 8, 17, 24 10AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation Supplementary Material A. Proof of Theorems A.1. Proof of Theorem 3.1 We start expanding test error Err with few modifications from GDE [21]: Ehâˆ¼HA[ErrDT (h)] (14) â‰œ EHA[EDT [1(h(X; Î˜) Ì¸= Y )]] (15) = EDT [EHA[1(h(X; Î˜) Ì¸= Y )] (exchanging expectations) (16) = EDT [1 âˆ’ ËœhY (X)] (17) = Kâˆ’1X k=0 Z x (1 âˆ’ Ëœhk(x)) p(X = x, Y= k)dx (by definition of expectation) (18) = Z qâˆˆâˆ†K Kâˆ’1X k=0 Z x (1 âˆ’ Ëœhk(x)) p(X = x, Y= k, Ëœh(X) = q)dxdq (introducing Ëœh as a r.v.) (19) = Z qâˆˆâˆ†K Kâˆ’1X k=0 Z x (1 âˆ’ Ëœhk(x)) p(Y = k, Ëœh(X) = q)p(X = x|Y = k, Ëœh(X) = q)dxdq (20) = Z qâˆˆâˆ†K Kâˆ’1X k=0 p(Y = k, Ëœh(X) = q) Z x (1 âˆ’ Ëœhk(x)| {z } =qk ) p(X = x|Y = k, Ëœh(X) = q)dxdq (21) = Z qâˆˆâˆ†K Kâˆ’1X k=0 p(Y = k, Ëœh(X) = q) Z x (1 âˆ’ qk)| {z } constant w.r.t. R x p(X = x|Y = k, Ëœh(X) = q)dxdq (22) = Z qâˆˆâˆ†K Kâˆ’1X k=0 p(Y = k, Ëœh(X) = q)(1 âˆ’ qk) Z x p(X = x|Y = k, Ëœh(X) = q)dx | {z } =1 dq (23) = Z qâˆˆâˆ†K Kâˆ’1X k=0 p(Y = k, Ëœh(X) = q)(1 âˆ’ qk)dq (24) = Z qâˆˆ[0,1] Kâˆ’1X k=0 p(Y = k, Ëœhk(X) = q)(1 âˆ’ q)dq (refer [21]) (25) = Z qâˆˆ[0,1] Kâˆ’1X k=0 p(Y = k|Ëœhk(X) = q)| {z } =q p(Ëœhk(X) = q)(1 âˆ’ q)dq (26) = Z qâˆˆ[0,1] q(1 âˆ’ q) Kâˆ’1X k=0 p(Ëœhk(X) = q)dq. (confidence-prediction calibration) (27) 11Then, we expand the prediction disagreement with dropouts (PDD) from its definition: Ehâˆ¼HA[PDDDT (h)] (28) â‰œ EHA ï£® ï£¯ï£°EDT ï£® ï£° 1 N NX i=1 1[h(X; Î˜) Ì¸= h(X; Î˜dropouti)] ï£¹ ï£» ï£¹ ï£ºï£» (29) = EDT ï£® ï£¯ï£°EHA ï£® ï£° 1 N NX i=1 1[h(X; Î˜) Ì¸= h(X; Î˜dropouti)] ï£¹ ï£» ï£¹ ï£ºï£» (exchanging expectations) (30) = EDT ï£® ï£¯ï£°EHA ï£® ï£° 1 N NX i=1 Kâˆ’1X k=0 1[h(X; Î˜) = k](1 âˆ’ 1[h(X; Î˜dropouti) = k]) ï£¹ ï£» ï£¹ ï£ºï£» (31) = EDT ï£® ï£° Kâˆ’1X k=0 1 N NX i=1 EHA \u0002 1[h(X; Î˜) = k](1 âˆ’ 1[h(X; Î˜dropouti) = k]) \u0003 ï£¹ ï£» (32) = EDT ï£® ï£° Kâˆ’1X k=0 EHA \u0002 1[h(X; Î˜) = k] \u0003 EHA[1 âˆ’ 1 N NX i=1 1[h(X; Î˜dropouti) = k]] ï£¹ ï£» (Dropout independence (Definition 3.1)) (33) = EDT ï£® ï£° Kâˆ’1X k=0 Ëœhk(X)(1 âˆ’ Ëœhk(X)) ï£¹ ï£» (34) = Z x Kâˆ’1X k=0 Ëœhk(x)(1 âˆ’ Ëœhk(x))p(X = x)dx (by definition of expectation) (35) = Z qâˆˆâˆ†K Z x Kâˆ’1X k=0 Ëœhk(x)(1 âˆ’ Ëœhk(x))p \u0010 X = x, Ëœh(X) = q \u0011 dxdq (introducing Ëœh as a r.v.) (36) = Z qâˆˆâˆ†K p(Ëœh(X) = q) Z x Kâˆ’1X k=0 Ëœhk(x)(1 âˆ’ Ëœhk(x))| {z } Ëœhk(x)=qk p \u0010 X = x|Ëœh(X) = q \u0011 dxdq (37) = Z qâˆˆâˆ†K p(Ëœh(X) = q) Z x Kâˆ’1X k=0|{z} bring to the front qk(1 âˆ’ qk)p(X = x|Ëœh(X) = q)dxdq (38) = Kâˆ’1X k=0 Z qâˆˆâˆ†K p(Ëœh(X) = q) Z x qk(1 âˆ’ qk)| {z } constant w.r.t. R x p(X = x|Ëœh(X) = q)dxdq (39) = Kâˆ’1X k=0 Z qâˆˆâˆ†K | {z } swap p(Ëœh(X) = q)qk(1 âˆ’ qk) Z x p(X = x|Ëœh(X) = q)dx | {z } =1 dq (40) = Z qâˆˆâˆ†K Kâˆ’1X k=0 qk(1 âˆ’ qk)p(Ëœh(X) = q)dq (41) = Z qâˆˆ[0,1] q(1 âˆ’ q) Kâˆ’1X k=0 p(Ëœhk(X) = q)dq. (refer [21]) (42) 12Equation 27 is equivalent to Equation 42: Ehâˆ¼HA[ErrDT (h)] = Ehâˆ¼HA[PDDDT (h)], (43) which concludes the proof of Theorem 3.1. A.2. Proof of Theorem 3.2 From robust confidence-prediction calibration, the over-confident modelâ€™s conditional probability of the major class kâ€² is scaled by a, while other classesâ€™ conditional probabilities are equally scaled up by b. Then, Equation 27 now becomes: Ehâˆ¼HA[ErrDT (h)] (44) = Z qâˆˆ[0,1] Kâˆ’1X k=0 p(Y = k|Ëœhk(X) = q)p(Ëœhk(X) = q)(1 âˆ’ q)dq (45) = Z qâˆˆ[0,1] p(Y = kâ€²|Ëœhkâ€²(X) = q)p(Ëœhkâ€²(X) = q)(1 âˆ’ q) + X kÌ¸=kâ€² p(Y = k|Ëœhk(X) = q)p(Ëœhk(X) = q)(1 âˆ’ q)dq (46) = Z qâˆˆ[0,1] aq p(Ëœhkâ€²(X) = q)(1 âˆ’ q) + X kÌ¸=kâ€² bq p(Ëœhk(X) = q)(1 âˆ’ q)dq (robust confidence-prediction calibration) (47) = Z qâˆˆ[0,1] aq(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq + b Z qâˆˆ[0,1] X kÌ¸=kâ€² q(1 âˆ’ q) p(Ëœhk(X) = q)dq. (48) We rewrite Equation 48 as: Z qâˆˆ[0,1] X kÌ¸=kâ€² q(1 âˆ’ q) p(Ëœhk(X) = q)dq = 1 b Ehâˆ¼HA[ErrDT (h)] âˆ’ Z qâˆˆ[0,1] a b q(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq. (49) Then, we rewrite PDD (Equation 42): Ehâˆ¼HA[PDDDT (h)] (50) = Z qâˆˆ[0,1] q(1 âˆ’ q) Kâˆ’1X k=0 p(Ëœhk(X) = q)dq (51) = Z qâˆˆ[0,1] q(1 âˆ’ q) p(Ëœhkâ€²(X) = q) + q(1 âˆ’ q) X kÌ¸=kâ€² p(Ëœhk(X) = q)dq (52) = Z qâˆˆ[0,1] q(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq + Z qâˆˆ[0,1] q(1 âˆ’ q) X kÌ¸=kâ€² p(Ëœhk(X) = q)dq (53) = Z qâˆˆ[0,1] b âˆ’ a b q(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq + 1 b Ehâˆ¼HA[ErrDT (h)]. (Equation 49) (54) Finally, we obtain the equality between Err and PDD: Ehâˆ¼HA[ErrDT (h)] (55) = b Ehâˆ¼HA[PDDDT (h)] âˆ’ Z qâˆˆ[0,1] (b âˆ’ a) q(1 âˆ’ q) p(Ëœhkâ€²(X) = q)dq, (56) which concludes the proof of Theorem 3.2. Note that without weighting (a = b = 1), the result is identical to Theorem 3.1. 13B. Additional Experiments GDE with multiple pre-trained models. We compare AETTA with the original version of GDE (denoted as GDE*), utilizing multiple pre-trained models with access to training data. We report the result in Table 4. Due to the misalignment of confidence-prediction calibration, GDE* underperforms AETTA even with full access to source data. Table 4. Mean absolute error (MAE) (%) of the accuracy estimation on continual CIFAR100-C. TTA Method Dataset Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†“) GDE* [21] 14.54 Â± 8.14 4.11 Â± 2.43 7.27 Â± 0.16 9.89 Â± 0.29 7.44 Â± 0.13 5.79 Â± 0.23 8.17 Â± 0.87Continual CIFAR100-C AETTA 5.85 Â± 0.36 4.18 Â± 0.82 6.67 Â± 0.12 6.55 Â± 0.17 5.86 Â± 0.10 5.32 Â± 0.18 5.74 Â± 0.13 ImageNet-R. To demonstrate the dataset generality of AETTA, we report the accuracy estimation result on ResNet18 architecture on ImageNet-R (Table 5). AETTA outperformed the baselines in all TTA methods, showing AETTA is applicable in various datasets (e.g., CIFAR10-C, CIFAR100-C, ImageNet-C, and ImageNet-R). Table 5. Mean absolute error (MAE) (%) of the accuracy estimation on ResNet18 on ImageNet-R. Bold numbers are the lowest error. Averaged over three different random seeds. TTA Method Dataset Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†“) SrcValid 37.00 Â± 0.14 37.91 Â± 0.18 36.58 Â± 0.24 35.05 Â± 0.16 34.43 Â± 0.05 37.82 Â± 0.41 36.46 Â± 0.05 SoftmaxScore [7] 10.79 Â± 0.17 13.87 Â± 0.09 15.02 Â± 0.14 14.76 Â± 0.07 14.08 Â± 0.04 12.25 Â± 0.42 13.46 Â± 0.06 GDE [21] 62.81 Â± 0.12 61.36 Â± 0.14 63.27 Â± 0.18 64.86 Â± 0.10 62.64 Â± 0.12 55.23 Â± 0.29 61.70 Â± 0.02 AdvPerturb [23] 13.42 Â± 0.28 16.04 Â± 0.36 17.90 Â± 0.28 21.19 Â± 0.22 31.12 Â± 0.12 9.91 Â± 0.73 18.26 Â± 0.03 ImageNet-R AETTA 8.02 Â± 0.12 6.87 Â± 0.08 7.06 Â± 0.19 7.07 Â± 0.11 8.63 Â± 0.19 6.79 Â± 0.29 7.41 Â± 0.05 ResNet50. To demonstrate the model generality of AETTA, we report the accuracy estimation result on ResNet50 architecture on ImageNet-C (Table 6). AETTA outperformed the baselines in general, showing AETTA is applicable to diverse model architectures. Table 6. Mean absolute error (MAE) (%) of the accuracy estimation on ResNet50 on ImageNet-C. Bold numbers are the lowest error. Averaged over three different random seeds for 15 types of corruption. TTA Method Dataset Method TENT [34] EATA [28] SAR [29] CoTTA [35] RoTTA [36] SoTTA [12] Avg. (â†“) SrcValid 46.46 Â± 0.15 34.19 Â± 0.67 30.35 Â± 0.75 46.47 Â± 0.17 12.28 Â± 0.11 19.28 Â± 0.18 31.50 Â± 0.26 SoftmaxScore [7] 23.58 Â± 0.03 24.14 Â± 0.04 26.22 Â± 0.05 23.57 Â± 0.04 24.32 Â± 0.02 17.87 Â± 0.24 23.28 Â± 0.03 GDE [21] 68.39 Â± 0.04 57.08 Â± 0.08 55.81 Â± 0.06 68.36 Â± 0.04 58.69 Â± 0.09 48.15 Â± 0.33 59.41 Â± 0.04 AdvPerturb [23] 12.77 Â± 0.04 21.16 Â± 0.05 23.66 Â± 0.08 12.77 Â± 0.05 16.44 Â± 0.00 25.28 Â± 0.32 18.68 Â± 0.05 Fully ImageNet-C AETTA 6.14 Â± 0.05 9.15 Â± 0.03 8.50 Â± 0.07 6.15 Â± 0.04 28.28 Â± 0.03 36.90 Â± 0.36 15.85 Â± 0.09 SrcValid 46.38 Â± 0.10 35.83 Â± 0.74 24.35 Â± 1.86 46.46 Â± 0.22 13.79 Â± 0.16 5.12 Â± 0.29 28.65 Â± 0.46 SoftmaxScore [7] 23.58 Â± 0.03 21.34 Â± 0.06 16.64 Â± 0.25 23.61 Â± 0.01 19.99 Â± 0.25 51.60 Â± 0.75 26.13 Â± 0.12 GDE [21] 68.36 Â± 0.03 58.41 Â± 0.14 60.20 Â± 0.24 68.38 Â± 0.01 68.98 Â± 0.52 86.08 Â± 0.36 68.40 Â± 0.09 AdvPerturb [23] 12.80 Â± 0.04 19.82 Â± 0.12 21.50 Â± 0.14 12.77 Â± 0.02 13.77 Â± 0.35 4.79 Â± 0.17 14.24 Â± 0.07 Continual ImageNet-C AETTA 6.15 Â± 0.05 10.81 Â± 0.01 6.41 Â± 0.08 6.00 Â± 0.04 14.90 Â± 0.30 4.21 Â± 0.12 8.08 Â± 0.04 14C. Discussion Potential Societal Impact. The computational overheads associated with test-time adaptation (TTA) could raise environ- mental concerns, particularly regarding carbon emissions. Our algorithm introduces N extra model inferences for accuracy estimation. Importantly, our approach of utilizing dropout inference is computationally lightweight compared to baseline methods involving model retraining [21] and adversarial backpropagation [23]. Recent advancements, such as the memory- economic TTA [20], are anticipated to tackle these challenges effectively. This implies that, despite the computational demands, the environmental impact of our approach could be mitigated by integrating emerging strategies for resource-efficient TTA implementations. Limitations and Future Directions. Our research investigates the possibility of accuracy estimation for TTA with only unlabeled data. A promising direction for further improvements is the (1) optimization of the weighting constant b (or corresponding a), which stands to fine-tune the calibration process, and (2) estimation of the variable C for more precise error estimates. Also, we presented a case study on model recovery to demonstrate the practicality of accuracy estimation. While we chose a heuristic method to reset the model for the simplicity of analysis, there exists room for improvement to be more effective. Beyond model recovery, we also envision the potential of accuracy estimation in broader applications, such as model refinement and maintenance processes, and enhancing the dynamics of human-AI interactions, which we leave as future work. D. Experiment Details We conducted all experiments under three random seeds (0, 1, 2) and reported the average values with standard deviations. The experiments were performed on NVIDIA GeForce RTX 3090 and NVIDIA TITAN RTX GPUs. D.1. Accuracy Estimation Details AETTA (Ours). We used the number of dropout inference samples N = 10 and prediction disagreement weighting hyperparameter Î± = 3 for all experiments. The maximum entropy for the model Emax is calculated as Emax = Ent(âƒ—1K/K) where K is a number of classes and âƒ—1K is one vector with size K; which results in 2.3, 4.6, and 6.9 for 10, 100, and 1,000 classes. We applied the Dropout module for each residual block layer in ResNet18 [17], where the dropout rate is 0.4, 0.3, and 0.2 for 10, 100, and 1,000 classes, following previous studies which apply different hyperparameters for different numbers of classes [12, 28, 35]. SrcValid. For SrcValid, we used labeled source-domain validation data and calculated the accuracy. We used 1,000 random samples from the validation set of the source dataset. SoftmaxScore. For SoftmaxScore [7], we utilized the average softmax score for the current test batch as the estimated accuracy. We additionally applied temperature scaling [16] with temperature value T = 2, which showed the best estimation performance on CIFAR10-C, to enhance the estimation performance. GDE. For generalization disagreement equality (GDE) [ 21], we calculated the (dis)agreement rate between predictions of the test batch over a pair of models. Unlike the setting in domain adaptation of utilizing multiple pre-trained models, we utilized the models in different adaptation stages. Specifically, we compared the two models: (1) the currently adapted model and (2) the previous model right before the adaptation. This follows the suggestion that utilizing only two models is sufficient to calculate disagreement [21]. AdvPerturb. Adversarial perturbation [23] estimates the source model accuracy by calculating the agreement between the domain-adapted and source models by applying adversarial perturbation on the source model side. In the TTA setting, we compared the test-time-adapted model with the source model and applied the FGSM [14] adversarial attack with attack size following the original paper (Ïµ = 1/255). D.2. TTA Method Details In this study, we followed the official implementation of TTA methods. To maintain consistency, we adopted the optimal hyperparameters reported in the corresponding papers or source code repositories. We also provide additional implementation details and the use of hyperparameters if not specified in the original paper or the source code. 15TENT. For TENT [34], we configured the learning rate as LR = 0.001 for CIFAR10-C/CIFAR100-C andLR = 0.00025 for ImageNet-C, aligning with the guidelines outlined in the original paper. The implementation followed the official code.3 EATA. For EATA [28], we followed the original configuration of LR = 0.005/0.005/0.00025 for CIFAR10-C/CIFAR100- C/ImageNet-C, entropy constant E0 = 0.4 Ã— ln K, where K represents the number of classes. Additionally, we set the cosine sample similarity threshold Ïµ = 0.4/0.4/0.05, trade-off parameter Î² = 1/1/2, 000, and moving average factor Î± = 0.1. The Fisher importance calculation involved 2,000 samples, as recommended. The implementation followed the official code.4 SAR. For SAR [29], we selected a batch size 64 for fair comparisons. We set a learning rate of LR = 0.00025, sharpness threshold Ï = 0.5, and entropy threshold E0 = 0.4 Ã— lnK, following the recommendations from the original paper. The top layer (layer 4 for ResNet18) was frozen, consistent with the original paper. The implementation followed the official code.5 CoTTA. For CoTTA [35], we set the restoration factor p = 0.01, and exponential moving average (EMA) factor Î± = 0.999. For augmentation confidence threshold pth, we followed the authorsâ€™ guidelines as pth = 0.92 for CIFAR10-C, pth = 0.72 for CIFAR100-C, and pth = 0.1 for ImageNet-C. The implementation followed the official code.6 RoTTA. For RoTTA [36], we utilized the Adam optimizer [ 22] with a learning rate of LR = 0.001 and Î² = 0.9. We followed the original hyperparameters, including BN-statistic exponential moving average updating rateÎ± = 0.05, Teacher modelâ€™s exponential moving average updating rate Î½ = 0.001, timeliness parameter Î»t = 1.0, and uncertainty parameter Î»u = 1.0. The implementation followed the original code.7 SoTTA. For SoTTA [12], the Adam optimizer [22] was employed, featuring a BN momentum ofm = 0.2 and a learning rate of LR = 0.001 with a single adaptation epoch. The memory size was set to 64, with the confidence threshold C0 configured as 0.99 for CIFAR10-C (10 classes), 0.66 for CIFAR100-C (100 classes), and 0.33 for ImageNet-C (1,000 classes). The entropy-sharpness L2-norm constraint Ï was set to 0.5, aligning with the suggestion [8]. The top layer was frozen following the original paper. The implementation followed the original code.8 D.3. Experiment Setting Details Datasets. CIFAR10-C/CIFAR100-C/ImageNet-C [18] are the most widely used benchmarks for test-time adaptation (TTA) [11, 12, 28, 29, 34â€“36]. All datasets contain 15 corruption types, including Gaussian, Snow, Frost, Fog, Brightness, Contrast, Elastic Transformation, Pixelate, and JPEG Compression. Each corruption is applied in 5 levels of severity, where we adopt the highest severity level of 5. CIFAR10-C and CIFAR100-C consist of 50,000 train images and 10,000 test images for 10 and 100 classes. ImageNet-C consists of 1,281,167 train images and 50,000 test images for 1,000 classes. Pre-Training. We employed the ResNet18 [ 17] as the backbone network. The model is trained for each CIFAR10- C/CIFAR100-C/ImageNet-C on the training dataset. For CIFAR10-C/CIFAR100-C, we utilized the stochastic gradient descent with a batch size of 128, a learning rate of 0.1, and a momentum of 0.9, with cosine annealing learning rate scheduling [25] for 200 epochs. For ImageNet-C, we utilized the pre-trained model from TorchVision [26]. Test-Time Adaptation. For the fully TTA, each TTA method adapts to one corruption at a time. For thecontinual TTA, each TTA method continually adapts to 15 corruptions in the predefined order of [Gaussian, Snow, Frost, Fog, Brightness, Contrast, Elastic Transformation, Pixelate, and JPEG Compression], following the previous study [35]. For all experiments, we use the batch size of 64, with memory size 64 for RoTTA [36] and SoTTA [12] for a fair comparison. 3https://github.com/DequanWang/tent 4https://github.com/mr-eggplant/EATA 5https://github.com/mr-eggplant/SAR 6https://github.com/qinenergy/cotta 7https://github.com/BIT-DA/RoTTA 8https://github.com/taeckyung/sotta 16D.4. Model Recovery Details (Section 5) AETTA (Ours). With AETTA, our reset algorithm detects two cases: (1) consecutive low accuracies and (2) sudden accuracy drops. For consecutive low accuracies, we utilize the information of estimated accuracy from each 5 batches. Regarding hard lower-bound thresholding, we employ a threshold value of 0.2. We reset both the modelâ€™s weights to those from the source model and the optimizerâ€™s state to its initialization value. Episodic. Episodic resetting was first introduced by MEMO [37], where the model resets after every batch. We reset both the modelâ€™s weights and the optimizerâ€™s state to its value before adaptation. MRS. The Model Recovery Scheme (MRS) was initially introduced by SAR [ 29] to recover the model from collapsing. The reset occurs when the moving average of entropy loss falls below a certain threshold. We utilized the threshold value of 0.2 introduced in the original paper. We reset both the modelâ€™s weights to those from the source model and the optimizerâ€™s state to its initialization value. Stochastic. Stochastic restoration was first introduced by CoTTA [ 35]. A small number of model weights are stochastically restored to the initial weights of the source model, with a certain probability specified by the restoration factor. We use the restoration factor 0.01, as introduced in the original work. FisherStochastic. Fisher information based restoration was proposed by PETAL [3], based on the stochastic restoration [35]. It applies stochastic restoration based on layer importance measured by the Fisher information matrix (FIM). We use an FIM-based parameter restoration quantile value of 0.03 for CIFAR100-C, as recommended in the original paper. The parameter with an FIM value less than 0.03-quantile would be restored to the original source weight. DistShift. DistShift assumes that the model knows when the distribution changes and thus acts as an oracle. Resetting occurs when the test data distribution (corruption) changes. We reset both the modelâ€™s weights to those from the source model and the optimizerâ€™s state to its initialization value. E. License of Assets Datasets. CIFAR10/CIFAR100 (MIT License), CIFAR10-C/CIFAR100-C (Creative Commons Attribution 4.0 International) and ImageNet-C (Apache 2.0). Codes. Torchvision for ResNet18 and ResNet50 (Apache 2.0), the official repository of TENT (MIT License), the official repository of EATA (MIT License), the official repository of SAR (BSD 3-Clause License), the official repository of CoTTA (MIT License), the official repository of RoTTA (MIT License), and the official repository of SoTTA (MIT License). 17F. Result Details We report the detailed results per corruption in the main experiments. Table 1 in the main paper is detailed in Table 7, Table 8, and Table 9. Table 2 in the main paper is detailed in Table 10, Table 11, and Table 12. Table 3 in the main paper is detailed in Table 13. Table 7. Mean absolute error (MAE) (%) of the accuracy estimation on fully CIFAR10-C. Averaged over three different random seeds. Noise Blur Weather Digital TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 24.85 Â± 0.83 21.82 Â± 0.74 32.41 Â± 0.90 11.60 Â± 0.53 32.49 Â± 1.50 12.78 Â± 0.45 11.16 Â± 0.62 15.90 Â± 0.57 17.90 Â± 1.04 13.12 Â± 0.78 8.46 Â± 0.35 12.62 Â± 0.33 21.53 Â± 1.26 16.35 Â± 0.68 22.57 Â± 1.26 18.37 Â± 0.29 SoftmaxScore [7] 8.40 Â± 0.10 6.57 Â± 0.91 12.95 Â± 1.53 3.96 Â± 0.50 14.30 Â± 2.12 3.76 Â± 0.12 3.52 Â± 0.36 4.40 Â± 0.08 6.20 Â± 0.94 4.08 Â± 0.50 3.13 Â± 0.08 4.06 Â± 0.36 6.62 Â± 1.00 4.63 Â± 0.47 7.32 Â± 1.40 6.26 Â± 0.49 GDE [21] 25.29 Â± 0.67 22.16 Â± 0.78 32.75 Â± 1.04 12.07 Â± 0.92 33.26 Â± 1.83 12.78 Â± 0.55 11.25 Â± 0.84 16.02 Â± 0.55 18.57 Â± 1.07 13.56 Â± 1.14 8.81 Â± 0.38 12.72 Â± 0.25 21.58 Â± 1.23 16.64 Â± 1.03 22.97 Â± 1.34 18.69 Â± 0.28 AdvPerturb [23] 48.04 Â± 2.26 44.69 Â± 3.91 41.20 Â± 5.55 28.88 Â± 3.38 10.96 Â± 2.02 18.75 Â± 2.07 22.50 Â± 1.34 5.56 Â± 0.43 14.27 Â± 2.42 10.58 Â± 2.22 2.48 Â± 0.08 52.38 Â± 1.67 4.73 Â± 0.25 35.74 Â± 1.12 5.20 Â± 0.10 23.06 Â± 1.17 TENT [34] AETTA 4.12 Â± 0.45 4.67 Â± 0.42 4.59 Â± 0.45 3.14 Â± 0.11 7.05 Â± 0.49 3.20 Â± 0.03 3.07 Â± 0.35 3.66 Â± 0.11 4.07 Â± 0.58 3.32 Â± 0.26 2.70 Â± 0.05 4.29 Â± 0.19 4.01 Â± 0.38 3.69 Â± 0.13 4.41 Â± 0.35 4.00 Â± 0.03 SrcValid 18.53 Â± 0.43 16.06 Â± 1.16 24.04 Â± 1.75 10.55 Â± 0.25 23.95 Â± 2.07 11.72 Â± 0.61 10.26 Â± 0.11 12.81 Â± 0.31 12.85 Â± 0.48 10.27 Â± 0.36 7.78 Â± 0.32 8.88 Â± 0.82 19.00 Â± 1.34 12.62 Â± 0.56 16.18 Â± 1.01 14.37 Â± 0.33 SoftmaxScore [7] 4.75 Â± 0.62 3.85 Â± 0.37 9.08 Â± 0.24 4.14 Â± 0.41 8.77 Â± 2.09 3.92 Â± 0.19 4.44 Â± 0.42 3.50 Â± 0.30 3.54 Â± 0.39 4.02 Â± 0.24 4.79 Â± 0.48 4.22 Â± 0.47 4.38 Â± 0.40 3.58 Â± 0.37 4.70 Â± 0.42 4.78 Â± 0.12 GDE [21] 22.88 Â± 0.72 20.42 Â± 0.72 30.68 Â± 0.46 11.07 Â± 0.19 30.04 Â± 2.50 12.58 Â± 0.56 10.78 Â± 0.38 14.99 Â± 0.28 14.52 Â± 0.56 11.48 Â± 0.13 8.27 Â± 0.46 9.32 Â± 0.48 21.01 Â± 0.92 14.85 Â± 0.11 21.31 Â± 0.97 16.95 Â± 0.22 AdvPerturb [23] 50.21 Â± 4.36 45.60 Â± 3.84 44.13 Â± 4.72 31.34 Â± 2.85 16.32 Â± 0.62 19.30 Â± 1.78 22.95 Â± 2.10 6.43 Â± 0.19 17.52 Â± 3.03 13.62 Â± 0.85 2.73 Â± 0.15 56.00 Â± 1.18 4.93 Â± 0.06 37.56 Â± 0.69 5.99 Â± 0.70 24.97 Â± 1.00 EATA [28] AETTA 3.86 Â± 0.28 4.09 Â± 0.25 5.56 Â± 0.77 3.07 Â± 0.23 6.88 Â± 1.05 3.42 Â± 0.20 3.07 Â± 0.29 3.25 Â± 0.03 3.48 Â± 0.12 3.31 Â± 0.33 2.73 Â± 0.11 2.76 Â± 0.23 4.45 Â± 0.10 3.34 Â± 0.35 4.72 Â± 0.75 3.87 Â± 0.14 SrcValid 32.05 Â± 1.03 30.47 Â± 0.81 37.29 Â± 0.79 12.22 Â± 0.20 33.83 Â± 0.43 13.71 Â± 0.10 12.62 Â± 0.36 18.37 Â± 0.36 19.73 Â± 0.52 14.61 Â± 0.57 9.26 Â± 0.24 13.12 Â± 0.43 23.28 Â± 0.20 20.67 Â± 0.02 28.02 Â± 0.54 21.28 Â± 0.27 SoftmaxScore [7] 4.21 Â± 0.33 4.08 Â± 0.17 5.52 Â± 0.59 6.28 Â± 0.31 4.89 Â± 0.20 5.92 Â± 0.26 6.49 Â± 0.52 4.85 Â± 0.27 4.86 Â± 0.29 5.80 Â± 0.59 7.11 Â± 0.48 5.34 Â± 0.30 4.26 Â± 0.24 4.55 Â± 0.09 3.94 Â± 0.11 5.21 Â± 0.22 GDE [21] 31.88 Â± 1.08 30.38 Â± 0.85 37.17 Â± 0.78 12.22 Â± 0.20 33.72 Â± 0.46 13.71 Â± 0.10 12.62 Â± 0.36 18.37 Â± 0.36 19.73 Â± 0.52 14.61 Â± 0.57 9.26 Â± 0.24 13.12 Â± 0.43 23.28 Â± 0.20 20.67 Â± 0.02 27.99 Â± 0.55 21.25 Â± 0.27 AdvPerturb [23] 42.25 Â± 2.34 37.73 Â± 2.89 38.52 Â± 4.53 30.55 Â± 3.11 9.85 Â± 1.85 18.17 Â± 1.49 21.66 Â± 2.37 4.60 Â± 0.60 14.48 Â± 2.98 11.73 Â± 0.52 2.71 Â± 0.14 52.81 Â± 2.08 4.92 Â± 0.04 31.36 Â± 0.89 6.98 Â± 0.44 21.89 Â± 0.95 SAR [29] AETTA 4.91 Â± 0.84 5.15 Â± 0.89 4.75 Â± 0.19 2.92 Â± 0.14 5.42 Â± 0.47 3.09 Â± 0.06 3.18 Â± 0.21 3.55 Â± 0.37 3.65 Â± 0.17 3.25 Â± 0.34 2.81 Â± 0.06 3.58 Â± 0.61 3.87 Â± 0.15 3.69 Â± 0.43 4.47 Â± 0.23 3.89 Â± 0.07 SrcValid 23.70 Â± 0.75 21.84 Â± 0.28 28.79 Â± 0.21 12.46 Â± 0.33 29.57 Â± 0.62 13.92 Â± 0.06 12.75 Â± 0.25 17.30 Â± 0.41 17.21 Â± 0.30 14.75 Â± 0.51 9.26 Â± 0.21 15.14 Â± 0.06 21.29 Â± 0.43 17.69 Â± 0.14 20.78 Â± 0.38 18.43 Â± 0.16 SoftmaxScore [7] 16.82 Â± 0.51 17.21 Â± 0.63 16.33 Â± 0.22 6.71 Â± 0.42 12.30 Â± 0.19 7.02 Â± 0.43 7.30 Â± 0.71 9.69 Â± 0.48 12.00 Â± 0.63 7.54 Â± 0.45 7.18 Â± 0.56 7.90 Â± 0.61 12.01 Â± 0.38 11.76 Â± 0.74 12.69 Â± 0.63 10.96 Â± 0.28 GDE [21] 15.65 Â± 0.77 14.29 Â± 0.35 19.35 Â± 0.33 12.08 Â± 0.17 21.18 Â± 0.52 13.08 Â± 0.16 12.20 Â± 0.07 14.43 Â± 0.15 13.44 Â± 0.17 13.60 Â± 0.49 9.20 Â± 0.16 13.16 Â± 0.30 16.40 Â± 0.06 13.91 Â± 0.58 15.46 Â± 0.45 14.50 Â± 0.03 AdvPerturb [23] 16.79 Â± 0.32 15.09 Â± 0.89 18.84 Â± 3.83 31.44 Â± 3.23 6.81 Â± 0.51 20.83 Â± 2.16 23.18 Â± 2.46 6.05 Â± 0.33 11.83 Â± 1.56 17.25 Â± 1.20 2.64 Â± 0.06 55.25 Â± 1.82 14.63 Â± 1.63 21.96 Â± 1.58 7.41 Â± 0.68 18.00 Â± 0.82 CoTTA [35] AETTA 15.34 Â± 1.06 15.26 Â± 1.54 14.98 Â± 0.87 3.02 Â± 0.06 6.45 Â± 0.60 3.22 Â± 0.17 3.20 Â± 0.28 4.11 Â± 0.24 5.57 Â± 0.48 3.48 Â± 0.39 2.79 Â± 0.05 4.24 Â± 0.10 5.56 Â± 0.63 6.10 Â± 0.92 9.18 Â± 0.89 6.83 Â± 0.47 SrcValid 27.12 Â± 7.07 27.75 Â± 6.21 14.88 Â± 3.34 12.12 Â± 3.16 25.35 Â± 1.09 5.02 Â± 0.23 4.88 Â± 0.72 14.33 Â± 3.02 36.52 Â± 1.99 11.62 Â± 1.44 35.55 Â± 2.35 35.93 Â± 0.82 20.00 Â± 0.14 7.96 Â± 0.72 26.23 Â± 0.98 20.35 Â± 1.31 SoftmaxScore [7] 4.68 Â± 0.46 4.64 Â± 0.15 5.19 Â± 0.31 7.29 Â± 0.50 4.77 Â± 0.27 7.12 Â± 0.50 7.73 Â± 0.65 6.49 Â± 0.31 6.28 Â± 0.47 7.32 Â± 0.76 8.40 Â± 0.59 4.71 Â± 0.47 5.25 Â± 0.04 5.89 Â± 0.43 4.39 Â± 0.14 6.01 Â± 0.23 GDE [21] 32.94 Â± 0.75 30.87 Â± 0.91 39.40 Â± 0.72 12.02 Â± 0.22 34.18 Â± 0.90 13.48 Â± 0.48 12.01 Â± 0.26 17.90 Â± 0.80 21.73 Â± 0.82 13.93 Â± 0.51 8.90 Â± 0.42 40.52 Â± 2.50 22.68 Â± 0.44 21.22 Â± 0.37 27.31 Â± 0.69 23.27 Â± 0.43 AdvPerturb [23] 40.38 Â± 2.57 36.59 Â± 2.88 35.02 Â± 3.67 29.64 Â± 2.94 9.29 Â± 1.72 17.31 Â± 1.01 21.45 Â± 2.59 4.81 Â± 0.35 11.96 Â± 2.41 11.24 Â± 0.41 2.70 Â± 0.09 26.49 Â± 4.84 5.42 Â± 0.24 29.92 Â± 0.45 8.06 Â± 0.59 19.35 Â± 0.99 RoTTA [36] AETTA 13.47 Â± 5.78 13.35 Â± 5.69 9.74 Â± 3.87 3.55 Â± 0.44 5.42 Â± 1.13 3.68 Â± 0.27 3.88 Â± 0.43 4.45 Â± 0.93 4.93 Â± 1.02 4.51 Â± 0.62 3.31 Â± 0.33 12.13 Â± 6.65 4.66 Â± 1.17 4.97 Â± 1.13 4.57 Â± 0.24 6.44 Â± 1.35 SrcValid 11.98 Â± 4.00 10.86 Â± 0.74 8.25 Â± 0.47 9.73 Â± 2.10 23.16 Â± 0.58 4.54 Â± 0.68 4.74 Â± 1.04 5.55 Â± 0.66 16.12 Â± 2.74 4.56 Â± 0.17 13.62 Â± 2.37 38.68 Â± 6.48 19.00 Â± 0.45 5.57 Â± 0.67 20.67 Â± 0.57 13.13 Â± 0.85 SoftmaxScore [7] 4.10 Â± 0.13 4.46 Â± 0.27 4.50 Â± 0.17 5.45 Â± 1.04 5.05 Â± 0.65 5.47 Â± 0.69 6.14 Â± 0.62 4.82 Â± 0.53 4.91 Â± 0.97 5.61 Â± 0.82 6.17 Â± 1.00 4.36 Â± 0.85 4.23 Â± 0.41 5.25 Â± 0.70 4.07 Â± 0.26 4.97 Â± 0.50 GDE [21] 23.46 Â± 0.77 20.15 Â± 0.46 29.27 Â± 0.45 10.60 Â± 0.38 28.84 Â± 0.86 11.03 Â± 0.11 10.00 Â± 0.56 13.53 Â± 0.58 14.42 Â± 0.16 10.67 Â± 0.40 7.09 Â± 0.09 13.81 Â± 1.96 19.08 Â± 0.52 14.25 Â± 0.50 20.51 Â± 0.82 16.45 Â± 0.21 AdvPerturb [23] 47.94 Â± 3.36 43.98 Â± 3.57 44.74 Â± 4.05 30.14 Â± 2.33 12.47 Â± 2.81 18.81 Â± 1.68 22.85 Â± 2.61 5.48 Â± 0.77 16.01 Â± 2.86 12.78 Â± 1.13 2.68 Â± 0.20 49.76 Â± 2.32 4.95 Â± 0.33 37.03 Â± 1.34 5.63 Â± 0.43 23.68 Â± 0.85 SoTTA [12] AETTA 9.08 Â± 2.79 9.51 Â± 2.49 9.23 Â± 2.73 3.58 Â± 0.27 5.01 Â± 0.52 3.63 Â± 0.45 3.77 Â± 0.57 3.86 Â± 0.42 4.99 Â± 1.17 4.24 Â± 0.90 3.05 Â± 0.07 5.15 Â± 1.28 4.33 Â± 0.63 5.43 Â± 1.39 4.41 Â± 0.51 5.28 Â± 0.87 18Table 8. Mean absolute error (MAE) (%) of the accuracy estimation on fully CIFAR100-C. Averaged over three different random seeds. Noise Blur Weather Digital TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 46.38 Â± 1.17 45.01 Â± 1.16 51.81 Â± 1.79 31.42 Â± 0.67 49.43 Â± 0.58 33.51 Â± 0.64 31.37 Â± 0.35 39.05 Â± 0.33 38.89 Â± 0.28 34.25 Â± 0.38 28.72 Â± 0.33 33.04 Â± 0.61 41.81 Â± 0.75 35.52 Â± 0.51 44.24 Â± 0.66 38.96 Â± 0.22 SoftmaxScore [7] 13.70 Â± 0.41 14.53 Â± 0.58 11.33 Â± 0.70 20.57 Â± 0.40 13.53 Â± 0.49 19.91 Â± 0.60 21.14 Â± 0.25 17.30 Â± 0.27 17.10 Â± 0.23 18.95 Â± 0.23 21.15 Â± 0.12 17.26 Â± 0.66 18.07 Â± 0.57 19.69 Â± 0.13 15.89 Â± 0.14 17.34 Â± 0.10 GDE [21] 49.21 Â± 0.79 47.38 Â± 0.87 54.91 Â± 0.53 31.71 Â± 0.36 50.52 Â± 0.75 33.61 Â± 0.70 31.61 Â± 0.37 40.02 Â± 0.45 40.32 Â± 0.13 36.41 Â± 0.33 28.89 Â± 0.17 32.74 Â± 0.61 42.20 Â± 0.70 36.20 Â± 0.11 45.87 Â± 0.35 40.11 Â± 0.05 AdvPerturb [23] 36.92 Â± 1.76 38.54 Â± 0.24 35.93 Â± 0.49 31.08 Â± 0.42 26.47 Â± 1.53 18.05 Â± 0.82 24.02 Â± 0.77 8.33 Â± 0.53 21.92 Â± 1.07 19.26 Â± 0.03 4.58 Â± 0.38 48.38 Â± 0.25 5.43 Â± 0.10 37.17 Â± 2.42 6.42 Â± 0.25 24.17 Â± 0.41 TENT [34] AETTA 6.55 Â± 0.59 6.09 Â± 0.17 7.60 Â± 0.31 5.57 Â± 0.18 10.27 Â± 0.36 6.05 Â± 0.37 5.60 Â± 0.53 8.26 Â± 0.09 7.21 Â± 0.03 5.81 Â± 0.09 5.54 Â± 0.28 7.32 Â± 0.56 6.99 Â± 0.66 5.50 Â± 0.23 8.96 Â± 0.08 6.89 Â± 0.15 SrcValid 7.65 Â± 0.94 7.33 Â± 0.33 7.51 Â± 0.42 15.32 Â± 1.91 8.35 Â± 0.45 13.56 Â± 1.08 12.54 Â± 1.32 9.21 Â± 1.68 8.91 Â± 0.48 9.31 Â± 0.73 17.52 Â± 1.75 15.60 Â± 0.77 9.99 Â± 1.31 9.80 Â± 0.28 8.09 Â± 0.44 10.71 Â± 0.31 SoftmaxScore [7] 36.65 Â± 1.55 35.32 Â± 1.08 40.06 Â± 2.16 15.38 Â± 1.48 35.65 Â± 2.20 19.64 Â± 2.12 20.05 Â± 5.94 27.09 Â± 4.80 31.54 Â± 4.28 24.67 Â± 4.45 15.80 Â± 2.67 25.68 Â± 7.41 31.88 Â± 2.77 26.64 Â± 2.28 31.81 Â± 0.85 27.86 Â± 1.11 GDE [21] 83.95 Â± 1.83 83.36 Â± 1.31 88.21 Â± 0.66 55.73 Â± 3.68 84.37 Â± 1.49 62.93 Â± 2.76 60.31 Â± 7.35 73.24 Â± 4.38 77.51 Â± 2.86 70.26 Â± 4.24 40.71 Â± 3.37 62.07 Â± 9.58 79.02 Â± 2.84 71.39 Â± 1.01 79.95 Â± 1.07 71.53 Â± 2.12 AdvPerturb [23] 9.32 Â± 0.83 8.30 Â± 0.59 5.08 Â± 0.16 16.05 Â± 1.45 5.75 Â± 0.87 7.72 Â± 0.40 10.48 Â± 1.96 4.03 Â± 0.44 6.07 Â± 1.16 6.79 Â± 1.07 3.90 Â± 0.18 21.65 Â± 6.92 2.93 Â± 0.09 12.38 Â± 0.61 2.87 Â± 0.07 8.22 Â± 0.56 EATA [28] AETTA 18.86 Â± 2.19 19.47 Â± 1.46 18.76 Â± 5.27 17.54 Â± 1.56 26.65 Â± 2.14 21.51 Â± 1.48 19.45 Â± 2.91 20.39 Â± 2.07 18.76 Â± 1.79 19.32 Â± 0.12 11.18 Â± 1.82 23.44 Â± 4.90 24.58 Â± 0.69 20.48 Â± 2.46 21.82 Â± 5.09 20.15 Â± 1.70 SrcValid 53.44 Â± 0.56 51.46 Â± 0.76 59.19 Â± 0.77 32.52 Â± 0.17 53.90 Â± 0.52 35.00 Â± 0.71 33.63 Â± 0.21 43.03 Â± 0.48 43.55 Â± 0.30 38.69 Â± 0.40 30.12 Â± 0.20 33.17 Â± 0.40 43.77 Â± 0.40 39.64 Â± 0.44 49.16 Â± 0.23 42.68 Â± 0.21 SoftmaxScore [7] 20.82 Â± 0.65 21.98 Â± 0.41 18.42 Â± 0.24 27.91 Â± 0.39 20.67 Â± 0.57 26.77 Â± 0.56 27.81 Â± 0.20 24.33 Â± 0.51 24.01 Â± 0.40 26.76 Â± 0.48 27.92 Â± 0.16 25.97 Â± 0.20 25.72 Â± 0.41 26.20 Â± 0.38 23.11 Â± 0.08 24.56 Â± 0.25 GDE [21] 53.09 Â± 0.53 51.11 Â± 0.69 58.81 Â± 0.77 32.45 Â± 0.21 53.63 Â± 0.55 34.91 Â± 0.76 33.60 Â± 0.26 42.90 Â± 0.57 43.42 Â± 0.32 38.63 Â± 0.43 30.05 Â± 0.19 33.08 Â± 0.44 43.65 Â± 0.37 39.50 Â± 0.44 48.87 Â± 0.21 42.51 Â± 0.23 AdvPerturb [23] 35.15 Â± 1.78 36.42 Â± 1.64 32.87 Â± 1.13 30.78 Â± 0.58 23.87 Â± 1.07 16.74 Â± 0.22 22.52 Â± 0.46 7.21 Â± 0.46 21.01 Â± 0.61 18.54 Â± 0.59 4.30 Â± 0.42 48.28 Â± 0.16 5.65 Â± 0.37 34.21 Â± 2.97 6.09 Â± 0.46 22.91 Â± 0.60 SAR [29] AETTA 5.75 Â± 0.45 5.33 Â± 0.29 6.90 Â± 0.24 5.19 Â± 0.22 9.56 Â± 0.54 6.43 Â± 0.32 5.82 Â± 0.30 8.34 Â± 0.28 7.15 Â± 0.38 5.47 Â± 0.18 5.37 Â± 0.19 6.04 Â± 0.23 6.57 Â± 0.50 5.72 Â± 0.33 8.50 Â± 0.24 6.54 Â± 0.15 SrcValid 53.11 Â± 0.39 51.88 Â± 0.44 57.18 Â± 0.18 36.41 Â± 0.61 53.90 Â± 0.59 38.59 Â± 0.67 37.33 Â± 0.46 44.93 Â± 0.62 44.30 Â± 0.32 43.99 Â± 0.46 32.17 Â± 0.16 41.50 Â± 1.22 45.74 Â± 0.20 40.52 Â± 0.10 47.13 Â± 0.13 44.58 Â± 0.30 SoftmaxScore [7] 34.06 Â± 0.49 35.00 Â± 0.50 32.31 Â± 0.35 32.88 Â± 0.53 32.16 Â± 0.58 33.73 Â± 0.76 34.70 Â± 0.60 36.25 Â± 0.96 36.42 Â± 0.36 36.35 Â± 0.55 30.59 Â± 0.77 32.11 Â± 0.49 36.57 Â± 0.30 38.82 Â± 0.21 35.60 Â± 0.09 34.50 Â± 0.35 GDE [21] 36.44 Â± 0.63 35.59 Â± 0.34 38.06 Â± 0.50 31.10 Â± 0.04 38.74 Â± 0.55 31.56 Â± 0.59 30.66 Â± 0.31 32.25 Â± 0.84 31.99 Â± 0.24 32.19 Â± 0.47 29.77 Â± 0.36 33.19 Â± 0.08 33.02 Â± 0.17 29.45 Â± 0.39 34.16 Â± 0.50 33.21 Â± 0.24 AdvPerturb [23] 26.80 Â± 0.88 26.32 Â± 0.95 26.90 Â± 0.45 32.56 Â± 0.56 12.67 Â± 0.28 24.33 Â± 0.97 27.17 Â± 0.14 5.68 Â± 0.18 11.58 Â± 0.31 30.58 Â± 0.42 5.21 Â± 0.30 47.59 Â± 0.76 10.03 Â± 0.60 14.24 Â± 1.60 6.28 Â± 0.19 20.53 Â± 0.14 CoTTA [35] AETTA 9.24 Â± 0.38 9.97 Â± 0.55 8.79 Â± 0.53 5.03 Â± 0.20 4.83 Â± 0.22 4.73 Â± 0.21 4.92 Â± 0.11 4.66 Â± 0.11 4.76 Â± 0.43 4.41 Â± 0.16 5.04 Â± 0.36 5.68 Â± 0.24 4.78 Â± 0.22 6.27 Â± 0.28 7.65 Â± 0.15 6.05 Â± 0.12 SrcValid 28.06 Â± 2.60 29.10 Â± 2.49 16.22 Â± 0.43 34.38 Â± 1.94 10.57 Â± 1.13 7.34 Â± 0.25 17.58 Â± 2.21 14.31 Â± 1.55 30.17 Â± 1.28 15.75 Â± 2.45 30.84 Â± 2.27 28.00 Â± 1.54 31.30 Â± 1.65 15.53 Â± 1.36 43.38 Â± 1.76 23.50 Â± 0.51 SoftmaxScore [7] 18.70 Â± 0.62 19.63 Â± 0.63 17.09 Â± 0.46 29.83 Â± 0.32 21.67 Â± 0.49 28.86 Â± 0.09 30.26 Â± 0.35 25.59 Â± 0.36 21.84 Â± 0.54 28.33 Â± 0.32 29.95 Â± 0.16 13.55 Â± 0.61 27.63 Â± 0.23 26.73 Â± 0.37 23.09 Â± 0.49 24.18 Â± 0.19 GDE [21] 59.99 Â± 1.07 59.43 Â± 1.11 63.72 Â± 0.99 33.71 Â± 0.18 56.11 Â± 0.24 36.10 Â± 0.55 34.68 Â± 0.67 46.27 Â± 0.67 52.01 Â± 0.59 41.07 Â± 0.17 31.91 Â± 0.62 62.02 Â± 0.22 45.38 Â± 0.57 44.14 Â± 1.05 53.79 Â± 0.67 48.02 Â± 0.56 AdvPerturb [23] 25.47 Â± 1.49 26.56 Â± 1.30 25.08 Â± 0.90 28.92 Â± 0.25 19.97 Â± 0.92 15.41 Â± 0.66 21.68 Â± 0.69 6.37 Â± 0.19 13.92 Â± 0.74 15.02 Â± 0.93 4.50 Â± 0.35 20.75 Â± 1.25 6.84 Â± 0.53 28.80 Â± 3.46 8.34 Â± 0.62 17.84 Â± 0.65 RoTTA [36] AETTA 6.37 Â± 1.21 6.88 Â± 0.64 4.81 Â± 0.43 4.74 Â± 0.23 6.28 Â± 0.34 5.29 Â± 0.11 5.18 Â± 0.42 7.22 Â± 0.43 7.58 Â± 1.46 4.74 Â± 0.26 4.79 Â± 0.48 21.01 Â± 3.35 5.53 Â± 0.49 5.28 Â± 0.56 7.43 Â± 1.21 6.88 Â± 0.10 SrcValid 13.43 Â± 2.25 12.55 Â± 1.41 8.28 Â± 1.68 37.61 Â± 3.05 12.41 Â± 3.74 6.47 Â± 0.88 12.99 Â± 1.60 16.44 Â± 1.42 13.05 Â± 1.58 7.58 Â± 0.80 10.12 Â± 1.70 51.02 Â± 4.34 35.45 Â± 0.57 11.12 Â± 4.35 41.55 Â± 0.87 19.34 Â± 0.63 SoftmaxScore [7] 21.66 Â± 0.49 22.18 Â± 0.45 19.31 Â± 0.05 25.96 Â± 0.20 21.08 Â± 0.62 25.26 Â± 0.47 26.54 Â± 0.43 24.57 Â± 0.52 24.12 Â± 0.19 25.49 Â± 0.26 26.25 Â± 0.47 23.62 Â± 0.52 25.30 Â± 0.45 25.17 Â± 0.29 23.23 Â± 0.39 23.98 Â± 0.21 GDE [21] 41.62 Â± 0.27 40.60 Â± 0.39 48.16 Â± 0.43 26.49 Â± 0.24 44.28 Â± 0.48 28.68 Â± 0.42 26.67 Â± 0.34 33.51 Â± 0.51 34.05 Â± 0.18 30.44 Â± 0.51 24.30 Â± 0.32 27.73 Â± 0.69 36.20 Â± 0.21 31.28 Â± 0.44 39.52 Â± 0.24 34.24 Â± 0.12 AdvPerturb [23] 41.39 Â± 1.33 41.35 Â± 1.19 38.06 Â± 0.94 32.19 Â± 0.31 27.92 Â± 1.51 18.64 Â± 0.14 24.83 Â± 0.76 10.19 Â± 0.29 24.05 Â± 0.89 21.34 Â± 0.74 4.84 Â± 0.51 48.66 Â± 0.26 6.74 Â± 0.18 38.48 Â± 1.95 7.88 Â± 0.29 25.77 Â± 0.47 SoTTA [12] AETTA 8.11 Â± 0.91 7.95 Â± 0.39 6.35 Â± 0.55 4.67 Â± 0.32 5.03 Â± 0.26 4.28 Â± 0.18 4.50 Â± 0.28 4.68 Â± 0.21 4.73 Â± 0.42 5.00 Â± 0.37 4.18 Â± 0.04 5.30 Â± 0.20 4.58 Â± 0.07 4.94 Â± 0.48 5.02 Â± 0.19 5.29 Â± 0.18 19Table 9. Mean absolute error (MAE) (%) of the accuracy estimation on fully ImageNet-C. Averaged over three different random seeds. Noise Blur Weather Digital TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 53.54 Â± 1.08 52.12 Â± 1.12 53.28 Â± 0.95 54.72 Â± 0.95 53.66 Â± 1.07 42.96 Â± 0.92 32.78 Â± 0.83 37.25 Â± 0.96 38.77 Â± 0.97 25.06 Â± 0.94 10.47 Â± 0.67 53.56 Â± 0.77 27.86 Â± 0.85 22.35 Â± 0.70 28.55 Â± 0.71 39.13 Â± 0.89 SoftmaxScore [7] 11.11 Â± 0.14 11.97 Â± 0.06 11.35 Â± 0.03 9.82 Â± 0.09 10.59 Â± 0.07 19.16 Â± 0.09 26.76 Â± 0.09 22.44 Â± 0.05 21.08 Â± 0.06 31.41 Â± 0.05 34.87 Â± 0.01 9.52 Â± 0.04 28.83 Â± 0.05 32.26 Â± 0.14 28.88 Â± 0.11 20.67 Â± 0.01 GDE [21] 85.03 Â± 0.14 83.75 Â± 0.06 84.81 Â± 0.04 85.74 Â± 0.09 84.87 Â± 0.08 74.26 Â± 0.10 64.29 Â± 0.08 68.95 Â± 0.06 70.47 Â± 0.07 56.71 Â± 0.02 41.78 Â± 0.02 84.43 Â± 0.09 59.48 Â± 0.07 53.93 Â± 0.12 60.29 Â± 0.14 70.58 Â± 0.01 AdvPerturb [23] 13.38 Â± 0.12 14.08 Â± 0.05 13.44 Â± 0.04 4.43 Â± 0.15 5.21 Â± 0.14 11.48 Â± 0.05 11.47 Â± 0.13 17.17 Â± 0.13 8.67 Â± 0.10 26.80 Â± 0.03 6.56 Â± 0.16 11.99 Â± 0.03 17.97 Â± 0.03 19.11 Â± 0.14 6.69 Â± 0.19 12.56 Â± 0.03 TENT [34] AETTA 4.88 Â± 0.10 4.27 Â± 0.02 4.93 Â± 0.09 7.23 Â± 0.11 5.03 Â± 0.15 4.53 Â± 0.09 4.72 Â± 0.12 4.35 Â± 0.13 4.37 Â± 0.11 9.50 Â± 0.12 8.88 Â± 0.05 6.24 Â± 0.02 7.34 Â± 0.06 8.95 Â± 0.21 6.82 Â± 0.17 6.14 Â± 0.03 SrcValid 50.34 Â± 1.01 48.89 Â± 0.88 49.88 Â± 0.76 52.47 Â± 0.59 51.11 Â± 0.57 40.01 Â± 0.83 28.80 Â± 0.84 32.41 Â± 0.71 35.23 Â± 0.95 21.78 Â± 0.93 8.88 Â± 0.53 51.16 Â± 0.97 23.11 Â± 1.18 19.03 Â± 0.72 25.30 Â± 0.92 35.89 Â± 0.79 SoftmaxScore [7] 12.31 Â± 0.08 13.18 Â± 0.15 12.71 Â± 0.04 10.26 Â± 0.14 10.97 Â± 0.05 19.72 Â± 0.03 27.54 Â± 0.10 23.79 Â± 0.12 21.46 Â± 0.08 30.90 Â± 0.11 32.96 Â± 0.08 10.51 Â± 0.08 29.11 Â± 0.07 31.61 Â± 0.08 28.90 Â± 0.04 21.06 Â± 0.03 GDE [21] 81.21 Â± 0.16 79.99 Â± 0.27 80.82 Â± 0.03 77.04 Â± 0.50 77.95 Â± 0.07 70.22 Â± 0.13 60.30 Â± 0.02 64.37 Â± 0.15 67.25 Â± 0.16 53.43 Â± 0.10 40.26 Â± 0.01 76.64 Â± 0.03 55.33 Â± 0.09 50.67 Â± 0.07 57.02 Â± 0.03 66.17 Â± 0.07 AdvPerturb [23] 15.44 Â± 0.07 16.26 Â± 0.19 15.70 Â± 0.07 4.89 Â± 0.07 6.05 Â± 0.14 13.36 Â± 0.11 14.92 Â± 0.09 20.93 Â± 0.14 10.72 Â± 0.22 29.38 Â± 0.13 5.97 Â± 0.17 13.31 Â± 0.14 22.32 Â± 0.09 21.23 Â± 0.19 7.34 Â± 0.14 14.52 Â± 0.01 EATA [28] AETTA 5.28 Â± 0.12 4.72 Â± 0.05 5.28 Â± 0.07 7.45 Â± 0.09 5.12 Â± 0.10 4.37 Â± 0.07 5.23 Â± 0.18 4.60 Â± 0.13 4.73 Â± 0.13 10.46 Â± 0.12 9.22 Â± 0.09 5.38 Â± 0.09 8.25 Â± 0.16 9.47 Â± 0.10 7.68 Â± 0.05 6.48 Â± 0.02 SrcValid 39.53 Â± 1.22 37.69 Â± 1.46 39.79 Â± 1.36 43.89 Â± 1.00 43.75 Â± 0.82 33.12 Â± 0.77 25.52 Â± 1.06 27.90 Â± 0.86 31.43 Â± 1.03 17.14 Â± 0.46 9.03 Â± 0.71 40.82 Â± 0.33 19.89 Â± 1.25 16.74 Â± 0.89 20.27 Â± 1.14 29.77 Â± 0.94 SoftmaxScore [7] 18.07 Â± 0.26 19.20 Â± 0.20 18.08 Â± 0.21 14.90 Â± 0.25 15.23 Â± 0.29 24.02 Â± 0.06 29.50 Â± 0.06 26.57 Â± 0.09 23.87 Â± 0.16 33.16 Â± 0.11 34.57 Â± 0.09 12.88 Â± 1.75 31.62 Â± 0.09 33.20 Â± 0.20 31.47 Â± 0.02 24.42 Â± 0.08 GDE [21] 75.10 Â± 0.28 73.20 Â± 0.21 75.19 Â± 0.25 77.65 Â± 0.21 77.44 Â± 0.28 66.24 Â± 0.07 58.62 Â± 0.07 61.48 Â± 0.10 65.23 Â± 0.16 50.56 Â± 0.07 40.51 Â± 0.12 74.62 Â± 0.99 53.29 Â± 0.08 49.16 Â± 0.20 53.97 Â± 0.02 63.48 Â± 0.03 AdvPerturb [23] 22.95 Â± 0.27 24.15 Â± 0.14 22.86 Â± 0.25 7.84 Â± 0.11 10.46 Â± 0.36 18.99 Â± 0.17 17.74 Â± 0.13 24.62 Â± 0.12 13.19 Â± 0.07 32.89 Â± 0.05 6.06 Â± 0.06 21.28 Â± 0.94 25.45 Â± 0.13 23.36 Â± 0.15 9.55 Â± 0.11 18.76 Â± 0.06 SAR [29] AETTA 5.38 Â± 0.27 5.24 Â± 0.16 5.11 Â± 0.15 8.06 Â± 0.04 6.19 Â± 0.27 4.53 Â± 0.08 5.17 Â± 0.14 4.97 Â± 0.11 4.71 Â± 0.04 9.73 Â± 0.16 8.68 Â± 0.10 5.39 Â± 0.33 7.76 Â± 0.17 8.66 Â± 0.19 6.89 Â± 0.03 6.43 Â± 0.09 SrcValid 55.20 Â± 0.50 54.09 Â± 0.55 54.87 Â± 0.49 56.70 Â± 0.86 55.43 Â± 0.45 45.10 Â± 0.55 34.91 Â± 0.54 39.13 Â± 0.55 40.12 Â± 0.54 27.92 Â± 0.56 10.68 Â± 0.44 56.19 Â± 0.65 29.77 Â± 0.49 24.40 Â± 0.41 31.80 Â± 0.56 41.09 Â± 0.53 SoftmaxScore [7] 9.93 Â± 0.07 10.66 Â± 0.11 10.24 Â± 0.03 8.36 Â± 0.10 9.36 Â± 0.05 17.69 Â± 0.14 25.68 Â± 0.03 21.47 Â± 0.07 20.57 Â± 0.05 30.40 Â± 0.06 35.07 Â± 0.08 7.79 Â± 0.13 28.04 Â± 0.03 31.69 Â± 0.11 27.39 Â± 0.08 19.62 Â± 0.02 GDE [21] 86.85 Â± 0.06 85.76 Â± 0.13 86.52 Â± 0.02 88.18 Â± 0.12 87.04 Â± 0.05 76.83 Â± 0.14 66.63 Â± 0.03 70.86 Â± 0.07 71.81 Â± 0.06 59.64 Â± 0.06 42.23 Â± 0.09 87.87 Â± 0.13 61.50 Â± 0.03 56.13 Â± 0.11 63.53 Â± 0.08 72.76 Â± 0.02 AdvPerturb [23] 11.73 Â± 0.07 12.19 Â± 0.09 11.84 Â± 0.03 3.81 Â± 0.06 4.33 Â± 0.03 9.70 Â± 0.09 9.46 Â± 0.06 15.50 Â± 0.13 7.86 Â± 0.13 24.07 Â± 0.09 6.72 Â± 0.20 9.11 Â± 0.13 15.96 Â± 0.09 17.56 Â± 0.16 5.96 Â± 0.34 11.05 Â± 0.02 CoTTA [35] AETTA 4.76 Â± 0.07 4.00 Â± 0.04 4.79 Â± 0.07 7.69 Â± 0.18 5.04 Â± 0.06 4.63 Â± 0.08 4.49 Â± 0.15 4.39 Â± 0.08 4.25 Â± 0.10 8.97 Â± 0.12 8.81 Â± 0.09 6.70 Â± 0.18 7.00 Â± 0.02 8.44 Â± 0.19 6.27 Â± 0.19 6.02 Â± 0.03 SrcValid 15.32 Â± 0.10 13.73 Â± 0.68 15.71 Â± 0.14 4.79 Â± 0.54 17.18 Â± 1.34 5.81 Â± 0.55 9.04 Â± 1.50 8.44 Â± 0.80 5.54 Â± 0.33 8.84 Â± 1.21 10.68 Â± 0.77 14.01 Â± 0.55 7.27 Â± 0.34 5.59 Â± 0.27 12.32 Â± 0.91 10.28 Â± 0.28 SoftmaxScore [7] 11.98 Â± 0.07 12.84 Â± 0.28 12.31 Â± 0.13 9.96 Â± 0.18 10.93 Â± 0.12 19.51 Â± 0.09 27.15 Â± 0.18 23.28 Â± 0.02 20.61 Â± 0.11 31.75 Â± 0.10 33.58 Â± 0.05 11.05 Â± 0.14 29.18 Â± 0.04 32.08 Â± 0.09 29.22 Â± 0.10 21.03 Â± 0.04 GDE [21] 80.31 Â± 0.05 79.07 Â± 0.33 80.18 Â± 0.21 82.25 Â± 0.26 81.56 Â± 0.12 70.30 Â± 0.10 60.45 Â± 0.17 64.30 Â± 0.07 67.01 Â± 0.25 52.64 Â± 0.18 38.45 Â± 0.03 77.50 Â± 0.21 55.15 Â± 0.07 50.24 Â± 0.01 56.48 Â± 0.20 66.39 Â± 0.04 AdvPerturb [23] 13.96 Â± 0.07 14.55 Â± 0.30 14.24 Â± 0.13 4.68 Â± 0.09 5.18 Â± 0.05 11.83 Â± 0.05 12.11 Â± 0.12 17.54 Â± 0.06 7.91 Â± 0.12 27.54 Â± 0.11 6.71 Â± 0.08 12.27 Â± 0.11 18.72 Â± 0.11 19.66 Â± 0.02 7.09 Â± 0.19 12.93 Â± 0.04 RoTTA [36] AETTA 14.33 Â± 0.14 14.97 Â± 0.22 14.49 Â± 0.10 8.62 Â± 0.48 7.53 Â± 0.33 14.33 Â± 0.27 13.02 Â± 0.16 11.06 Â± 0.16 12.36 Â± 0.13 17.18 Â± 0.13 16.82 Â± 0.13 8.27 Â± 0.27 15.24 Â± 0.05 32.03 Â± 0.07 22.07 Â± 0.11 14.82 Â± 0.01 SrcValid 28.39 Â± 0.39 25.90 Â± 0.41 28.46 Â± 0.79 9.76 Â± 2.10 7.02 Â± 0.68 21.34 Â± 2.88 12.78 Â± 1.76 18.59 Â± 0.86 6.08 Â± 0.71 18.38 Â± 0.76 12.63 Â± 0.92 22.00 Â± 0.98 13.36 Â± 1.19 9.43 Â± 0.81 5.84 Â± 0.67 16.00 Â± 0.33 SoftmaxScore [7] 19.01 Â± 0.14 20.58 Â± 0.17 19.52 Â± 0.27 16.57 Â± 0.42 17.93 Â± 0.07 24.41 Â± 0.09 27.95 Â± 0.15 26.76 Â± 0.28 23.75 Â± 0.09 30.23 Â± 0.10 30.71 Â± 0.14 6.66 Â± 0.36 30.04 Â± 0.14 30.52 Â± 0.09 29.35 Â± 0.21 23.60 Â± 0.07 GDE [21] 62.46 Â± 0.16 60.09 Â± 0.20 62.04 Â± 0.18 64.31 Â± 0.25 63.47 Â± 0.16 53.92 Â± 0.34 48.60 Â± 0.35 50.02 Â± 0.29 54.63 Â± 0.18 42.15 Â± 0.15 35.24 Â± 0.17 64.78 Â± 0.07 43.55 Â± 0.18 40.82 Â± 0.15 45.04 Â± 0.07 52.74 Â± 0.02 AdvPerturb [23] 27.73 Â± 0.10 29.55 Â± 0.21 28.38 Â± 0.31 12.10 Â± 0.29 17.45 Â± 0.17 24.33 Â± 0.18 23.11 Â± 0.23 30.31 Â± 0.26 17.63 Â± 0.08 36.11 Â± 0.08 5.52 Â± 0.12 21.22 Â± 0.32 31.03 Â± 0.08 26.34 Â± 0.10 12.61 Â± 0.06 22.90 Â± 0.02 SoTTA [12] AETTA 17.92 Â± 0.25 18.73 Â± 0.95 16.32 Â± 2.09 14.69 Â± 1.33 7.64 Â± 0.29 18.94 Â± 0.59 17.21 Â± 0.54 16.92 Â± 0.51 14.49 Â± 0.37 20.84 Â± 0.02 18.54 Â± 0.44 12.70 Â± 1.06 20.46 Â± 0.39 25.44 Â± 0.42 20.13 Â± 0.17 17.40 Â± 0.26 20Table 10. Mean absolute error (MAE) (%) of the accuracy estimation on continual CIFAR10-C. Averaged over three different random seeds. t TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 24.85 Â± 0.83 17.83 Â± 1.52 22.28 Â± 0.17 8.89 Â± 1.17 19.20 Â± 3.28 8.62 Â± 3.45 7.16 Â± 2.71 9.00 Â± 3.73 8.13 Â± 2.54 7.34 Â± 2.32 4.44 Â± 0.57 6.28 Â± 1.89 7.70 Â± 3.52 5.22 Â± 1.67 5.68 Â± 2.27 10.84 Â± 1.83 SoftmaxScore [7] 8.40 Â± 0.10 12.84 Â± 2.07 24.30 Â± 4.53 20.45 Â± 7.09 38.03 Â± 11.59 37.45 Â± 14.78 37.21 Â± 16.96 42.53 Â± 19.10 45.88 Â± 18.10 49.95 Â± 15.87 49.10 Â± 14.58 56.89 Â± 12.63 62.16 Â± 13.50 63.30 Â± 12.88 68.01 Â± 12.02 41.10 Â± 11.66 GDE [21] 25.29 Â± 0.67 22.33 Â± 1.77 33.67 Â± 4.42 25.64 Â± 6.92 45.16 Â± 10.64 41.70 Â± 13.71 40.88 Â± 16.32 46.23 Â± 18.18 49.25 Â± 16.91 52.99 Â± 14.83 51.55 Â± 13.76 59.15 Â± 12.01 65.02 Â± 12.36 65.40 Â± 11.94 70.16 Â± 11.23 46.29 Â± 10.93 AdvPerturb [23] 48.04 Â± 2.26 44.46 Â± 5.59 44.82 Â± 7.11 15.98 Â± 7.94 10.29 Â± 2.90 6.10 Â± 0.85 7.51 Â± 4.79 4.17 Â± 0.50 6.54 Â± 2.69 9.16 Â± 3.21 2.32 Â± 0.35 17.84 Â± 10.01 3.97 Â± 0.58 8.40 Â± 3.06 3.74 Â± 0.23 15.56 Â± 1.53 TENT [34] AETTA 4.12 Â± 0.45 4.02 Â± 0.26 4.63 Â± 0.31 8.37 Â± 3.30 6.92 Â± 0.72 11.18 Â± 4.48 10.40 Â± 6.13 9.48 Â± 2.58 12.23 Â± 5.64 11.40 Â± 5.47 13.30 Â± 0.62 14.01 Â± 5.38 14.17 Â± 6.47 13.96 Â± 4.59 12.58 Â± 5.01 10.05 Â± 1.69 SrcValid 18.53 Â± 0.43 11.25 Â± 0.30 17.43 Â± 1.46 7.76 Â± 0.72 20.95 Â± 1.86 8.86 Â± 0.99 7.02 Â± 0.97 10.91 Â± 1.06 9.68 Â± 1.26 7.36 Â± 1.45 4.34 Â± 0.70 6.45 Â± 0.16 16.05 Â± 1.85 8.15 Â± 0.85 11.16 Â± 2.45 11.06 Â± 0.11 SoftmaxScore [7] 4.75 Â± 0.62 6.20 Â± 1.19 15.17 Â± 1.79 10.01 Â± 3.73 21.53 Â± 3.27 18.50 Â± 7.97 15.43 Â± 6.98 16.81 Â± 4.13 17.71 Â± 7.04 15.33 Â± 7.57 12.30 Â± 5.92 14.49 Â± 5.54 21.08 Â± 4.63 18.07 Â± 6.59 23.67 Â± 6.32 15.40 Â± 4.73 GDE [21] 22.88 Â± 0.72 20.96 Â± 1.47 31.37 Â± 2.07 21.28 Â± 4.63 36.43 Â± 3.32 29.58 Â± 8.64 25.03 Â± 7.81 26.76 Â± 4.68 27.17 Â± 7.62 23.91 Â± 8.61 19.29 Â± 6.98 21.44 Â± 6.17 31.55 Â± 4.68 26.22 Â± 6.77 32.68 Â± 5.87 26.44 Â± 5.16 AdvPerturb [23] 50.21 Â± 4.36 45.51 Â± 5.20 42.95 Â± 5.29 23.78 Â± 5.30 12.43 Â± 0.75 11.88 Â± 4.12 16.14 Â± 4.75 4.38 Â± 0.46 12.59 Â± 3.26 9.28 Â± 2.72 2.47 Â± 0.07 44.14 Â± 6.38 4.71 Â± 0.28 28.64 Â± 6.81 4.84 Â± 0.67 20.93 Â± 2.83 EATA [28] AETTA 3.86 Â± 0.28 3.98 Â± 0.12 5.96 Â± 1.90 5.97 Â± 2.48 9.89 Â± 1.84 10.47 Â± 6.25 8.03 Â± 5.24 7.47 Â± 3.19 7.79 Â± 5.72 7.02 Â± 4.80 5.59 Â± 3.33 6.80 Â± 3.37 6.69 Â± 3.13 7.13 Â± 4.33 10.22 Â± 4.52 7.13 Â± 3.33 SrcValid 32.05 Â± 1.03 30.47 Â± 0.76 37.42 Â± 0.42 12.20 Â± 0.20 33.88 Â± 0.52 13.69 Â± 0.12 12.62 Â± 0.36 18.37 Â± 0.36 19.73 Â± 0.52 14.61 Â± 0.57 9.26 Â± 0.24 13.12 Â± 0.43 23.28 Â± 0.20 20.67 Â± 0.02 28.03 Â± 0.53 21.29 Â± 0.26 SoftmaxScore [7] 4.21 Â± 0.33 4.04 Â± 0.20 5.54 Â± 0.53 6.28 Â± 0.32 4.91 Â± 0.14 5.93 Â± 0.25 6.49 Â± 0.52 4.85 Â± 0.27 4.86 Â± 0.29 5.80 Â± 0.59 7.11 Â± 0.48 5.34 Â± 0.30 4.26 Â± 0.24 4.55 Â± 0.09 3.94 Â± 0.11 5.21 Â± 0.22 GDE [21] 31.88 Â± 1.08 30.35 Â± 0.80 37.25 Â± 0.49 12.19 Â± 0.20 33.80 Â± 0.52 13.68 Â± 0.13 12.62 Â± 0.36 18.37 Â± 0.36 19.73 Â± 0.52 14.61 Â± 0.57 9.26 Â± 0.24 13.12 Â± 0.43 23.28 Â± 0.20 20.67 Â± 0.02 28.01 Â± 0.52 21.25 Â± 0.27 AdvPerturb [23] 42.25 Â± 2.34 37.75 Â± 2.91 38.40 Â± 4.24 30.55 Â± 3.11 9.77 Â± 1.93 18.20 Â± 1.52 21.66 Â± 2.37 4.60 Â± 0.60 14.48 Â± 2.98 11.73 Â± 0.52 2.71 Â± 0.14 52.81 Â± 2.08 4.92 Â± 0.04 31.36 Â± 0.89 6.98 Â± 0.45 21.88 Â± 0.93 SAR [29] AETTA 4.91 Â± 0.84 5.14 Â± 0.85 4.77 Â± 0.15 2.91 Â± 0.14 5.45 Â± 0.50 3.08 Â± 0.06 3.18 Â± 0.21 3.55 Â± 0.37 3.65 Â± 0.17 3.25 Â± 0.34 2.81 Â± 0.06 3.58 Â± 0.61 3.87 Â± 0.15 3.69 Â± 0.43 4.48 Â± 0.23 3.89 Â± 0.06 SrcValid 23.70 Â± 0.75 21.71 Â± 0.16 28.09 Â± 0.28 12.26 Â± 0.05 28.88 Â± 0.55 13.78 Â± 0.09 12.46 Â± 0.35 17.09 Â± 0.59 17.19 Â± 0.48 15.34 Â± 0.36 9.18 Â± 0.14 16.33 Â± 0.42 21.34 Â± 0.68 16.88 Â± 0.25 20.29 Â± 0.38 18.30 Â± 0.25 SoftmaxScore [7] 16.82 Â± 0.51 16.82 Â± 0.61 16.38 Â± 0.27 8.79 Â± 0.51 13.43 Â± 0.32 9.90 Â± 0.53 10.29 Â± 0.48 12.04 Â± 0.84 14.12 Â± 0.52 10.76 Â± 0.50 10.49 Â± 0.65 9.82 Â± 0.61 13.90 Â± 0.44 15.08 Â± 0.74 15.73 Â± 0.81 12.96 Â± 0.37 GDE [21] 15.65 Â± 0.77 14.46 Â± 0.13 19.48 Â± 0.59 11.93 Â± 0.06 21.35 Â± 0.41 13.05 Â± 0.12 12.00 Â± 0.21 14.71 Â± 0.35 13.73 Â± 0.30 14.20 Â± 0.32 9.14 Â± 0.13 14.62 Â± 0.20 16.83 Â± 0.33 13.66 Â± 0.33 15.56 Â± 0.37 14.69 Â± 0.15 AdvPerturb [23] 16.79 Â± 0.32 15.00 Â± 0.78 19.37 Â± 3.92 31.13 Â± 3.19 7.05 Â± 0.41 20.30 Â± 2.25 23.01 Â± 2.44 5.86 Â± 0.42 11.50 Â± 1.57 16.32 Â± 1.37 2.55 Â± 0.09 53.39 Â± 1.32 13.96 Â± 1.62 23.41 Â± 1.77 7.14 Â± 0.62 17.79 Â± 0.74 CoTTA [35] AETTA 15.34 Â± 1.06 13.13 Â± 1.39 12.06 Â± 0.89 3.15 Â± 0.12 5.08 Â± 0.30 3.29 Â± 0.04 3.18 Â± 0.30 3.45 Â± 0.05 3.92 Â± 0.27 3.51 Â± 0.21 2.75 Â± 0.02 5.01 Â± 0.15 4.15 Â± 0.21 4.18 Â± 0.37 5.06 Â± 0.57 5.82 Â± 0.30 SrcValid 27.12 Â± 7.07 26.34 Â± 6.79 9.26 Â± 2.75 7.15 Â± 1.06 24.37 Â± 0.72 5.96 Â± 0.94 4.82 Â± 1.05 4.60 Â± 0.29 17.57 Â± 1.70 4.44 Â± 0.77 4.69 Â± 0.63 21.73 Â± 4.14 16.11 Â± 0.21 8.78 Â± 0.75 17.58 Â± 0.24 13.37 Â± 0.89 SoftmaxScore [7] 4.68 Â± 0.46 5.10 Â± 0.20 5.00 Â± 0.09 11.86 Â± 0.78 8.45 Â± 0.59 13.92 Â± 1.06 15.37 Â± 0.84 14.95 Â± 0.47 15.51 Â± 0.36 16.15 Â± 0.63 15.69 Â± 0.45 15.48 Â± 0.47 15.65 Â± 0.13 15.52 Â± 0.31 15.31 Â± 0.30 12.57 Â± 0.43 GDE [21] 32.94 Â± 0.75 27.97 Â± 1.10 33.95 Â± 0.74 13.61 Â± 0.39 28.49 Â± 0.73 11.81 Â± 0.16 9.71 Â± 0.21 13.20 Â± 0.20 12.86 Â± 0.46 11.37 Â± 0.26 7.00 Â± 0.28 11.11 Â± 0.41 16.67 Â± 0.31 13.76 Â± 0.19 18.09 Â± 0.36 17.50 Â± 0.30 AdvPerturb [23] 40.38 Â± 2.57 39.03 Â± 3.20 40.39 Â± 3.88 29.63 Â± 2.87 13.44 Â± 2.20 18.72 Â± 1.44 23.67 Â± 3.12 6.03 Â± 0.60 17.61 Â± 3.15 13.01 Â± 0.57 2.73 Â± 0.09 53.28 Â± 0.74 4.84 Â± 0.13 36.60 Â± 1.21 4.90 Â± 0.44 22.95 Â± 0.82 RoTTA [36] AETTA 13.47 Â± 5.78 12.40 Â± 5.05 10.05 Â± 3.52 3.69 Â± 0.21 5.45 Â± 0.92 3.39 Â± 0.15 3.24 Â± 0.16 3.67 Â± 0.69 3.90 Â± 0.61 3.75 Â± 0.44 2.77 Â± 0.03 3.37 Â± 0.36 4.00 Â± 0.14 3.48 Â± 0.22 3.73 Â± 0.35 5.36 Â± 1.22 SrcValid 11.98 Â± 4.00 5.70 Â± 1.02 9.03 Â± 3.17 6.60 Â± 2.08 21.16 Â± 1.40 6.41 Â± 0.73 3.82 Â± 0.36 9.00 Â± 1.38 5.61 Â± 0.97 5.74 Â± 0.40 3.94 Â± 0.35 15.30 Â± 2.22 15.65 Â± 0.40 5.94 Â± 0.52 15.07 Â± 0.88 9.40 Â± 0.85 SoftmaxScore [7] 4.10 Â± 0.13 4.13 Â± 0.63 3.96 Â± 0.62 4.79 Â± 0.18 5.39 Â± 1.27 3.72 Â± 0.26 4.37 Â± 0.89 3.67 Â± 0.24 3.55 Â± 0.36 4.41 Â± 0.53 4.39 Â± 0.81 6.63 Â± 0.32 3.88 Â± 0.22 4.35 Â± 0.22 4.15 Â± 0.57 4.37 Â± 0.09 GDE [21] 23.46 Â± 0.77 17.63 Â± 0.94 24.00 Â± 0.97 14.12 Â± 1.41 26.42 Â± 1.21 15.42 Â± 0.99 11.27 Â± 0.58 15.05 Â± 0.48 14.27 Â± 0.48 13.33 Â± 0.37 8.85 Â± 0.15 15.49 Â± 1.19 19.61 Â± 1.30 15.91 Â± 1.09 20.61 Â± 1.00 17.03 Â± 0.70 AdvPerturb [23] 47.94 Â± 3.36 47.49 Â± 4.59 50.19 Â± 5.41 26.66 Â± 1.29 16.53 Â± 1.72 15.64 Â± 0.97 21.76 Â± 2.19 4.96 Â± 0.25 15.67 Â± 3.26 10.46 Â± 0.47 2.61 Â± 0.19 48.72 Â± 0.34 4.51 Â± 0.34 35.66 Â± 0.51 5.64 Â± 0.52 23.63 Â± 0.78 SoTTA [12] AETTA 7.91 Â± 1.16 5.83 Â± 0.56 5.76 Â± 0.77 3.27 Â± 0.06 4.58 Â± 0.11 3.57 Â± 0.19 3.28 Â± 0.17 3.49 Â± 0.10 3.66 Â± 0.08 3.79 Â± 0.13 2.94 Â± 0.02 3.81 Â± 0.21 4.20 Â± 0.01 4.07 Â± 0.07 3.87 Â± 0.02 4.27 Â± 0.12 21Table 11. Mean absolute error (MAE) (%) of the accuracy estimation on continual CIFAR100-C. Averaged over three different random seeds. t TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 46.38 Â± 1.17 32.85 Â± 3.59 28.45 Â± 3.99 12.51 Â± 0.84 16.92 Â± 2.40 5.75 Â± 0.60 3.84 Â± 0.73 3.88 Â± 1.45 2.77 Â± 0.87 2.32 Â± 0.35 2.12 Â± 0.20 2.00 Â± 0.13 1.87 Â± 0.15 1.73 Â± 0.30 1.65 Â± 0.26 11.00 Â± 0.58 SoftmaxScore [7] 13.70 Â± 0.41 5.34 Â± 0.21 13.91 Â± 0.58 21.16 Â± 0.94 38.51 Â± 1.59 50.42 Â± 4.50 59.40 Â± 6.35 70.82 Â± 5.52 78.56 Â± 3.43 82.11 Â± 1.88 84.99 Â± 1.14 89.52 Â± 0.24 87.46 Â± 1.72 88.87 Â± 1.65 89.56 Â± 0.63 58.29 Â± 1.82 GDE [21] 49.21 Â± 0.79 48.12 Â± 0.60 60.77 Â± 0.20 56.99 Â± 1.30 74.34 Â± 1.15 77.88 Â± 4.24 82.28 Â± 5.11 90.14 Â± 3.30 93.71 Â± 1.63 95.33 Â± 0.77 95.86 Â± 0.45 96.93 Â± 0.43 96.88 Â± 0.62 97.25 Â± 0.75 97.31 Â± 0.82 80.87 Â± 1.29 AdvPerturb [23] 36.92 Â± 1.76 36.25 Â± 0.61 29.26 Â± 1.31 13.91 Â± 0.54 8.56 Â± 2.77 3.79 Â± 0.85 3.68 Â± 1.01 3.08 Â± 0.81 3.96 Â± 2.12 2.58 Â± 0.56 1.47 Â± 0.13 2.10 Â± 0.28 2.26 Â± 1.07 2.46 Â± 0.66 1.53 Â± 0.06 10.12 Â± 0.24 TENT [34] AETTA 6.55 Â± 0.59 7.40 Â± 0.10 7.52 Â± 0.54 13.45 Â± 0.40 6.30 Â± 0.56 6.87 Â± 0.81 8.36 Â± 1.09 8.09 Â± 2.80 5.08 Â± 1.37 3.84 Â± 0.58 3.53 Â± 0.33 2.97 Â± 0.32 2.73 Â± 0.35 2.54 Â± 0.51 2.51 Â± 0.42 5.85 Â± 0.36 SrcValid 7.65 Â± 0.94 1.97 Â± 0.17 1.59 Â± 0.33 1.47 Â± 0.43 1.24 Â± 0.22 1.36 Â± 0.26 1.31 Â± 0.23 1.22 Â± 0.20 1.07 Â± 0.10 1.01 Â± 0.08 0.94 Â± 0.04 0.98 Â± 0.11 1.13 Â± 0.20 1.11 Â± 0.11 1.09 Â± 0.10 1.68 Â± 0.18 SoftmaxScore [7] 36.65 Â± 1.55 64.29 Â± 1.84 70.97 Â± 1.45 75.02 Â± 1.73 77.61 Â± 1.85 78.47 Â± 2.34 78.46 Â± 0.61 79.04 Â± 0.36 82.42 Â± 0.71 81.35 Â± 0.18 84.35 Â± 0.31 89.83 Â± 0.75 82.75 Â± 0.91 83.33 Â± 1.63 84.09 Â± 1.09 76.58 Â± 0.71 GDE [21] 83.95 Â± 1.83 94.00 Â± 0.88 94.99 Â± 0.74 94.52 Â± 0.94 95.15 Â± 0.50 94.73 Â± 1.31 94.57 Â± 1.16 93.63 Â± 1.11 95.31 Â± 1.51 95.46 Â± 0.38 95.31 Â± 0.51 94.60 Â± 1.34 94.55 Â± 0.70 94.51 Â± 0.48 94.81 Â± 1.49 94.01 Â± 0.43 AdvPerturb [23] 9.32 Â± 0.83 4.85 Â± 1.55 2.07 Â± 0.54 1.55 Â± 0.70 1.41 Â± 0.20 1.31 Â± 0.43 1.22 Â± 0.16 1.21 Â± 0.52 0.88 Â± 0.36 0.89 Â± 0.27 0.52 Â± 0.07 1.08 Â± 0.57 0.98 Â± 0.25 1.27 Â± 0.22 0.93 Â± 0.14 1.97 Â± 0.33 EATA [28] AETTA 18.86 Â± 2.19 7.14 Â± 2.67 2.59 Â± 0.40 4.21 Â± 3.24 3.33 Â± 2.13 2.64 Â± 1.35 2.03 Â± 0.25 1.90 Â± 0.14 1.78 Â± 0.06 1.74 Â± 0.06 1.97 Â± 0.34 8.42 Â± 10.00 2.10 Â± 0.09 1.92 Â± 0.10 2.04 Â± 0.48 4.18 Â± 0.82 SrcValid 53.44 Â± 0.56 44.48 Â± 0.19 50.08 Â± 0.66 32.15 Â± 0.18 47.60 Â± 0.38 33.57 Â± 0.57 30.57 Â± 0.27 38.18 Â± 0.81 36.38 Â± 0.46 35.00 Â± 0.48 27.36 Â± 0.32 29.30 Â± 0.55 39.09 Â± 0.36 33.58 Â± 0.22 42.22 Â± 0.34 38.20 Â± 0.22 SoftmaxScore [7] 20.82 Â± 0.65 23.48 Â± 0.20 20.68 Â± 0.05 25.76 Â± 0.19 21.30 Â± 0.50 24.92 Â± 0.54 26.40 Â± 0.30 23.71 Â± 0.68 23.90 Â± 0.26 25.12 Â± 0.32 26.21 Â± 0.19 25.49 Â± 0.24 24.85 Â± 0.45 25.13 Â± 0.06 22.95 Â± 0.60 24.05 Â± 0.29 GDE [21] 53.09 Â± 0.53 44.65 Â± 0.17 51.31 Â± 0.41 33.64 Â± 0.17 48.74 Â± 0.41 34.68 Â± 0.61 31.44 Â± 0.31 39.11 Â± 0.72 37.62 Â± 0.29 36.45 Â± 0.28 28.86 Â± 0.08 30.48 Â± 0.33 40.06 Â± 0.27 34.55 Â± 0.24 43.42 Â± 0.28 39.21 Â± 0.22 AdvPerturb [23] 35.15 Â± 1.78 42.48 Â± 1.22 40.57 Â± 0.60 29.46 Â± 0.65 28.50 Â± 1.19 16.57 Â± 0.38 23.68 Â± 0.46 8.75 Â± 0.68 25.17 Â± 0.46 18.91 Â± 0.75 4.57 Â± 0.42 49.75 Â± 0.52 5.52 Â± 0.24 38.29 Â± 2.90 6.54 Â± 0.50 24.93 Â± 0.57 SAR [29] AETTA 5.75 Â± 0.45 5.35 Â± 0.22 6.31 Â± 0.08 6.59 Â± 0.22 9.11 Â± 0.29 7.66 Â± 0.31 6.16 Â± 0.37 8.37 Â± 0.47 7.06 Â± 0.21 6.12 Â± 0.09 5.78 Â± 0.30 5.65 Â± 0.01 6.32 Â± 0.36 5.90 Â± 0.35 7.93 Â± 0.15 6.67 Â± 0.12 SrcValid 53.11 Â± 0.39 51.92 Â± 0.46 57.00 Â± 0.31 36.42 Â± 0.36 54.13 Â± 0.72 39.30 Â± 0.46 38.28 Â± 0.42 46.48 Â± 0.48 46.81 Â± 0.58 47.73 Â± 0.89 33.94 Â± 0.43 44.55 Â± 1.25 49.18 Â± 0.38 42.97 Â± 0.08 49.48 Â± 0.27 46.09 Â± 0.38 SoftmaxScore [7] 34.06 Â± 0.49 34.58 Â± 0.52 32.05 Â± 0.53 33.14 Â± 0.76 31.92 Â± 0.80 34.68 Â± 0.79 35.83 Â± 0.82 36.94 Â± 1.04 37.46 Â± 0.85 36.13 Â± 0.91 36.94 Â± 1.03 40.90 Â± 0.70 38.04 Â± 0.86 42.67 Â± 0.64 38.70 Â± 0.68 36.27 Â± 0.68 GDE [21] 36.44 Â± 0.63 36.25 Â± 0.17 39.37 Â± 0.40 31.48 Â± 0.46 40.05 Â± 0.54 32.73 Â± 0.55 32.12 Â± 0.19 34.87 Â± 0.38 35.40 Â± 0.79 36.28 Â± 0.78 31.54 Â± 0.36 37.31 Â± 0.43 36.98 Â± 0.26 32.82 Â± 0.43 37.87 Â± 0.69 35.43 Â± 0.30 AdvPerturb [23] 26.80 Â± 0.88 26.08 Â± 0.93 27.02 Â± 0.54 32.75 Â± 0.77 11.69 Â± 0.89 23.72 Â± 1.09 26.36 Â± 0.40 5.63 Â± 0.17 9.87 Â± 0.12 27.10 Â± 0.57 4.87 Â± 0.27 44.56 Â± 1.41 7.57 Â± 0.44 14.56 Â± 1.39 5.74 Â± 0.25 19.62 Â± 0.15 CoTTA [35] AETTA 9.24 Â± 0.38 8.52 Â± 0.55 6.75 Â± 0.35 5.20 Â± 0.13 5.06 Â± 0.25 5.54 Â± 0.16 5.70 Â± 0.29 5.49 Â± 0.31 5.88 Â± 0.33 6.71 Â± 0.59 7.38 Â± 0.10 9.70 Â± 0.72 6.33 Â± 0.14 5.14 Â± 0.27 5.66 Â± 0.45 6.55 Â± 0.17 SrcValid 28.06 Â± 2.60 29.86 Â± 2.79 13.52 Â± 1.12 22.72 Â± 0.61 18.32 Â± 1.73 12.14 Â± 0.85 5.78 Â± 0.25 8.58 Â± 0.39 23.32 Â± 0.81 10.68 Â± 2.60 6.52 Â± 1.30 25.88 Â± 4.11 33.45 Â± 0.64 13.98 Â± 3.80 38.61 Â± 0.73 19.43 Â± 1.17 SoftmaxScore [7] 18.70 Â± 0.62 21.28 Â± 0.40 19.45 Â± 0.34 28.25 Â± 0.20 22.90 Â± 0.62 29.05 Â± 0.26 31.75 Â± 0.27 28.49 Â± 0.44 29.37 Â± 0.19 30.03 Â± 0.28 31.39 Â± 0.69 28.52 Â± 0.44 30.99 Â± 0.70 29.72 Â± 0.36 28.03 Â± 0.41 27.19 Â± 0.12 GDE [21] 59.99 Â± 1.07 57.35 Â± 0.80 61.31 Â± 0.96 36.40 Â± 0.92 53.91 Â± 0.73 34.73 Â± 0.63 31.10 Â± 0.63 39.01 Â± 0.31 37.56 Â± 0.48 37.15 Â± 0.45 26.90 Â± 0.24 33.56 Â± 0.20 38.31 Â± 0.64 34.69 Â± 0.46 43.29 Â± 0.95 41.68 Â± 0.45 AdvPerturb [23] 25.47 Â± 1.49 28.60 Â± 0.91 27.71 Â± 0.81 26.38 Â± 0.74 22.80 Â± 1.70 15.78 Â± 0.72 23.44 Â± 0.96 8.93 Â± 0.85 24.12 Â± 0.74 16.68 Â± 0.95 4.56 Â± 0.43 44.85 Â± 0.74 5.96 Â± 0.33 36.17 Â± 3.16 6.18 Â± 0.16 21.18 Â± 0.71 RoTTA [36] AETTA 6.37 Â± 1.21 7.00 Â± 0.80 4.77 Â± 0.44 6.20 Â± 0.32 6.54 Â± 0.45 5.69 Â± 0.27 4.89 Â± 0.24 6.59 Â± 0.15 4.83 Â± 0.55 5.52 Â± 0.25 4.78 Â± 0.26 7.60 Â± 0.80 5.40 Â± 0.16 4.92 Â± 0.69 6.84 Â± 0.76 5.86 Â± 0.10 SrcValid 13.43 Â± 2.25 8.45 Â± 1.26 9.32 Â± 2.50 14.85 Â± 2.02 23.51 Â± 3.62 9.03 Â± 1.89 6.22 Â± 1.14 26.37 Â± 2.50 10.83 Â± 3.76 8.66 Â± 1.84 20.27 Â± 0.21 35.17 Â± 2.57 29.05 Â± 3.38 14.48 Â± 4.68 33.72 Â± 0.71 17.56 Â± 1.57 SoftmaxScore [7] 21.66 Â± 0.49 22.56 Â± 0.75 18.88 Â± 0.55 21.70 Â± 0.73 18.70 Â± 1.01 22.58 Â± 0.47 24.48 Â± 0.34 21.62 Â± 0.61 22.08 Â± 0.10 22.18 Â± 0.08 23.67 Â± 0.48 21.86 Â± 0.55 22.45 Â± 0.65 22.42 Â± 0.63 21.45 Â± 0.49 21.89 Â± 0.35 GDE [21] 41.62 Â± 0.27 37.46 Â± 0.91 46.03 Â± 0.18 33.39 Â± 0.87 44.99 Â± 1.03 32.05 Â± 0.66 28.16 Â± 0.28 35.19 Â± 0.80 33.80 Â± 0.28 32.74 Â± 0.13 26.34 Â± 0.48 29.23 Â± 0.80 37.40 Â± 0.78 31.99 Â± 1.11 38.42 Â± 0.57 35.25 Â± 0.27 AdvPerturb [23] 41.39 Â± 1.33 45.03 Â± 0.81 40.28 Â± 1.21 25.84 Â± 0.41 26.78 Â± 1.90 16.58 Â± 0.85 23.72 Â± 0.36 9.68 Â± 0.69 24.71 Â± 0.74 19.14 Â± 0.83 4.52 Â± 0.20 47.12 Â± 1.27 5.70 Â± 0.02 37.97 Â± 2.21 8.41 Â± 0.72 25.12 Â± 0.39 SoTTA [12] AETTA 8.11 Â± 0.91 7.19 Â± 0.44 7.34 Â± 0.79 4.99 Â± 0.31 4.97 Â± 0.25 4.30 Â± 0.19 4.33 Â± 0.14 4.86 Â± 0.24 4.90 Â± 0.34 5.23 Â± 0.46 4.24 Â± 0.19 5.20 Â± 0.32 4.61 Â± 0.10 5.01 Â± 0.27 4.58 Â± 0.13 5.32 Â± 0.18 22Table 12. Mean absolute error (MAE) (%) of the accuracy estimation on continual ImageNet-C. Averaged over three different random seeds. t TTA Method Acc. Estimation Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†“) SrcValid 53.54 Â± 1.08 48.82 Â± 1.21 47.13 Â± 1.16 48.84 Â± 1.07 44.94 Â± 1.16 34.83 Â± 1.25 26.16 Â± 1.18 32.41 Â± 1.21 31.80 Â± 1.02 21.17 Â± 1.05 8.93 Â± 0.73 43.25 Â± 0.72 20.57 Â± 0.66 17.02 Â± 0.49 20.10 Â± 0.27 33.30 Â± 0.93 SoftmaxScore [7] 11.11 Â± 0.14 13.76 Â± 0.03 14.42 Â± 0.09 11.60 Â± 0.01 13.15 Â± 0.12 19.04 Â± 0.18 24.78 Â± 0.06 19.82 Â± 0.06 19.35 Â± 0.11 26.70 Â± 0.07 28.68 Â± 0.08 9.97 Â± 0.05 25.38 Â± 0.09 26.50 Â± 0.13 25.86 Â± 0.07 19.34 Â± 0.02 GDE [21] 85.03 Â± 0.14 80.80 Â± 0.02 79.82 Â± 0.06 82.06 Â± 0.02 79.46 Â± 0.13 70.43 Â± 0.17 61.92 Â± 0.06 68.34 Â± 0.08 68.10 Â± 0.10 57.45 Â± 0.07 44.38 Â± 0.07 79.03 Â± 0.07 57.35 Â± 0.07 53.54 Â± 0.08 56.74 Â± 0.08 68.30 Â± 0.01 AdvPerturb [23] 13.38 Â± 0.12 16.92 Â± 0.07 18.51 Â± 0.08 5.92 Â± 0.07 9.30 Â± 0.16 15.03 Â± 0.20 14.79 Â± 0.06 18.37 Â± 0.09 12.01 Â± 0.04 26.75 Â± 0.06 5.86 Â± 0.09 17.02 Â± 0.05 21.98 Â± 0.12 18.40 Â± 0.10 8.03 Â± 0.09 14.82 Â± 0.02 TENT [34] AETTA 4.88 Â± 0.10 4.53 Â± 0.06 5.19 Â± 0.22 8.64 Â± 0.11 5.99 Â± 0.06 5.60 Â± 0.25 4.74 Â± 0.16 5.75 Â± 0.20 4.81 Â± 0.07 6.50 Â± 0.13 5.62 Â± 0.12 6.85 Â± 0.13 5.43 Â± 0.19 5.27 Â± 0.12 5.12 Â± 0.15 5.66 Â± 0.05 SrcValid 50.34 Â± 1.01 48.73 Â± 0.91 49.54 Â± 0.80 51.63 Â± 0.70 50.92 Â± 0.57 39.99 Â± 0.75 30.20 Â± 1.06 34.05 Â± 0.72 36.29 Â± 0.93 23.21 Â± 0.69 9.74 Â± 0.59 49.05 Â± 0.79 25.37 Â± 0.63 20.56 Â± 0.80 26.64 Â± 0.92 36.42 Â± 0.76 SoftmaxScore [7] 12.31 Â± 0.08 12.95 Â± 0.12 12.55 Â± 0.06 10.51 Â± 0.20 10.60 Â± 0.07 19.20 Â± 0.17 26.02 Â± 0.02 22.11 Â± 0.06 20.15 Â± 0.11 29.26 Â± 0.11 31.42 Â± 0.05 11.22 Â± 0.46 27.09 Â± 0.14 29.88 Â± 0.08 27.14 Â± 0.07 20.16 Â± 0.05 GDE [21] 81.21 Â± 0.16 80.02 Â± 0.13 80.73 Â± 0.07 76.16 Â± 0.24 77.51 Â± 0.44 69.92 Â± 0.12 61.37 Â± 0.06 65.81 Â± 0.11 68.10 Â± 0.07 54.61 Â± 0.10 41.10 Â± 0.05 74.94 Â± 0.60 57.03 Â± 0.17 51.96 Â± 0.08 58.28 Â± 0.06 66.58 Â± 0.03 AdvPerturb [23] 15.44 Â± 0.07 16.25 Â± 0.13 15.88 Â± 0.10 5.13 Â± 0.06 6.00 Â± 0.03 13.33 Â± 0.14 13.52 Â± 0.19 19.48 Â± 0.04 10.13 Â± 0.08 28.15 Â± 0.04 6.26 Â± 0.18 15.43 Â± 0.63 20.22 Â± 0.19 20.08 Â± 0.17 6.95 Â± 0.11 14.15 Â± 0.06 EATA [28] AETTA 5.28 Â± 0.12 4.75 Â± 0.05 5.43 Â± 0.05 7.19 Â± 0.11 4.93 Â± 0.06 4.28 Â± 0.10 5.39 Â± 0.18 4.53 Â± 0.09 5.01 Â± 0.06 11.19 Â± 0.08 10.40 Â± 0.13 4.79 Â± 0.20 8.85 Â± 0.21 10.46 Â± 0.22 8.41 Â± 0.07 6.73 Â± 0.03 SrcValid 39.53 Â± 1.22 26.07 Â± 1.15 24.30 Â± 1.02 33.06 Â± 0.50 26.55 Â± 1.30 23.04 Â± 0.42 18.50 Â± 0.11 24.48 Â± 0.14 24.45 Â± 0.62 15.04 Â± 0.55 6.99 Â± 0.44 32.56 Â± 0.97 14.51 Â± 1.34 11.73 Â± 0.83 13.62 Â± 0.68 22.30 Â± 0.55 SoftmaxScore [7] 18.07 Â± 0.26 22.21 Â± 0.25 21.62 Â± 0.20 13.92 Â± 0.16 16.91 Â± 0.29 19.36 Â± 0.28 23.96 Â± 0.21 20.32 Â± 0.16 20.23 Â± 0.08 27.65 Â± 0.07 29.54 Â± 0.02 11.81 Â± 0.70 26.78 Â± 0.17 28.10 Â± 0.06 28.13 Â± 0.07 21.91 Â± 0.16 GDE [21] 75.10 Â± 0.28 67.51 Â± 0.30 68.29 Â± 0.23 77.94 Â± 0.10 73.27 Â± 0.31 69.21 Â± 0.32 62.70 Â± 0.22 67.53 Â± 0.16 66.89 Â± 0.10 55.50 Â± 0.09 45.27 Â± 0.05 73.24 Â± 0.29 56.67 Â± 0.16 51.98 Â± 0.09 54.24 Â± 0.09 64.36 Â± 0.15 AdvPerturb [23] 22.95 Â± 0.27 30.05 Â± 0.34 30.19 Â± 0.24 7.97 Â± 0.03 16.05 Â± 0.38 17.26 Â± 0.23 16.44 Â± 0.14 20.51 Â± 0.21 14.11 Â± 0.12 28.50 Â± 0.04 5.37 Â± 0.20 22.67 Â± 0.25 24.31 Â± 0.11 20.91 Â± 0.10 10.33 Â± 0.17 19.17 Â± 0.14 SAR [29] AETTA 5.38 Â± 0.27 4.83 Â± 0.05 4.67 Â± 0.12 13.98 Â± 0.07 9.91 Â± 0.30 9.50 Â± 0.15 6.54 Â± 0.15 7.50 Â± 0.05 5.88 Â± 0.14 5.58 Â± 0.11 4.96 Â± 0.02 6.59 Â± 0.11 4.97 Â± 0.01 5.01 Â± 0.06 4.94 Â± 0.02 6.68 Â± 0.04 SrcValid 55.20 Â± 0.50 54.08 Â± 0.55 54.85 Â± 0.50 56.48 Â± 0.54 55.35 Â± 0.61 45.25 Â± 0.55 34.90 Â± 0.55 39.10 Â± 0.60 40.10 Â± 0.57 27.96 Â± 0.51 10.73 Â± 0.40 56.36 Â± 0.45 29.61 Â± 0.71 24.28 Â± 0.56 31.70 Â± 0.66 41.06 Â± 0.54 SoftmaxScore [7] 9.92 Â± 0.07 10.66 Â± 0.11 10.25 Â± 0.03 8.45 Â± 0.02 9.39 Â± 0.03 17.61 Â± 0.12 25.68 Â± 0.05 21.49 Â± 0.12 20.60 Â± 0.10 30.40 Â± 0.06 35.08 Â± 0.08 7.74 Â± 0.18 28.08 Â± 0.08 31.71 Â± 0.09 27.43 Â± 0.07 19.63 Â± 0.01 GDE [21] 86.92 Â± 0.11 85.84 Â± 0.09 86.59 Â± 0.05 88.22 Â± 0.10 87.15 Â± 0.11 77.00 Â± 0.10 66.67 Â± 0.08 70.86 Â± 0.17 71.83 Â± 0.17 59.67 Â± 0.13 42.25 Â± 0.07 88.09 Â± 0.04 61.51 Â± 0.10 56.11 Â± 0.10 63.50 Â± 0.14 72.81 Â± 0.07 AdvPerturb [23] 11.72 Â± 0.07 12.20 Â± 0.09 11.85 Â± 0.03 3.88 Â± 0.15 4.36 Â± 0.10 9.61 Â± 0.09 9.48 Â± 0.11 15.52 Â± 0.17 7.89 Â± 0.14 24.08 Â± 0.08 6.72 Â± 0.21 9.07 Â± 0.17 15.97 Â± 0.09 17.59 Â± 0.15 5.98 Â± 0.33 11.06 Â± 0.02 CoTTA [35] AETTA 4.75 Â± 0.07 4.01 Â± 0.03 4.80 Â± 0.07 7.44 Â± 0.20 5.06 Â± 0.22 4.66 Â± 0.06 4.51 Â± 0.13 4.42 Â± 0.03 4.24 Â± 0.08 8.98 Â± 0.13 8.83 Â± 0.09 6.46 Â± 0.44 6.96 Â± 0.07 8.36 Â± 0.24 6.26 Â± 0.19 5.98 Â± 0.04 SrcValid 15.32 Â± 0.10 18.63 Â± 0.24 21.33 Â± 0.24 7.87 Â± 0.64 4.26 Â± 0.10 4.70 Â± 0.33 9.33 Â± 0.78 7.02 Â± 0.35 4.60 Â± 0.14 7.37 Â± 0.56 5.56 Â± 0.51 19.87 Â± 3.35 5.95 Â± 0.65 5.32 Â± 0.25 6.34 Â± 0.60 9.56 Â± 0.26 SoftmaxScore [7] 11.98 Â± 0.07 16.57 Â± 0.16 17.30 Â± 0.14 13.34 Â± 0.22 16.79 Â± 0.35 17.72 Â± 0.39 20.62 Â± 0.14 17.70 Â± 0.17 17.19 Â± 0.08 18.56 Â± 0.23 26.66 Â± 0.07 7.63 Â± 1.41 21.56 Â± 0.24 20.65 Â± 0.15 19.14 Â± 0.11 17.56 Â± 0.08 GDE [21] 80.31 Â± 0.05 75.64 Â± 0.34 75.58 Â± 0.12 78.75 Â± 0.45 75.50 Â± 0.41 73.86 Â± 0.52 70.37 Â± 0.27 73.65 Â± 0.16 73.73 Â± 0.24 73.21 Â± 0.33 60.84 Â± 0.08 85.80 Â± 2.29 68.56 Â± 0.12 69.35 Â± 0.37 71.30 Â± 0.26 73.76 Â± 0.22 AdvPerturb [23] 13.96 Â± 0.07 18.59 Â± 0.21 20.19 Â± 0.19 6.39 Â± 0.09 12.37 Â± 0.49 10.70 Â± 0.43 9.35 Â± 0.04 12.77 Â± 0.09 9.00 Â± 0.05 12.01 Â± 0.13 4.08 Â± 0.04 9.25 Â± 1.09 15.19 Â± 0.13 7.64 Â± 0.24 4.28 Â± 0.21 11.05 Â± 0.05 RoTTA [36] AETTA 14.33 Â± 0.14 12.64 Â± 0.40 9.38 Â± 0.71 7.12 Â± 0.97 5.32 Â± 0.83 6.73 Â± 0.13 9.97 Â± 0.43 14.78 Â± 0.30 13.99 Â± 0.19 10.84 Â± 0.07 12.30 Â± 0.07 11.51 Â± 2.42 11.92 Â± 0.35 11.48 Â± 1.03 15.47 Â± 0.56 11.19 Â± 0.12 SrcValid 28.39 Â± 0.39 24.64 Â± 2.41 21.33 Â± 2.05 11.91 Â± 0.91 6.16 Â± 0.22 12.34 Â± 1.06 7.23 Â± 1.43 14.57 Â± 1.82 8.24 Â± 0.60 19.17 Â± 0.97 9.67 Â± 0.83 23.36 Â± 1.46 11.31 Â± 0.68 9.89 Â± 0.84 5.92 Â± 0.43 14.28 Â± 0.28 SoftmaxScore [7] 19.01 Â± 0.14 20.35 Â± 0.14 19.30 Â± 0.32 10.82 Â± 0.52 10.91 Â± 1.19 11.64 Â± 2.29 19.47 Â± 1.35 20.00 Â± 0.74 19.98 Â± 0.16 27.16 Â± 0.13 28.53 Â± 0.16 6.86 Â± 0.57 25.73 Â± 0.50 27.97 Â± 0.24 27.39 Â± 0.25 19.67 Â± 0.50 GDE [21] 62.46 Â± 0.16 58.40 Â± 0.17 59.83 Â± 0.27 68.57 Â± 0.46 67.82 Â± 1.14 65.51 Â± 2.04 56.52 Â± 1.44 56.27 Â± 0.64 57.53 Â± 0.16 44.74 Â± 0.34 38.05 Â± 0.20 63.36 Â± 0.63 48.33 Â± 0.37 43.13 Â± 0.26 45.89 Â± 0.28 55.76 Â± 0.45 AdvPerturb [23] 27.73 Â± 0.10 31.55 Â± 0.15 30.82 Â± 0.31 9.56 Â± 0.42 14.54 Â± 0.85 14.59 Â± 1.72 17.39 Â± 0.85 24.67 Â± 0.45 16.20 Â± 0.32 33.31 Â± 0.21 5.19 Â± 0.08 23.24 Â± 0.93 27.07 Â± 0.24 24.12 Â± 0.30 12.45 Â± 0.09 20.83 Â± 0.39 SoTTA [12] AETTA 17.92 Â± 0.25 16.51 Â± 0.62 18.41 Â± 0.09 20.63 Â± 0.51 16.50 Â± 0.53 18.76 Â± 4.82 16.27 Â± 4.31 18.90 Â± 1.16 19.99 Â± 1.58 25.06 Â± 1.90 21.37 Â± 1.10 19.28 Â± 1.51 17.33 Â± 1.16 23.02 Â± 1.12 18.30 Â± 0.88 19.22 Â± 0.79 23Table 13. Average accuracy improvement (%p) with model recovery. Averaged over three different random seeds. t Gau. Shot Imp. Def. Gla. Mot. Zoom Snow Fro. Fog Brit. Cont. Elas. Pix. JPEG Avg.(â†‘) Episodic [37] -10.41 Â± 0.85 -10.27 Â± 0.40 -4.58 Â± 0.93 22.41 Â± 1.13 14.47 Â± 0.72 38.62 Â± 2.00 44.44 Â± 2.82 41.68 Â± 2.66 44.55 Â± 3.61 51.44 Â± 2.92 62.95 Â± 1.48 61.34 Â± 1.23 50.74 Â± 1.07 53.72 Â± 0.45 42.53 Â± 0.57 33.58 Â± 1.04 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 20.38 Â± 18.28 44.40 Â± 13.41 53.45 Â± 1.36 59.25 Â± 1.04 58.27 Â± 3.48 44.38 Â± 3.80 46.87 Â± 5.07 34.81 Â± 6.96 24.12 Â± 2.11 Stochastic [35] -0.48 Â± 0.48 2.40 Â± 0.63 6.59 Â± 0.56 20.81 Â± 1.10 19.07 Â± 1.31 37.15 Â± 1.75 44.49 Â± 2.82 43.04 Â± 1.88 46.81 Â± 2.67 51.22 Â± 1.81 61.12 Â± 1.34 59.45 Â± 0.53 48.60 Â± 1.16 53.83 Â± 1.09 44.89 Â± 1.82 35.93 Â± 0.78 FisherStochastic [3] 0.45 Â± 0.59 4.13 Â± 0.91 7.91 Â± 0.88 23.24 Â± 0.83 21.79 Â± 0.45 41.00 Â± 1.72 47.98 Â± 2.94 47.45 Â± 3.31 51.60 Â± 3.74 57.52 Â± 3.38 65.52 Â± 1.51 66.03 Â± 0.45 55.12 Â± 1.64 61.53 Â± 0.59 52.85 Â± 0.45 40.27 Â± 1.29 DistShift 0.00 Â± 0.00 0.52 Â± 0.73 5.11 Â± 0.08 23.92 Â± 0.83 20.31 Â± 0.73 40.73 Â± 2.29 47.28 Â± 2.44 46.85 Â± 3.02 49.87 Â± 3.51 56.18 Â± 2.86 65.19 Â± 1.73 63.53 Â± 1.44 53.79 Â± 1.10 60.17 Â± 0.53 50.53 Â± 0.41 38.93 Â± 1.15 TENT [34] AETTA -3.27 Â± 0.91 -1.57 Â± 0.76 1.50 Â± 0.45 23.05 Â± 0.89 17.29 Â± 1.24 39.66 Â± 2.39 46.02 Â± 2.71 44.59 Â± 2.61 46.55 Â± 3.93 54.21 Â± 2.72 63.87 Â± 1.58 62.71 Â± 1.21 52.67 Â± 0.81 56.91 Â± 1.16 47.67 Â± 1.46 36.79 Â± 1.20 Episodic [37] 28.27 Â± 2.76 37.60 Â± 1.31 31.76 Â± 0.81 63.90 Â± 0.48 40.46 Â± 0.52 61.49 Â± 1.03 63.09 Â± 0.42 52.08 Â± 0.59 52.18 Â± 0.62 56.85 Â± 0.84 66.88 Â± 0.36 63.27 Â± 0.17 52.45 Â± 0.56 55.18 Â± 0.54 43.79 Â± 0.46 51.28 Â± 0.52 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 Stochastic [35] 1.28 Â± 0.79 -0.43 Â± 1.00 0.01 Â± 1.27 -0.03 Â± 0.76 -0.06 Â± 0.75 -0.74 Â± 0.46 0.03 Â± 0.34 -0.20 Â± 0.80 0.35 Â± 0.70 0.16 Â± 0.77 0.14 Â± 0.89 0.10 Â± 0.66 -0.21 Â± 0.31 -0.21 Â± 0.49 -0.29 Â± 0.06 -0.01 Â± 0.47 FisherStochastic [3] 1.27 Â± 1.08 0.16 Â± 1.79 0.55 Â± 1.53 -0.09 Â± 1.35 -0.30 Â± 1.15 -0.44 Â± 1.27 -0.14 Â± 1.14 -0.07 Â± 1.11 0.00 Â± 1.27 0.11 Â± 1.38 0.39 Â± 1.54 0.47 Â± 1.13 0.06 Â± 0.81 0.01 Â± 1.07 -0.17 Â± 0.62 0.12 Â± 1.16 DistShift 0.00 Â± 0.00 8.72 Â± 1.54 5.02 Â± 1.00 34.33 Â± 7.43 8.69 Â± 1.25 30.29 Â± 8.46 37.89 Â± 1.08 18.97 Â± 1.48 16.83 Â± 0.86 24.31 Â± 3.47 54.64 Â± 4.55 43.38 Â± 8.46 13.47 Â± 1.74 22.46 Â± 3.63 13.61 Â± 2.30 22.17 Â± 2.38 EATA [28] AETTA 25.52 Â± 2.94 35.73 Â± 1.87 27.52 Â± 1.66 59.91 Â± 2.41 32.61 Â± 3.46 57.93 Â± 1.86 60.50 Â± 0.21 50.05 Â± 0.52 49.48 Â± 0.59 56.00 Â± 0.55 64.97 Â± 0.95 62.84 Â± 0.28 49.02 Â± 0.75 54.48 Â± 1.30 43.01 Â± 0.97 48.64 Â± 0.74 Episodic [37] -7.28 Â± 0.41 -14.44 Â± 0.47 -14.37 Â± 0.37 -0.14 Â± 0.27 -8.55 Â± 0.48 -1.79 Â± 0.11 -3.65 Â± 0.26 -6.93 Â± 0.67 -8.78 Â± 0.34 -5.24 Â± 0.20 -2.85 Â± 0.37 -4.94 Â± 0.27 -5.93 Â± 0.54 -8.75 Â± 0.63 -11.33 Â± 0.51 -7.00 Â± 0.26 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 Stochastic [35] -2.16 Â± 0.29 -5.38 Â± 0.65 -4.81 Â± 0.57 1.07 Â± 0.26 -3.35 Â± 0.76 0.10 Â± 0.50 -0.77 Â± 0.30 -1.89 Â± 1.06 -3.17 Â± 0.82 -1.22 Â± 0.40 0.05 Â± 0.45 -1.98 Â± 0.21 -1.26 Â± 0.06 -2.40 Â± 0.91 -2.77 Â± 0.92 -2.00 Â± 0.48 FisherStochastic [3] -3.68 Â± 0.55 -9.44 Â± 0.30 -9.95 Â± 0.22 0.84 Â± 0.29 -6.57 Â± 0.48 -0.80 Â± 0.28 -2.69 Â± 0.28 -5.41 Â± 0.41 -7.03 Â± 0.28 -3.79 Â± 0.27 -1.84 Â± 0.37 -3.63 Â± 0.14 -4.48 Â± 0.47 -6.21 Â± 0.36 -8.02 Â± 0.59 -4.85 Â± 0.13 DistShift 0.00 Â± 0.00 -6.23 Â± 0.40 -7.32 Â± 0.23 1.20 Â± 0.05 -4.93 Â± 0.43 -0.34 Â± 0.27 -2.05 Â± 0.31 -3.68 Â± 0.37 -5.70 Â± 0.31 -1.99 Â± 0.27 -1.20 Â± 0.34 -2.58 Â± 0.19 -3.51 Â± 0.43 -4.84 Â± 0.41 -5.58 Â± 0.38 -3.25 Â± 0.10 SAR [29] AETTA -4.81 Â± 0.79 -10.45 Â± 0.79 -11.13 Â± 0.30 0.26 Â± 0.32 -7.17 Â± 0.81 -1.19 Â± 0.29 -3.23 Â± 0.31 -6.24 Â± 0.67 -8.02 Â± 0.39 -4.33 Â± 0.10 -2.33 Â± 0.33 -4.51 Â± 0.23 -4.73 Â± 0.63 -7.71 Â± 0.90 -9.28 Â± 0.75 -5.66 Â± 0.20 Episodic [37] 0.04 Â± 0.15 0.04 Â± 0.08 -0.16 Â± 0.10 0.11 Â± 0.16 0.40 Â± 0.54 0.86 Â± 0.14 1.09 Â± 0.07 1.77 Â± 0.17 2.67 Â± 0.42 4.14 Â± 0.60 1.77 Â± 0.40 3.28 Â± 0.47 3.55 Â± 0.39 2.71 Â± 0.24 2.44 Â± 0.24 1.65 Â± 0.10 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 Stochastic [35] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 FisherStochastic [3] 0.00 Â± 0.01 -0.01 Â± 0.10 0.01 Â± 0.06 0.08 Â± 0.08 -0.12 Â± 0.12 0.10 Â± 0.12 0.06 Â± 0.14 0.13 Â± 0.10 0.17 Â± 0.18 0.25 Â± 0.09 0.11 Â± 0.08 0.26 Â± 0.11 0.16 Â± 0.13 0.39 Â± 0.08 0.34 Â± 0.08 0.13 Â± 0.03 DistShift 0.00 Â± 0.00 0.03 Â± 0.12 -0.15 Â± 0.11 0.06 Â± 0.13 0.23 Â± 0.50 0.70 Â± 0.14 0.94 Â± 0.06 1.58 Â± 0.12 2.49 Â± 0.40 3.75 Â± 0.67 1.75 Â± 0.39 3.03 Â± 0.53 3.33 Â± 0.35 2.51 Â± 0.13 2.39 Â± 0.34 1.51 Â± 0.09 CoTTA [35] AETTA 0.04 Â± 0.12 0.01 Â± 0.08 -0.20 Â± 0.10 0.10 Â± 0.17 0.36 Â± 0.54 0.84 Â± 0.11 1.08 Â± 0.08 1.77 Â± 0.15 2.66 Â± 0.40 4.12 Â± 0.62 1.75 Â± 0.40 3.28 Â± 0.50 3.57 Â± 0.40 2.71 Â± 0.25 2.46 Â± 0.25 1.64 Â± 0.11 Episodic [37] -24.93 Â± 2.06 -27.94 Â± 1.45 -28.25 Â± 1.39 -25.30 Â± 1.05 -22.52 Â± 1.12 -18.68 Â± 0.41 -25.71 Â± 0.90 -12.13 Â± 0.62 -26.39 Â± 0.71 -19.78 Â± 1.40 -4.26 Â± 0.02 -45.54 Â± 0.81 -9.18 Â± 0.69 -38.08 Â± 2.90 -9.80 Â± 0.68 -22.57 Â± 0.85 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 -1.45 Â± 2.50 -0.71 Â± 1.24 -0.71 Â± 1.23 -1.32 Â± 2.29 -1.61 Â± 2.79 -0.26 Â± 0.45 -1.80 Â± 3.24 -10.03 Â± 15.10 -4.13 Â± 6.75 -3.90 Â± 6.62 -3.60 Â± 5.15 -1.97 Â± 2.23 Stochastic [35] -0.01 Â± 0.05 -1.11 Â± 0.41 -1.49 Â± 0.48 -0.80 Â± 0.40 -2.59 Â± 0.80 -1.11 Â± 0.44 -1.34 Â± 0.14 -3.34 Â± 0.16 -4.90 Â± 1.24 -2.12 Â± 0.61 -1.24 Â± 0.42 -8.43 Â± 2.16 -2.90 Â± 0.73 -3.71 Â± 1.02 -3.13 Â± 0.14 -2.55 Â± 0.49 FisherStochastic [3] 0.06 Â± 0.02 -0.53 Â± 0.20 -1.09 Â± 0.08 -0.43 Â± 0.17 -1.67 Â± 0.10 -0.79 Â± 0.19 -0.92 Â± 0.26 -2.74 Â± 0.30 -4.86 Â± 0.49 -1.10 Â± 0.59 -1.30 Â± 0.58 -14.10 Â± 3.20 -5.25 Â± 1.02 -4.39 Â± 0.55 -4.26 Â± 0.17 -2.89 Â± 0.13 DistShift 0.00 Â± 0.00 -3.39 Â± 0.63 -4.32 Â± 0.33 2.12 Â± 0.80 -3.61 Â± 0.31 -1.38 Â± 0.26 -4.71 Â± 0.45 -7.69 Â± 0.11 -16.56 Â± 0.46 -4.50 Â± 0.68 -5.47 Â± 0.53 -34.53 Â± 2.13 -7.52 Â± 1.34 -11.48 Â± 0.46 -11.39 Â± 0.32 -7.63 Â± 0.23 RoTTA [36] AETTA -1.65 Â± 1.34 -4.18 Â± 0.72 -21.72 Â± 11.69 -0.19 Â± 1.08 -4.32 Â± 0.81 -2.65 Â± 0.86 -4.63 Â± 1.03 -4.04 Â± 0.70 -7.17 Â± 0.41 -4.57 Â± 0.57 -0.09 Â± 0.23 -9.63 Â± 1.20 -4.96 Â± 0.95 -13.39 Â± 0.64 -7.30 Â± 0.71 -6.03 Â± 0.89 Episodic [37] -41.21 Â± 1.71 -45.52 Â± 0.96 -41.25 Â± 0.82 -26.70 Â± 0.44 -28.23 Â± 1.84 -18.73 Â± 0.68 -26.11 Â± 0.25 -13.13 Â± 0.53 -27.12 Â± 0.69 -21.52 Â± 0.24 -2.35 Â± 0.35 -47.36 Â± 1.01 -7.10 Â± 0.90 -37.60 Â± 2.26 -12.16 Â± 0.42 -26.40 Â± 0.51 MRS [29] 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 0.00 Â± 0.00 Stochastic [35] -1.39 Â± 0.46 -1.88 Â± 0.81 -1.05 Â± 0.13 3.72 Â± 0.28 -1.21 Â± 1.64 2.05 Â± 0.76 1.04 Â± 0.54 0.36 Â± 0.96 -0.15 Â± 0.61 1.43 Â± 1.19 1.48 Â± 0.34 1.35 Â± 0.51 -0.11 Â± 0.29 0.50 Â± 1.04 -0.83 Â± 0.49 0.35 Â± 0.51 FisherStochastic [3] -3.33 Â± 1.05 -5.23 Â± 0.91 -4.51 Â± 0.40 4.22 Â± 0.43 -4.15 Â± 1.61 1.65 Â± 0.71 0.42 Â± 1.03 -1.37 Â± 0.24 -2.01 Â± 0.21 -0.24 Â± 0.72 1.21 Â± 0.84 -0.55 Â± 1.59 -1.85 Â± 0.84 -1.01 Â± 1.07 -3.73 Â± 0.11 -1.36 Â± 0.51 DistShift 0.00 Â± 0.00 -4.06 Â± 0.34 -3.60 Â± 0.37 6.17 Â± 0.58 0.01 Â± 1.65 3.94 Â± 0.76 0.90 Â± 0.38 1.75 Â± 0.13 -0.92 Â± 0.26 2.28 Â± 0.42 2.83 Â± 0.66 1.94 Â± 0.58 0.52 Â± 0.95 0.25 Â± 0.82 -1.87 Â± 0.54 0.68 Â± 0.19 SoTTA [12] AETTA -7.58 Â± 1.91 -10.51 Â± 2.83 -18.71 Â± 18.80 1.54 Â± 0.35 -5.16 Â± 1.00 0.43 Â± 1.14 -2.90 Â± 1.49 -2.25 Â± 1.29 -6.29 Â± 0.51 -2.56 Â± 0.85 0.88 Â± 0.32 -8.40 Â± 0.60 -1.87 Â± 0.78 -4.69 Â± 0.23 -6.53 Â± 0.75 -4.97 Â± 1.58 24",
      "meta_data": {
        "arxiv_id": "2404.01351v1",
        "authors": [
          "Taeckyung Lee",
          "Sorn Chottananurak",
          "Taesik Gong",
          "Sung-Ju Lee"
        ],
        "published_date": "2024-04-01T04:21:49Z",
        "pdf_url": "https://arxiv.org/pdf/2404.01351v1.pdf"
      }
    },
    {
      "title": "Persistent Test-time Adaptation in Recurring Testing Scenarios",
      "abstract": "Current test-time adaptation (TTA) approaches aim to adapt a machine learning\nmodel to environments that change continuously. Yet, it is unclear whether TTA\nmethods can maintain their adaptability over prolonged periods. To answer this\nquestion, we introduce a diagnostic setting - recurring TTA where environments\nnot only change but also recur over time, creating an extensive data stream.\nThis setting allows us to examine the error accumulation of TTA models, in the\nmost basic scenario, when they are regularly exposed to previous testing\nenvironments. Furthermore, we simulate a TTA process on a simple yet\nrepresentative $\\epsilon$-perturbed Gaussian Mixture Model Classifier, deriving\ntheoretical insights into the dataset- and algorithm-dependent factors\ncontributing to gradual performance degradation. Our investigation leads us to\npropose persistent TTA (PeTTA), which senses when the model is diverging\ntowards collapse and adjusts the adaptation strategy, striking a balance\nbetween the dual objectives of adaptation and model collapse prevention. The\nsupreme stability of PeTTA over existing approaches, in the face of lifelong\nTTA scenarios, has been demonstrated over comprehensive experiments on various\nbenchmarks. Our project page is available at https://hthieu166.github.io/petta.",
      "full_text": "Persistent Test-time Adaptation in Recurring Testing Scenarios Trung-Hieu Hoang1 Duc Minh Vo2 Minh N. Do1,3 1Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign 2The University of Tokyo 3VinUni-Illinois Smart Health Center, VinUniversity {hthieu, minhdo}@illinois.edu vmduc@nlab.ci.i.u-tokyo.ac.jp Abstract Current test-time adaptation (TTA) approaches aim to adapt a machine learn- ing model to environments that change continuously. Yet, it is unclear whether TTA methods can maintain their adaptability over prolonged periods. To answer this question, we introduce a diagnostic setting - recurring TTA where envi- ronments not only change but also recur over time, creating an extensive data stream. This setting allows us to examine the error accumulation of TTA models, in the most basic scenario, when they are regularly exposed to previous testing environments. Furthermore, we simulate a TTA process on a simple yet repre- sentative Ïµ-perturbed Gaussian Mixture Model Classifier, deriving theoretical insights into the dataset- and algorithm-dependent factors contributing to gradual performance degradation. Our investigation leads us to propose persistent TTA (PeTTA), which senses when the model is diverging towards collapse and adjusts the adaptation strategy, striking a balance between the dual objectives of adaptation and model collapse prevention. The supreme stability of PeTTA over existing approaches, in the face of lifelong TTA scenarios, has been demonstrated over comprehensive experiments on various benchmarks. Our project page is available at https://hthieu166.github.io/petta. 1 Introduction Machine learning (ML) models have demonstrated significant achievements in various areas [18, 38, 47, 23]. Still, they are inherently susceptible to distribution-shift [46, 13, 48, 21, 6] (also known as the divergence between the training and testing environments), leading to a significant degradation in model performance. The ability to deviate from the conventional testing setting appears as a crucial aspect in boosting ML modelsâ€™ adaptability when confronted with a new testing environment that has been investigated [ 30, 53, 14]. Among common domain generalization methods [ 58, 24, 1], test-time adaptation (TTA) takes the most challenging yet rewarding path that leverages unlabeled data available at test time for self-supervised adaptation prior to the final inference [57, 39, 8, 41, 59]. Early TTA studies have concentrated on a simply ideal adaptation scenario where the test samples come from a fixed single domain [57, 39, 41]. As a result, such an assumption is far from the ever- changing and complex testing environments. To confront continually changing environments [59, 12], Yuan et al. [61] proposed a practical TTA scenario where distribution changing and correlative sampling occur [15] simultaneously. Though practical TTA is more realistic than what the previous assumptions have made, it still assumes that any environment only appears once in the data stream, a condition which does not hold true. Taking a surveillance camera as an example, it might accom- modate varying lighting conditions recurringly day after day (Fig. 1-left). Based on this reality, we hypothesize that the recurring of those conditions may reveal the error accumulation phenomenon in TTA, resulting in performance degradation over a long period. To verify our hypothesis, we simulate a 38th Conference on Neural Information Processing Systems (NeurIPS 2024). arXiv:2311.18193v4  [cs.CV]  2 Nov 2024Testing Error Time Day 1 Illumination Condition Day 2 Day 3 0 50 100 150 200 250 300 0 0.2 0.4 0.6 0.8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 201 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Test-time adaptation step Testing Error No TTA RoTTA PeTTA (ours) Figure 1: Recurring Test-time Adaption (TTA). (left) Testing environments may change recurringly and preserving adaptability when visiting the same testing condition is not guaranteed. (right) The testing error of RoTTA [61] progressively raises (performance degradation) and exceeds the error of the source model (no TTA) while our PeTTA demonstrates its stability when adapting to the test set of CIFAR-10-C [19] 20 times. The bold lines denote the running mean and the shaded lines in the background represent the testing error on each domain (excluding the source model, for clarity). recurring testing environment and observe the increasing error rate by recurringly adapting to the test set of CIFAR-10-C [19] multiple times. We showcase the testing error of RoTTA [61] after 20 cycles of adaptation in Fig. 1-right. As expected, RoTTA can successfully adapt and deliver encouraging outcomes within the first few passes. However, this advantage is short-lived as our study uncovers a significant issue: TTA approaches in this setting may experience severe and persistent degradation in performance. Consequently, the testing error of RoTTA gradually escalates over time and quickly surpasses the model without adaptation. This result confirms the risk of TTA deployment in our illustrative scenario, as an algorithm might work well in the first place and gradually degenerate. Therefore, ensuring sustainable quality is crucial for real-world applications, especially given the recurring nature of testing environments. This study examines whether the adaptability of a TTA algorithm persists over an extended testing stream. Specifically, in the most basic scenario, where the model returns to a previously encountered testing environment after undergoing various adjustments. We thus propose a more general testing scenario than the practical TTA [61], namely recurring TTA, where the environments not only change gradually but also recur in a correlated manner over time. We first analyze a simulation using the Ïµâˆ’perturbed Gaussian Mixture Model Classifier (Ïµâˆ’GMMC) on a synthesized dataset and derive a theoretical analysis to confirm our findings, offering insights to tackle similar issues in deep neural networks. The analysis provides hints for reasoning the success of many recent robust continual TTA approaches [61, 12, 59, 15] and leading us to propose a simple yet effective baseline to avoid performance degradation, namely Persistent TTA (PeTTA). PeTTA continuously monitors the chance of collapsing and adjusts the adaptation strategy on the fly, striking a balance between the two objectives: adaptation and collapse prevention. Our contributions can be summarized as follows: â€¢ First, this work proposes a testing scenario - recurring TTA, a simple yet sufficient setup for diagnosing the overlooked gradual performance degradation phenomenon of TTA. â€¢ Second, we formally define the phenomenon of TTA collapsing and undertake a theoretical analysis on an Ïµ-GMMC, shedding light on dataset-dependent and algorithm-dependent factors that contribute to the error accumulation during TTA processes. â€¢ Third, we introduce persistent TTA (PeTTA)- a simple yet effective adaptation scheme that surpasses all baseline models and demonstrates a persisting performance. For more context on related work, readers are directed to visit our discussions in Appdx. A. 2 Background Test-time Adaptation (TTA). A TTA algorithm operates on an ML classifier ft : X â†’ Ywith parameter Î¸t âˆˆ Î˜ (parameter space) gradually changing over time (t âˆˆ T) that maps an input image x âˆˆ Xto a category (label) y âˆˆ Y. Let the capital letters (Xt, Yt) âˆˆ X Ã— Ydenote a pair of random variables with the joint distribution Pt(x, y) âˆˆ Pd, tâˆˆ T. Here, Pd belongs to collection of D sets of testing scenarios (domains) {Pd}D d=1. The covariate shift [46] is assumed: Pt(x) and Ptâ€²(x) 2could be different but Pt(y|x) = Ptâ€²(y|x) holds âˆ€t Ì¸= tâ€². At t = 0, Î¸0 is initialized by a supervised model trained on P0 âˆˆ P0 (source dataset). The model then explores an online stream of testing data. For each t >0, it receives Xt (typically in form of a batch of Nt testing samples) for adapting itself ftâˆ’1 â†’ ft before making the final prediction ft (Xt). TTA with Mean Teacher Update. To achieve a stable optimization process, the main (teacher) model ft are updated indirectly through a student model with parameters Î¸â€² t [57, 61, 12, 15, 55]. At first, the teacher model in the previous step introduces a pseudo label [28] Ë†Yt for each Xt: Ë†Yt = ftâˆ’1(Xt). (1) With a classification loss LCLS (e.g., cross-entropy [16]), and a model parameters regularizer R, the student model is first updated with a generic optimization operatorOptim, followed by an exponential moving average (EMA) update of the teacher model parameter Î¸tâˆ’1: Î¸â€² t = Optim Î¸â€²âˆˆÎ˜ EPt h LCLS \u0010 Ë†Yt, Xt; Î¸â€² \u0011i + Î»R(Î¸â€²), (2) Î¸t = (1 âˆ’ Î±)Î¸tâˆ’1 + Î±Î¸â€² t, (3) with Î± âˆˆ (0, 1) - the update rate of EMA, andÎ» âˆˆ R+ - the weighting coefficient of the regularization term, are the two hyper-parameters. Practical TTA. In practical TTA [61], two characteristics of the aforementioned distribution of data stream are noticeable. Firstly, Ptâ€™s can be partitioned by tdâ€™s in which {Pt}td t=tdâˆ’1 âŠ‚ Pd. Here, each partition of consecutive steps follows the same underlying distribution which will change continually through D domains [59] (P1 â†’ P2 Â·Â·Â· â†’ PD). Secondly, the category distribution in each testing batch is temporally correlated [15]. This means within a batch, a small subset of categories is dominant over others, making the marginal distribution Pt(y) = 0, âˆ€y Ì¸âˆˆ Yt âŠ‚ Yeven though the category distribution over all batches are balanced. Optimizing under this low intra-batch diversity (|Yt| â‰ª |Y|) situation can slowly degenerate the model [7]. 3 Recurring TTA and Theoretical Analysis This section conducts a theoretical analysis on a concrete failure case of a simple TTA model. The results presented at the end of Sec. 3.2 will elucidate the factors contributing to the collapse (Sec. 3.1), explaining existing good practices (Sec. 3.3) and give insights into potential solutions (Sec. 4). 3.1 Recurring TTA and Model Collapse Recurring TTA.To study the gradual performance degradation (or model collapse), we propose anew testing scenario based on practical TTA [61]. Conducting a single pass through D distributions, as done in earlier studies [61, 59], may not effectively identify the degradation. To promote consistency, our recurring TTA performs revisiting the previous distributions K times to compare the incremental error versus the previous visits. For example, a sequence with K = 2 could be P1 â†’ P2 â†’ Â·Â·Â· â†’ PD â†’ P1 â†’ P2 â†’ Â·Â·Â· â†’ PD. Appdx. D extends our justifications on constructing recurring TTA. Definition 1 (Model Collapse). A model is said to be collapsed from step Ï„ âˆˆ T, Ï„ <âˆž if there exists a non-empty subset of categories ËœY âŠ‚ Ysuch that Pr{Yt âˆˆ ËœY} > 0 but the marginal Pr{Ë†Yt âˆˆ ËœY} converges to zero in probability: lim tâ†’Ï„ Pr{Ë†Yt âˆˆ ËœY} = 0. Here, upon collapsing, a model tends to ignore almost categories in ËœY. As it is irrecoverable once collapsed, the only remedy would be resetting all parameters back to Î¸0. 3.2 Simulation of Failure and Theoretical Analysis Collapsing behavior varies across datasets and the adaptation processes. Formally studying this phenomenon on a particular real dataset and a TTA algorithm is challenging. Therefore, we propose a theoretical analysis on Ïµ-perturbed binary Gaussian Mixture Model Classifier (Ïµ-GMMC) that shares the typical characteristics by construction and demonstrates the same collapsing pattern in action (Sec. 5.1) as observed on real continual TTA processes (Sec. 5.3). 3Pseudo-label Predictor Ë†Yt = argmax yâˆˆY Pr(Xt|y;Î¸tâˆ’1) Xt Mean-teacher Update Î¸â€² t = Optim Î¸â€²âˆˆÎ˜ EPt h LCLS \u0010Ë†Yt, Xt;Î¸â€²\u0011i Î¸t = (1âˆ’Î±)Î¸tâˆ’1 +Î±Î¸â€² t Ïµt Â·Â·Â· Î¸tâˆ’1 Î¸t Â·Â·Â· Figure 2: Ïµ-perturbed binary Gaussian Mix- ture Model Classifier, imitating a continual TTA algorithm for theoretical analysis. Two main components include a pseudo-label predictor (Eq. 1), and a mean teacher up- date (Eqs. 2, 3). The predictor is perturbed for retaining a false negative rate of Ïµt to simulate an undesirable TTA testing stream. Simulated Testing Stream. Observing a testing stream with (Xt, Yt) âˆˆ X Ã— Y= R Ã— {0, 1} and the underlying joint distribution Pt(x, y) = py,t Â· N(x; Âµy, Ïƒ2 y). The main task is predicting Xt was sampled from cluster 0 or 1 (negative or positive). Conveniently, let py,t âˆ† = Pt(y) = Pr(Yt = y) and Ë†py,t âˆ† = Pr( Ë†Yt = y) be the marginal distribution of the true label Yt and pseudo label Ë†Yt. GMMC and TTA. GMMC first implies an equal prior distribution by construction which is desirable for the actual TTA algorithms (e.g., category-balanced sampling strategies in [ 61, 15]). Thus, it simplifies ft into a maximum likelihood estimation ft(x) = argmaxyâˆˆY Pr(x|y; Î¸t) with Pr(x|y; Î¸t) = N(x; Ë†Âµy,t, Ë†Ïƒ2 y,t). The goal is estimating a set of parameters Î¸t = {Ë†Âµy,t, Ë†Ïƒ2 y,t}yâˆˆY. A perfect classifier Î¸0 = {Âµy, Ïƒ2 y}yâˆˆY is initialized at t = 0. For the consecutive steps, the simplicity of GMMC allows solving the Optim (for finding Î¸â€² t, Eq. 2) perfectly by computing the empirical mean and variance of new samples, approximating EPt. The mean teacher update (Eq. 3) for GMMC is: Ë†Âµy,t = ( (1 âˆ’ Î±)Ë†Âµy,tâˆ’1 + Î±EPt h Xt|Ë†Yt i if Ë†Yt = y Ë†Âµy,tâˆ’1 otherwise . (4) The update of Ë†Ïƒ2 y,t is similar. Ë†Yt = ftâˆ’1(Xt) can be interpreted as a pseudo label (Eq. 1). Ïµ-GMMC. Severe distribution shifts or low intra-batch category diversity of recurring TTA/practical TTA both result in an increase in the error rate of the predictor . Instead of directly modeling the dynamic changes of py,t (which can be complicated depending on the dataset), we study an Ïµâˆ’pertubed GMMC (Ïµâˆ’GMMC), where py,t is assumed to be static (defined below) and the pseudo- label predictor of this model is perturbed to simulate undesirable effects of the testing stream on the predictor. Two kinds of errors appear in a binary classifier [4]. Let Ïµt = Pr{Yt = 1|Ë†Yt = 0} (5) be the false negative rate (FNR) of the model at step t. Without loss of generality, we study the increasing type II collapse of Ïµ-GMMC. By intentionally flipping the true positive pseudo labels in simulation, an FNR of Ïµt is maintained (Fig. 2). Assumption 1 (Static Data Stream). The marginal distribution of the true label follows the same Bernoulli distribution Ber(p0): p0,t = p0, (p1,t = p1 = 1 âˆ’ p0), âˆ€t âˆˆ T. Lemma 1 (Increasing FNR). Under Assumption 1, a binary Ïµ-GMMC would collapsed (Def. 1) with lim tâ†’Ï„ Ë†p1,t = 0 (or lim tâ†’Ï„ Ë†p0,t = 1, equivalently) if and only if lim tâ†’Ï„ Ïµt = p1. Lemma 1 states the negative correlation between Ë†p1,t and Ïµt. Unsurprisingly, towards the collapsing point where all predictions are zeros, the FNR also increases at every step and eventually reaches the highest possible FNR of p1. Lemma 2 (Ïµ-GMMC After Collapsing ). For a binary Ïµ-GMMC model, with Assumption 1, if lim tâ†’Ï„ Ë†p1,t = 0 (collapsing), the cluster 0 in GMMC converges in distribution to a single-cluster GMMC with parameters: N(Ë†Âµ0,t, Ë†Ïƒ2 0,t) d. â†’ N(p0Âµ0 + p1Âµ1, p0Ïƒ2 0 + p1Ïƒ2 1 + p0p1(Âµ0 âˆ’ Âµ1)2). Lemma 2 states the resulting Ïµâˆ’GMMC after collapsing. Cluster 0 now covers the whole data distribution (and assigning label 0 for all samples). Furthermore, collapsing happens when Ë†Âµ0,t moves toward Âµ1. We next investigate the factors and conditions for this undesirable convergence. 4Theorem 1 (Convergence of Ïµâˆ’GMMC). For a binary Ïµ-GMMC model, with Assumption 1, let the distance from Ë†Âµ0,t toward Âµ1 is d0â†’1 t = |EPt [Ë†Âµ0,t] âˆ’ Âµ1|, then: d0â†’1 t âˆ’ d0â†’1 tâˆ’1 â‰¤ Î± Â· p0 Â· \u0012 |Âµ0 âˆ’ Âµ1| âˆ’d0â†’1 tâˆ’1 1 âˆ’ Ïµt \u0013 . From Thm. 1, we observe that the distance d0â†’1 t â€™s converges (also indicating the convergence to the distribution in Lemma 2) if d0â†’1 t < d0â†’1 tâˆ’1 . The model collapse happens when this condition holds for a sufficiently long period. Corollary 1 (A Condition forÏµâˆ’GMMC Collapse). With fixedp0, Î±, Âµ0, Âµ1, Ïµâˆ’GMMC is collapsed if there exists a sequence of {Ïµt}Ï„ Ï„âˆ’âˆ†Ï„ (Ï„ â‰¥ âˆ†Ï„ > 0) such that: p1 â‰¥ Ïµt > 1 âˆ’ d0â†’1 tâˆ’1 |Âµ0 âˆ’ Âµ1|, t âˆˆ [Ï„ âˆ’ âˆ†Ï„ , Ï„]. Corollary 1 introduces a condition Ïµ-GMMC collapse. Here, Ïµtâ€™s are non-decreasing, lim tâ†’Ï„ Ïµt = p1. Remarks. Thm. 1 concludes two sets of factors contributing to collapse: (i) data-dependent factors: the prior data distribution (p0), the nature difference between two categories (|Âµ0 âˆ’ Âµ1|); and (ii) algorithm-dependent factors: the update rate (Î±), the FNR at each step (Ïµt). Ïµ-GMMC analysis sheds light on explaining model collapse on real datasets (Sec. 5.3), reasons the existing approaches (Sec. 3.3) and motivates the development of our baseline (Sec. 4). 3.3 Connection to Existing Solutions Prior TTA algorithms have already incorporated implicit mechanisms to mitigate model collapse. The theoretical results in the previous section explain the rationale behind these effective strategies. Regularization Term for Î¸t. Knowing that f0 is always well-behaved, an attempt is restricting the divergence of Î¸t from Î¸0, e.g. using R(Î¸t) âˆ† = âˆ¥Î¸0 âˆ’ Î¸tâˆ¥2 2 regularization [40]. The key idea is introducing a penalty term to avoid an extreme divergence as happening in Thm. 1. Memory Bank for Harmonizing Pt(x). Upon receiving Xt, samples in this batch are selectively updated to a memory bank M (which already contains a subset of some instances ofXtâ€², tâ€² < tin the previous steps). By keeping a balanced number of samples from each category, distribution PM t (y) of samples in M is expected to have less zero entries than Pt(y), making the optimization step over PM t more desirable. From Thm. 1, M moderates the extreme value of the category distribution (p0 term) which typically appears on batches with low intra-batch category diversity. 4 Persistent Test-time Adaptation (PeTTA) Now we introduce our Persistent TTA (PeTTA) approach. Further inspecting Thm. 1, while Ïµt (Eq. 5) is not computable without knowing the true labels, the measure of divergence from the initial distribution (analogously to d0â†’1 tâˆ’1 term) can provide hints to fine-tune the adaptation process. Key Idea. A proper adjustment toward the TTA algorithm can break the chain of monotonically increasing Ïµtâ€™s in Corollary 1 to prevent the model collapse. In the mean teacher update, the larger value of Î» (Eq. 2) prioritizes the task of preventing collapse on one hand but also limits its adaptability to the new testing environment. Meanwhile, Î± (Eq. 3) controls the weight on preserving versus changing the model from the previous step. Drawing inspiration from the exploration-exploitation tradeoff [49, 25] encountered in reinforcement learning [54], we introduce a mechanism for adjusting Î» and Î± on the fly, balancing between the two primary objectives: adaptation and preventing model collapse. Our strategy is prioritizing collapse prevention (increasing Î») and preserving the model from previous steps (decreasing Î±) when there is a significant deviation from Î¸0. In [40, 61, 59], Î» and Î± were fixed through hyper-parameter tuning. This is suboptimal due to varying TTA environments and the lack of validation set [62]. Furthermore, Thm. 1 suggests the convergence rate quickly escalates when Ïµt increases, making constant Î», Î±insufficient to prevent collapse. Sensing the Divergence of Î¸t. We first equip PeTTA with a mechanism for measuring its divergence from Î¸0. Since ft(x) = argmax yâˆˆY Pr(y|x; Î¸t), we can decompose Pr(y|x; Î¸t) = [h (Ï•Î¸t(x))]y, with Ï•Î¸t(Â·) is a Î¸t-parameterized deep feature extractor followed by a fixed classification head (a linear and softmax layer) h(Â·). The operator [Â·]y extracts the yth component of a vector. 5Since h(Â·) remains unchanged, instead of comparing the divergence in the parameter space (Î˜) or between the output probability Pr(y|x; Î¸t) and Pr(y|x; Î¸0), we suggest an inspection over the feature embedding space that preserves a maximum amount of information in our case (data processing inequality [9]). Inspired by [31] and under Gaussian assumption, the Mahalanobis distance of the first moment of the feature embedding vectors is compared. Let z = Ï•Î¸t(x), we keep track of a collection of the running mean of feature vector z: {Ë†Âµy t }yâˆˆY in which Ë†Âµy t is EMA updated with vector z if ft(x) = y. The divergence of Î¸t at step t, evaluated on class y is defined as: Î³y t = 1 âˆ’ exp \u0010 âˆ’(Ë†Âµy t âˆ’ Âµy 0)T (Î£y 0)âˆ’1 (Ë†Âµy t âˆ’ Âµy 0) \u0011 , (6) where Âµy 0 and Î£y 0 are the pre-computed empirical mean and covariant matrix of feature vectors in the source dataset (P0). The covariant matrix here is diagonal for simplicity. In practice, without directly accessing the training set, we assume a small set of unlabeled samples can be drawn from the source distribution for empirically computing these values (visit Appdx. E.4 for further details). Here, we implicitly expect the independence of each entry in z and TTA approaches learn to align feature vectors of new domains back to the source domain (P0). Therefore, the accumulated statistics of these feature vectors at each step should be concentrated near the vectors of the initial model. The value of Î³y t âˆˆ [0, 1] is close to 0 when Î¸t = Î¸0 and increases exponentially as Ë†Âµy t diverging from Âµy 0. Adaptive Regularization and Model Update. With Î±0, Î»0 are initial values, utilizing Î³y t derived in Eq. 6, a pair of (Î»t, Î±t) is adaptively chosen at each step: Â¯Î³t = 1 | Ë†Yt| X yâˆˆ Ë†Yt Î³y t , Ë†Yt = n Ë†Y (i) t |i = 1, Â·Â·Â· , Nt o ; Î»t = Â¯Î³t Â· Î»0, Î± t = (1 âˆ’ Â¯Î³t) Â· Î±0, (7) Ë†Yt is a set of unique pseudo labels in a testing batch ( Ë†Y (i) t is the ith realization of Ë†Yt). Anchor Loss. Penalizing the divergence with regular vector norms in high-dimensional space (Î˜) is insufficient (curse of dimensionality [5, 51]), especially with a large model and limited samples. Anchor loss LAL can nail down the similarity between ft and f0 in the probability space [32, 12]: LAL(Xt; Î¸) = âˆ’ X yâˆˆY Pr(y|Xt; Î¸0) log Pr(y|Xt; Î¸), (8) which is equivalent to minimizing the KL divergence DKL (Pr(y|Xt; Î¸0)âˆ¥Pr(y|Xt; Î¸)). Persistent TTA.Having all the ingredients, we design our approach, PeTTA, following the convention setup of the mean teacher update, with the category-balanced memory bank and the robust batch normalization layer from [61]. Appdx. E.1 introduces the pseudo code of PeTTA. ForLCLS, either the self-training scheme [12] or the regular cross-entropy [16] is adopted. With R(Î¸), cosine similarity or L2 distance are both valid metrics for measuring the distance between Î¸ and Î¸0 in the parameter space. Fisher regularizer coefficient [ 40, 27] can also be used, optionally. To sum up, the teacher model update of PeTTA is an elaborated version of EMA with Î»t, Î±t (Eq. 7) and LAL (Eq. 8): Î¸â€² t = Optim Î¸â€²âˆˆÎ˜ EPt h LCLS \u0010 Ë†Yt, Xt; Î¸â€² \u0011 + LAL (Xt; Î¸â€²) i + Î»tR(Î¸â€²), Î¸t = (1 âˆ’ Î±t)Î¸tâˆ’1 + Î±tÎ¸â€² t. 5 Experimental Results 5.1 Ïµâˆ’MMC Simulation Result Simulation Setup. A total of 6000 samples from two Gaussian distributions: N(Âµ0 = 0, Ïƒ2 0 = 1) and N(Âµ1 = 2, Ïƒ2 1 = 1) with p0 = p1 = 1 2 are synthesized and gradually released in a batch of B = 10 samples. For evaluation, an independent set of 2000 samples following the same distribution is used for computing the prediction frequency, and the false negative rate (FNR). Ïµâˆ’GMMC update follows Eq. 4 with Î± = 5eâˆ’2. To simulate model collapse, the predictor is intercepted and 10% of the true-postive pseudo labels at each testing step are randomly flipped (Corollary 1). Simulation Result. In action, both the likelihood of predicting class 0 (Fig. 3a-left) and theÏµt (Eq. 5) (Fig. 3c-right, solid line) gradually increases over time as expected (Lemma 1). After collapsing, 60 120 240 360 480 6000 0.2 0.4 0.6 0.8 1 Testing Step (t) 0 120 240 360 480 6000 0.2 0.4 0.6 0.8 1 Testing Step (t) âˆ’4 âˆ’2 0 2 4xâˆ’4 âˆ’2 0 2 40 0.2 0.4 0.6 0.8 1 x Probability density N(Âµ0, Ïƒ0) N(Âµ1, Ïƒ1) N(Ë†Âµ0, Ë†Ïƒ0) N(Ë†Âµ1, Ë†Ïƒ1) 0 100 200 300 400 500 600 0.8 1.2 1.6 2.0 Testing step (t) |Ë†Âµ0,t âˆ’Âµ1| Numerical Simulation Theoretical Result 0 100 200 300 400 500 600 0.1 0.2 0.3 0.4 0.5 Testing step (t) Ïµt Prediction Frequency GMMCÏµ-GMMC Ïµ-GMMC GMMC (a) (b) (c) Figure 3: Simulation result on Ïµ-perturbed Gaussian Mixture Model Classifier ( Ïµ-GMMC) and GMMC (perturbed-free). (a) Histogram of model predictions through time. A similar prediction frequency pattern is observed on CIFAR-10-C (Fig. 5a-left). (b) The probability density function of the two clusters after convergence versus the true data distribution. The initial two clusters of Ïµ-GMMC collapsed into a single cluster with parameters stated in Lemma 2. In the perturbed-free, GMMC converges to the true data distribution. (c) Distance toward Âµ1 (|EPt [Ë†Âµ0,t] âˆ’ Âµ1|) and false- negative rate (Ïµt) in simulation coincides with the result in Thm. 1 (with Ïµt following Corollary 1). Ïµ-GMMC merges the two initial clusters, resulting in a single one (Fig. 3b-left) with parameters that match Lemma 2. The distance from Ë†Âµ0,t (initialized at Âµ0) towards Âµ1 converges (Fig. 3c-left, solid line), coincided with the analysis in Thm. 1 when Ïµt is chosen following Corollary 1 (Fig. 3c, dashed line). GMMC (perturbed-free) stably produces accurate predictions (Fig. 3a-right) and approximates the true data distribution (Fig. 3b-right). The simulation empirically validates our analysis (Sec. 3.2), confirming the vulnerability of TTA models when the pseudo labels are inaccurately estimated. 5.2 Setup - Benchmark Datasets Datasets. We benchmark the performance on four TTA classification tasks. Specifically, CIFAR10 â†’ CIFAR10-C, CIFAR100â†’ CIFAR100-C, and ImageNet â†’ ImageNet-C [19] are three corrupted images classification tasks (corruption level 5, the most severe). Additionally, we incorporate DomainNet [44] with 126 categories from four domains for the task real â†’ clipart, painting, sketch. Compared Methods. Besides PeTTA, the following algorithms are investigated: CoTTA [ 59], EATA [40], RMT [12], MECTA [22], RoTTA [61], ROID [37] and TRIBE [52]. Noteworthy, only RoTTA is specifically designed for the practical TTA setting while others fit the continual TTA setting in general. A parameter-free approach: LAME [ 7] and a reset-based approach (i.e., reverting the model to the source model after adapting to every 1, 000 images): RDumb [45] are also included. Recurring TTA. Following the practical TTA setup, multiple testing scenarios from each testing set will gradually change from one to another while the Dirichlet distribution (Dir(0.1) for CIFAR10- C, DomainNet, and ImageNet-C, and Dir(0.01) for CIFAR100-C) generates category temporally correlated batches of data. For all experiments, we set the number of revisits K = 20 (times) as this number is sufficient to fully observe the gradual degradation on existing TTA baselines. Implementation Details. We use PyTorch [43] for implementation. RobustBench [10] and torchvision [35] provide pre-trained source models. Hyper-parameter choices are kept as close as possible to the original selections of authors. Visit Sec. G for more implementation details. Unless otherwise noted, for all PeTTA experiments, the EMA update rate for robust batch normalization [61] and feature embedding statistics is set to 5eâˆ’2; Î±0 = 1eâˆ’3 and cosine similarity regularizer is used. On CIFAR10/100-C and ImageNet-C we use the self-training loss in [ 12] for LCLS and Î»0 = 10 while the regular cross-entropy loss [ 13] and Î»0 = 1 (severe domain shift requires prioritizing 7Table 1: Average classification error of the task CIFAR-10â†’ CIFAR-10-C in recurring TTA. The lowest error is in bold,(âˆ—)average value across 5 runs (different random seeds) is reported for PeTTA. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Source 43.5 43.5 LAME [7] 31.1 31.1 CoTTA [59]82.2 85.6 87.2 87.8 88.2 88.5 88.7 88.7 88.9 88.9 88.9 89.2 89.2 89.2 89.1 89.2 89.2 89.1 89.3 89.388.3EATA [40]81.6 87.0 88.7 88.7 88.9 88.7 88.6 89.0 89.3 89.6 89.5 89.6 89.7 89.7 89.3 89.6 89.6 89.8 89.9 89.488.8RMT [12]77.5 76.9 76.5 75.8 75.5 75.5 75.4 75.4 75.5 75.3 75.5 75.6 75.5 75.5 75.7 75.6 75.7 75.6 75.7 75.875.8MECTA [22]72.2 82.0 85.2 86.3 87.0 87.3 87.3 87.5 88.1 88.8 88.9 88.9 88.6 89.1 88.7 88.8 88.5 88.6 88.3 88.886.9RoTTA [61]24.6 25.5 29.6 33.6 38.2 42.8 46.2 50.6 52.2 54.1 56.5 57.5 59.4 60.2 61.7 63.0 64.8 66.1 68.2 70.351.3RDumb [45]31.1 32.1 32.3 31.6 31.9 31.8 31.8 31.9 31.9 32.1 31.7 32.0 32.5 32.0 31.9 31.6 31.9 31.4 32.3 32.431.9ROID [37]72.7 72.6 73.1 72.4 72.7 72.8 72.7 72.7 72.9 72.8 72.9 72.9 72.8 72.5 73.0 72.8 72.5 72.5 72.7 72.772.7TRIBE [52]15.3 16.6 16.6 16.3 16.7 17.0 17.3 17.4 17.4 18.0 17.9 18.0 17.9 18.6 18.2 18.8 18.0 18.2 18.4 18.017.5PeTTA(ours)(âˆ—) 24.323.022.622.422.422.522.322.522.822.822.622.722.722.922.622.722.622.822.923.022.8 adaptability) are applied in DomainNet experiments. In Appdx. F.5, we provide a sensitivity analysis on the choice of hyper-parameter Î»0 in PeTTA. 5.3 Result - Benchmark Datasets Recurring TTA Performance. Fig. 1-right presents the testing error on CIFAR-10-C in recurring TTA setting. RoTTA [61] exhibits promising performance in the first several visits but soon raises and eventually exceeds the source model (no TTA). The classification error of compared methods on CIFAR-10â†’CIFAR-10-C, and ImageNet â†’ ImageNet-C [19] tasks are shown in Tab. 1, and Tab. 2. Appdx. F.1 provides the results on the other two datasets. The observed performance degradation of CoTTA [59], EATA [40], RoTTA [61], and TRIBE [52] confirms the risk of error accumulation for an extensive period. While RMT [12], MECTA [22], and ROID [37] remain stable, they failed to adapt to the temporally correlated test stream at the beginning, with a higher error rate than the source model. LAME [7] (parameter-free TTA) and RDumb [45] (reset-based TTA) do not suffer from collapsing. However, their performance is lagging behind, and knowledge accumulation is limited in these approaches that could potentially favor a higher performance as achieved by PeTTA. Furthermore, LAME [7] is highly constrained by the source model, and selecting a precise reset frequency in RDumb [45] is challenging in practice (see Appdx. F.3 for a further discussion). 0 10 20 30 40 16 18 20 22 24 Recurring TTA Visit Classification Error PeTTA (ours) TRIBE [52] Figure 4: Classification error of TRIBE [ 52] and PeTTA (ours) of the task CIFAR-10â†’CIFAR10-C task in recurring TTA with 40 visits. In average, PeTTA outperforms almost every baseline approaches and persists across 20 vis- its over the three datasets. The only exception is at the case of TRIBE [ 52] on CIFAR-10- C. While this state-of-the-art model provides stronger adaptability, outweighing the PeTTA, and baseline RoTTA [61] in several recurrences, the risk of the model collapsing still presents in TRIBE [52]. This can be clearly observed when we increase the observation period to 40 recur- ring visits in Fig. 4. As the degree of freedom for adaptation in PeTTA is more constrained, it takes a bit longer for adaptation but remains sta- ble afterward. Fig. 5b-bottom exhibits the con- fusion matrix at the last visit with satisfactory accuracy. The same results are also observed when shuffling the order of domain shifts within each recurrence (Appdx. D.3), or extending the number of recurrences to 40 visits (Appdx. F.4). Continuously Changing Corruption (CCC) [45] Performance. Under CCC [45], Tab. 3 reveals the supreme performance of PeTTA over RoTTA [61] and RDumb [45]. Here, we report the average classification error between two consecutive adaptation step intervals. An adaptation step in this table corresponds to a mini-batch of data with 64 images. The model is adapted to 80, 000 steps in total with more than 5.1M images, significantly longer than 20 recurring TTA visits. Undoubtedly, PeTTA still achieves good performance where the corruptions are algorithmically generated, non-cyclic with two or more corruption types can happen simultaneously. This experiment also empirically justifies the construction of our recurring TTA as a diagnostic tool (Appdx. D.2) where similar observations are concluded on the two settings. Obviously, our recurring TTA is notably simpler than CCC [45]. 8Table 2: Average classification error of the task ImageNet â†’ ImageNet-C in recurring TTA scenario. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Source 82.0 82.0 LAME [7] 80.9 80.9 CoTTA [59]98.6 99.1 99.4 99.4 99.5 99.5 99.5 99.5 99.6 99.7 99.6 99.6 99.6 99.6 99.6 99.6 99.6 99.6 99.7 99.799.5EATA [40]60.4 59.3 65.4 72.6 79.1 84.2 88.7 92.7 95.2 96.9 97.7 98.1 98.4 98.6 98.7 98.8 98.8 98.9 98.9 99.089.0RMT [12]72.3 71.0 69.9 69.1 68.8 68.5 68.4 68.3 70.0 70.2 70.1 70.2 72.8 76.8 75.6 75.1 75.1 75.2 74.8 74.771.8MECTA [22]77.2 82.8 86.1 87.9 88.9 89.4 89.8 89.9 90.0 90.4 90.6 90.7 90.7 90.8 90.8 90.9 90.8 90.8 90.7 90.889.0RoTTA [61]68.3 62.1 61.8 64.5 68.4 75.4 82.7 95.1 95.8 96.6 97.1 97.9 98.3 98.7 99.0 99.1 99.3 99.4 99.5 99.687.9RDumb [45]72.2 73.0 73.2 72.8 72.2 72.8 73.3 72.7 71.9 73.0 73.2 73.1 72.0 72.7 73.3 73.1 72.1 72.6 73.3 73.172.8ROID [37]62.7 62.3 62.3 62.3 62.5 62.3 62.4 62.4 62.3 62.6 62.5 62.3 62.5 62.4 62.5 62.4 62.4 62.5 62.4 62.562.4TRIBE [52]63.664.0 64.9 67.8 69.6 71.7 73.5 75.5 77.4 79.8 85.0 96.5 99.4 99.8 99.9 99.8 99.8 99.9 99.9 99.984.4PeTTA(ours)(âˆ—) 65.361.759.859.159.459.659.859.359.460.060.361.060.760.460.660.760.860.760.460.260.5 Table 3: Average classification error on CCC [45] setting. Each column presents the average error within an adaptation interval (e.g., the second column provides the average error between the 6701 and 13400 adaptation steps). Each adaptation step here is performed on a mini-batch of 64 images. CCC [45] Adaptation Stepâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method6700 13400 20100 26800 33500 40200 46900 53600 60200 66800 73400 80000Avg Source 0.83 0.83 0.83 0.83 0.83 0.84 0.84 0.83 0.84 0.83 0.83 0.83 0.83 RoTTA [61]0.70 0.85 0.92 0.96 0.98 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.95 RDumb [45]0.78 0.74 0.75 0.77 0.75 0.72 0.75 0.77 0.75 0.74 0.75 0.75 0.75 PeTTA(ours) 0.67 0.63 0.62 0.65 0.65 0.64 0.64 0.68 0.63 0.63 0.65 0.65 0.64 0.46 0.44 0.4 0.43 0.46 0.47 0.44 0.43 0.48 0.4 0.43 0.43 0.41 airplane bird cat dog frog ship auto deer horse truck 0.13 0.34 0.44 0.32 0.14 0.44 0.51 0.46 0.46 0.34 airplane bird catdog frog ship auto deer horse truck Inter-category cosine similarity (source model)Misclassification rate of collapsed RoTTA 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.69 0 0 0 0.08 0 0.04 0 0.13 0.05 0.34 0.17 0 0 0.1 0 0.03 0 0.23 0.13 0.24 0 0.1 0.03 0.44 0 0.11 0 0.07 0.01 0.21 0 0 0.11 0.32 0 0.21 0 0.14 0.01 0.14 0 0 0.01 0.71 0 0.06 0.01 0.06 0.01 0.21 0 0 0.07 0.44 0 0.16 0 0.1 0.01 0.05 0 0 0.08 0.51 0 0.25 0 0.1 0.01 0.17 0 0 0.03 0.46 0 0.04 0.21 0.06 0.04 0.46 0 0 0.01 0.06 0 0.03 0 0.41 0.03 0.34 0 0 0 0.12 0 0.03 0 0.18 0.32 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.01 0.06 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.75 0.07 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.06 0.72 0.05 0.04 0.06 0.02 0.01 0.01 0.02 0 0.06 0.07 0.76 0.01 0.05 0.02 0.01 0 0 0 0.07 0.19 0.05 0.59 0.05 0.02 0.01 0.01 0 0 0.03 0.07 0.02 0.01 0.84 0 0.01 0.01 0.01 0 0.06 0.06 0.08 0.02 0.02 0.74 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.03 0 0.84 0.02 0.01 0.05 0.02 0.03 0.01 0 0.02 0.01 0.04 0.82 1 5 10 15 200 0.2 0.4 0.6 0.8 1 Visits 1 5 10 15 200 0.2 0.4 0.6 0.8 1 Visits RoTTA [61] PeTTA (ours) PeTTA (ours) - 20th visit RoTTA [61] - 20th visit Predicted label (a) (b)(c) True labelTrue label Prediction Frequency Figure 5: Recurring TTA (20 visits) on CIFAR-10 â†’CIFAR10-C task. (a) Histogram of model predictions (10 labels are color-coded). PeTTA achieves a persisting performance while RoTTA [61] degrades. (b) Confusion matrix at the last visit, RoTTA classifies all samples into a few categories (e.g., 0: airplane, 4: deer). (c) Force-directed graphs showing (left) the most prone to misclassification pairs (arrows indicating the portion and pointing from the true to the misclassified category); (right) similar categories tend to be easily collapsed. Edges denote the average cosine similarity of feature vectors (source model), only the highest similar pairs are shown. Best viewed in color. Collapsing Pattern. The rise in classification error (Fig. 1-right) can be reasoned by the prediction frequency of RoTTA [ 61] in an recurring TTA setting (Fig. 5a-left). Similar to Ïµ-GMMC, the likelihood of receiving predictions on certain categories gradually increases and dominates the others. Further inspecting the confusion matrix of a collapsed model (Fig. 5b-top) reveals two major groups of categories are formed and a single category within each group represents all members, thereby becoming dominant. To see this, Fig. 5c-left simplifies the confusion matrix by only visualizing the 9Table 4: Average (across 20 visits) error of multiple variations of PeTTA: without (w/o) R(Î¸), LAL; LAL only; fixed regularization coefficient Î»; adaptive coef- ficient Î»t, update rate Î±t; using anchor loss LAL. Method CF-10-CCF-100-CDN IN-C Baseline w/oR(Î¸),LAL 42.6 63.0 77.9 93.4 R(Î¸)fixedÎ»= 0.1Î»0 43.3 65.0 80.0 92.5R(Î¸)fixedÎ»=Î»0 42.0 64.6 66.6 92.9 LALonly 25.4 56.5 47.5 68.1 PeTTA -Î»t 27.1 55.0 59.7 92.7PeTTA -Î»t +Î±t 23.9 41.4 44.5 75.7PeTTA -Î»t +LAL 26.2 36.3 43.2 62.0 PeTTA -Î»t +Î±t +LAL 22.8 35.1 42.9 60.5 Table 5: Average (across 20 visits) error of PeTTA. PeTTA favors various choices of reg- ularizers R(Î¸): L2 and cosine similarity in conjunction with Fisher [27, 40] coefficient. Method CF-10-CCF-100-CDN IN-CR(Î¸) Fisher L2 âœ— 23.0 35.6 43.1 70.8âœ“ 22.7 36.0 43.9 70.0 Cosine âœ— 22.8 35.1 42.9 60.5âœ“ 22.6 35.9 43.3 63.8 CF: CIFAR, DN: DomainNet, IN: ImageNet top prone-to-misclassified pair of categories. Here, label deer is used for almost every living animal while airplane represents transport vehicles. The similarity between categories in the feature space of the source model (Fig. 5c-right) is correlated with the likelihood of being merged upon collapsing. As distance in feature space is analogous to |Âµ0 âˆ’ Âµ1| (Thm. 1), closer clusters are at a higher risk of collapsing. This explains and showcases that the collapsing behavior is predictable up to some extent. 5.4 Ablation Study Effect of Each Component. Tab. 4 gives an ablation study on PeTTA, highlighting the use of a regularization term (R(Î¸)) with a fixed choice of Î», Î±not only fails to mitigate model collapse but may also introduce a negative effect (rows 2-3). Trivially applying the anchor loss (LAL) alone is also incapable of eliminating the lifelong performance degradation in continual TTA (row 4). Within PeTTA, adopting the adaptiveÎ»t scheme alone (row 5) or in conjunction with either Î±t or anchor loss LAL (rows 6-7) partially stabilizes the performance. Under the drastic domain shifts with a larger size of categories or model parameters (e.g., on CIFAR-100-C, DomainNet, ImageNet-C), restricting Î±t adjustment limits the ability of PeTTA to stop undesirable updates while a common regularization term without LAL is insufficient to guide the adaptation. Thus, leveraging all elements secures the persistence of PeTTA (row 8). Various Choices of Regularizers. The design of PeTTA is not coupled with any specific regu- larization term. Demonstrated in Tab. 5, PeTTA works well for the two common choices: L2 and cosine similarity. The conjunction use of Fisher coefficent [27, 40] for weighting the model parameter importance is also studied. While the benefit (in terms of improving accuracy) varies across datasets, PeTTA accommodates all choices, as the model collapse is not observed in any of the options. 6 Discussions and Conclusion On a Potential Risk of TTA in Practice. We provide empirical and theoretical evidence on the risk of deploying continual TTA algorithms. Existing studies fail to detect this issue with a single pass per test set. The recurring TTA could be conveniently adopted as astraightforward evaluation, where its challenging test stream magnifies the error accumulation that a model might encounter in practice. Limitations. PeTTA takes one step toward mitigating the gradual performance degradation of TTA. Nevertheless, a complete elimination of error accumulation cannot be guaranteed rigorously through regularization. Future research could delve deeper into expanding our efforts to develop an algorithm that achieves error accumulation-free by construction. Furthermore, as tackling the challenge of the temporally correlated testing stream is not the focus of PeTTA, using a small memory bank as in [61, 15] is necessary. It also assumes the features statistics from the source distribution are available (Appdx. E.3, E.4). These constraints potentially limit its scalability in real-world scenarios. Conclusion. Towards trustworthy and reliable TTA applications, we rigorously study theperformance degradation problem of TTA. The proposed recurring TTAsetting highlights the limitations of modern TTA methods, which struggle to prevent the error accumulation when continuously adapting to demanding test streams. Theoretically inspecting a failure case of Ïµâˆ’GMMC paves the road for designing PeTTA- a simple yet efficient solution that continuously assesses the model divergence for harmonizing the TTA process, balancing adaptation, and collapse prevention. 10Acknowledgements This work was supported by the Jump ARCHES Endowment through the Health Care Engineering Systems Center, JSPS/MEXT KAKENHI JP24K20830, ROIS NII Open Collaborative Research 2024-24S1201, in part by the National Institute of Health (NIH) under Grant R01 AI139401, and in part by the Vingroup Innovation Foundation under Grant VINIF.2021.DA00128. References [1] Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution gener- alization. In A. Beygelzimer, Y . Dauphin, P. Liang, and J. Wortman Vaughan, editors,Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/forum?id=jlchsFOLfeF. [2] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, and Lucas Page-Caccia. Online continual learning with maximal interfered retrieval. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÃ©-Buc, E. Fox, and R. Garnett, editors,Advances in Neural Information Processing Systems, volume 32, 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/ file/15825aee15eb335cc13f9b559f166ee8-Paper.pdf. [3] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. Gradient based sample se- lection for online continual learning. In Advances in Neural Information Processing Systems , volume 32, 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/ e562cd9c0768d5464b64cf61da7fc6bb-Paper.pdf. [4] Amitav Banerjee, U. B. Chitnis, S. L. Jadhav, J. S. Bhawalkar, and S. Chaudhury. Hypothesis testing, type I and type II errors. Industrial Psychiatry Journal, 18(2):127â€“131, 2009. ISSN 0972-6748. doi: 10.4103/0972-6748.62274. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2996198/. [5] Richard Bellman. Dynamic Programming. Princeton University Press, Princeton, NJ, USA, 1957. [6] Arno Blaas, Andrew Miller, Luca Zappella, Joern-Henrik Jacobsen, and Christina Heinze-Deml. Con- siderations for distribution shift robustness in health. In ICLR 2023 Workshop on Trustworthy Machine Learning for Healthcare, 2023. URL https://openreview.net/forum?id=y7XveyWYzIB. [7] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8334â€“8343, 2022. doi: 10.1109/CVPR52688.2022.00816. [8] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In Proceedings of the IEEE International Conference on Computer Vision, 2022. [9] Thomas M. Cover and Joy A. Thomas.Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing). Wiley-Interscience, USA, 2006. ISBN 0471241954. [10] Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2021. URL https://openreview.net/forum?id=SSKZPJCt7B. [11] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(7):3366â€“3385, 2022. doi: 10.1109/ TPAMI.2021.3057446. [12] Mario DÃ¶bler, Robert A. Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 7704â€“7714, June 2022. [13] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In Proceedings of the 32nd International Conference on Machine Learning , volume 37 of Proceedings of Machine Learning Research , pages 1180â€“1189, Lille, France, 07â€“09 Jul 2015. PMLR. URL https://proceedings.mlr.press/v37/ganin15.html. [14] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-Adversarial Training of Neural Networks, pages 189â€“ 209. Springer International Publishing, 2017. doi: 10.1007/978-3-319-58347-1_10. URL https: //doi.org/10.1007/978-3-319-58347-1_10 . [15] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. NOTE: Robust continual test-time adaptation against temporal correlation. In Advances in Neural Information Processing Systems, 2022. 11[16] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In L. Saul, Y . Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems , volume 17, 2004. URL https://proceedings.neurips.cc/paper_files/paper/2004/file/ 96f2b50b5d3613adf9c27049b2a888c7-Paper.pdf. [17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385, 2015. [18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1026â€“1034, 2015. [19] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. Proceedings of the International Conference on Learning Representations, 2019. [20] Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. AugMix: A simple data processing method to improve robustness and uncertainty. Proceedings of the International Conference on Learning Representations (ICLR), 2020. [21] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pages 8320â€“8329, 2021. doi: 10.1109/ICCV48922.2021.00823. [22] Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, and Michael Spranger. MECTA: Memory-economic continual test-time model adaptation. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=N92hjSf5NNh. [23] Fabian Isensee, Paul F. Jaeger, Simon A. A. Kohl, Jens Petersen, and Klaus H. Maier-Hein. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature Methods, 18(2):203â€“211, February 2021. ISSN 1548-7105. doi: 10.1038/s41592-020-01008-z. URL https: //www.nature.com/articles/s41592-020-01008-z . [24] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. In M. Ranzato, A. Beygelzimer, Y . Dauphin, P.S. Liang, and J. Wort- man Vaughan, editors, Advances in Neural Information Processing Systems , volume 34, pages 2427â€“2440, 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/ 1415fe9fea0fa1e45dddcff5682239a0-Paper.pdf. [25] Michael N. Katehakis and Arthur F. Veinott. The multi-armed bandit problem: Decomposition and compu- tation. Mathematics Operations Research, 12:262â€“268, 1987. URL https://api.semanticscholar. org/CorpusID:656323. [26] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412. 6980. [27] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks.Pro- ceedings of the National Academy of Sciences, 114(13):3521â€“3526, 2017. doi: 10.1073/pnas.1611835114. URL https://www.pnas.org/doi/abs/10.1073/pnas.1611835114. [28] Dong-Hyun Lee. Pseudo-label : The simple and efficient semi-supervised learning method for deep neural networks. ICML 2013 Workshop : Challenges in Representation Learning (WREPL), 07 2013. [29] T. Lee, S. Chottananurak, T. Gong, and S. Lee. Aetta: Label-free accuracy estimation for test-time adaptation. In 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 28643â€“28652, Los Alamitos, CA, USA, jun 2024. IEEE Computer Society. doi: 10.1109/CVPR52733. 2024.02706. URL https://doi.ieeecomputersociety.org/10.1109/CVPR52733.2024.02706. [30] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018. [31] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical domain adaptation. In International Conference on Learning Representations Workshop, 2017. URL https://openreview.net/forum?id=BJuysoFeg. [32] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(12):2935â€“2947, 2018. doi: 10.1109/TPAMI.2017.2773081. [33] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? Source hypothesis transfer for unsupervised domain adaptation. In International Conference on Machine Learning (ICML), pages 6028â€“6039, 2020. 12[34] Sen Lin, Peizhong Ju, Yingbin Liang, and Ness Shroff. Theory on forgetting and generalization of continual learning. In Proceedings of the 40th International Conference on Machine Learning, ICMLâ€™23, 2023. [35] TorchVision maintainers and contributors. Torchvision: Pytorchâ€™s computer vision library. https: //github.com/pytorch/vision, 2016. [36] Robert A Marsden, Mario DÃ¶bler, and Bin Yang. Gradual test-time adaptation by self-training and style transfer. arXiv preprint arXiv:2208.07736, 2022. [37] Robert A Marsden, Mario DÃ¶bler, and Bin Yang. Universal test-time adaptation through weight ensem- bling, diversity weighting, and prior correction. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2555â€“2565, 2024. [38] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing scenes as neural radiance fields for view synthesis. In Proceedings of the European Conference on Computer Vision (ECCV), 2020. [39] A. Tuan Nguyen, Thanh Nguyen-Tang, Ser-Nam Lim, and Philip Torr. TIPI: Test time adaptation with transformation invariance. In Conference on Computer Vision and Pattern Recognition 2023, 2023. URL https://openreview.net/forum?id=NVh1cy37Ge. [40] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In The Internetional Conference on Machine Learning, 2022. [41] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=g2YraF75Tj. [42] K. R. Parthasarathy. Introduction to Probability and Measure , volume 33 of Texts and Readings in Mathematics. Hindustan Book Agency, Gurgaon, 2005. ISBN 978-81-85931-55-5 978-93-86279-27-9. doi: 10.1007/978-93-86279-27-9. URL http://link.springer.com/10.1007/978-93-86279-27-9 . [43] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas KÃ¶pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library, 2019. [44] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In Proceedings of the IEEE International Conference on Computer Vision, pages 1406â€“1415, 2019. [45] Ori Press, Steffen Schneider, Matthias Kuemmerer, and Matthias Bethge. RDumb: A simple approach that questions our progress in continual test-time adaptation. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=VfP6VTVsHc. [46] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. Dataset Shift in Machine Learning. The MIT Press, 2009. ISBN 0262170051. [47] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 8748â€“8763. PMLR, 18â€“24 Jul 2021. URL https://proceedings. mlr.press/v139/radford21a.html. [48] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do ImageNet classifiers generalize to ImageNet? In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning Research, pages 5389â€“5400. PMLR, 09â€“15 Jun 2019. URL https://proceedings.mlr.press/v97/ recht19a.html. [49] Mooweon Rhee and Tohyun Kim. Exploration and Exploitation, pages 543â€“546. Palgrave Macmillan UK, London, 2018. ISBN 978-1-137-00772-8. doi: 10.1057/978-1-137-00772-8_388. URL https: //doi.org/10.1057/978-1-137-00772-8_388 . [50] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, , and Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interference. In Interna- tional Conference on Learning Representations, 2019. URL https://openreview.net/forum?id= B1gTShAct7. [51] Tanin Sirimongkolkasem and Reza Drikvandi. On Regularisation Methods for Analysis of High Di- mensional Data. Annals of Data Science , 6(4):737â€“763, December 2019. ISSN 2198-5812. doi: 10.1007/s40745-019-00209-4. URL https://doi.org/10.1007/s40745-019-00209-4 . 13[52] Yongyi Su, Xun Xu, and Kui Jia. Towards real-world test-time adaptation: Tri-net self-training with balanced normalization. Proceedings of the AAAI Conference on Artificial Intelligence, 38(13):15126â€“ 15135, 2024. [53] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Hal DaumÃ© III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 9229â€“9248. PMLR, 13â€“18 Jul 2020. URL https://proceedings. mlr.press/v119/sun20b.html. [54] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 2018. [55] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPSâ€™17, page 1195â€“1204, 2017. ISBN 9781510860964. [56] Daniel Vela, Andrew Sharp, Richard Zhang, Trang Nguyen, An Hoang, and Oleg S. Pianykh. Temporal quality degradation in AI models. Scientific Reports, 12(1):11654, July 2022. ISSN 2045-2322. doi: 10.1038/s41598-022-15245-z. URL https://www.nature.com/articles/s41598-022-15245-z . [57] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c. [58] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, and Tao Qin. Generalizing to unseen domains: A survey on domain generalization. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pages 4627â€“4635. International Joint Conferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/628. URL https://doi.org/10. 24963/ijcai.2021/628. Survey Track. [59] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 7201â€“7211, June 2022. [60] Zachary Young and Robert Steele. Empirical evaluation of performance degradation of machine learning-based predictive models â€“ a case study in healthcare information systems. International Journal of Information Management Data Insights , 2(1):100070, 2022. ISSN 2667-0968. doi: https: //doi.org/10.1016/j.jjimei.2022.100070. URL https://www.sciencedirect.com/science/article/ pii/S2667096822000143. [61] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test-time adaptation in dynamic scenarios. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15922â€“ 15932, 2023. [62] Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML , 2023. URL https: //openreview.net/forum?id=0Go_RsG_dYn. 14Persistent Test-time Adaptation in Recurring Testing Scenarios Technical Appendices Table of Contents A Related Work 16 B Proof of Lemmas and Theorems 16 B.1 Proof of Lemma 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 B.2 Proof of Lemma 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 B.3 Proof of Theorem 1 and Corollary 1. . . . . . . . . . . . . . . . . . . . . . . . 18 C Further Justifications on Gaussian Mixture Model Classifier 19 D Further Justifications on the Recurring Testing Scenario 20 D.1 Recurring TTA Follows the Design of a Practical TTA Stream . . . . . . . . . . 20 D.2 Recurring TTA as a Diagnostic Tool . . . . . . . . . . . . . . . . . . . . . . . . 20 D.3 Recurring TTA with Random Orders . . . . . . . . . . . . . . . . . . . . . . . 20 E Further Justifications on Persistent TTA (PeTTA) 21 E.1 Pseudo Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 E.2 Anchor Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 E.3 The Use of the Memory Bank . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 E.4 Empirical Mean and Covariant Matrix of Feature Vectors on the Source Dataset . 23 E.5 Novelty of PeTTA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 F Additional Experimental Results of PeTTA 24 F.1 Performance of PeTTA Versus Compared Methods . . . . . . . . . . . . . . . . 24 F.2 An Inspection of PeTTA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 F.3 Does Model Reset Help? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 F.4 PeTTA with 40 Recurring Visits . . . . . . . . . . . . . . . . . . . . . . . . . . 27 F.5 The Sensitivity of Hyper-parameter Choices in PeTTA . . . . . . . . . . . . . . 27 F.6 More Details on the Ablation Study . . . . . . . . . . . . . . . . . . . . . . . . 27 F.7 More Confusion Matrices in Recurring TTA Setting . . . . . . . . . . . . . . . 29 G Experimental Details 29 G.1 Computing Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 G.2 Experiments on CCC Testing Stream . . . . . . . . . . . . . . . . . . . . . . . 29 G.3 Test-time Adaptation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 G.4 The Use of Existing Assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 15A Related Work Towards Robust and Practical TTA. While forming the basis, early single-target TTA ap- proaches [53, 57, 39, 41, 33] is far from practice. Observing the dynamic of many testing envi- ronments, a continual TTA setting is proposed where an ML model continuously adapts to a sequence of multiple shifts [36, 59]. Meanwhile, recent studies [15, 7] point out that the category distribution realistic streams is highly temporally correlated. Towards real-world TTA setting, Yuanet al. [61] launch the practical TTA which considers the simultaneous occurrence of the two aforementioned challenges. For a robust and gradual adaptation, an update via the mean teacher [55] mechanism is exploited in many continual TTA algorithms [59, 61, 12, 22]. To moderate the temporally correlated test stream, common approaches utilize a small memory bank for saving a category-balanced subset of testing samples [15, 61], inspired by the replay methods [50, 2] to avoid forgetting in the task of continual learning [34, 3, 11]. Our study emphasizes another perspective: beyond a supreme performance, a desirable TTA should also sustain it for an extended duration. Temporal Performance Degradation.By studying the quality of various ML models across multiple industry applications [56, 60] the issue of AI â€œaging\" with the temporal model degradation progress, even with data coming from a stable process has been confirmed. In TTA, the continuous changes of model parameters through gradient descent aggravate the situation, as also recently noticed in [45]. Apart from observation, we attempt to investigate and provide theoretical insights towards the mechanism of this phenomenon. Accumulated Errors in TTA. In TTA, the issue of accumulated error has been briefly acknowledged. Previous works strive to avoid drastic changes to model parameters as a good practice. Up to some degree, it helps to avoid performance degradation. Nevertheless, it is still unclear whether their effectiveness truly eliminates the risk. To preserve in-distribution performance, regularization [27, 40] or replaying of training samples at test-time [ 12] have been used. Other studies explore reset (recovering the initial model parameters) strategies [59, 45], periodically or upon the running entropy loss approaches a threshold [ 41]. Unfortunately, knowledge accumulated in the preceding steps will vanish, and a bad heuristic choice of threshold or period leads to highly frequent model resets. Noteworthy, tuning those hyper-parameters is exceedingly difficult due to the unavailability of the validation set [62]. LAME [ 7] suggests a post-processing step for adaptation (without updating the parameters). This approach, however, still limits the knowledge accumulation. Our PeTTA is reset-free by achieving an adaptable continual test-time training. B Proof of Lemmas and Theorems In this section, we prove the theoretical results regarding the Ïµâˆ’perturbed Gaussian Mixture Model Classifier (Ïµâˆ’GMMC) introduced in Sec. 3.2. We first briefly summarize the definition of model collapse and the static data stream assumption: Definition 1 (Model Collapse). A model is said to be collapsed from step Ï„ âˆˆ T, Ï„ <âˆž if there exists a non-empty subset of categories ËœY âŠ‚ Ysuch that Pr{Yt âˆˆ ËœY} > 0 but the marginal Pr{Ë†Yt âˆˆ ËœY} converges to zero in probability: lim tâ†’Ï„ Pr{Ë†Yt âˆˆ ËœY} = 0. Assumption 1 (Static Data Stream). The marginal distribution of the true label follows the same Bernoulli distribution Ber(p0): p0,t = p0, (p1,t = p1 = 1 âˆ’ p0), âˆ€t âˆˆ T. Preliminary. Following the same set of notations introduced in the main text, recall that we denoted py,t âˆ† = Pr{Yt = y}, Ë†py,t âˆ† = Pr{Ë†Yt = y} (marginal distribution of the true label Yt and pseudo label Ë†Yt receiving label y, respectively) and Ïµt = Pr{Yt = 1|Ë†Yt = 0} (the false negative rate (FNR) of 16Ïµâˆ’GMMC). At testing step t, we obtain the following relations: EPt h Xt|Ë†Yt = 0 i = (1 âˆ’ Ïµt)Âµ0 + ÏµtÂµ1, (9) EPt h Xt|Ë†Yt = 1 i = Âµ1, (10) VarPt \u0010 Xt|Ë†Yt = 0 \u0011 = (1 âˆ’ Ïµt)Ïƒ2 0 + ÏµtÏƒ2 1 + Ïµt(1 âˆ’ Ïµt)(Âµ0 âˆ’ Âµ1)2, (11) VarPt \u0010 Xt|Ë†Yt = 1 \u0011 = Ïƒ2 1. (12) In addition, under Assumption 1, the marginal distribution Pt(x) (also referred as data distribution in our setup) is: Pt(x) = N(x; p0Âµ0 + p1Âµ1, p0Ïƒ2 0 + p1Ïƒ2 1 + p0p1(Âµ0 âˆ’ Âµ1)2) âˆ€t âˆˆ T. (13) B.1 Proof of Lemma 1 Lemma 1 (Increasing FNR). Under Assumption 1, a binary Ïµ-GMMC would collapsed (Def. 1) with lim tâ†’Ï„ Ë†p1,t = 0 (or lim tâ†’Ï„ Ë†p0,t = 1, equivalently) if and only if lim tâ†’Ï„ Ïµt = p1. Proof. Under Assumption 1, we have EPt [Xt] = p0Âµ0 + (1 âˆ’ p0)Âµ1. Also note that: EPt [Xt] = EPt h EPt h Xt|Ë†Yt ii = EPt h Xt|Ë†Yt = 0 i Ë†p0,t + EPt h Xt|Ë†Yt = 1 i Ë†p1,t (14) = [(1 âˆ’ Ïµt)Âµ0 + ÏµtÂµ1] Ë†p0,t + Âµ1(1 âˆ’ Ë†p0,t) = [(1 âˆ’ Ïµt)Ë†p0,t] Âµ0 + [1 âˆ’ Ë†p0,t(1 âˆ’ Ïµt)] Âµ1 = p0Âµ0 + (1 âˆ’ p0)Âµ1, where the second equality follows Eqs. 9-10. Therefore: Ë†p0,t = p0 1 âˆ’ Ïµt . (15) Eq. 15 shows positive correlation between Ë†p0,t and Ïµt. Given lim tâ†’Ï„ Ïµt = p1, taking the limit introduces: lim tâ†’Ï„ Ë†p0,t = lim tâ†’Ï„ p0 1 âˆ’ Ïµt = p0 1 âˆ’ p1 = 1. Similarly, having lim tâ†’Ï„ Ë†p0,t = 1, the false negative rate Ïµt when t â†’ Ï„ is: lim tâ†’Ï„ Ïµt = 1 âˆ’ p0 = p1. Since Ë†p0,t + Ë†p1,t = 1, lim tâ†’Ï„ Ë†p1,t = 0, equivalently. Towards the collapsing point, the model tends to predict a single label (class 0 in the current setup). In addition, the FNR of the model Ïµt also raises correspondingly. B.2 Proof of Lemma 2. Lemma 2 (Ïµ-GMMC After Collapsing ). For a binary Ïµ-GMMC model, with Assumption 1, if lim tâ†’Ï„ Ë†p1,t = 0 (collapsing), the cluster 0 in GMMC converges in distribution to a single-cluster GMMC with parameters: N(Ë†Âµ0,t, Ë†Ïƒ2 0,t) d. â†’ N(p0Âµ0 + p1Âµ1, p0Ïƒ2 0 + p1Ïƒ2 1 + p0p1(Âµ0 âˆ’ Âµ1)2). Proof. From Eqs. 9-10, under the increasing type II collapse of Ïµâˆ’GMMC setting, the perturbation does not affect the approximation of Âµ1. Meanwhile, when Ïµt increases, one can expect that Ë†Âµ0,t 17moves further away from Âµ0 toward Âµ1. Frist, the mean teacher model of GMMC (Eq. 4, main text) gives: EPt h Ë†Âµ0,t|Ë†Yt = 1 i = EPtâˆ’1 [Ë†Âµ0,tâˆ’1] , EPt h Ë†Âµ0,t|Ë†Yt = 0 i = (1 âˆ’ Î±)EPtâˆ’1 h Ë†Âµ0,tâˆ’1|Ë†Yt = 0 i + Î±EPt h Xt|Ë†Yt = 0 i = (1 âˆ’ Î±)EPtâˆ’1 [Ë†Âµ0,tâˆ’1] + Î± \u0010 EPt h Xi|Ë†Yt = 0 i\u0011 , EPt h Ë†Âµ1,t|Ë†Yt = 1 i = (1 âˆ’ Î±)EPtâˆ’1 h Ë†Âµ1,tâˆ’1|Ë†Yt = 1 i + Î±EPt h Xt|Ë†Yt = 1 i = (1 âˆ’ Î±)EPtâˆ’1 [Ë†Âµ1,tâˆ’1] + Î± \u0010 EPt h Xi|Ë†Yt = 1 i\u0011 , EPt h Ë†Âµ1,t|Ë†Yt = 0 i = EPtâˆ’1 [Ë†Âµ1,tâˆ’1] . By defining uy,t = EPt [Ë†Âµy,t], we obtain the following recurrence relation between u0,t and u0,tâˆ’1: u0,t = EPt h Ë†Âµ0,t|Ë†Yt = 0 i Ë†p0,t + EPt h Ë†Âµ0,t|Ë†Yt = 1 i Ë†p1,t = \u0010 (1 âˆ’ Î±)u0,tâˆ’1 + Î±EPt h Xt|Ë†Yt = 0 i\u0011 Ë†p0,t + u0,tâˆ’1 Ë†p1,t = [(1 âˆ’ Î±)Ë†p0,t + Ë†p1,t] u0,tâˆ’1 + Î±Ë†p0,tEPt h Xt|Ë†Yt = 0 i = (1 âˆ’ Î±Ë†p0,t)u0,tâˆ’1 + Î±Ë†p0,tEPt h Xt|Ë†Yt = 0 i = (1 âˆ’ Î±Ë†p0,t)u0,tâˆ’1 + Î±Ë†p0,t [(1 âˆ’ Ïµt)Âµ0 + ÏµtÂµ1] . (16) Given lim tâ†’Ï„ Ë†p0,t = 1, it follows that lim tâ†’Ï„ Ïµ0,t = p1 by Lemma 1. From this point: u0,t = (1 âˆ’ Î±)u0,tâˆ’1 + Î± (p0Âµ0 + p1Âµ1) âˆ€t > Ï„. Taking the limit t â†’ âˆž: lim tâ†’âˆž u0,t = lim tâ†’âˆž (1 âˆ’ Î±)u0,tâˆ’1 + Î± (p0Âµ0 + p1Âµ1) = lim tâ†’âˆž (1 âˆ’ Î±)t Ë†Âµ0,0 + Î± tX i=1 (1 âˆ’ Î±)iâˆ’1 (p0Âµ0 + p1Âµ1) = lim tâ†’âˆž (1 âˆ’ Î±)t Ë†Âµ0,0 + (1 âˆ’ (1 âˆ’ Î±)t)(p0Âµ0 + p1Âµ1) = p0Âµ0 + p1Âµ1. The second equation is obtained by solving the recurrence relation. When lim tâ†’Ï„ Ë†p0,t = 1, {Ë†Âµy,t}yâˆˆ{0,1} becomes a deterministic values. Hence, giving uy,t = EPt [Ë†Âµy,t] = Ë†Âµ0,t(âˆ€t > Ï„) and lim tâ†’âˆž Ë†Âµ0,t = lim tâ†’âˆž u0,t = p0Âµ0 + p1Âµ1. (17) Repeating the steps above with Eqs. 11-12 in place of Eqs. 9-10, we obtain a similar result for Ïƒ2 0,t: lim tâ†’âˆž Ë†Ïƒ2 0,t = p0Ïƒ2 0 + p1Ïƒ2 1 + p0p1(Âµ0 âˆ’ Âµ1)2. (18) By LÃ©vyâ€™s continuity theorem (p. 302, [ 42]), from Eqs. 17-18, when t â†’ âˆž, the estimated distribution of the first cluster N(x; Ë†Âµ0,tË†Ïƒ2 0,t) converges to the whole data distribution Pt(x) (Eq. 13) when collapsing. B.3 Proof of Theorem 1 and Corollary 1. Theorem 1 (Convergence of Ïµâˆ’GMMC). For a binary Ïµ-GMMC model, with Assumption 1, let the distance from Ë†Âµ0,t toward Âµ1 is d0â†’1 t = |EPt [Ë†Âµ0,t] âˆ’ Âµ1|, then: d0â†’1 t âˆ’ d0â†’1 tâˆ’1 â‰¤ Î± Â· p0 Â· \u0012 |Âµ0 âˆ’ Âµ1| âˆ’d0â†’1 tâˆ’1 1 âˆ’ Ïµt \u0013 . 18Proof. Substituting Eq. 15 into Ë†p0,t of Eq. 16 gives: u0,t = \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 u0,tâˆ’1 + Î±p0 1 âˆ’ Ïµt [(1 âˆ’ Ïµt)Âµ0 + ÏµtÂµ1] . Hence, we have the distance from u0,t toward Âµ1: |u0,t âˆ’ Âµ1| = \f\f\f\f \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 u0,tâˆ’1 + Î±p0Âµ0 + Î±p0ÏµtÂµ1 1 âˆ’ Ïµt âˆ’ Âµ1 \f\f\f\f = \f\f\f\f \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 (u0,tâˆ’1 âˆ’ Âµ1) + Î±p0Âµ0 + Î±p0ÏµtÂµ1 1 âˆ’ Ïµt âˆ’ Î±p0Âµ1 1 âˆ’ Ïµt \f\f\f\f = \f\f\f\f \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 (u0,tâˆ’1 âˆ’ Âµ1) + Î±p0Âµ0 âˆ’ Î±p0Âµ1(1 âˆ’ Ïµt) 1 âˆ’ Ïµt \f\f\f\f = \f\f\f\f \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 (u0,tâˆ’1 âˆ’ Âµ1) + Î±p0(Âµ0 âˆ’ Âµ1) \f\f\f\f â‰¤ \u0012 1 âˆ’ Î±p0 1 âˆ’ Ïµt \u0013 |u0,tâˆ’1 âˆ’ Âµ1| + Î±p0|Âµ0 âˆ’ Âµ1|. The last inequality holds due to the triangle inequality. Equivalently, |u0,t âˆ’ Âµ1| âˆ’ |u0,tâˆ’1 âˆ’ Âµ1| â‰¤Î± Â· p0 Â· \u0012 |Âµ0 âˆ’ Âµ1| âˆ’|u0,tâˆ’1 âˆ’ Âµ1| 1 âˆ’ Ïµt \u0013 . Let d0â†’1 t = |EPt [Ë†Âµ0,t] âˆ’ Âµ1|, we conclude that: d0â†’1 t âˆ’ d0â†’1 tâˆ’1 â‰¤ Î± Â· p0 Â· \u0012 |Âµ0 âˆ’ Âµ1| âˆ’d0â†’1 tâˆ’1 1 âˆ’ Ïµt \u0013 . Corollary 1 (A Condition forÏµâˆ’GMMC Collapse). With fixedp0, Î±, Âµ0, Âµ1, Ïµâˆ’GMMC is collapsed if there exists a sequence of {Ïµt}Ï„ Ï„âˆ’âˆ†Ï„ (Ï„ â‰¥ âˆ†Ï„ > 0) such that: p1 â‰¥ Ïµt > 1 âˆ’ d0â†’1 tâˆ’1 |Âµ0 âˆ’ Âµ1|, t âˆˆ [Ï„ âˆ’ âˆ†Ï„ , Ï„]. Proof. Initialized at Âµ0, Ïµ-GMMC is collapsing when Ë†Âµ0,t converges to the mid-point p0Âµ0 + p1Âµ1 (Lemma 2), i.e., moving closer to Âµ1. From Thm. 1, the distance towards Âµ1 d0â†’1 t < d0â†’1 tâˆ’1 if |Âµ0 âˆ’ Âµ1| âˆ’|u0,tâˆ’1 âˆ’ Âµ1| 1 âˆ’ Ïµt < 0 â‡” |Âµ0 âˆ’ Âµ1| < |u0,tâˆ’1 âˆ’ Âµ1| 1 âˆ’ Ïµt â‡” Ïµt > 1 âˆ’ |u0,tâˆ’1 âˆ’ Âµ1| |Âµ0 âˆ’ Âµ1| . When there exists this sequence{Ïµt}Ï„ Ï„âˆ’âˆ†Ï„ (Ï„ â‰¥ âˆ†Ï„ > 0) it follows that d0â†’1 t < d0â†’1 tâˆ’1 and Ïµt > Ïµtâˆ’1 is guaranteed âˆ€t âˆˆ [Ï„ âˆ’ âˆ†Ï„ , Ï„]. Hence, lim tâ†’Ï„ Ïµt = p1 (model collapsed, by Lemma 1). C Further Justifications on Gaussian Mixture Model Classifier One may notice that in Ïµ-GMMC (Sec. 4.2), the classifier is defined ft(x) = argmaxyâˆˆY Pr(x|y; Î¸t) (maximum likelihood estimation) while in general, ft(x) = argmaxyâˆˆY Pr(y|x; Î¸t) (maximum a posterior estimation), parameterized by a neural network. In this case, since the equal prior (i.e., Pr(y; Î¸t) = Pr(yâ€²; Î¸t), âˆ€y, yâ€² âˆˆ C) is enforced in Ïµ-GMMC, the two definitions are equivalent. Proof. Having: argmaxyâˆˆY Pr(y|x; Î¸t) = argmaxyâˆˆY Pr(x|y; Î¸t) Pr(y; Î¸t)P yâ€²âˆˆY Pr(x|yâ€²; Î¸t) Pr(yâ€²; Î¸t) = argmaxyâˆˆY Pr(x|y; Î¸t). We conclude that the two definitions are equivalent. In fact, it is well-known that maximum likelihood estimation is a special case of maximum a posterior estimation when the prior is uniform. 19D Further Justifications on the Recurring Testing Scenario D.1 Recurring TTA Follows the Design of a Practical TTA Stream Note that in recurring TTA, besides the recurrence of environments (or corruptions) as in [59, 40], the distribution of class labels is also temporally correlated (non-i.i.d.) as suggested by [15, 61] to reflect the practical testing stream better. In short, recurring TTA is formed by recurring the environments of practical TTA scenario introduced in [61] multiple times (readers are encouraged to visit the original paper for additional motivations on this scenario). D.2 Recurring TTA as a Diagnostic Tool Noticeably, CoTTA [59] also performed 10-round repetition across multiple domain shifts to simulate a lifelong TTA testing stream just like our recurring TTA. However, the key difference is CoTTA assumes the distribution of class labels is i.i.d., which does not hold in many real-life testing scenarios as argued in [ 15, 61]. Our recurring TTA lifts this assumption and allows temporally correlated (non-i.i.d.) label distribution (more challenging, more practical). This extension allows recurring TTA to spot the risk of model collapse on CoTTA [59] and other methods. The over-simplicity of the repeating scheme in CoTTA for spotting performance degradation is also suggested in [45]. Clearly, it seems not to be a problem at first glance in Tab. 5 of [59] (CoTTAâ€™s 10-round repetition), but in fact, the risk in CoTTA remains, as explored in our scenario and also on CCC [45]. The construction of our recurring TTA is notably simple - a technical effort to extend the testing stream. However, this simplicity is on purpose, serving as a diagnostic tool for lifelong continual TTA. Counterintuitively, our experiments on four different tasks with the latest methods verify that even if the model is exposed to the same environment(the most basic case), their adaptability and performance are still consistently reduced (demonstrated visually in Fig. 1, quantitatively in Sec. 5.3). We believe that the extensive testing stream by recurrence in our setup is a simple yet sufficient scenario to demonstrate the vulnerability of existing continual TTA methods when facing the issue of model collapse (compared to CCC [45], a notably more complicated scenario than our recurring TTA). Indeed, recurring shifts are sufficient to show this failure mode and any lifelong TTA method should necessarily be able to handle recurring conditions. D.3 Recurring TTA with Random Orders Recall that in Sec. 3.1,recurring TTAis constructed by repeatingthe same sequence of D distributions K times. For example, a sequence with K = 2 could be P1 â†’ P2 â†’ Â·Â·Â· â†’ PD â†’ P1 â†’ P2 â†’ Â·Â·Â· â†’ PD. For simplicity and consistency that promote reproducibility, the same order of image corruptions (following [61]) is used for all recurrences. This section presents supplementary experimental findings indicating that the order of image corruptions within each recurrence, indeed, does not affect the demonstration of TTA model collapse and the performance of our PeTTA. Experiment Setup. We refer to the setting same-order as using one order of image corruptions in [61] for all recurrences (specifically, on CIFAR-10/100-C and ImageNet-C:motion â†’ snow â†’ fog â†’ shot â†’ defocus â†’ contrast â†’ zoom â†’ brightness â†’ frost â†’ elastic â†’ glass â†’ gaussian â†’ pixelated â†’ jpeg â†’ impulse). Conversely, in random-order, the order of image corruptions is randomly shuffled at the beginning of each recurrence. Hence, the corruption orders across K recurrences are now entirely different. We redo the experiment of the second setting three times (with different random seeds = 0, 1, 2). Nevertheless, different TTA methods are ensured to be evaluated on the same testing stream, since it is fixed after generation. Without updating its parameters, the performance of the source model is trivially independent of the order of corruptions. Experimental Result. The experimental results are visualized in Fig. 6. The first column plots the experiments under the same-order, while the remaining three columns plot the experiments in the random-order setting, with varying random seeds. Note that the message conveyed by each sub-figure entirely matches that of Fig. 1-right. Discussions. Clearly, a similar collapsing pattern is observed in all three TTA tasks, with three combinations of 20 image corruption orders. This pattern also matches the easiest setting using the same order of image corruptions we promoted in recurring TTA. 201 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 1 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 1 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 1 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Same-order Random-order (seed=0) Random-order (seed=1) Random-order (seed=2) Testing Error Recurring TTA visit Recurring TTA visit Recurring TTA visit Recurring TTA visit (a) CIFAR-10 â†’ CIFAR-10-C task. 1 5 10 15 20 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Same-order Random-order (seed=0) Random-order (seed=1) Random-order (seed=2) Testing Error Recurring TTA visit Recurring TTA visit Recurring TTA visit Recurring TTA visit (b) CIFAR-100 â†’ CIFAR-100-C task. 1 5 10 15 20 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.5 0.6 0.7 0.8 0.9 1.0 1 5 10 15 20 0.5 0.6 0.7 0.8 0.9 1.0 Same-order Random-order (seed=0) Random-order (seed=1) Random-order (seed=2) Testing Error Recurring TTA visit Recurring TTA visit Recurring TTA visit Recurring TTA visit (c) ImageNet â†’ ImageNet-C task. Figure 6: Recurring TTA with different order of corruptions. This figure plots the testing error of two TTA approaches: RoTTA - - [61], and, PeTTA- - (ours), and source model-Ã—- as a reference performance under our recurring TTA (with 20 visits) across three TTA tasks. On the same-order experiments (column 1), the same order of image corruptions is applied for all 20 visits. Meanwhile, in random-order, this order is reshuffled at the beginning of each visit (columns 2-4). Random-order experiments are redone three times with different random seeds. Here, we empirically validate that using the same order of domain shifts (image corruptions) in our recurring TTA is sufficient to showcase the model collapse and evaluate the persistence of our PeTTA. Best viewed in color. E Further Justifications on Persistent TTA (PeTTA) E.1 Pseudo Code We summarize the key steps of our proposed PeTTA in Alg. 1, with the key part (lines 4-13) highlighted in blue. Our approach fits well in the general workflow of a TTA algorithm, enhancing the regular mean-teacher update step. Appdx. E.5 elaborates more on our contributions in PeTTA, distinguishing them from other components proposed in previous work. The notations and definitions of all components follow the main text (described in detail in Sec. 4). On line 8 of Alg. 1, as a 21Algorithm 1 Persistent TTA (PeTTA) Input: Classification model ft and its deep feature extractor Ï•Î¸t, both parameterized by Î¸t âˆˆ Î˜. Testing stream {Xt}T t=0, initial model parameter (Î¸0), initial update rate (Î±0), regularization term coefficient (Î»0), empirical mean ({Âµy 0}yâˆˆY) and covariant matrix ({Î£y 0}yâˆˆY) of feature vectors in the training set, Ë†Âµy t EMA update rate (Î½). 1 Ë†Âµy 0 â† Âµy 0, âˆ€y âˆˆ Y; // Initialization 2 for t âˆˆ [1, Â·Â·Â· , T] do 3 Ë†Yt â† ftâˆ’1(Xt) ; // Obtaining pseudo-labels for all samples in Xt 4 // Persistent TTA (PeTTA) 5 Ë†Yt â† n Ë†Y (i) t |i = 1, Â·Â·Â· , Nt o ; // Set of (unique) pseudo-labels in Xt 6 Â¯Î³t â† 0 ; 7 for y âˆˆ Ë†Yt do 8 Î³y t â† 1 âˆ’ exp \u0010 âˆ’(Ë†Âµy t âˆ’ Âµy 0)T (Î£y 0)âˆ’1 (Ë†Âµy t âˆ’ Âµy 0) \u0011 ; // Divergence sensing term on category y 9 Â¯Î³t â† Â¯Î³t + Î³y t | Ë†Yt| ; // Average divergence sensing term for step t 10 Ë†Âµy t â† (1 âˆ’ Î½)Ë†Âµy tâˆ’1 + Î½Ï•Î¸tâˆ’1 (Xt|Ë†Yt = y) ; // EMA update of Ë†Âµy t for samples with Ë†Yt = y 11 end 12 Î»t â† Â¯Î³t Â· Î»0 ; // Computing adaptive regularization term coefficient 13 Î±t â† (1 âˆ’ Â¯Î³t) Â· Î±0 ; // Computing adaptive update rate 14 // Regular Mean-teacher Update 15 Î¸â€² t â† Optim Î¸â€²âˆˆÎ˜ EPt h LCLS \u0010 Ë†Yt, Xt; Î¸â€² \u0011 + LAL (Xt; Î¸â€²) i + Î»tR(Î¸â€²) ; // Student model update 16 Î¸t â† (1 âˆ’ Î±t)Î¸tâˆ’1 + Î±tÎ¸â€² t. ; // Teacher model update 17 // Final prediction 18 yeild ft(Xt) ; // Returning the final inference with updated model ft 19 end shorthand notation, Ï•Î¸tâˆ’1 (Xt|Ë†Yt = y) denotes the empirical mean of all feature vectors of X(i) t (extracted by Ï•Î¸tâˆ’1 \u0010 X(i) t \u0011 ) if Ë†Y (i) t = y, i= 1, Â·Â·Â· , Nt in the current testing batch. E.2 Anchor Loss KL Divergence Minimization-based Interpretation of Anchor Loss. In Sec. 4, we claimed that minimizing the anchor loss LAL is equivalent to minimizing the relative entropy (or KL divergence) between the output probability of two models parameterized by Î¸0 and Î¸. Proof. Having: DKL (Pr(y|Xt; Î¸0)||Pr(y|Xt; Î¸)) = X yâˆˆY Pr(y|Xt; Î¸0) log Pr(y|Xt; Î¸0) Pr(y|Xt; Î¸) = âˆ’ X yâˆˆY Pr(y|Xt; Î¸0) log Pr(y|Xt; Î¸) | {z } LAL(Xt;Î¸) âˆ’H(Pr(y|Xt; Î¸0))| {z } constant . Hence, argmin Î¸âˆˆÎ˜ LAL(Xt; Î¸) = argmin Î¸âˆˆÎ˜ DKL (Pr(y|Xt; Î¸0)||Pr(y|Xt; Î¸)) . 22Intuitively, a desirable TTA solution should be able to adapt to novel testing distributions on the one hand, but it should not significantly diverge from the initial model. LAL fits this purpose, constraining the KL divergence between two models at each step. Connections between Anchor Loss and Regularizer Term. While supporting the same objective (collapse prevention by avoiding the model significantly diverging from the source model), the major difference between Anchor loss ( LAL) and the Regularizer term ( R(Î¸)) is that the anchor loss operates on the probability space of model prediction while the regularizer term works on the model parameter spaces. Tab. 4 (lines 1 and 5) summarizes the ablation study when each of them is eliminated. We see the role of the regularization term is crucial for avoiding model collapse, while the anchor loss guides the adaptation under the drastic domain shift. Nevertheless, fully utilizing all components is suggested for maintaining TTA persistence. E.3 The Use of the Memory Bank The size of Memory Bank. The size of the memory bank in PeTTA is relatively small, equal to the size of one mini-batch for update (64 images, specifically). The Use of the Memory Bank in PeTTA is Fair with Respect To the Compared Methods.Our directly comparable method - RoTTA [61] also takes this advantage (referred to as category-balanced sampling, Sec. 3.2 of [ 61]). Hence, the comparison between PeTTA and RoTTA is fair in terms of additional memory usage. Noteworthy, the use of a memory bank is a common practice in TTA literature (e.g., [15, 8, 61]), especially in situations where the class labels are temporally correlated or non-i.i.d. distributed (as we briefly summarized in Appdx. A - Related Work section). CoTTA [59], EATA [40] and MECTA [ 22] (compared method) assume labels are i.i.d. distributed. Hence, a memory bank is unnecessary, but their performance under temporally correlated label distribution has dropped significantly as a trade-off. The RMT [12] (compared method) does not require a memory bank but it needs to cache a portion of the source training set for replaying (Sec. 3.3 in [12]) which even requires more resources than the memory bank. Eliminating the Need for a Memory Bank. As addressing the challenge of temporally correlated label distribution on the testing stream is not the focus of PeTTA, we have conveniently adopted the use of the memory bank proposed in [61]. Since this small additional memory requirement is not universally applied in every real-world scenario, we believe that this is a reasonable assumption, and commonly adopted in TTA practices. Nevertheless, exploring alternative ways for reducing the memory size (e.g., storing the embedded features instead of the original image) would be an interesting future direction. E.4 Empirical Mean and Covariant Matrix of Feature Vectors on the Source Dataset Two Ways of Computing Âµy 0 and Î£y 0 in Practice. One may notice that in PeTTA, computing Î³y t requires the pre-computed empirical mean (Âµy 0) and covariance (Î£y 0) of the source dataset . This requirement may not be met in real-world situations where the source data is unavailable. In practice, the empirical mean and covariance matrix computed on the source distribution can be provided in the following two ways: 1. Most ideally, these values are computed directly by inference on the entire training set once the model is fully trained. They will be provided alongside the source-distribution pre-trained model as a pair for running TTA. 2. With only the source pre-trained model available, assume we can sample a set of unlabeled data from the source distribution. The (pseudo) labels for them are obtained by inferring from the source model. Since the source model is well-performed in this case, using pseudo is approximately as good as the true label. Accessing the Source Distribution Assumption in TTA. In fact, the second way is typically assumed to be possible in previous TTA methods such as EATA [40], and MECTA [22] (a compared method) to estimate a Fisher matrix (for anti-forgetting regularization purposes). Our work - PeTTA follows the same second setup as the previous approaches mentioned above. A variation of RMT [12] (a compared method) approach even requires having the fully labeled source data available at test-time for source replaying (Sec. 3.3 of [12]). This variation is used for comparison in our experiments. 23We believe that having the empirical mean and covariant matrix pre-computed on a portion of the source distribution in PeTTA is a reasonable assumption . Even in the ideal way, revealing the statistics might not severely violate the risk of data privacy leakage or require notable additional computing resources. Number of Samples Needed for Computation. To elaborate more on the feasibility of setting (2) mentioned above, we perform a small additional experiment on the performance of PeTTA while varying the number of samples used for computing the empirical mean and covariant matrix on the source distribution. In this setting, we use the test set of CIFAR-10, CIFAR-100, DomainNet validation set of ImageNet (original images, without corruption, or the real domain test set of DomainNet), representing samples from the source distribution. The total number of images is 10, 000 in CIFAR-10/A00, 50, 000 in ImageNet, and 69, 622 in DomainNet. We randomly sample 25%, 50%, 75%, and 100% of the images in this set to run PeTTA for 20 rounds of recurring. The result is provided in Tab. 6 below. Table 6: Average classification error of PeTTA (across 20 visits) with varying sizes of source samples used for computing feature empirical mean (Âµy 0) and covariant matrix (Î£y 0). TTA Task 25% 50% 75% 100% CIFAR-10â†’CIFAR-10-C 22.96 22.99 23.03 22.75 CIFAR-100â†’CIFAR-100-C 35.01 35.11 35.09 35.15 DomainNet:realâ†’clipâ†’paintâ†’sketch 43.18 43.12 43.15 42.89 ImageNetâ†’ImageNet-C 61.37 59.68 61.05 60.46 The default choice of PeTTA is using 100% samples of the validation set of the source dataset. However, we showcase that it is possible to reduce the number of unlabeled samples from the source distribution to compute the empirical mean and covariant matrix for PeTTA, without significantly impacting its performance. E.5 Novelty of PeTTA PeTTA is composed of multiple components. Among them, the anchor loss is an existing idea (examples of previous work utilizing this idea are [ 32, 12]). Similarly, the mean-teacher update; and regularization are well-established techniques and very useful for the continual or gradual TTA scenario. Hence, we do not aim to improve or alternate these components. Nevertheless, the novelty of our contribution is the sensing of the divergence and adaptive model update, in which the importance of minimizing the loss (adaptation) and regularization (collapse prevention) is changed adaptively. In short, we propose a harmonic way of combining those elements adaptively to achieve a persistent TTA process. The design of PeTTA draws inspiration from a theoretical analysis (Sec. 3.2), empirically surpassing both the conventional reset-based approach [45] (Appdx. F.3) and other continual TTA approaches [61, 12, 59, 22, 7] on our proposed recurring TTA (Sec. 3.1, Appdx. F.1), as well as the previously established CCC [45] benchmark. F Additional Experimental Results of PeTTA F.1 Performance of PeTTA Versus Compared Methods Performance on CIFAR-100-C and Domainnet Datasets. Due to the length constraint, the classification errors on the tasks CIFAR-100â†’CIFAR-100-C, and real â†’ clipart, painting, sketch of DomainNet are provided in Tab. 7 and Tab. 8. To prevent model collapse, the adaptability of PeTTA is more constrained. As a result, it requires more time for adaptation initially (e.g., in the first visit) but remains stable thereafter. Generally, consistent trends and observations are identified across all four TTA tasks. Standard Deviation of PeTTA Performance Across Multiple Runs. For PeTTA experiments marked with (*) in Tab. 1, Tab. 2, Tab. 7, and Tab. 8, the average performance across five independent runs with different random seeds is reported. Due to the space constraint, the corresponding standard deviation values are now reported in Tab. 9. Generally, the average standard deviation across runs 24Table 7: Average classification error of the task CIFAR-100 â†’ CIFAR-100-C in recurring TTA scenario. The lowest error is highlighted in bold, (âˆ—)average value across 5 runs (different random seeds) is reported for PeTTA. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Source 46.5 46.5 LAME [7] 40.5 40.5 CoTTA [59]53.4 58.4 63.4 67.6 71.4 74.9 78.2 81.1 84.0 86.7 88.8 90.7 92.3 93.5 94.7 95.6 96.3 97.0 97.3 97.683.1EATA [40]88.5 95.0 96.8 97.3 97.4 97.2 97.2 97.3 97.4 97.5 97.5 97.5 97.6 97.7 97.7 97.7 97.8 97.8 97.7 97.796.9RMT [12]50.5 48.6 47.9 47.4 47.3 47.1 46.9 46.9 46.6 46.8 46.7 46.5 46.5 46.6 46.5 46.5 46.5 46.5 46.5 46.547.1MECTA [22]44.8 44.3 44.6 43.1 44.8 44.2 44.4 43.8 43.8 43.9 44.6 43.8 44.4 44.6 43.9 44.2 43.8 44.4 44.9 44.244.2RoTTA [61]35.5 35.2 38.5 41.9 45.3 49.2 52.0 55.2 58.1 61.5 64.6 67.5 70.7 73.2 75.4 77.1 79.2 81.5 82.8 84.561.4RDumb [45]36.7 36.7 36.6 36.6 36.7 36.8 36.7 36.5 36.6 36.5 36.7 36.6 36.5 36.7 36.5 36.6 36.6 36.7 36.6 36.536.6ROID [37]76.4 76.4 76.2 76.2 76.3 76.1 75.9 76.1 76.3 76.3 76.6 76.3 76.8 76.7 76.6 76.3 76.2 76.0 75.9 76.076.3TRIBE [52]33.8 33.335.334.935.335.137.1 37.2 37.2 39.1 39.2 41.1 41.0 43.1 45.1 45.1 45.0 44.9 44.9 44.939.6PeTTA(ours)(âˆ—) 35.834.434.735.035.135.135.235.335.335.335.235.335.235.235.135.235.235.235.235.235.1 Table 8: Average classification error of the task real â†’ clipart â†’ painting â†’ sketch on DomainNet dataset in recurring TTA scenario. Episodic TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Source 45.3 45.3 LAME [7] 45.6 45.6 CoTTA [59]96.2 97.1 97.4 97.8 98.1 98.2 98.4 98.4 98.4 98.5 98.6 98.6 98.6 98.6 98.6 98.7 98.7 98.7 98.7 98.798.3RMT [12]76.2 77.1 77.3 77.3 77.2 77.1 76.8 76.9 76.5 76.4 76.4 76.3 76.4 76.2 76.2 76.1 76.4 76.1 76.0 75.876.5MECTA [22]94.6 98.4 98.6 98.8 99.1 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.0 99.098.7RoTTA [61]44.3 43.8 44.7 46.7 48.7 50.8 52.7 55.0 57.1 59.7 62.7 65.1 68.0 70.3 72.7 75.2 77.2 79.6 82.6 85.362.1RDumb [45]44.3 44.4 44.3 44.5 44.2 44.2 44.3 44.5 44.4 44.2 44.3 44.3 44.3 44.3 44.5 44.3 44.2 44.3 44.4 44.344.3PeTTA(ours)(âˆ—) 43.842.642.342.342.642.842.843.042.942.943.143.042.943.043.043.143.042.842.942.942.9 stays within Â±0.1% for small datasets (CIFAR-10-C, CIFAR-100-C) andÂ±0.5% for larger datasets (ImageNet-C, DomainNet). Table 9: Mean and standard deviation classification error of PeTTA on the four datasets: CIFAR-10-C (CF-10-C), CIFAR-100-C (CF-100-C), DomainNet (DN), and ImageNet-C (IN-C) with recurring TTA scenario. Each experiment is run 5 times with different random seeds. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Dataset1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg CF-10-C24.3 23.0 22.6 22.4 22.4 22.5 22.3 22.5 22.8 22.8 22.6 22.7 22.7 22.9 22.6 22.7 22.6 22.8 22.9 23.022.8Â±0.4Â±0.3Â±0.4Â±0.3Â±0.3Â±0.3Â±0.4Â±0.2Â±0.3Â±0.4Â±0.4Â±0.2Â±0.1Â±0.3Â±0.5Â±0.2Â±0.2Â±0.3Â±0.4Â±0.5 Â±0.1 CF-100-C35.8 34.4 34.7 35.0 35.1 35.1 35.2 35.3 35.3 35.3 35.2 35.3 35.2 35.2 35.1 35.2 35.2 35.2 35.2 35.235.1Â±0.4Â±0.4Â±0.2Â±0.2Â±0.1Â±0.1Â±0.2Â±0.2Â±0.1Â±0.2Â±0.1Â±0.2Â±0.2Â±0.1Â±0.1Â±0.1Â±0.1Â±0.1Â±0.2Â±0.2 Â±0.1 DN43.8 42.6 42.3 42.3 42.6 42.8 42.8 43.0 42.9 42.9 43.1 43.0 42.9 43.0 43.0 43.1 43.0 42.8 42.9 42.942.9Â±0.1Â±0.1Â±0.2Â±0.2Â±0.3Â±0.3Â±0.3Â±0.4Â±0.4Â±0.4Â±0.4Â±0.4Â±0.4Â±0.3Â±0.3Â±0.2Â±0.4Â±0.3Â±0.3Â±0.3 Â±0.3 IN-C65.3 61.7 59.8 59.1 59.4 59.6 59.8 59.3 59.4 60.0 60.3 61.0 60.7 60.4 60.6 60.7 60.8 60.7 60.4 60.260.5Â±0.6Â±0.5Â±0.5Â±0.5Â±1.4Â±1.1Â±1.0Â±0.5Â±0.8Â±0.9Â±0.4Â±0.8Â±0.9Â±0.8Â±0.9Â±0.8Â±1.0Â±0.6Â±0.6Â±0.7 Â±0.5 F.2 An Inspection of PeTTA In Fig. 7, we showcase an inspection of our PeTTA on the task CIFAR-10â†’ CIFAR-10-C [19] in a typical recurring TTA with 20 visits. Specifically, the visualizations of PeTTA parameters ( Â¯Î³t, Î»t, and Î±t), adaptation losses (LCLS, LAL) and regularization term (R(Î¸)) are provided. Here, we observe the values of adaptive parameters Î»t and Î±t continuously changing through time, as the testing scenarios evolve during recurring TTA. This proposed mechanismstabilizes the value of the loss functions, and regularization term, balancing between the two primary objectives: adaptation and preventing model collapse. Thus, the error rate persists as a result. A similar pattern is observed on other datasets (CIFAR-100-C [19] and DomainNet [44]). F.3 Does Model Reset Help? Experiment Setup. We use the term â€œmodel resetâ€ to represent the action of â€œreverting the current TTA model to the source modelâ€ . This straightforward approach is named RDumb [ 45]. We thoroughly conducted experiments to compare the performance of RDumb with PeTTA. The implementation of RDumb in this setting is as follows. We employ RoTTA [61] as the base test-time adaptor due to the characteristics of the practical TTA [ 61] stream. The model (including model 25parameters, the optimizer state, and the memory bank) is reset after adapting itself to T images.1 For each dataset, three values of this hyper-parameter T are selected: â€¢ T = 1, 000: This is the value selected by the RDumbâ€™s authors [ 45]. Unless specifically stated, we use this value when reporting the performance of RDumb [45] in all other tables. â€¢ T = 10, 000 (CIFAR-10/100-C), T = 5, 000 (ImageNet-C) and T = 24, 237 (Domain- Net).2 This value is equal to the number of samples in the test set of a single corruption type, i.e., the model is reset exactly after visiting each Piâ€™s (see Sec. 3.1 for notations). For DomainNet [44], since the number of images within each domain is unequal, the average number of images is used instead. â€¢ T = 150, 000 (CIFAR-10/100-C), T = 75, 000 (ImageNet-C) and T = 72, 712 (Domain- Net). This number is equal to the number of samples in one recurrence of our recurring TTA, i.e., the model is reset exactly after visitingP1 â†’ Â·Â·Â· â†’ PD. Here, D = 15 - types of corruptions [19] for CIFAR-10/100-C and ImageNet-C and D = 3 for DomainNet (clipart, painting, sketch). For example, the model is reset 20 times within a recurring TTA setting with 20 recurrences under this choice of T. The second and the last reset scheme could be interpreted as assuming the model has access to an oracle model with a capability of signaling the transitions between domains, or recurrences. Typically, this is an unrealistic capability in real-world scenarios, and a desirable continual TTA algorithm should be able to operate independently without knowing when the domain shift happening. Experimental Results. An empirical comparison between RDumb [45] and our PeTTA are reported in Tab. 10, Tab. 11, Tab. 12 and Tab. 13 for all four tasks. Table 10: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on CIFAR-10â†’ CIFAR-10-C task. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Reset Every1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg T= 100031.1 32.1 32.3 31.6 31.9 31.8 31.8 31.9 31.9 32.1 31.7 32.0 32.5 32.0 31.9 31.6 31.9 31.4 32.3 32.431.9T= 1000025.8 25.9 26.5 26.1 26.4 25.4 25.8 25.8 26.1 26.2 26.1 26.1 26.1 26.1 26.1 25.9 25.5 25.5 25.7 26.226.0T= 15000024.8 25.3 24.3 24.1 25.3 25.4 25.4 24.5 25.0 24.9 25.0 24.8 25.0 24.5 24.9 24.1 24.0 24.7 24.9 24.424.8 PeTTA(ours)(âˆ—) 24.323.022.622.422.422.522.322.522.822.822.622.722.722.922.622.722.622.822.923.022.8 Table 11: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on CIFAR-100-C dataset. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Reset Every1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg T= 100036.7 36.7 36.6 36.6 36.7 36.8 36.7 36.5 36.6 36.5 36.7 36.6 36.5 36.7 36.5 36.6 36.6 36.7 36.6 36.536.6T= 1000043.5 43.6 43.7 43.7 43.4 43.5 43.6 43.4 43.5 43.6 43.8 43.5 43.5 43.6 43.4 43.6 43.5 43.8 43.7 43.643.6T= 15000035.435.4 35.4 35.3 35.4 35.4 35.5 35.6 35.4 35.4 35.535.3 35.235.435.135.835.135.6 35.3 35.835.4 PeTTA(ours)(âˆ—) 35.834.434.735.035.135.135.235.335.335.335.235.335.235.235.135.235.235.235.235.235.1 Table 12: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on DomainNet dataset. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Reset Every1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg T= 100044.3 44.4 44.3 44.5 44.2 44.2 44.3 44.5 44.4 44.2 44.3 44.3 44.3 44.3 44.5 44.3 44.2 44.3 44.4 44.344.3T= 2423744.1 44.3 43.9 44.2 44.1 44.3 44.2 44.4 44.1 44.1 44.0 44.3 44.1 44.0 44.0 44.2 44.1 44.1 44.1 44.444.1T= 7271244.3 44.3 44.0 44.3 44.1 44.3 44.2 44.4 44.2 44.1 44.0 44.1 44.2 44.1 44.1 44.1 44.1 44.0 44.0 44.344.2 PeTTA(ours)(âˆ—) 43.842.642.342.342.642.842.843.042.942.943.143.042.943.043.043.143.042.842.942.942.9 Discussions. Across datasets and reset frequencies, our PeTTA approach is always better than RDumb [45]. The supreme performance holds even when RDumb has access to the oracle information that can reset the model exactly at the transition between each domain shift or recurrence. Importantly, this oracle information is typically unavailable in practice. 1A slight abuse of notation. T here is the number of images between two consecutive resets, following the notation on Sec. 3 of [45], not the sample indices in our notations. 2A subset of 5, 000 samples from ImageNet-C are selected following RobustBench [10] for a consistent evaluation with other benchmarks. 26Table 13: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on ImageNet-C dataset. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Reset Every1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg T= 100072.2 73.0 73.2 72.8 72.2 72.8 73.3 72.7 71.9 73.0 73.2 73.1 72.0 72.7 73.3 73.1 72.1 72.6 73.3 73.172.8T= 500070.2 70.8 71.6 72.1 72.4 72.6 72.9 73.1 73.2 73.6 73.7 73.9 74.0 74.0 74.3 74.1 74.1 73.8 73.5 71.973.0T= 7500067.0 67.1 67.2 67.5 67.5 67.6 67.8 67.6 67.6 67.6 67.5 67.7 67.6 67.9 68.1 67.9 67.4 67.5 67.7 67.567.6 PeTTA(ours)(âˆ—) 65.361.759.859.159.459.659.859.359.460.060.361.060.760.460.660.760.860.760.460.260.5 Noteworthy, it is clear that the performance of RDumb varies when changing the choice of the reset frequency. For a given choice of T, the better performance on one dataset does not guarantee the same performance on other datasets. For example, T = 1, 000 - the best empirical value found by RDumb authors [45] on CCC, does not give the best performance on our recurring TTA scenario; the second choice of T negatively impact the performance on many tasks; the third choice gives the best results, but knowing this exact recurrence frequency of the testing stream is unrealistic. The result highlights the challenge in practice when tuning this parameter (too slow/frequent), especially in the TTA setting where a validation set is unavailable. Our PeTTA, in contrast, is reset-free. F.4 PeTTA with 40 Recurring Visits To demonstrate the persistence of PeTTA over an even longer testing stream, in Tab. 14 and Fig. 8, we provide the evaluation results of PeTTA on recurring with 40 recurrences. F.5 The Sensitivity of Hyper-parameter Choices in PeTTA Table 15: Sensitivity of PeTTA with different choices ofÎ»0. Dataset Î»0 = 1e0 Î»0 = 5e0 Î»0 = 1e1 Î»0 = 5e1 Î»0 = 1e2 CIFAR-10-C 22.9 22.7 22.8 23.2 24.1 CIFAR-100-C 35.7 35.3 35.1 35.6 36.1 ImageNet-C 61.2 61.0 60.5 61.3 62.4 There are two hyper-parameters in PeTTA: Î±0 and Î»0. The initial learning rate of Î±0 = 1eâˆ’3 is used for all experiments. We do not tune this hyper-parameter, and the choice of Î±0 is universal across all datasets, following the previous works/compared methods (e.g., RoTTA [61], CoTTA [59]). Since Î»0 is more specific to PeTTA, we included a sensitive analysis with different choices of Î»0 on PeTTA, evaluated with images from CIFAR-10/100-C and ImageNet-C in Tab. 15. Overall, the choice of Î»0 is not extremely sensitive, and while the best value is1e1 on most datasets, other choices such as 5e0 or 5e1 also produce roughly similar performance. Selecting Î»0 is intuitive, the larger value of Î»0 stronger prevents the model from collapsing but also limits its adaptability as a trade-off. In action, Î»0 is an initial value and will be adaptively scaled with the sensing model divergence mechanism in PeTTA, meaning it does not require careful tuning. More generally, this hyper- parameter can be tuned similarly to the hyper-parameters of other TTA approaches, via an additional validation set, or some accuracy prediction algorithm [29] when labeled data is unavailable. F.6 More Details on the Ablation Study We provide the detailed classification error for each visit in the recurring TTA setting of each row entry in Tab. 4 (PeTTA Ablation Study): Tab. 16, Tab. 17, Tab. 18, Tab. 19; and Tab. 5 (PeTTA with various choices of regularizers): Tab. 20, Tab. 21, Tab. 22, Tab. 23. Fig. 9 presents an additional examination of the ablation study conducted on the task CIFAR-100 â†’ CIFAR-100-C [19] for our PeTTA approach. We plot the classification error (top) and the value of Â¯Î³t (bottom) for various PeTTA variations. As the model diverges from the initial state, the value of Â¯Î³t increases. Unable to adjust Î±t or constraint the probability space via LAL limits the ability of PeTTA to prevent model collapse. In all variations with the model collapse in ablation studies, the rapid saturation of Â¯Î³t is all observed. Therefore, incorporating all components in PeTTA is necessary. 27Table 16: Average classification error of multiple variations of PeTTA. Experiments on CIFAR10â†’ CIFAR10-C [19] task. Episodic TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Baseline w/oR(Î¸) 23.5 24.0 27.4 29.9 33.4 35.6 38.0 40.7 43.1 45.0 46.0 48.6 50.0 49.7 50.8 51.5 52.3 53.3 54.3 55.542.6 R(Î¸)fixedÎ»= 0.1Î»0 23.5 24.0 27.2 29.8 33.4 35.3 37.9 40.5 43.3 45.3 46.8 49.3 50.9 51.0 52.1 53.2 54.0 54.8 56.0 57.643.3R(Î¸)fixedÎ»=Î»0 23.5 23.6 26.2 28.4 31.6 33.5 36.4 38.7 41.1 43.1 44.8 47.6 49.3 49.5 50.9 52.1 53.1 54.2 55.6 57.042.0 PeTTA-Î»t 24.9 25.3 26.0 26.4 27.2 26.5 27.2 27.1 27.4 27.7 27.8 28.0 27.5 28.0 27.7 27.4 27.0 27.6 27.8 27.827.1PeTTA-Î»t+Î±t 25.5 24.5 23.7 23.1 23.222.423.3 23.2 23.7 24.1 23.9 24.5 24.3 24.0 23.8 23.9 23.8 24.1 24.6 24.723.9PeTTA-Î»t+LAL 23.323.9 24.6 25.3 26.2 25.9 26.4 26.6 26.9 26.6 26.7 26.7 26.7 26.8 26.8 27.2 26.9 26.9 26.8 27.026.2 PeTTAÎ±t+LAL 24.323.0 22.6 22.4 22.422.522.3 22.5 22.8 22.8 22.6 22.7 22.7 22.9 22.6 22.7 22.6 22.8 22.9 23.022.8 Table 17: Average classification error of multiple variations of PeTTA. Experiments on CIFAR-100 â†’ CIFAR100-C [19] task. Episodic TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Baseline w/oR(Î¸) 40.2 46.3 51.2 54.4 57.3 59.4 61.3 62.6 63.9 65.1 66.3 67.1 68.1 68.9 69.6 70.3 71.1 71.6 72.4 72.963.0 R(Î¸)fixedÎ»= 0.1Î»0 40.5 46.1 51.5 55.1 58.2 60.5 62.6 64.2 65.7 67.3 68.6 69.5 70.6 71.6 72.5 73.4 74.2 74.9 75.8 76.565.0R(Î¸)fixedÎ»=Î»0 41.8 47.6 52.6 56.1 58.9 60.7 62.5 63.9 65.0 66.2 67.1 68.3 69.5 70.3 71.4 72.4 73.4 74.1 75.0 75.664.6 PeTTA-Î»t 39.4 43.4 46.6 49.1 51.0 52.6 53.8 54.7 55.7 56.5 57.1 57.7 58.3 58.8 59.3 59.9 60.6 61.0 61.6 62.155.0PeTTA-Î»t+Î±t 39.4 40.1 40.8 40.7 41.2 41.5 41.4 41.6 41.5 41.5 41.7 41.6 41.8 41.7 41.8 42.0 41.9 41.9 42.0 41.841.4PeTTA-Î»t+LAL 36.2 35.6 35.7 36.1 36.2 36.4 36.4 36.5 36.2 36.2 36.6 36.5 36.5 36.6 36.5 36.6 36.5 36.5 36.3 36.536.3 PeTTAÎ»t+Î±t+LAL 35.8 34.4 34.7 35.0 35.1 35.1 35.2 35.3 35.3 35.3 35.2 35.3 35.2 35.2 35.1 35.2 35.2 35.2 35.2 35.235.1 Table 18: Average classification error of multiple variations of PeTTA. Experiments onreal â†’ clipart, painting, sketch task from DomainNet [44] task. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Baseline w/oR(Î¸) 52.3 69.0 68.6 68.6 69.4 70.5 71.8 73.4 75.6 77.6 78.8 81.0 82.8 84.3 85.9 87.4 88.5 89.9 90.8 92.177.9 R(Î¸)fixedÎ»= 0.1Î»0 52.5 70.0 69.8 70.0 71.1 72.5 74.6 76.1 77.8 80.4 81.9 83.5 85.2 87.2 89.1 90.2 91.5 93.2 94.1 94.980.0R(Î¸)fixedÎ»=Î»0 54.6 69.8 63.7 56.0 61.7 76.4 70.4 62.5 58.2 76.0 73.6 66.8 58.6 62.3 80.8 75.5 67.0 59.9 59.3 78.366.6 PeTTA-Î»t 49.2 64.5 62.4 60.9 59.6 58.6 57.7 57.8 57.6 57.7 58.0 58.5 59.0 59.5 59.8 61.1 62.0 62.6 63.6 64.959.7PeTTA-Î»t+Î±t 43.942.5 42.3 42.3 42.6 42.843.1 43.7 43.9 44.3 44.6 45.1 45.4 45.7 45.7 46.1 46.1 46.2 46.5 46.444.5PeTTA-Î»t+LAL 43.6 42.542.6 42.6 42.9 43.0 43.3 43.4 43.1 43.243.143.3 43.3 43.2 43.2 43.9 43.7 43.0 43.2 43.543.2 PeTTAÎ»t+Î±t+LAL 43.8 42.642.3 42.3 42.6 42.8 42.8 43.0 42.9 42.9 43.1 43.0 42.9 43.0 43.0 43.1 43.0 42.8 42.9 42.942.9 Table 19: Average classification error of multiple variations of PeTTA. Experiments on ImageNetâ†’ ImageNet-C [19] task. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg Baseline w/oR(Î¸) 66.9 61.9 72.7 93.6 97.4 97.8 98.0 98.2 98.3 98.3 98.4 98.4 98.5 98.5 98.6 98.6 98.6 98.6 98.7 98.793.4 R(Î¸)fixedÎ»= 0.1Î»0 65.5 70.9 79.1 85.2 90.3 92.6 95.8 95.8 95.4 97.3 96.9 97.7 97.9 98.2 98.0 98.7 98.6 98.4 98.4 98.792.5R(Î¸)fixedÎ»=Î»0 66.5 62.1 73.0 93.5 97.0 97.2 97.5 97.5 97.6 97.5 97.7 97.7 97.7 97.8 97.9 97.9 98.0 98.0 98.0 97.992.9 PeTTA-Î»t 65.9 62.1 76.3 96.7 97.0 96.9 96.9 96.9 97.0 97.1 97.0 97.2 97.0 97.1 97.1 97.0 97.0 97.0 97.0 97.092.7PeTTA-Î»t+Î±t 64.870.5 74.6 75.8 75.5 75.8 76.1 76.2 76.2 76.5 76.7 77.0 76.9 77.4 77.1 77.3 77.2 77.4 77.6 77.475.7PeTTA-Î»t+LAL 64.8 61.160.0 59.8 60.4 60.4 61.2 61.2 61.8 61.9 62.1 62.2 62.1 62.9 62.1 62.8 62.7 62.1 62.8 66.662.0 PeTTA(ours)(âˆ—) 65.3 61.7 59.8 59.1 59.4 59.6 59.8 59.3 59.4 60.0 60.3 61.0 60.7 60.4 60.6 60.7 60.8 60.7 60.4 60.260.5 Table 20: Average classification error of PeTTA with various choices of regularizers. Experiments on CIFAR-10 â†’ CIFAR-10-C [19] task. Episodic TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg L2 25.6 24.8 23.8 23.1 23.2 22.7 23.0 22.7 22.7 22.7 22.8 22.7 22.8 22.7 22.522.3 22.2 22.4 22.7 22.823.0L2+Fisher25.2 23.7 22.5 21.8 22.3 21.5 22.3 22.1 22.5 22.8 22.6 22.622.622.8 22.6 22.9 22.6 22.9 23.0 23.322.7 Cosine 24.3 23.022.6 22.4 22.4 22.5 22.3 22.5 22.8 22.8 22.6 22.7 22.7 22.9 22.6 22.7 22.6 22.8 22.9 23.022.8Cosine+Fisher25.1 23.822.2 21.6 22.0 21.4 22.0 21.8 22.1 22.3 22.5 22.4 22.6 22.6 22.422.7 22.6 22.8 22.8 23.322.6 Table 21: Average classification error of PeTTA with various choices of regularizers. Experiments on CIFAR-100 â†’ CIFAR-100-C [19] task. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg L2 36.9 35.5 35.5 35.5 35.7 35.6 35.6 35.5 35.5 35.4 35.6 35.5 35.7 35.7 35.7 35.7 35.8 35.5 35.4 35.535.6L2+Fisher36.8 35.4 35.4 35.8 35.9 36.0 35.9 35.9 35.9 35.8 36.1 36.1 36.1 36.1 36.1 36.1 36.2 36.0 36.0 35.936.0 Cosine 35.8 34.4 34.7 35.0 35.1 35.1 35.2 35.3 35.3 35.3 35.2 35.3 35.2 35.2 35.1 35.2 35.2 35.2 35.2 35.235.1Cosine+Fisher36.7 35.2 35.5 35.6 35.9 35.9 36.1 36.0 36.0 35.9 36.0 36.0 36.0 36.1 36.0 36.0 35.9 35.9 35.9 36.035.9 28Table 22: Average classification error of PeTTA with various choices of regularizers. Experiments on real â†’ clipart, painting, sketch task from DomainNet [44] dataset. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg L2 43.8 42.7 42.5 42.4 42.8 42.9 43.0 43.1 43.1 43.2 43.4 43.3 43.2 43.3 43.2 43.2 43.4 43.0 43.1 43.143.1L2+Fisher43.9 42.8 42.7 43.0 43.2 43.4 43.6 43.8 43.9 44.1 44.0 44.2 44.2 44.2 44.4 44.4 44.5 44.5 44.5 44.543.9 Cosine 43.8 42.642.3 42.3 42.6 42.8 42.8 43.0 42.9 42.9 43.1 43.0 42.9 43.0 43.0 43.1 43.0 42.8 42.9 42.942.9Cosine+Fisher43.7 42.542.5 42.6 42.9 43.2 43.2 43.5 43.4 43.5 43.4 43.5 43.4 43.6 43.5 43.5 43.4 43.5 43.3 43.443.3 Table 23: Average classification error of PeTTA with various choices of regularizers. Experiments on ImageNet â†’ ImageNet-C [19] task. Recurring TTA visitâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Avg L2 70.8 72.2 71.5 69.8 72.3 69.3 70.3 70.5 70.0 70.8 70.2 72.1 71.4 70.8 70.9 70.9 69.7 71.0 71.1 70.470.8L2+Fisher70.5 70.0 69.5 69.4 69.6 69.9 69.2 69.3 72.2 70.4 71.0 70.5 71.7 71.5 71.3 68.4 68.6 68.8 68.7 68.770.0 Cosine 65.361.7 59.8 59.1 59.4 59.6 59.8 59.3 59.4 60.0 60.3 61.0 60.7 60.4 60.6 60.7 60.8 60.7 60.4 60.260.5Cosine+Fisher65.1 61.760.9 61.2 61.9 62.6 62.8 63.2 64.2 63.4 64.3 64.4 63.9 64.3 65.8 65.5 64.9 65.0 65.2 65.263.8 F.7 More Confusion Matrices in Recurring TTA Setting For the task CIFAR-10â†’ CIFAR-10-C [19] in recurring TTA setting (with 20 visits), we additionally showcase the confusion matrix of RoTTA [61] (Fig. 10) and our proposed PeTTA (Fig. 11) at each visit. Our PeTTA persistently achieves competitive performance across 20 visits while RoTTA [61] gradually degrades. G Experimental Details G.1 Computing Resources A computer cluster equipped with an Intel(R) Core(TM) 3.80GHz i7-10700K CPU, 64 GB RAM, and one NVIDIA GeForce RTX 3090 GPU (24 GB VRAM) is used for our experiments. G.2 Experiments on CCC Testing Stream In this section, we further evaluate the performance of our PeTTA on the testing data stream of Continuous Changing Corruption (CCC) [ 45] setting. Here we use the baseline accuracy 20%, transition speed 1000, and random seed 44.3 The compared methods are source model (ResNet 50), PeTTA, RoTTA [61], and RDumb [45]. Noteworthy, different from recurring TTA, the class labels here are i.i.d. distributed. The adaptation configuration of PeTTA follows the same settings as used on ImageNet-C, while the same setting introduced in Sec. F.3, with T = 1000 is used for RDumb [45]. G.3 Test-time Adaptation Methods Pre-trained Model on Source Distribution. Following previous studies [57, 61, 12, 59], only the batch norm layers are updated. As stated in Sec. 5.2, RobustBench [10] and torchvision [35] provide pre-trained models trained on source distributions. Specifically, for ImageNet-C and Do- mainNet experiments, a ResNet50 model [17] pre-trained on ImageNet V2 (specifically, checkpoint ResNet50_Weights.IMAGENET1K_V2 of torchvision) is used. From RobustBench, the model with checkpoint Standard and Hendrycks2020AugMix_ResNeXt [20] are adopted for CIFAR10-C and CIFAR-100-C experiments, respectively. Lastly, experiments on DomainNet dataset utilize the checkpoint (best_real_2020) provided in AdaContrast [8] study.4 Optimizer. Without specifically stated, Adam [26] optimizer with learning rate equal 1eâˆ’3, and Î² = (0.9, 0.999) is selected as a universal choice for all experiments. More Details on PeTTA. Since designing the batch normalization layers, and the memory bank is not the key focus of PeTTA, we conveniently adopt the implementation of the Robust Batch Norm layer and the Category-balanced Sampling strategy using a memory bank introduced in RoTTA [61]. 3https://github.com/oripress/CCC 4https://github.com/DianCh/AdaContrast 29G.4 The Use of Existing Assets Many components of PeTTA is utilized from the official repository of RoTTA [61] 5 and RMT [12]. 6 These two assets are released under MIT license. All the datasets, including CIFAR-10-C, CIFAR- 100-C and ImageNet-C [ 19] are publicly available online, released under Apache-2.0 license. 7 DomainNet dataset [44] (cleaned version) is also released for research purposes.8 5https://github.com/BIT-DA/RoTTA 6https://github.com/mariodoebler/test-time-adaptation 7https://github.com/hendrycks/robustness 8https://ai.bu.edu/M3SDA/ 300 10000 20000 30000 40000 Test-time adaptation step (t) 0.40 0.60 0.80 1.00 Â¯Î³t 0 10000 20000 30000 40000 Test-time adaptation step (t) 4.00 6.00 8.00 10.00Î»t 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.00 0.25 0.50 0.75 1.00Î±t 1e 3 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.00 1.00 2.00 3.00 4.00LCLS 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.00 2.50 5.00 7.50 10.00LAL 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.00 0.50 1.00 1.50 2.00 R(Î¸) 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.00 0.25 0.50 0.75 1.00Testing error Figure 7: An inspection of PeTTA on the task CIFAR-10 â†’ CIFAR-10-C [19] in a recurring with 20 visits (visits are separated by the vertical dashed lines). Here, we visualize (rows 1-3) the dynamic of PeTTA adaptive parameters (Â¯Î³t, Î»t, Î±t), (rows 4-5) the value of the loss functions (LCLS, LAL) and (row 6) the value of the regularization term (R(Î¸)) and (row 7) the classification error rate at each step. The solid line in the foreground of each plot denotes the running mean. The plots show an adaptive change of Î»t, Î±t through time in PeTTA, which stabilizes TTA performance, making PeTTA achieve a persisting adaptation process in all observed values across 20 visits. 31Figure 8: Testing error of PeTTA with 40 recurring TTA visits. Total Visits CF-10-C CF-100-C IN-C 20 visits 22.8 35.1 60.5 40 visits 22.9 35.1 61.0 Table 14: Average testing error of PeTTA in recurring TTA with 20 and 40 visits. PeTTA demonstrates its persistence over an extended testing time horizon beyond the 20 th visit milestone (Fig. 8â€™s horizontal dashed line). 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.20 0.30 0.40 0.50 0.60 0.70 0.80Testing Error PeTTA - Î»t Baseline w/o R(Î¸) PeTTA - Î»t + Î±t R(Î¸) fixed Î»= 0.1Î»0 PeTTA - Î»t + LAL R(Î¸) fixed Î»= Î»0 PeTTA - Î»t  + Î±t  + LAL 0 10000 20000 30000 40000 Test-time adaptation step (t) 0.20 0.40 0.60 0.80 1.00 Â¯Î³t PeTTA - Î»t PeTTA - Î»t + Î±t PeTTA - Î»t + LAL PeTTA - Î»t  + Î±t  + LAL Figure 9: An inspection on the ablation study of multiple variations of PeTTA on the task CIFAR-100 â†’ CIFAR-100-C [19] in an episodic TTA with 20 visits (visits are separated by the vertical dashed lines). (top): testing error of multiple variations of PeTTA. The performance of PeTTA without (w/o) R(Î¸), or fixed regularization coefficient ( Î» = Î»0/0.1Î»0) degrades through time (the top 3 lines). The degradation of PeTTA -Î»t is still happening but at a slower rate (justification below). The performance of the other three variations persists through time with PeTTA -Î»t + Î±t + LAL achieves the best performance. (bottom): changes of Â¯Î³t in multiple variations of PeTTA. When limiting the degree of freedom in adjusting Î±t or lacking of supervision from LAL (e.g., PeTTA -Î»t + Î±t, PeTTA -Î»t + LAL, and especially PeTTA -Î»t), the value of Î³t, unfortunately, escalates and eventually saturated. After this point, PeTTA has the same effect as using a fixed regularization coefficient. Therefore, fully utilizing all components is necessary to preserve the persistence of PeTTA. Best viewed in color. 320: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.79 0.01 0.04 0.03 0.02 0.01 0.01 0.02 0.05 0.02 0.02 0.82 0.01 0.01 0 0.01 0.01 0.01 0.01 0.09 0.06 0 0.68 0.07 0.04 0.03 0.06 0.03 0.01 0.01 0.02 0.01 0.04 0.66 0.04 0.08 0.07 0.05 0.01 0.02 0.03 0 0.04 0.06 0.68 0.02 0.06 0.09 0.01 0.01 0.03 0 0.05 0.15 0.03 0.61 0.03 0.07 0.01 0.01 0.02 0.01 0.03 0.07 0.02 0.02 0.8 0.02 0 0.01 0.01 0 0.02 0.03 0.03 0.02 0.01 0.87 0 0.01 0.09 0.02 0.02 0.02 0.01 0 0.02 0.01 0.77 0.04 0.03 0.03 0.01 0.01 0 0 0.01 0.01 0.03 0.85 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.76 0.01 0.03 0.03 0.01 0 0.03 0.02 0.07 0.03 0.02 0.76 0 0.01 0 0 0.03 0.01 0.02 0.16 0.07 0 0.63 0.08 0.06 0.02 0.08 0.04 0.01 0.01 0.02 0 0.04 0.7 0.04 0.04 0.09 0.05 0.01 0.02 0.03 0 0.03 0.05 0.73 0.01 0.06 0.08 0.01 0.01 0.01 0 0.03 0.23 0.04 0.53 0.06 0.08 0.01 0.01 0.02 0 0.02 0.1 0.02 0.01 0.81 0.01 0 0.01 0.01 0 0.01 0.05 0.03 0.01 0.01 0.87 0 0.01 0.08 0.01 0.01 0.02 0.01 0 0.02 0.01 0.8 0.04 0.03 0.02 0.01 0.02 0 0 0.02 0.01 0.02 0.87 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.7 0.01 0.03 0.04 0.02 0 0.03 0.03 0.09 0.06 0.01 0.72 0 0.01 0 0 0.04 0 0.01 0.2 0.07 0 0.56 0.1 0.08 0.02 0.09 0.04 0.01 0.02 0.01 0 0.03 0.7 0.05 0.02 0.13 0.04 0 0.02 0.04 0 0.03 0.07 0.69 0 0.08 0.07 0.01 0.01 0.01 0 0.04 0.26 0.05 0.42 0.13 0.07 0 0.01 0.01 0 0.02 0.11 0.03 0 0.8 0.01 0 0.01 0.01 0 0.02 0.06 0.05 0.01 0.04 0.8 0 0.01 0.07 0.01 0.01 0.03 0.01 0 0.03 0.01 0.78 0.05 0.02 0.01 0.01 0.02 0.01 0 0.04 0.01 0.02 0.86 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.62 0.01 0.03 0.06 0.03 0 0.05 0.04 0.09 0.08 0.01 0.66 0 0.02 0.01 0 0.04 0 0.02 0.25 0.07 0 0.48 0.13 0.1 0.02 0.13 0.03 0.01 0.02 0.01 0 0.02 0.68 0.05 0.02 0.17 0.03 0 0.02 0.03 0 0.02 0.07 0.67 0 0.12 0.07 0.01 0.01 0.01 0 0.02 0.29 0.07 0.39 0.14 0.06 0 0.01 0.01 0 0.01 0.11 0.04 0 0.8 0.01 0 0.01 0.01 0 0.02 0.08 0.06 0.01 0.06 0.75 0 0.01 0.05 0.01 0.01 0.04 0.02 0 0.05 0.01 0.74 0.07 0.01 0.01 0 0.03 0.01 0 0.05 0.01 0.02 0.86 True label 1st visit 2nd visit 3rd visit 4th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.56 0 0.03 0.07 0.04 0 0.07 0.04 0.1 0.1 0.01 0.61 0 0.01 0.01 0 0.07 0 0.02 0.26 0.08 0 0.42 0.13 0.13 0.02 0.15 0.03 0.01 0.02 0.02 0 0.01 0.62 0.06 0.02 0.21 0.03 0 0.02 0.03 0 0.02 0.06 0.66 0 0.16 0.06 0.01 0.01 0.01 0 0.02 0.3 0.08 0.34 0.17 0.06 0 0.02 0.01 0 0.01 0.12 0.07 0 0.76 0.01 0 0.02 0.01 0 0.02 0.1 0.08 0.01 0.08 0.69 0 0.02 0.05 0.01 0.01 0.05 0.02 0 0.09 0.01 0.68 0.09 0.01 0.01 0 0.03 0.02 0 0.09 0.01 0.02 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.51 0 0.02 0.07 0.04 0 0.09 0.03 0.1 0.14 0.01 0.56 0 0.01 0.02 0 0.09 0 0.02 0.29 0.08 0 0.35 0.15 0.16 0.02 0.18 0.03 0.01 0.03 0.02 0 0.01 0.57 0.07 0.02 0.27 0.02 0 0.03 0.04 0 0.01 0.08 0.62 0 0.18 0.05 0.01 0.01 0.01 0 0.01 0.29 0.09 0.3 0.21 0.05 0 0.02 0.01 0 0.01 0.12 0.09 0 0.75 0 0 0.01 0.02 0 0.01 0.11 0.12 0.01 0.1 0.6 0 0.03 0.06 0.01 0 0.04 0.02 0 0.09 0 0.66 0.11 0.01 0.01 0 0.02 0.03 0 0.11 0 0.02 0.8 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.48 0 0.02 0.08 0.04 0 0.11 0.03 0.11 0.13 0.01 0.54 0 0.01 0.02 0 0.11 0 0.02 0.28 0.09 0 0.3 0.16 0.16 0.02 0.21 0.02 0.01 0.03 0.02 0 0.01 0.51 0.08 0.01 0.33 0.01 0.01 0.02 0.03 0 0.01 0.05 0.65 0 0.21 0.03 0.01 0.01 0.02 0 0.01 0.27 0.11 0.25 0.28 0.03 0 0.02 0.01 0 0.01 0.12 0.1 0 0.75 0 0 0.01 0.02 0 0.01 0.11 0.13 0.01 0.13 0.56 0 0.03 0.06 0 0 0.06 0.03 0 0.13 0 0.6 0.11 0.02 0.01 0 0.03 0.04 0 0.15 0 0.02 0.73 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.46 0 0.01 0.07 0.06 0 0.13 0.01 0.09 0.15 0.01 0.48 0 0.01 0.04 0 0.16 0 0.01 0.28 0.09 0 0.27 0.15 0.19 0.01 0.23 0.01 0.01 0.03 0.02 0 0.01 0.44 0.12 0.01 0.37 0.01 0.01 0.02 0.04 0 0.01 0.05 0.63 0 0.23 0.02 0.01 0.01 0.02 0 0.01 0.25 0.13 0.22 0.33 0.02 0 0.01 0.01 0 0 0.11 0.15 0 0.71 0 0 0.01 0.02 0 0.01 0.09 0.22 0 0.15 0.47 0 0.02 0.08 0 0 0.06 0.05 0 0.15 0 0.55 0.1 0.02 0.01 0 0.04 0.05 0 0.16 0 0.02 0.7 True label 5th visit 6th visit 7th visit 8th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.47 0 0.01 0.06 0.06 0 0.13 0.01 0.1 0.16 0.02 0.47 0 0.01 0.04 0 0.13 0 0.03 0.29 0.1 0 0.24 0.12 0.22 0.01 0.24 0.01 0.01 0.03 0.03 0 0 0.4 0.12 0.01 0.39 0 0.01 0.02 0.05 0 0.01 0.06 0.61 0 0.23 0.02 0.01 0.01 0.03 0 0.01 0.22 0.15 0.2 0.35 0.02 0 0.02 0.01 0 0 0.11 0.15 0 0.7 0 0.01 0.01 0.03 0 0.01 0.08 0.25 0 0.15 0.44 0.01 0.03 0.09 0 0 0.04 0.07 0 0.14 0 0.55 0.1 0.02 0.01 0 0.03 0.05 0 0.16 0 0.02 0.7 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.46 0 0.01 0.05 0.07 0 0.14 0.01 0.1 0.16 0.04 0.43 0 0.02 0.07 0 0.14 0 0.03 0.27 0.11 0 0.22 0.11 0.23 0.01 0.26 0.01 0.02 0.03 0.04 0 0 0.33 0.16 0.01 0.43 0 0.01 0.02 0.05 0 0 0.03 0.66 0 0.23 0.01 0.01 0.01 0.04 0 0.01 0.22 0.15 0.18 0.37 0.01 0.01 0.02 0.01 0 0 0.1 0.19 0 0.68 0 0.01 0.01 0.03 0 0.01 0.08 0.28 0.01 0.16 0.41 0.01 0.03 0.11 0 0 0.04 0.05 0 0.14 0 0.56 0.09 0.04 0.01 0 0.02 0.08 0 0.18 0 0.02 0.65 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.47 0 0.01 0.04 0.07 0 0.14 0 0.1 0.16 0.04 0.42 0 0.01 0.07 0 0.15 0 0.05 0.26 0.11 0 0.21 0.1 0.26 0.01 0.26 0 0.02 0.03 0.05 0 0 0.31 0.18 0.01 0.42 0 0.01 0.02 0.06 0 0 0.04 0.65 0 0.21 0.01 0.01 0.02 0.04 0 0.01 0.17 0.21 0.15 0.39 0.01 0.01 0.02 0.01 0 0 0.1 0.24 0 0.64 0 0.01 0.01 0.04 0 0.01 0.09 0.28 0 0.16 0.39 0 0.03 0.14 0 0 0.03 0.07 0 0.14 0 0.52 0.09 0.05 0.01 0 0.03 0.1 0 0.18 0 0.03 0.61 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.49 0 0.01 0.03 0.06 0 0.14 0 0.11 0.17 0.07 0.4 0 0.01 0.07 0 0.12 0 0.07 0.27 0.13 0 0.19 0.08 0.27 0.01 0.25 0 0.02 0.03 0.07 0 0 0.27 0.19 0 0.43 0 0.02 0.03 0.07 0 0 0.02 0.64 0 0.23 0.01 0.01 0.01 0.06 0 0.01 0.19 0.18 0.13 0.39 0.01 0.01 0.02 0.02 0 0 0.09 0.22 0 0.65 0 0.01 0.01 0.05 0 0 0.07 0.32 0 0.15 0.36 0.01 0.04 0.17 0 0 0.03 0.07 0 0.12 0 0.53 0.08 0.06 0.01 0 0.01 0.13 0 0.17 0 0.03 0.59 True label 9th visit 10th visit 11th visit 12th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.5 0 0 0.02 0.08 0 0.13 0 0.1 0.15 0.09 0.37 0 0.01 0.11 0 0.11 0 0.08 0.24 0.15 0 0.18 0.07 0.31 0.01 0.24 0 0.03 0.02 0.09 0 0 0.24 0.17 0 0.44 0 0.02 0.03 0.08 0 0 0.02 0.66 0 0.19 0.01 0.02 0.02 0.08 0 0.01 0.15 0.23 0.11 0.38 0.01 0.01 0.02 0.02 0 0 0.08 0.31 0 0.55 0 0.02 0.01 0.05 0 0 0.05 0.37 0 0.14 0.34 0.01 0.04 0.2 0 0 0.03 0.06 0 0.12 0 0.52 0.08 0.08 0.01 0 0.01 0.11 0 0.15 0 0.04 0.59 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.54 0 0 0.02 0.06 0 0.11 0 0.12 0.15 0.13 0.35 0 0.01 0.1 0 0.09 0 0.12 0.21 0.16 0 0.18 0.07 0.29 0.01 0.24 0 0.03 0.02 0.11 0 0 0.22 0.19 0 0.42 0 0.03 0.03 0.08 0 0 0.03 0.65 0 0.2 0.01 0.02 0.01 0.09 0 0.01 0.12 0.29 0.08 0.37 0 0.02 0.02 0.02 0 0 0.09 0.29 0 0.56 0 0.02 0.01 0.06 0 0 0.05 0.39 0 0.13 0.32 0.01 0.04 0.23 0 0 0.02 0.07 0 0.1 0 0.51 0.07 0.12 0.01 0 0.01 0.11 0 0.13 0 0.05 0.57 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.56 0 0 0.02 0.08 0 0.1 0 0.12 0.12 0.18 0.32 0 0 0.11 0 0.08 0 0.13 0.19 0.18 0 0.15 0.05 0.34 0 0.2 0 0.04 0.02 0.12 0 0 0.19 0.27 0 0.36 0 0.04 0.02 0.09 0 0 0.02 0.69 0 0.15 0.01 0.02 0.02 0.11 0 0 0.1 0.33 0.07 0.33 0 0.03 0.01 0.03 0 0 0.09 0.35 0 0.5 0 0.02 0.01 0.08 0 0 0.04 0.43 0 0.1 0.29 0.01 0.04 0.26 0 0 0.02 0.08 0 0.08 0 0.51 0.06 0.15 0.01 0 0.01 0.12 0 0.1 0 0.07 0.55 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.58 0 0 0.01 0.07 0 0.09 0 0.13 0.11 0.16 0.32 0 0 0.11 0 0.07 0 0.16 0.18 0.18 0 0.15 0.05 0.36 0 0.19 0 0.04 0.02 0.14 0 0 0.18 0.26 0 0.35 0 0.05 0.02 0.1 0 0 0.01 0.69 0 0.15 0.01 0.03 0.01 0.11 0 0 0.1 0.36 0.05 0.32 0 0.04 0.01 0.03 0 0 0.08 0.38 0 0.46 0 0.03 0.01 0.09 0 0 0.04 0.43 0 0.09 0.29 0.02 0.04 0.29 0 0 0.02 0.09 0 0.08 0 0.47 0.06 0.18 0.01 0 0.01 0.11 0 0.08 0 0.1 0.5 True label 13th visit 14th visit 15th visit 16th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.6 0 0 0.01 0.08 0 0.08 0 0.13 0.1 0.2 0.28 0 0 0.1 0 0.06 0 0.19 0.17 0.2 0 0.14 0.05 0.36 0 0.18 0 0.05 0.02 0.17 0 0 0.16 0.28 0 0.29 0 0.08 0.02 0.1 0 0 0.01 0.71 0 0.11 0.01 0.04 0.02 0.13 0 0 0.1 0.4 0.04 0.27 0 0.05 0.01 0.04 0 0 0.09 0.4 0 0.41 0 0.04 0.01 0.1 0 0 0.04 0.45 0 0.07 0.27 0.03 0.04 0.34 0 0 0.01 0.08 0 0.05 0 0.47 0.05 0.22 0.01 0 0.01 0.13 0 0.06 0 0.12 0.44 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.62 0 0 0.01 0.09 0 0.08 0 0.13 0.08 0.24 0.26 0 0 0.1 0 0.05 0 0.19 0.15 0.2 0 0.13 0.04 0.41 0 0.16 0 0.05 0.02 0.16 0 0 0.14 0.3 0 0.29 0 0.09 0.02 0.11 0 0 0.01 0.7 0 0.1 0.01 0.05 0.02 0.14 0 0 0.09 0.42 0.02 0.27 0 0.05 0.01 0.03 0 0 0.09 0.44 0 0.39 0 0.04 0.01 0.12 0 0 0.04 0.43 0 0.06 0.28 0.03 0.04 0.35 0 0 0.01 0.07 0 0.06 0 0.46 0.04 0.26 0.01 0 0.01 0.13 0 0.06 0 0.13 0.41 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.67 0 0 0 0.1 0 0.05 0 0.11 0.06 0.3 0.21 0 0 0.1 0 0.03 0 0.21 0.13 0.26 0 0.11 0.04 0.4 0 0.11 0 0.06 0.02 0.2 0 0 0.13 0.32 0 0.21 0 0.12 0.02 0.13 0 0 0.01 0.72 0 0.07 0.01 0.05 0.01 0.2 0 0 0.09 0.42 0.01 0.19 0 0.08 0.01 0.04 0 0 0.08 0.49 0 0.3 0 0.07 0.01 0.16 0 0 0.03 0.45 0 0.04 0.24 0.05 0.03 0.42 0 0 0.01 0.06 0 0.04 0 0.43 0.04 0.33 0.01 0 0 0.11 0 0.03 0 0.15 0.36 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.69 0 0 0 0.08 0 0.04 0 0.13 0.05 0.34 0.17 0 0 0.1 0 0.03 0 0.23 0.13 0.24 0 0.1 0.03 0.44 0 0.11 0 0.07 0.01 0.21 0 0 0.11 0.32 0 0.21 0 0.14 0.01 0.14 0 0 0.01 0.71 0 0.06 0.01 0.06 0.01 0.21 0 0 0.07 0.44 0 0.16 0 0.1 0.01 0.05 0 0 0.08 0.51 0 0.25 0 0.1 0.01 0.17 0 0 0.03 0.46 0 0.04 0.21 0.06 0.04 0.46 0 0 0.01 0.06 0 0.03 0 0.41 0.03 0.34 0 0 0 0.12 0 0.03 0 0.18 0.32 Predicted label Predicted label Predicted label Predicted label True label 17th visit 18th visit 19th visit 20th visit Figure 10: The dynamic of the confusion matrix of RoTTA [61] in episodic TTA with 20 visits. 330: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.77 0.01 0.04 0.03 0.03 0.01 0.02 0.02 0.05 0.02 0.02 0.84 0.01 0.02 0 0.01 0.02 0.01 0.02 0.06 0.04 0 0.69 0.07 0.05 0.05 0.05 0.02 0.01 0.01 0.04 0.01 0.05 0.62 0.05 0.1 0.06 0.04 0.01 0.02 0.03 0 0.06 0.07 0.68 0.05 0.04 0.05 0.01 0.01 0.01 0 0.04 0.14 0.03 0.7 0.03 0.04 0.01 0.01 0.01 0.01 0.04 0.06 0.03 0.03 0.78 0.01 0.01 0.01 0.03 0 0.03 0.04 0.04 0.04 0.01 0.79 0.01 0.01 0.08 0.02 0.02 0.02 0.01 0.01 0.02 0.01 0.8 0.03 0.03 0.05 0.02 0.02 0.01 0.01 0.01 0.01 0.03 0.82 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.77 0.01 0.04 0.03 0.02 0.01 0.03 0.01 0.06 0.02 0.01 0.87 0.01 0.01 0 0.01 0.01 0 0.02 0.05 0.04 0 0.7 0.09 0.05 0.03 0.06 0.02 0.01 0.01 0.03 0.01 0.06 0.64 0.05 0.08 0.06 0.04 0.01 0.02 0.02 0 0.05 0.06 0.74 0.03 0.05 0.04 0.01 0.01 0.01 0 0.05 0.15 0.04 0.66 0.04 0.04 0.01 0.01 0.02 0.01 0.04 0.06 0.02 0.02 0.78 0.01 0.01 0.03 0.02 0 0.03 0.05 0.05 0.03 0.01 0.81 0 0.01 0.05 0.02 0.01 0.02 0.01 0 0.02 0.01 0.83 0.03 0.02 0.05 0.01 0.02 0.01 0.01 0.01 0.01 0.03 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.74 0.01 0.05 0.03 0.02 0 0.03 0.01 0.06 0.02 0.02 0.87 0.01 0.02 0 0 0.01 0 0.02 0.05 0.05 0 0.7 0.07 0.05 0.03 0.06 0.02 0.01 0.01 0.02 0.01 0.05 0.68 0.05 0.07 0.07 0.03 0.01 0.02 0.02 0 0.05 0.06 0.77 0.02 0.04 0.03 0 0 0.01 0 0.07 0.15 0.04 0.65 0.04 0.03 0.01 0.01 0.01 0 0.03 0.07 0.03 0.02 0.83 0.01 0 0.01 0.01 0 0.03 0.04 0.04 0.02 0.01 0.82 0 0.01 0.06 0.02 0.01 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.01 0.02 0.01 0 0.01 0.01 0.03 0.85 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.76 0.01 0.05 0.04 0.02 0 0.02 0.01 0.07 0.03 0.01 0.87 0.01 0.01 0 0 0.01 0 0.02 0.05 0.04 0 0.73 0.06 0.05 0.03 0.06 0.01 0.01 0.01 0.01 0.01 0.05 0.71 0.05 0.06 0.06 0.03 0.01 0.01 0.02 0 0.04 0.05 0.78 0.02 0.04 0.03 0.01 0 0.01 0 0.06 0.17 0.04 0.64 0.04 0.03 0.01 0.01 0.01 0 0.03 0.06 0.03 0.01 0.85 0.01 0 0.01 0.01 0 0.04 0.04 0.05 0.02 0.01 0.81 0.01 0.01 0.05 0.02 0.01 0.02 0.01 0 0.02 0 0.84 0.02 0.02 0.05 0.01 0.02 0.01 0 0.02 0.01 0.04 0.83 True label 1st visit 2nd visit 3rd visit 4th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.76 0.02 0.04 0.04 0.02 0 0.02 0.01 0.08 0.02 0.02 0.86 0.01 0.02 0 0 0.01 0 0.02 0.05 0.04 0 0.73 0.07 0.05 0.03 0.05 0.01 0.01 0.01 0.01 0.01 0.06 0.69 0.05 0.06 0.07 0.02 0.01 0.01 0.02 0 0.05 0.07 0.76 0.02 0.04 0.03 0.01 0 0.01 0 0.07 0.17 0.04 0.64 0.03 0.03 0.01 0.01 0.01 0 0.03 0.07 0.02 0.01 0.84 0.01 0.01 0.01 0.01 0 0.04 0.04 0.06 0.02 0.01 0.81 0.01 0.01 0.04 0.02 0.02 0.02 0.01 0 0.02 0 0.86 0.02 0.02 0.05 0.02 0.02 0.01 0 0.02 0.01 0.03 0.82 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.74 0.01 0.05 0.04 0.02 0 0.03 0.01 0.07 0.02 0.01 0.88 0.01 0.01 0 0 0.01 0 0.02 0.05 0.05 0 0.74 0.07 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.05 0.7 0.06 0.06 0.07 0.02 0.01 0.01 0.01 0 0.04 0.06 0.79 0.02 0.04 0.02 0.01 0 0.01 0 0.06 0.17 0.04 0.65 0.04 0.03 0.01 0.01 0.01 0 0.03 0.07 0.02 0.01 0.85 0 0 0.01 0.01 0 0.04 0.04 0.06 0.02 0.01 0.8 0.01 0.01 0.04 0.02 0.01 0.02 0.01 0 0.02 0 0.87 0.02 0.02 0.05 0.02 0.02 0 0 0.02 0.01 0.04 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.76 0.01 0.04 0.04 0.02 0 0.03 0.01 0.07 0.02 0.01 0.88 0.01 0.01 0 0 0.01 0 0.02 0.05 0.04 0 0.74 0.06 0.05 0.02 0.05 0.01 0.01 0.01 0.01 0.01 0.06 0.68 0.05 0.06 0.08 0.02 0.01 0.01 0.01 0 0.05 0.06 0.79 0.01 0.04 0.02 0 0 0.01 0 0.07 0.18 0.05 0.61 0.04 0.03 0.01 0.01 0 0 0.03 0.06 0.02 0.01 0.86 0 0 0 0.01 0 0.04 0.04 0.06 0.02 0.01 0.8 0 0.01 0.06 0.02 0.02 0.02 0.01 0 0.02 0 0.84 0.02 0.02 0.05 0.01 0.03 0.01 0 0.02 0.01 0.04 0.81 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.75 0.01 0.04 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.87 0.01 0.01 0 0 0.02 0 0.02 0.06 0.04 0 0.73 0.08 0.05 0.02 0.05 0.01 0.01 0.01 0.01 0 0.05 0.73 0.05 0.05 0.07 0.02 0.01 0.01 0.01 0 0.05 0.06 0.79 0.01 0.05 0.02 0.01 0 0.01 0 0.06 0.18 0.04 0.63 0.04 0.02 0.01 0.01 0 0 0.03 0.08 0.02 0.01 0.83 0 0 0 0.01 0 0.04 0.05 0.07 0.02 0.01 0.79 0 0.01 0.04 0.02 0.01 0.02 0.01 0 0.02 0 0.86 0.02 0.02 0.04 0.01 0.03 0.01 0 0.03 0.01 0.04 0.81 True label 5th visit 6th visit 7th visit 8th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.74 0.01 0.05 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.74 0.07 0.05 0.02 0.06 0.01 0.01 0.01 0.01 0 0.06 0.71 0.05 0.05 0.07 0.02 0.01 0.01 0.01 0 0.04 0.07 0.79 0.01 0.04 0.02 0.01 0 0.01 0 0.07 0.19 0.05 0.62 0.04 0.02 0.01 0 0 0 0.03 0.07 0.02 0.01 0.84 0 0 0.01 0.01 0 0.05 0.05 0.08 0.02 0.02 0.77 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.02 0.02 0.01 0 0.02 0.01 0.04 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.74 0.01 0.05 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.06 0.04 0 0.73 0.07 0.05 0.02 0.05 0.01 0.01 0.01 0.01 0.01 0.05 0.7 0.06 0.05 0.08 0.02 0.02 0.02 0.02 0 0.05 0.07 0.79 0.01 0.04 0.02 0.01 0 0.01 0 0.07 0.19 0.05 0.6 0.04 0.03 0.01 0.01 0 0 0.04 0.07 0.02 0.01 0.84 0 0 0.01 0.01 0 0.04 0.05 0.08 0.02 0.01 0.78 0 0 0.04 0.02 0.02 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.02 0.02 0.01 0 0.02 0.01 0.04 0.81 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.02 0.06 0.05 0.02 0 0.04 0.01 0.07 0.02 0.01 0.87 0.01 0.01 0 0 0.02 0 0.02 0.06 0.04 0 0.74 0.08 0.05 0.02 0.05 0.01 0.01 0.01 0.01 0 0.06 0.73 0.05 0.05 0.07 0.01 0.01 0.01 0.02 0 0.06 0.07 0.76 0.01 0.04 0.02 0.01 0 0 0 0.06 0.19 0.05 0.61 0.05 0.02 0.01 0 0 0 0.03 0.07 0.02 0.01 0.86 0 0 0 0.01 0 0.04 0.05 0.08 0.02 0.01 0.77 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.03 0 0.84 0.02 0.01 0.04 0.02 0.03 0.01 0 0.02 0 0.03 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.72 0.01 0.05 0.04 0.02 0 0.04 0.01 0.08 0.02 0.01 0.87 0.01 0.01 0 0 0.02 0 0.02 0.04 0.05 0 0.72 0.08 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.06 0.73 0.05 0.04 0.06 0.02 0.01 0.01 0.02 0 0.05 0.06 0.79 0.01 0.04 0.02 0.01 0 0.01 0 0.06 0.19 0.05 0.61 0.04 0.03 0.01 0 0 0 0.03 0.09 0.02 0.01 0.83 0 0 0 0.01 0 0.05 0.05 0.07 0.02 0.01 0.78 0 0.01 0.03 0.02 0.02 0.02 0.01 0 0.03 0 0.85 0.02 0.01 0.05 0.01 0.03 0.01 0 0.02 0 0.04 0.83 True label 9th visit 10th visit 11th visit 12th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.01 0.05 0.04 0.02 0 0.03 0.01 0.09 0.02 0.01 0.86 0.01 0.01 0 0 0.02 0 0.02 0.06 0.04 0 0.73 0.08 0.05 0.02 0.05 0.01 0.01 0 0.02 0 0.06 0.73 0.05 0.04 0.06 0.02 0.01 0.01 0.01 0 0.05 0.06 0.8 0.01 0.04 0.02 0.01 0 0.01 0 0.07 0.19 0.05 0.6 0.04 0.02 0.01 0.01 0 0 0.03 0.07 0.02 0.01 0.86 0 0 0 0.01 0 0.05 0.05 0.07 0.02 0.01 0.77 0 0 0.03 0.02 0.02 0.02 0.01 0 0.04 0 0.83 0.02 0.01 0.05 0.02 0.02 0.01 0 0.02 0 0.04 0.82 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.75 0.01 0.05 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.87 0.01 0.02 0 0 0.02 0 0.02 0.05 0.05 0 0.72 0.08 0.05 0.02 0.05 0.01 0.01 0 0.01 0.01 0.05 0.73 0.05 0.05 0.07 0.01 0.01 0.01 0.01 0 0.05 0.06 0.79 0.01 0.05 0.02 0.01 0 0.01 0 0.07 0.21 0.05 0.57 0.05 0.02 0.01 0 0 0 0.03 0.07 0.02 0.01 0.86 0 0 0 0.01 0 0.05 0.05 0.08 0.02 0.02 0.76 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.02 0.03 0.01 0 0.02 0 0.04 0.81 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.72 0.01 0.05 0.05 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.73 0.08 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.06 0.72 0.05 0.04 0.07 0.01 0.01 0.01 0.02 0 0.04 0.06 0.79 0.01 0.04 0.02 0.01 0 0.01 0 0.07 0.2 0.05 0.6 0.04 0.02 0.01 0.01 0 0 0.04 0.07 0.02 0.01 0.85 0 0 0 0.01 0 0.05 0.05 0.08 0.02 0.01 0.78 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.02 0.02 0.01 0 0.02 0 0.04 0.82 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.75 0.01 0.05 0.04 0.02 0 0.02 0.01 0.09 0.02 0.01 0.86 0.01 0.02 0 0 0.02 0 0.02 0.05 0.04 0 0.74 0.07 0.05 0.02 0.05 0.01 0.01 0.01 0.02 0 0.06 0.73 0.05 0.04 0.07 0.01 0.01 0.01 0.02 0 0.05 0.06 0.78 0.01 0.05 0.02 0.01 0 0.01 0 0.07 0.19 0.05 0.6 0.05 0.02 0.01 0.01 0 0 0.03 0.07 0.02 0.01 0.85 0 0 0.01 0.01 0 0.04 0.06 0.08 0.02 0.01 0.77 0 0.01 0.04 0.02 0.03 0.03 0.01 0 0.04 0 0.8 0.02 0.01 0.05 0.02 0.02 0.01 0 0.02 0 0.04 0.83 True label 13th visit 14th visit 15th visit 16th visit 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.01 0.06 0.04 0.02 0 0.04 0.01 0.07 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.75 0.07 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.06 0.74 0.05 0.05 0.06 0.01 0.01 0.01 0.01 0 0.05 0.06 0.8 0.01 0.04 0.02 0 0 0.01 0 0.07 0.2 0.05 0.59 0.06 0.02 0.01 0.01 0 0 0.04 0.08 0.02 0.01 0.84 0 0 0 0.01 0 0.05 0.05 0.08 0.02 0.02 0.76 0 0.01 0.05 0.01 0.01 0.02 0.01 0 0.02 0 0.85 0.02 0.02 0.05 0.02 0.03 0.01 0 0.03 0 0.03 0.81 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.72 0.01 0.05 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.04 0.04 0 0.73 0.07 0.06 0.02 0.06 0.01 0.01 0 0.01 0 0.06 0.73 0.05 0.04 0.07 0.01 0.01 0.01 0.01 0 0.06 0.06 0.79 0.01 0.05 0.02 0.01 0 0.01 0 0.07 0.21 0.05 0.59 0.04 0.02 0.01 0 0 0 0.04 0.07 0.02 0.01 0.86 0 0 0 0.01 0 0.05 0.05 0.08 0.02 0.01 0.76 0.01 0.01 0.05 0.02 0.02 0.03 0.01 0 0.02 0 0.85 0.01 0.02 0.05 0.02 0.03 0.01 0 0.03 0.01 0.04 0.8 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.01 0.06 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.73 0.06 0.05 0.02 0.06 0.01 0.01 0.01 0.01 0 0.06 0.73 0.05 0.05 0.07 0.01 0.01 0.01 0.01 0 0.05 0.06 0.78 0.01 0.05 0.02 0.01 0 0.01 0 0.07 0.21 0.05 0.58 0.05 0.02 0.01 0.01 0 0 0.03 0.07 0.02 0.01 0.85 0 0.01 0.01 0.01 0 0.06 0.05 0.08 0.02 0.02 0.75 0 0.01 0.03 0.02 0.02 0.02 0.01 0 0.03 0 0.85 0.02 0.02 0.05 0.02 0.02 0.01 0 0.02 0 0.04 0.83 0: airplane 1: auto2: bird3: cat4: deer5: dog6: frog7: horse8: ship9: truck 0 1 2 3 4 5 6 7 8 9 0.73 0.01 0.06 0.04 0.02 0 0.03 0.01 0.08 0.02 0.01 0.88 0.01 0.01 0 0 0.02 0 0.02 0.05 0.04 0 0.75 0.07 0.05 0.02 0.05 0.01 0.01 0 0.01 0 0.06 0.72 0.05 0.04 0.06 0.02 0.01 0.01 0.02 0 0.06 0.07 0.76 0.01 0.05 0.02 0.01 0 0 0 0.07 0.19 0.05 0.59 0.05 0.02 0.01 0.01 0 0 0.03 0.07 0.02 0.01 0.84 0 0.01 0.01 0.01 0 0.06 0.06 0.08 0.02 0.02 0.74 0 0.01 0.04 0.02 0.02 0.02 0.01 0 0.03 0 0.84 0.02 0.01 0.05 0.02 0.03 0.01 0 0.02 0.01 0.04 0.82 Predicted label Predicted label Predicted label Predicted label True label 17th visit 18th visit 19th visit 20th visit Figure 11: The dynamic of the confusion matrix of PeTTA (ours) in episodic TTA with 20 visits. 34NeurIPS Paper Checklist 1. Claims Question: Do the main claims made in the abstract and introduction accurately reflect the paperâ€™s contributions and scope? Answer: [Yes] Justification: We have highlighted the three main claims and contributions of our work in both the abstract (highlighted in bold font) and the introduction section (listed as bullet points). Guidelines: â€¢ The answer NA means that the abstract and introduction do not include the claims made in the paper. â€¢ The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. â€¢ The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. â€¢ It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 2. Limitations Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have discussed the limitations and potential future work of our study in Sec. 6. Specifically, three main limitations are included: (1) Collapse prevention can not be guaranteed through regularization, PeTTA requires (2) the use of a relatively small memory bank is available and (3) the empirical mean and covariant matrix of feature vectors on the source dataset is computable. We also include discussions in Appdx. E.3 and Appdx. E.4 to further elaborate (2), and (3) respectively. Guidelines: â€¢ The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. â€¢ The authors are encouraged to create a separate \"Limitations\" section in their paper. â€¢ The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. â€¢ The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. â€¢ The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. â€¢ The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. â€¢ If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. â€¢ While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that arenâ€™t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an impor- tant role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 353. Theory Assumptions and Proofs Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We have provided the full proof of all lemmas and theorem in Appdx. B. Guidelines: â€¢ The answer NA means that the paper does not include theoretical results. â€¢ All the theorems, formulas, and proofs in the paper should be numbered and cross- referenced. â€¢ All assumptions should be clearly stated or referenced in the statement of any theorems. â€¢ The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. â€¢ Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced. 4. Experimental Result Reproducibility Question: Does the paper fully disclose all the information needed to reproduce the main ex- perimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: This study propose a new TTA approach - PeTTA. A full description of this approach is given in Sec. 4 with its pseudo-code provided in Appdx. E.1. The implementation of PeTTA in Python is also attached as supplemental material. Additionally, Sec. 5.2 and Appdx. G are dedicated to providing further implementation details for reproducing the main experimental results. Lastly, the construction of recurring TTA is notably simple, and can be easily extended to other TTA streams. Its configuration on each tasks is described in the Recurring TTA paragraph of Sec. 5.2. Guidelines: â€¢ The answer NA means that the paper does not include experiments. â€¢ If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. â€¢ If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. â€¢ Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. â€¢ While NeurIPS does not require releasing code, the conference does require all submis- sions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 36(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. 5. Open access to data and code Question: Does the paper provide open access to the data and code, with sufficient instruc- tions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: This study does not involve any private datasets. All datasets used in our exper- iments are publicly available online from previous works (more information in Appdx. G.4). The source code of PeTTA is also attached as supplemental material. Guidelines: â€¢ The answer NA means that paper does not include experiments requiring code. â€¢ Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. â€¢ While we encourage the release of code and data, we understand that this might not be possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). â€¢ The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. â€¢ The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. â€¢ The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. â€¢ At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). â€¢ Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. 6. Experimental Setting/Details Question: Does the paper specify all the training and test details (e.g., data splits, hyper- parameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The experimental settings of the key results in the paper have been provided in Sec. 5.1 (Simulation Setup) and Sec. 5.2 (Setup - Benchmark Datasets). In the supplementary material, any additional experimental results beyond the main paper, such as those in Appdx. D.3, and Appdx. F.3, are consistently preceded by a subsection titledExperiment Setup summarizing the experimental details before presenting the results. Guidelines: â€¢ The answer NA means that the paper does not include experiments. â€¢ The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. â€¢ The full details can be provided either with the code, in appendix, or as supplemental material. 7. Experiment Statistical Significance Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? 37Answer: [Yes] Justification: Due to the limited computing resources, we only extensively evaluate the performance of our proposed method (PeTTA) across 5 independent runs, with different random seeds. Specifically, the mean values in 5 runs are reported in Tab. 1, Tab. 2, Tab. 7, and Tab. 8. The corresponding standard deviation values are provided in Appdx. F.1. Guidelines: â€¢ The answer NA means that the paper does not include experiments. â€¢ The authors should answer \"Yes\" if the results are accompanied by error bars, confi- dence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. â€¢ The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). â€¢ The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) â€¢ The assumptions made should be given (e.g., Normally distributed errors). â€¢ It should be clear whether the error bar is the standard deviation or the standard error of the mean. â€¢ It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. â€¢ For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). â€¢ If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. 8. Experiments Compute Resources Question: For each experiment, does the paper provide sufficient information on the com- puter resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We have provided the information on the computing resources used in our experiments in Appdx. G.1. Guidelines: â€¢ The answer NA means that the paper does not include experiments. â€¢ The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. â€¢ The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. â€¢ The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didnâ€™t make it into the paper). 9. Code Of Ethics Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors have reviewed and to the best of our judgment, this study has conformed to the NeurIPS Code of Ethics. Guidelines: â€¢ The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. â€¢ If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. 38â€¢ The authors should make sure to preserve anonymity (e.g., if there is a special consid- eration due to laws or regulations in their jurisdiction). 10. Broader Impacts Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: This study advances the research in test-time adaptation area in general, and not tied to particular applications. Hence, there are no significant potential societal consequences of our work which we feel must be specifically highlighted here. Guidelines: â€¢ The answer NA means that there is no societal impact of the work performed. â€¢ If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. â€¢ Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. â€¢ The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. â€¢ The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. â€¢ If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). 11. Safeguards Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: To the best of our judgment, this study poses no risks for misuse. Guidelines: â€¢ The answer NA means that the paper poses no such risks. â€¢ Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. â€¢ Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. â€¢ We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. 12. Licenses for existing assets Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? 39Answer: [Yes] Justification: The original papers that produced the code package or dataset have been properly cited throughout the paper. Further information on the licenses of used assets are provided in Appdx. G.4. Guidelines: â€¢ The answer NA means that the paper does not use existing assets. â€¢ The authors should cite the original paper that produced the code package or dataset. â€¢ The authors should state which version of the asset is used and, if possible, include a URL. â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset. â€¢ For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. â€¢ If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. â€¢ For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. â€¢ If this information is not available online, the authors are encouraged to reach out to the assetâ€™s creators. 13. New Assets Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This study does not release new assets. Guidelines: â€¢ The answer NA means that the paper does not release new assets. â€¢ Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. â€¢ The paper should discuss whether and how consent was obtained from people whose asset is used. â€¢ At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. 14. Crowdsourcing and Research with Human Subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This study does not involve crowdsourcing nor research with human subjects. Guidelines: â€¢ The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. â€¢ Including this information in the supplemental material is fine, but if the main contribu- tion of the paper involves human subjects, then as much detail as possible should be included in the main paper. â€¢ According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects 40Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This study does not involve crowdsourcing nor research with human subjects. Guidelines: â€¢ The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. â€¢ Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. â€¢ We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. â€¢ For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. 41",
      "meta_data": {
        "arxiv_id": "2311.18193v4",
        "authors": [
          "Trung-Hieu Hoang",
          "Duc Minh Vo",
          "Minh N. Do"
        ],
        "published_date": "2023-11-30T02:24:44Z",
        "pdf_url": "https://arxiv.org/pdf/2311.18193v4.pdf"
      }
    },
    {
      "title": "Test Time Adaptation via Conjugate Pseudo-labels",
      "abstract": "Test-time adaptation (TTA) refers to adapting neural networks to distribution\nshifts, with access to only the unlabeled test samples from the new domain at\ntest-time. Prior TTA methods optimize over unsupervised objectives such as the\nentropy of model predictions in TENT [Wang et al., 2021], but it is unclear\nwhat exactly makes a good TTA loss. In this paper, we start by presenting a\nsurprising phenomenon: if we attempt to meta-learn the best possible TTA loss\nover a wide class of functions, then we recover a function that is remarkably\nsimilar to (a temperature-scaled version of) the softmax-entropy employed by\nTENT. This only holds, however, if the classifier we are adapting is trained\nvia cross-entropy; if trained via squared loss, a different best TTA loss\nemerges. To explain this phenomenon, we analyze TTA through the lens of the\ntraining losses's convex conjugate. We show that under natural conditions, this\n(unsupervised) conjugate function can be viewed as a good local approximation\nto the original supervised loss and indeed, it recovers the best losses found\nby meta-learning. This leads to a generic recipe that can be used to find a\ngood TTA loss for any given supervised training loss function of a general\nclass. Empirically, our approach consistently dominates other baselines over a\nwide range of benchmarks. Our approach is particularly of interest when applied\nto classifiers trained with novel loss functions, e.g., the recently-proposed\nPolyLoss, where it differs substantially from (and outperforms) an\nentropy-based loss. Further, we show that our approach can also be interpreted\nas a kind of self-training using a very specific soft label, which we refer to\nas the conjugate pseudolabel. Overall, our method provides a broad framework\nfor better understanding and improving test-time adaptation. Code is available\nat https://github.com/locuslab/tta_conjugate.",
      "full_text": "Test-Time Adaptation via Conjugate Pseudo-labels Sachin Goyalâ‹†1 Mingjie Sunâ‹†1 Aditi Raghunathan1 Zico Kolter1,2 1Carnegie Mellon University, 2Bosch Center for AI {sachingo, mingjies, raditi, zkolter}@cs.cmu.edu Abstract Test-time adaptation (TTA) refers to adapting neural networks to distribution shifts, with access to only the unlabeled test samples from the new domain at test-time. Prior TTA methods optimize over unsupervised objectives such as the entropy of model predictions in TENT [50], but it is unclear what exactly makes a good TTA loss. In this paper, we start by presenting a surprising phenomenon: if we attempt to meta-learn the â€œbestâ€ possible TTA loss over a wide class of functions, then we recover a function that isremarkably similar to (a temperature-scaled version of) the softmax-entropy employed by TENT. This only holds, however, if the classiï¬er we are adapting is trained via cross-entropy loss; if the classiï¬er is trained via squared loss, a different â€œbestâ€ TTA loss emerges. To explain this phenomenon, we analyze test-time adaptation through the lens of the training lossesâ€™sconvex conjugate. We show that under natural conditions, this (unsupervised) conjugate function can be viewed as a good local approximation to the original supervised loss and indeed, it recovers the â€œbestâ€ losses found by meta-learning. This leads to a generic recipe that can be used to ï¬nd a good TTA loss for any given supervised training loss function of a general class. Empirically, our approach consistently dominates other TTA alternatives over a wide range of domain adaptation benchmarks. Our approach is particularly of interest when applied to classiï¬ers trained with novel loss functions, e.g., the recently-proposed PolyLoss [25] function, where it differs substantially from (and outperforms) an entropy-based loss. Further, we show that our conjugate based approach can also be interpreted as a kind of self-training using a very speciï¬c soft label, which we refer to as the conjugate pseudo-label. Overall, our method provides a broad framework for better understanding and improving test-time adaptation. Code is available at https://github.com/locuslab/ tta_conjugate. 1 Introduction Modern deep networks perform exceeding well on new test inputs that are close to the training distribution. However, this performance dramatically decreases on test inputs drawn from a different distribution. While there is a large body of work on improving the robustness of models, most robust training methods are highly specialized to the setting they cater to. For e.g., they assume pre-speciï¬ed perturbations, subpopulations, and spurious correlations, or access to unlabeled data from the target distribution, and most methods offer close to no improvement on general distribution shifts beyond what they were trained for [12, 21]. In practice, it is often cumbersome (or even impossible) to precisely characterize all possible distri- bution shifts a model could encounter and then train accordingly. Instead, a model already trained on some source data must be able to adapt at test-time to new inputs from a different domain. This setting of test-time adaptation (TTA) has gained interest in recent years [ 6, 47, 50, 54]. TTA is typically accomplished by updating the source model parameters via a few steps of optimization on an unsupervised objective involving the new test sample from the target distribution. The choice â‹† Equal Contribution 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv:2207.09640v2  [cs.LG]  23 Nov 2022of this unsupervised objective, which we call the TTA loss, dictates the success of the adaptation procedure. [47] uses a self-supervised objective on the test sample, [50] uses the entropy of model predictions, and several follow-ups have proposed variants or alternatives [ 40, 54]. However, it remains unclear as to how to choose or guide the selection of this TTA loss, and thus far the choice of these losses has remained largely heuristic in nature. In this work, we begin by presenting a set of intriguing experiments where we attempt to learn the â€œbestâ€ TTA loss for a given source classiï¬er and distribution shift. We parameterize the TTA loss by another neural network whose parameters are learnt via meta-learning [ 3, 9] where we differentiate through the adaptation process to ï¬nd the TTA loss that achieves the best adaptation on distribution shifts. Surprisingly, we ultimately learn a TTA loss that looksremarkably similar to (a temperature-scaled version of) the softmax-entropy loss, which was already proposed by [50]. Why did we recover the commonly used softmax-entropy loss despite the fact that the procedure is capable of learning a very general class of losses and the meta-learning process could potentially specialize to both the source classiï¬er and the distribution shift of interest? Furthermore, we ï¬nd that this pattern only holds when the loss used to train the source classiï¬er is cross-entropy loss; when a different loss such as squared loss is used instead, the meta-learning procedure recovers a TTA loss that itself looks more like a negative squared error, and is very different from the softmax-entropy loss (Section 3). In order to explain this phenomenon, we propose to consider TTA through the lens of the convex conjugate function. Speciï¬cally, given a hypothesis function h(x) and label y, several common losses (cross-entropy and the squared loss amongst them, but not limited to these) can be written in the form L(h(x),y) = f(h(x)) âˆ’yTh(x) for some function f. In these cases, we show that â€œnaturalâ€ TTA loss for such classiï¬ers is precisely the (negation of) the convex conjugate evaluated at the gradient of h, LTTA(x) = âˆ’fâˆ—(âˆ‡f(h(x)), where fâˆ—is the convex conjugate of f. This framework not only recovers the results of our meta-learning experiments, but also justiï¬es why some speciï¬c choices of TTA loss in the previous literature work well (e.g., this framework recovers TENTâ€™s choice of softmax-entropy for cross-entropy-trained classiï¬er). Moreover, it also provides a broad framework for what the TTA loss should be when the source model is trained using various different loss functions (for example the recently-proposed PolyLoss [25, 29]) as is becoming increasingly common in machine learning. Further, we show that our proposed conjugate adaptation loss is in fact a kind of self-training with pseudo-labels [42], a classic approach in machine learning. Various formulations of the pseudo-label have been proposed in the literature, and our conjugate analysis provides a general recipe for the â€œcorrectâ€ choice of soft pseudo-labels given byË†y(x) = âˆ‡f(h(x)). We thus refer to these as conjugate pseudo-labels (Conjugate PLâ€™s), and believe our work provides a broad framework for understanding adaptation with unlabeled data in general. Finally, we empirically verify the effectiveness of our proposed conjugate adaptation loss across several datasets and training losses, such as cross-entropy and squared loss, along with the recently- proposed PolyLoss [ 25] (which itself has shown higher standard test accuracy on a wide range of vision tasks). Over all models, datasets and training losses, we ï¬nd our proposed conjugate pseudo-labeling consistently outperforms prior TTA losses and improves TTA performance over the current state of the art. 2 Background and preliminaries. Test-time adaptation. We are interested in mapping an input xâˆˆRd to a label yâˆˆY. We learn a model hÎ¸ : Rd â†¦â†’R|Y|parameterized by Î¸that maps an input xto predictions hÎ¸(x). We assume access to a trained source model and adapt at test-time over the test input, before making the ï¬nal prediction. This is the standard test-time adaptation (TTA) setting [47, 50]. During TTA, we update the model parameters on an unsupervised objective L(x,hÎ¸). For example, in TENT [50], this loss is the entropy of the softmax-normalized predictions of the model. At each time step of adaptation, we observe a batch of test inputs and we take a gradient step towards optimizing the TTA loss on this test batch. As is standard, we measure the average online performance of models across all steps (number of test batch inputs seen) in the adaptation process. Meta learning the loss function. In order to explore the existence of different TTA losses, we employ the meta-learning procedure where we attempt to learn the TTA loss. We use a similar procedure as prior work on meta-learning loss functions [3, 37] and parameterize the loss function via a neural network mÏ† : R|Y| â†¦â†’R that takes in the model predictions/logits and outputs a loss value. We want to learn parameter Ï†such that when we update Î¸via the loss function mÏ†, our ï¬nal 2performance is optimal. In order to do so, let xbe the unlabeled test samples to adapt to, and ybe the corresponding labels. We update Î¸and Ï†alternatively as follows. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t , Ï†t+1 â†Ï†t âˆ’Î²âˆ‚L(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , (1) where Lis some supervised surrogate loss function such as cross-entropy. Please refer to Appendix A3 for further details regarding meta-learning setup. Note that the meta-learning process above assumes access to labels yof test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We discuss our ï¬ndings from this exploration in the next section. 3 Test-time Adaptation via Meta-Learnt Losses The objective used in TENT is the softmax-entropy of the model predictions which essentially makes the classiï¬er more conï¬dent in its current predictions. The same can be achieved by various other loss formulations such as those mentioned in [40]. With so many possible choices for the loss function, what should we use for TTA? In this section, we attempt to answer this empirically and present some intriguing observations. (a)  (b) Figure 1: Visualization of meta loss (blue) by varying one input prediction score. (a) For cross-entropy loss trained model, the learnt meta loss can be approximated with a scaled softmax-entropy function (dashed red). (b) When the source model is trained with a squared loss for classiï¬cation, the learnt meta loss (blue) can be ï¬tted closely with a quadratic function (dashed red), shown in Figure 1b. The range (max/min) of the prediction score (logit) in x-axis is chosen to cover the empirical range of the predicted logits. Experiment 1. We learn the TTA loss parameterized by a neural network via meta-learning as described in Section 2. Our source classiï¬er is a ResNet-26 trained on CIFAR-10 and we adapt to distribution shifts in CIFAR-10-C. We use the 4 labeled validation noises in CIFAR-10-C to learn the meta-loss network parameters and we denote the resulting learnt loss function by meta-TTA loss. We then adapt the source classiï¬er to the test set of 15 corruptions by optimizing the meta-TTA loss. Observations. First, we ï¬nd that TTA using meta-TTA loss performs better than TENT (12.35% vs 13.14%), suggesting that there are better TTA losses than previous losses based on softmax-entropy. However, on examining this meta-TTA loss, we ï¬nd a surprising observation. Figure 1a (blue curve) visualizes the learnt meta-loss over model predictions as we vary a single class prediction with the rest ï¬xed. Qualitatively, the learnt meta-loss looks very similar to softmax-entropy in one dimension. In fact, we can ï¬t it closely with a scaled softmax-entropy function (dashed red curve): Î±Â·H(softmax(hÎ¸(x)/T)), where Î±is a magnitude parameter and T is a temperature scaler. We want to test if the meta-loss is basically learning the softmax-entropy function. Hence, we perform test-time adaptation with the ï¬tted softmax-entropy function instead (dashed red curve) and achieve an error of 12.32%, essentially recovering the performance of meta-TTA. 3Despite the ability to represent many different loss functions and potentially specialize to the CIFAR- 10-C setting, the meta-loss procedure gave back the standard entropy objective.Do we always recover a loss that looks like softmax-entropy? Experiment 2. In an attempt to isolate when we get back the entropy objective, we vary several things. We tried different architectures for the source classiï¬er, different lossesLduring the meta- learning process (1) and different training losses for the source classiï¬er. Results. We observed that we consistently recovered the temperature scaled softmax-entropy function in all cases except when we varied the training loss for the source classiï¬er (Appendix A.10). On using the squared loss function [18], a strikingly different meta-TTA loss emerges. Figure 1b (blue curve) shows the learnt meta-loss (13.48% error) for this network. Here again, the meta-TTA loss outperforms entropy (14.57%) but it is not simply due to a scaling factor. The loss now looks like the negative squared error (red curve). Like previously, we tried ï¬tting a quadratic loss directly to the meta loss in Figure 1b, and this time we even slightly outperformed the meta-TTA loss. To summarize, we used a meta-learning procedure to search for the â€œbestâ€ TTA loss, where the loss itself was parameterized by a neural network that could potentially represent arbitrarily complex loss functions. However, we ended up with loss functions displaying remarkable structure: across different architectures and different variants of meta-learning, for a classiï¬er trained with cross-entropy, the meta-TTA loss was temperature scaled softmax-entropy and for a classiï¬er trained with squared loss, the meta-TTA loss was a negative squared loss. This is interesting from both a practical and conceptual standpoint where the â€œbestâ€ TTA loss depends on the loss used to train the source classiï¬er in a clean fashion. We attempt to understand and explain this phenomenon in the next section. 4 Conjugate Pseudo Labels Results in the previous section raise an obvious question: why does softmax-entropy as used in TENT seem to be the â€œbestâ€ possible test time adaptation loss for classiï¬ers trained via cross-entropy (at least, best in the sense that meta-learning consistently recovers something which essentially mimics softmax-entropy, even though meta-loss is parameterized by a neural network and hence could learn much more complex functions speciï¬c to the model and the particular shift)? And why, alternatively, does a quadratic TTA loss seem to perform best when the classiï¬er is trained via squared loss? In this section, we offer an explanation of this phenomenon via the construct of the convex conjugate function [1]. As we will see, our method recovers softmax-entropy and quadratic loss as the â€œnaturalâ€ objectives for classiï¬ers trained via cross-entropy and squared loss respectively. Furthermore, for classiï¬ers trained via other loss functions, as is becoming increasingly common in deep learning, our approach naturally suggests corresponding test-time adaptation losses, which we show in the next section to comparatively outperform alternatives. Thus, we argue that our framework overall provides a compelling recipe for specifying the â€œcorrectâ€ method for TTA for a large class of possible losses. 4.1 Losses and the convex conjugate We begin by formally considering loss functions between a hypothesis outputhÎ¸(x) (e.g., the logit outputs of a classiï¬er, or the direct prediction of a regressor) and targetythat take the following form L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yThÎ¸(x) (2) for some function f; when there is no risk of confusion, we will use hin place of hÎ¸(x) for simplicity of notation. While not every loss can be expressed in such a form, this captures a wide variety of common losses (possibly scaled by a constant value). For example, cross-entropy loss corresponds to the choice f(h) = log âˆ‘ iexp(hi) and where y denotes a one-hot encoding of the class label; similarly, squared loss corresponds to the choice f(h) = 1 2 âˆ¥hâˆ¥2 2. When training an over-parameterized classiï¬er, we can roughly view the training process as (approxi- mately) attaining the minimum over hypotheses hfor each training example min Î¸ 1 t tâˆ‘ i=1 L(hÎ¸(xi),yi) â‰ˆ1 t tâˆ‘ i=1 min h L(h,yi) (3) 4where t is the number of training samples. However, in the case of losses in the form (2), the minimization over hin this form represents a very speciï¬c and well-known optimization problem: it is known as the convex conjugate [1] of the function f min h L(h,y) = min h {f(h) âˆ’yTh}= âˆ’fâ‹†(y) (4) where fâ‹† denotes the convex conjugate of f. fâ‹† is a convex function in y(and indeed, is convex regardless of whether or not f is convex). Furthermore, for the case that f is convex differentiable, the optimality condition of this minimization problem is given by âˆ‡f(hopt) = y, so we also have that fâ‹†(y) = fâ‹†(âˆ‡f(hopt)) (5) where hopt refers to the optimal classiï¬er (used interchangeably with hÎ¸opt ). Putting this all together, we can state (admittedly, in a rather informal manner) that under the assumption that Î¸opt is chosen so as to approximately minimize the empirical loss on the source data in the over-parameterized setting, we have that for tinputs 1 t tâˆ‘ i=1 L(hÎ¸opt (xi),yi) â‰ˆ1 t tâˆ‘ i=1 âˆ’fâ‹†(âˆ‡f(hÎ¸opt (xi))) (6) i.e., the empirical loss can be approximated by the (negative) conjugate applied to the gradient of the f, at least in a region close to the optimal Î¸opt that minimizes the empirical loss. But the later expression has the notable beneï¬t that it does not require any label yi in order to compute the loss, and thus can be used as a basis for TTA on target domain of the hypothesis function hÎ¸opt . Deï¬nition 1 (conjugate adaptation loss) Consider a loss function that takes the form given in 2, used for training a hypothesis hÎ¸ in the over-parameterized regime. We deï¬ne the conjugate adaptation loss Lconj(hÎ¸(x)) : R|Y|â†¦â†’R as follows. Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))âŠ¤hÎ¸(x). (7) 4.2 Recovery of existing test-time adaptation strategies Cross-entropy The interesting aspect to this formalism is that when applied to classiï¬ers trained with cross-entropy, it recovers exactly the TENT approach to TTA : minimizing the softmax-entropy of hÎ¸(x). And indeed, this loss was also recovered when using meta-learning to learn the â€œoptimalâ€ test-time adaptation loss. To see this, note that for cross-entropy, we have thatf(h) = log âˆ‘ iexp(hi), giving the optimality condition y= âˆ‡f(hopt) = exp(hopt)âˆ‘ iexp(hopt i ) and the conjugate function fâ‹†(y) = { âˆ‘ iyilog yi if âˆ‘ iyi = 1 âˆž otherwise . (8) In other words, Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (9) i.e. softmax-entropy of the model prediction, which is exactly the TTA loss that TENT uses. Squared loss For the squared loss, we have thatf(h) = 1 2 âˆ¥hâˆ¥2 2, leading to the optimality condition y = hand conjugate function fâ‹†(y) = 1 2 âˆ¥yâˆ¥2 2. Hence, the adaptation loss in this case would be simply given by Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’1 2 âˆ¥hâˆ¥2 2 which is also what we observed in the meta-learning experiments discussed in Section 3. 4.3 Conjugate pseudo-labels We now emphasize that by the nature of our approximations, there is an additional simple interpre- tation of the conjugate loss: it is also equal to the original loss (2) applied to the â€œpsuedo-labelsâ€ ËœyCPL Î¸ (x) = âˆ‡f(hÎ¸(x)), where CPL refers to conjugate pseudo-labels, i.e., Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))ThÎ¸(x) = L(hÎ¸(x),âˆ‡f(hÎ¸(x))). (10) 5This property is known as the Fenchel-Young inequality, that isf(x) + fâ‹†(u) â‰¥xTuholding with equality when u = âˆ‡f(x). In other words, our conjugate adaptation loss is precisely equivalent to self-training under the speciï¬c soft pseudo-labels given by ËœyCPL = âˆ‡f(hÎ¸(x)). And indeed, for many cases, this may be a more convenient form to compute than explicitly computing the conjugate function at all. For this reason, we refer to our method as that of conjugate pseudo-labels. In the case of cross-entropy loss, this approach then corresponds exactly to self-training using labels given by the softmax applied to the current hypothesis. We must emphasize, however, that while our conjugate formulation indeed has this â€œsimpleâ€ form for the case of cross-entropy loss, the real advantage comes in that it provides the â€œcorrectâ€pseudo-label for use with other losses, which may result in pseudo-labels different from the â€œcommonâ€ softmax operation. Example: conjugate pseudo-labels for PolyLoss. PolyLoss [25] is a recently-proposed simple alternative to cross-entropy loss than has been shown to improve performance across a wide variety of compute tasks. This loss is given by the form Lpoly(hÎ¸(x),y) = Lce(hÎ¸(x),y) + ÏµÂ·yT(1 âˆ’softmax(hÎ¸(x))) (11) We note that this can be put exactly into our conjugate form (equation 2) by writing the loss in a slightly more involved fashion, which we refer to as the expanded conjugate form Lpoly(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yTg(hÎ¸(x)). (12) where f is the log-sum-exp function as before, and g(h) = hâˆ’Ïµ(1 âˆ’softmax(h)). In order to formally put this into the form of the previous loss function (equation 2), we can simply deï¬ne an alternative hypothesis as the function hâ€² Î¸(x) = g(hÎ¸(x)), and then deï¬ne PolyLoss in the conjugate form as Lpoly(hâ€² Î¸(x),y) = f(gâˆ’1(hâ€² Î¸(x))) âˆ’yThâ€² Î¸(x). (13) Typically, however, it is easier to simply operate on the expanded conjugate form, which yields the optimality condition for the pseudo-label âˆ‡f(hopt) = Dg(hopt)ËœyCPL Î¸ (x), where D is the Jacobian operator. For the case of PolyLoss, this leads to the conjugate pseudo-label of the following form: ËœyCPL Î¸ (x) = (I+ Ïµdiag(z) âˆ’ÏµzzT)âˆ’1z, z â‰¡softmax(hÎ¸(x)). Test-time adaptation. Finally, we note that the above discussion doesnâ€™t actually address any topics related to test-time adaptation to OOD data, but merely provides a generic characterization of a self- training procedure for generic loss functions of the form(2). However, the application toTTA on OOD data is fairly straightforward: as long as the learnt source parameters Î¸is a reasonable approximation to the true optimal Î¸opt on the shifted domain, self-training with the conjugate pseudo-labels provides a reasonable proxy for ï¬ne-tuning the network on the true OOD loss. We emphasize that, common to most approaches for TTA , there are still some amount of design decisions that must be put in place; these are detailed in Section 5.1. In practice, we observe OOD generalization typically beneï¬ts (across all baselines) from an additional â€œtemperatureâ€ scaling, i.e., applying the TTA loss to hÎ¸(x)/T for some ï¬xed temperature T, although it requires a held-out validation dataset for tuningT. However, we should emphasize that truly unsupervisedTTA would require making an informed guess for the value of these hyper-parameters. The full procedure for test time adaptation via conjugate pseudo-labels is shown in Algorithm 1. Algorithm 1 Conjugate pseudo-labeling (Conjugate PL) Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’hÎ¸(x)âŠ¤y. N batches of test data Dtest = [x1,x2,...,x N] Hyperparams: learning rate Î·and temperature T. Let Â¯hÎ¸(x) def = hÎ¸(x)/T be the temperature scaled predictor. Let ËœyCPL Î¸ (x) denote the conjugate pseudo-label function ËœyCPL Î¸ (x) = âˆ‡(f(Â¯hÎ¸(x))). for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡L ( Â¯hÎ¸(xn),ËœyCPL Î¸ (xn) ) [Self-training with conjugate pseudo-labels] 65 Experiments In this section, we empirically evaluate the effectiveness and generality of the proposed conjugate pseudo-labeling procedure (Algorithm 1) for test-time adaptation on a variety of datasets. 5.1 Setup Datasets. We evaluate on the three common corruption benchmarks: adapting a classiï¬er trained on CIFAR-10 to CIFAR-10-C, CIFAR-100 to CIFAR-100-C and ImageNet to ImageNet-C [ 15]. Following the previous works [47, 50], we report the error averaged across corruptions at the highest severity for CIFAR-10/100-C and averaged across corruptions and severity level for ImageNet-C. We also evaluate on three domain adaptation datasets: adapting a classiï¬er trained on SVHN to MNIST, an ImageNet classiï¬er to ImageNet-R [16] and adapting from synthetic to real data in VISDA-C [38]. Models and Training losses. Following previous works on TTA[47, 50], we use ResNet-26 [14] as the source classiï¬er architecture for CIFAR-10/100 experiments, ResNet-18 for SVHN to MNIST and a ResNet-50 for ImageNet and source synthetic data on VisDA-C. We consider source classiï¬ers trained via the following loss functions: the de-facto cross-entropy, recently proposed polyloss [25] and squared loss [18]. Baselines. Our proposed conjugate pseudo-label is the classic approach of self-training with a speciï¬c form of pseudo-labels. In self-training, we replace the label ywith a pseudo-label Ëœy(x) and adapt by optimizing the loss function L(hÎ¸(x),Ëœy(x)). Note that we could either instantaneously update the pseudo-labels using the current classiï¬er, or generate pseudo-labels once with just the source classiï¬er. Instantaneous updates have been shown to work better for domain adaptation [7, 40], and we perform instantaneous updates for all methods. While we propose using ËœyCPL(x) = âˆ‡f(hÎ¸(x)) (See Section 4.3), we compare to the standard pseudo-labels used in the literature: â€¢ (i) the â€œhardâ€ pseudo-label (hard PL) where Ëœy(x) = arg maxi ( hÎ¸(x) ) i is the most likely class as predicted by hÎ¸. As is common in the self-training literature, we perform conï¬dence thresholding. â€¢ (ii) The â€œsoftâ€ pseudo-label (soft PL) where Ëœy(x) is obtained by applying a softmax function to the model predictions hÎ¸(x). We also compare with the following recently proposed test-time adaptation methods. â€¢ Entropy Minimization (ENT) [50] minimizes the entropy of model predictions. â€¢ Robust Pseudo-Label [40] where we minimize a robust classiï¬cation loss, Lrpl = qâˆ’1(1 âˆ’p(i|x)q) where i= argmaxjp(j|x) and qâˆˆ[0,1]. â€¢ MEMO [54] minimizes entropy of a modelâ€™s outputs across different augmentations of a test input. We implement a batch version, where we see multiple test points at once, for fair comparisons. TTA methodology. Following [ 50] and [40], we ï¬ne-tune by updating the learnable scale and shift parameters of the batch normalization layers across all adaptation losses. For each batch, batch normalization statistics is also updated, as suggested in [41]. We report performance at the end of one round of test-time adaptation over the entire test set. We tune the learning rate (LR) and temperature (T) on the validation noises in the corruption benchmark by grid-search. LR is selected from {1eâˆ’1,1eâˆ’2,... 1eâˆ’4}and T from {1,2 ... 5}. All the experiments have been performed on A6000 GPUâ€™s. On domain adaptation benchmarks, where there is no held-out target domain, we set T to be 1 and use the LR suggested by [ 6, 50]. We use the same hyperparameter tuning protocol across all methods. We single out temperature as a very important hyperparameter, as we discuss in the results below. 5.2 Results on classiï¬ers trained with cross-entropy We study the effectiveness of our proposed conjugate pseudo-labels when the source classiï¬er is trained via cross-entropy loss. In this case, baselines Softmax PL and ENT are the same as Conjugate PL. Thus we omit them in our results. Table 1, reports the performance of various TTA methods. When the source classiï¬er is trained via cross-entropy, our conjugate pseudo-label algorithm exactly corresponds to entropy minimization with an additional temperature scaling. Entropy minimization as 7Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 13.95 (Â±0.06) 13.97 ( Â±0.04) 12.60(Â±0.04) 13.07 (Â±0.05) \u0013 13.95 (Â±0.06) 12.85 ( Â±0.04) 12.51(Â±0.01) 12.51(Â±0.03) CIFAR-100-C \u0017 45.22 (Â±0.4) 39.80 ( Â±0.18) 38.52(Â±0.16) 41.15 (Â±0.25) \u0013 45.22 (Â±0.4) 36.37 ( Â±0.10) 37.38 ( Â±0.06) 36.10(Â±0.07) ImageNet-C \u0017 45.43(Â±0.05) 45.68 ( Â±0.01) 48.91( Â±0.03) 45.82(Â±0.01) \u0013 45.43 (Â±0.05) 45.61 ( Â±0.01) 48.91( Â±0.04) 45.36(Â±0.01) Table 1: Mean errors when adapting to corruptions using a source classiï¬er trained via cross- entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. With the right temperature scaling, softmax-entropy minimization matches or outperforms other approaches. Prior reported gains of other methods over softmax-entropy minimization disappear when we use temperature scaling. For additional context, the source classiï¬er errors without adaptation are: CIFAR-10-C (29.54%), CIFAR-100-C (62.26%), ImageNet-C (61.89%) proposed in prior work [50] does not tune the temperature parameter, and some newer objectives such as robust PL or MEMO outperform vanilla entropy minimization. For example, on CIFAR-100-C, vanilla ENT obtaines 41.15% average error, while robust PL improves this to39.80% and MEMO to 38.52%. However, with the right temperature scaling, entropy minimization obtains 36.10% error which outperforms the newer objectives (with and without temperature scaling). A similar observation holds for CIFAR-10-C and ImageNet-C as well. Essentially, the gains over vanilla entropy minimization vanish when we do temperature scaling, and entropy minimization (i.e. conjugate pseudo-labeling corresponding to cross-entropy) turns out to be the best objective after all. 5.3 Results on classiï¬ers trained with polyloss and squared loss In the case of cross-entropy, conjugate pseudo-labeling reduces to the familiar notion of entropy minimization. We now explore the performance of our method on different loss functions where the conjugate pseudo-labels differ substantially from entropy minimization (section 4.3). Table 2 presents the results on the corruption benchmarks and Table 3 presents the results on the other domain adaptation datasets for source classiï¬ers trained with PolyLoss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C \u0017 13.81(Â±0.12) 14.23(Â±0.02) 13.46(Â±0.06) 13.23(Â±0.07) 14.64(Â±0.11) 13.02(Â±0.09) \u0013 13.81(Â±0.12) 12.45(Â±0.05) 12.23(Â±0.06) 12.33(Â±0.04) 12.26(Â±0.04) 12.08(Â±0.05) CIFAR-100-C\u0017 40.47(Â±0.05) 42.86(Â±0.11) 40.12(Â±0.08) 39.90(Â±0.05) 41.00(Â±0.11) 38.17(Â±0.17) \u0013 40.47(Â±0.05) 39.80(Â±0.08) 38.23(Â±0.05) 39.23(Â±0.04) 37.04(Â±0.06) 36.83(Â±0.08) ImageNet-C \u0017 45.44(Â±0.21) 46.27(Â±0.03) 46.10(Â±0.03) 48.21(Â±0.05) 44.63(Â±0.03) 44.01(Â±0.01) \u0013 45.44(Â±0.21) 46.27(Â±0.03) 45.50(Â±0.02) 48.21(Â±0.04) 44.45(Â±0.03) 44.01(Â±0.01) Table 2: Mean errors when adapting to corruptions using a source classiï¬er trained via recently proposed Poly-1 Loss [ 25]. Conjugate pseudo-labeling consistently outperforms all previous ap- proaches. For additional context, source classiï¬er errors without adaptation : CIFAR-10-C (30.22%), CIFAR-100-C (63.91%) and ImageNet-C (62.18%). First, we note that, across all datasets in Table 2 and Table 3, our conjugate PL approach outperforms all other TTA losses. With polyloss classiï¬ers, entropy minimization is no longer the best methodâ€”on CIFAR-100-C, entropy minimization achieves38.23% error while our conjugate PL achieves36.83%. We see similar consistent gains on CIFAR-10-C, ImageNet-C, ImageNet-R and VisDA-C. On digit adaptation tasks from SVHN to MNIST/USPS/MNISTM, where there is a larger shift between source and target, the gains are especially pronounced. Figure 2 compares how the task loss (polyloss Ïµ= 6) on the test data decreases as we adapt the model through conjugate PL and other baselines. We use CIFAR-10-C as an example. Observe that our proposed conjugate PL indeed reduces the task loss the most among other baselines. 8Dataset Source Error Hard PL Robust PL EntropySoftmax PL Conjugate PL Ours SVHNâ†’MNIST 28.33 20.21 19.73 14.28 16.54 10.73 SVHNâ†’USPS 31.58 23.32 26.12 23.12 24.07 21.62 SVHNâ†’MNISTM61.69 50.73 51.35 49.33 50.47 47.59 ImageNet-R 64.19 58.52 59.46 58.25 56.62 55.63 VisDA-C 58.13 40.43 45.44 44.11 39.63 38.42 Table 3: Target error when adapting models trained via polyloss on source domains across different domain adaptation bench- marks. Conjugate pseudo-labeling offers consistent and substan- tial gains over previous approaches across three datasets. Figure 2: Task Loss (PolyLoss Ïµ= 6) evaluated on CIFAR-10-C test data during test-time adaptation. Furthermore, on CIFAR-10-C and ImageNet-C, we ï¬nd that adapting polyloss classiï¬ers via conjugate PL improves the performance over all methods applied to cross-entropy trained source classiï¬ers. For e.g., on ImageNet-C, the performance improves from 45.34% to 44.01%. However, this is only true when using the proposed conjugate PL. If we just did softmax-entropy minimization (even with temperature scaling), the ï¬nal adapted performance of a polyloss classiï¬er (45.5%) is in fact worse than that of a cross-entropy classiï¬er (45.34%). Our results suggest that as we develop new training losses that improve the source classiï¬ers, it is important to adapt via conjugate pseudo-labeling to reap the maximum gains. Similarly, we experiment with the case when the source classiï¬er is trained using squared loss on the CIFAR-10 and CIFAR-100 datasets, and observe consistent gains using the proposed conjugate pseudo-labels over the baselines. For example, on CIFAR-10-C, TTA using conjugate PL gives and error of 12.87%, outperforming baselines like ENT (13.24%) and Softmax PL (31.81%). Table 5 in Appendix A.7 shows the detailed results. Comparing Table 1 and Table 2, we see that the relative ordering between the various baselines differs. This is further evidence that the adaptation loss has to depend on the training loss, and we believe our conjugate pseudo-label approach captures this appropriately by offering consistent gains across the various settings we experimented with. 6 Related Works Test-time adaptation methods. In recent years, the setting of test-time adaptation has gained a lot of interest with a host of different approaches proposed in the literature. One family of TTA approaches update the source classiï¬er by minimizing an unsupervised loss on the target distribution [4, 6, 20, 22, 35, 36, 40, 43, 44, 50, 51, 54]. TENT [ 50] proposes to minimize the entropy of model predictions at test time. Several follow ups like [ 6, 35, 40, 44, 54] propose alternative TTA objectives, e.g. robust pseudo-labelling [40], likelihood ratio loss [35], entropy of marginal probability averaged across augmentations [54] and self-supervised contrastive losses [6, 49]. However, most of these objectives are heuristically designed or chosen. In this paper, we provide a principled approach of designing unsupervised objectives for TTA . Another family of approaches for test-time adaptation such as [ 2, 8, 13, 31, 34, 47] leverage an auxiliary self-supervised task (e.g. rotation prediction [ 47], masked autoencoders [10]) to update model parameters on each test sample. Crucially, these methods require modifying the source model training by augmenting the supervised training objective with an auxiliary self-supervised loss. Hence it cannot be applied to typical standard classiï¬ers that are trained by minimizing a supervised loss on the source data. Source-free domain adaptation. A very related setting to test-time adaptation is source-free domain adaptation, where a trained source classiï¬er must be adapted to a target distribution of interest, although the entire target unlabeled data is available at once. SHOT [28] proposes to optimize the source hypothesis (i.e. feature extractor) with a combination of entropy minimization, diversity and self-training on pseudo-labels on the unlabeled target data. [53] promotes feature clustering on features from target distributions. [24, 26] use generative modeling to estimate the underlying source distributions for enforcing feature invariance. Such approaches typically require multiple epochs over the target data and cannot be easily adopted to work in an online fashion. 9Unsupervised domain adaptation. The most canonical setting of domain adaptation involves access to labeled source data and unlabeled target data, all during training. The availability of source and target data during training lends itself to approaches that â€œalignâ€ the source and target representations in some way: [ 32, 33, 45, 48] match distribution statistics, [ 11] uses a discriminator, [ 46] uses self-supervised learning. However, such approaches require access to source data which might not always be feasible due to data privacy and efï¬ciency issues. Pseudo-labels and self-training. Self-training is a classic idea for leveraging unlabeled data, devel- oped ï¬rst for the semi-supervised setting. Self-training generates pseudo-labels on the unlabeled data, allowing us to use any â€œsupervisedâ€ loss on this pseudo-labeled data. Self-training has shown promising results in various settings like semi-supervised learning [ 19] and improving adversarial robustness [ 5]. Self-training has also been gaining attention in the setting of unsupervised domain adaptation [28, 39], where pseudo-labels generated on the unlabeled data from target domain is used to supervise the adaptation process. [ 7, 23, 52] provide theoretical insights into how self-training with pseudo-labels can help under distribution shift. TENT [50] (i.e entropy minimization) can be viewed as a form of self-training with instantaneous softmax pseudo-labels. Our work provides a general framework for the choice of soft pseudo-labels based on the conjugate analysis of the source training objective. Some prior works like [7, 17, 27, 30, 55, 56] have documented the improvement in performance when using instantaneous pseudo-labels over pre-computed pseudo-labels, and thus lend further support to the beneï¬ts of our proposed conjugate pseudo-labeling approach. The ex- periment results presented in this work supporting conjugate pseudo-labels suggest that conjugate pseudo-labels is a promising direction of pseudo-labeling in a broader context. 7 Conclusion, Limitations and Future Directions In this work, we proposed a general test-time adaptation loss, based on the convex conjugate formulation which in turn was motivated by the intriguing meta learning experiments. The fact that meta-learning recovers the proposed loss hints at some kind of optimality of the loss. In Section 4, we prove that for a broad set of loss functions, the proposed (unsupervised) conjugate loss is close to the oracle supervised loss. However, this still does not completely answer what the optimal test-time adaptation loss is and why. The meta-learning framework in this work was constrained to learn functions over the logits of each individual input. It can be expanded to more involved setups, where we consider functions over the intermediate representations too and also consider learning functions over a batch of input while accounting for their interactions. Beyond the choice of the adaptation loss itself, achieving good test-time adaptation generally involves several heuristics like updating only the batch norm parameters [50]. While our work was motivated by the loss function, via the meta-learning experiments, we discovered that temperature scaling is another important hyper-parameter that improves the performance of all previous baselines as well. At a high level, test-time adaptation has to be appropriately regularized to prevent the updates over batches from taking the model too far: updating only a few batch norm parameters is one way to do that, and perhaps temperature scaling provides a similar beneï¬cial regularization effect by making the network predictions on unlabeled inputs less conï¬dent. Understanding the role of these heuristics more concretely is an interesting direction for future work. It also remains an open problem to understand under what sort of real-world distribution shifts would self-training based approaches would help. Finally, it is also worth extending and applying the conjugate pseudo-labeling to other settings like semi-supervised learning. 8 Acknowledgments We thank Shubhang Bhatnagar and Asher Trockman for helping with running the ImageNet experi- ments. We thank Zhili Feng for useful feedback. Sachin Goyal and Mingjie Sun were supported by funding from the Bosch Center for Artiï¬cial Intelligence. Aditi Raghunathan was supported by an Open Philanthropy AI Fellowship. 10References [1] https://en.wikipedia.org/wiki/Convex_conjugate. [2] Pratyay Banerjee, Tejas Gokhale, and Chitta Baral. Self-supervised test-time learning for reading comprehension. In Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2021. [3] Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette, Ludovic Righetti, Gaurav Sukhatme, and Franziska Meier. Meta-learning via learned loss. arXiv preprint arXiv:1906.05374, 2019. [4] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [5] Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Un- labeled data improves adversarial robustness. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÃ©-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips. cc/paper/2019/file/32e0bd1497aa43e02a42f47d9d6515ad-Paper.pdf. [6] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [7] Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. In Advances in Neural Information Processing Systems, 2020. [8] Mohammad Zalbagi Darestani, Jiayu Liu, and Reinhard Heckel. Test-time training can close the natural distribution shift performance gap in deep learning based compressed sensing. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [9] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adap- tation of deep networks. In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017. [10] Yossi Gandelsaman, Yu Sun, Xinlei Chen, and Alexei A. Efros. Test-time training with masked autoencoders. In Advances in Neural Information Processing Systems, 2022. [11] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1â€“35, 2016. [12] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. InInternational Conference on Learning Representations, 2021. [13] Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Alenya, Pieter Abbeel, Alexei A. Efros, Lerrel Pinto, and Xiaolong Wang. Self-supervised policy adaptation during deployment. In International Conference on Learning Representations, 2021. [14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [15] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019. [16] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In In IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [17] Yosuke Higuchi, Niko Moritz, Jonathan Le Roux, and Takaaki Hori. Advancing momentum pseudo-labeling with conformer and initialization strategy. In IEEE International Conference on Acoustics, Speech and Signal Processing, 2022. 11[18] Like Hui and Mikhail Belkin. Evaluation of neural architectures trained with square loss vs cross-entropy in classiï¬cation tasks. In International Conference on Learning Representations, 2021. [19] Dong hyun Lee. Pseudo-label: The simple and efï¬cient semi-supervised learning method for deep neural networks. [20] Yusuke Iwasawa and Yutaka Matsuo. Test-time classiï¬er adjustment module for model-agnostic domain generalization. In Advances in Neural Information Processing Systems, 2021. [21] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton A. Earnshaw, Imran S. Haque, Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. Wilds: A benchmark of in-the-wild distribution shifts. In Proceedings of the 38th International Conference on Machine Learning (ICML), 2021. [22] Takeshi Kojima, Yutaka Matsuo, and Yusuke Iwasawa. Robustifying vision transformer without retraining from scratch by test-time class-conditional feature alignment. In International Joint Conference on Artiï¬cial Intelligence, 2022. [23] Ananya Kumar, Tengyu Ma, and Percy Liang. Understanding self-training for gradual domain adaptation. In Proceedings of the 37 th International Conference on Machine Learning (ICML), 2020. [24] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In IEEE Winter Conference on Applications of Computer Vision (WACV), 2021. [25] Zhaoqi Leng, Mingxing Tan, Chenxi Liu, Ekin Dogus Cubuk, Jay Shi, Shuyang Cheng, and Dragomir Anguelov. Polyloss: A polynomial expansion perspective of classiï¬cation loss functions. In International Conference on Learning Representations, 2022. [26] Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsuper- vised domain adaptation without source data. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [27] Xinzhe Li, Qianru Sun, Yaoyao Liu, Qin Zhou, Shibao Zheng, Tat-Seng Chua, and Bernt Schiele. Learning to self-train for semi-supervised few-shot classiï¬cation. In Advances in Neural Information Processing Systems, 2019. [28] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. InProceedings of the 37th International Conference on Machine Learning (ICML), 2020. [29] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r. Focal loss for dense object detection. In IEEE/CVF International Conference on Computer Vision (ICCV), 2017. [30] Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training for domain adaptation. In Advances in Neural Information Processing Systems, 2021. [31] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In Advances in Neural Information Processing Systems, 2021. [32] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S. Yu. Transfer feature learning with joint distribution adaptation. In IEEE/CVF International Conference on Computer Vision (ICCV), 2013. [33] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. Learning transferable features with deep adaptation networks. In Proceedings of the 32nd International Conference on Machine Learning, 2015. [34] Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf. Consistent video depth estimation. In SIGGRAPH, 2020. 12[35] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and Jan Hendrik Metzen. Test-Time Adaptation to Distribution Shift by Conï¬dence Maximization and Input Transformation. arXiv preprint arXiv: 2106.14999, 2021. [36] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efï¬cient test-time model adaptation without forgetting. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [37] Junhyuk Oh, Matteo Hessel, Wojciech M. Czarnecki, Zhongwen Xu, Hado P van Hasselt, Satinder Singh, and David Silver. Discovering reinforcement learning algorithms. In Advances in Neural Information Processing Systems, 2020. [38] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. Visda: The visual domain adaptation challenge, 2017. [39] Viraj Prabhu, Shivam Khare, Deeksha Kartik, and Judy Hoffman. Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [40] Evgenia Rusak, Steffen Schneider, George Pachitariu, Luisa Eck, Peter Vincent Gehler, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. If your data distribution shifts, use self- learning, 2022. URL https://openreview.net/forum?id=1oEvY1a67c1. [41] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In Advances in Neural Information Processing Systems, 2020. [42] H. Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transac- tions on Information Theory, 1965. [43] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test-time prompt tuning for zero-shot generalization in vision-language models. In Advances in Neural Information Processing Systems, 2022. [44] Prabhu Teja Sivaprasad and FranÃ§ois Fleuret. Test time adaptation through perturbation robust- ness. arXiv preprint arXiv: 2110.10232, 2021. [45] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment for unsupervised domain adaptation. arXiv preprint arXiv: 1612.01939, 2016. [46] Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A. Efros. Unsupervised domain adaptation through self-supervision. arXiv preprint arXiv:1909.11825, 2019. [47] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Proceedings of the 36th International Conference on Machine Learning (ICML), 2019. [48] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014. [49] Dequan Wang, Shaoteng Liu, Sayna Ebrahimi, Evan Shelhamer, and Trevor Darrell. On-target adaptation. arXiv preprint arXiv: 2109.01087, 2021. [50] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. [51] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [52] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. In-n-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness. In International Conference on Learning Representations, 2021. 13[53] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [54] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In Advances in Neural Information Processing Systems, 2022. [55] Yang Zou, Zhiding Yu, B. V . K. Vijaya Kumar, and Jinsong Wang. Domain adaptation for semantic segmentation via class-balanced self-training. European Conference on Computer Vision, 2018. [56] Yang Zou, Zhiding Yu, Xiaofeng Liu, B. V . K. Vijaya Kumar, and Jinsong Wang. Conï¬dence regularized self-training. In IEEE/CVF International Conference on Computer Vision (ICCV), 2019. 14A Appendix A.1 Conjugate Derivations Cross-Entropy Loss : L(h,y) = âˆ’ câˆ‘ i=1 yilog exp(hi)âˆ‘c j=1 exp(hj) = âˆ’ câˆ‘ i=1 yi âˆ—hi + log câˆ‘ j=1 exp(hj) = f(h) âˆ’yâŠ¤h, (14) where f(h) is log âˆ‘c j=1 exp(hj) and the constraint that âˆ‘c i=1 yi = 1. Now, the conjugate fâ‹†(y) is given by : fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {log câˆ‘ j=1 exp(hj) âˆ’yTh} (15) with the constraint âˆ‘c i=1 yi = 1. At the optimality, yi = (âˆ‡f(h))i = exp(hi)âˆ‘ jexp(hj) (16) Then, fâ‹†(y) = âˆ’log câˆ‘ j=1 exp(hj) + câˆ‘ i=1 hi exp(hi)âˆ‘ jexp(hj) = âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj), (17) if the constraint âˆ‘c i=1 yi = 1 is satisï¬ed, otherwise fâ‹†(y) = âˆžby duality. This in turn gives, the conjugate loss for cross-entropy (when the constraint is satisï¬ed) : Lconj(h) = âˆ’fâ‹†(y) = âˆ’fâ‹†(âˆ‡f(h)) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (18) Squared Loss : L(h,y) = 1 2||hâˆ’y||2 2 â‰ˆ1 2||h||2 2 âˆ’yâŠ¤h [ignoring the constant term] = f(h) âˆ’yâŠ¤h, (19) Now, the conjugate fâ‹†(y) is given by: fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {1 2||h||2 2 âˆ’yTh} = âˆ’1 2||h||2 2 (20) A.2 Experiments on Binary Classiï¬cation with Exponential Loss Here we present the results on a binary classiï¬cation task over a synthetic dataset of 100 dimensional gaussian clusters. 15Dataset Creation For the binary classiï¬cation task, we create a synthetic dataset similar to [23]. Speciï¬cally, let the data X âˆ¼ N(Âµ,Î£) âˆˆ R100 and labels Y âˆˆ {âˆ’1,+1}. We sample Âµ âˆ¼ N(k,I100). For Î£, similar to [ 23], we sample a diagonal matrix D, where each entry is sampled uniformly from a speciï¬ed range, and a rotation matrix U from a HAAR distribution, giving Î£ = UDUT. For the source data, we sample Âµâˆ’1 s ,Âµ+1 s ,Î£âˆ’1 s ,Î£+1 s as speciï¬ed above with k= 0. Now to create a distribution shifted data of various severity, we sampleÂµâˆ’1 t ,Âµ+1 t ,Î£âˆ’1 t ,Î£+1 t as speciï¬ed above with k= 1, which are then used to sample the shifted data as follows : Âµ1 Î» = Î»Âµ1 t + (1 âˆ’Î»)Âµ1 s Âµâˆ’1 Î» = Î»Âµâˆ’1 t + (1 âˆ’Î»)Âµâˆ’1 s Î£1 Î» = Î»Î£1 t + (1 âˆ’Î»)Î£1 s Î£âˆ’1 Î» = Î»Î£âˆ’1 t + (1 âˆ’Î»)Î£âˆ’1 s XÎ» âˆ¼N(ÂµÎ»,Î£Î») In the following experiments, easy shift refers to Î»= 0.6, moderate shift to Î»= 0.65 and hard shift to Î»= 0.7. Exponential Loss for Binary Classiï¬cation Let zbe the classiï¬cation score hÎ¸(x). For logistic training loss, conjugate adaptation loss would default to entropy with sigmoid probability. Thus, here we experiment with a different but also commonly used surrogate loss to 0/1 loss: exponential loss, which is deï¬ned as: Lexp(z,y) = exp(âˆ’yz) (21) where yâˆˆ{âˆ’1,+1}. It can be rewritten in the expanded conjugate form of: Lexp(z,y) = 1 2 Â· ( ez + eâˆ’z) âˆ’1 2 Â·yÂ· ( ez âˆ’eâˆ’z) (22) For exponential loss, the conjugate pseudo-label function and the conjugate pseudo-label loss are: yCPL exp (z) = ez âˆ’eâˆ’z ez + eâˆ’z, LCPL exp (z) = 2 ez + eâˆ’z (23) The model is adapted on shifted gaussian clusters and we compare the conjugate loss with two baseline approaches: 1) Hard pseudo-labelling exp(âˆ’yhard pl Â·z); 2) Entropy applied to sigmoid probability P(y= +1) = Ïƒ(z). The losses are compared on three degrees of shift (easy, moderate and hard), which is controlled by the drifted distance of Gaussian clusters. The results are shown in Figure 3, where we plot the accuracy curve with respect to adaptation iterations. With easy and moderate shift, conjugate loss (green) generalizes faster to shifted test data; with hard shift, only conjugate loss improves model accuracy on shifted test data while entropy (blue) deteriorates model performance. Figure 3: Test-time adaptation result on synthetic data with three shift levels ranging from easy, moderate and hard (detailed in section A.2). The source model is a linear classiï¬er trained with exponential loss Lexp = eâˆ’yhÎ¸(x). Adaptation with the conjugate loss generalizes better compared to baseline losses. 16A.3 Meta Learning Experiment Details In section 3 we talked about learning the meta-loss function parameterized by a neural network mÏ† : R|Y|â†¦â†’R, that takes in the model predictions/logits and outputs a loss value. Here we discuss the architecture chosen and the implementation details. Further, in Appendix A.4 we empirically show that the learnt meta-loss is not affected by the choice of task loss / surrogate loss used in meta learning (Lin Equation 1). Note that the task loss / surrogate loss function is used to update the meta-loss mÏ† during meta-learning. The surrogate loss is calculated on updated source modelâ€™s predictions on labeled samples from test domain. The surrogate loss tries to update the meta-loss in the outer loop such that when meta-loss is later used to update the source model in the inner loop, the source model generalizes better to the test domain. Architecture and Implementation Details Figure 4 gives an overall schema for meta-learning the loss function and algorithm 2 gives the pseudo-code for meta-learning the loss function. Below we describe this in further detail. We use a transformer (denoted by T) with a MLP (denoted by P) over the output of transformer as the architecture for mÏ†, i.e. mÏ†(x) = P(T(x)). Speciï¬cally, for a given source trained model hÎ¸ and input xâˆ¼Dtest : 1. Let hÎ¸(x) âˆˆR|Y|be the model predictions/logits, where |Y|denotes the number of classes. 2. Let hj Î¸(x) âˆˆR,âˆ€j âˆˆ|Y| be the prediction corresponding to class j. 3. The input to transformer is then given by z âˆˆR|Y|Ã—(1+e), where zj âˆˆR1+e,âˆ€j âˆˆ|Y| is the concatenation of hj Î¸(x) and the learnable positional embedding pej âˆˆRe. 4. The transformer output is given by w= T(z) âˆˆRd, where ddenotes the feed-forward dimension of the transformer. 5. The transformer output wis ï¬nally passed through a MLP to get the meta-loss valuemÏ†(hÎ¸(x)) = P(w) âˆˆR 6. The source model is updated by optimizing over the meta-loss. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t (24) 7. The updated source model is then used to update the meta-loss by optimizing over some supervised loss function Ltask. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , where (xâ€²,yâ€²) âˆ¼Dtest (25) Note that the last step assumes access to labels of test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We select the trasformer input embedding dimension (1 + e) from {16,32,64}and transformer feed-forward dimension dfrom {32,64,128}. The number of transformer layers and the hidden layers in MLP are selected from {1,2}. We use Adam optimizer with a learning rate of 1eâˆ’3 for learning the meta-loss (i.e. the transformer + MLP). We train the meta-loss for 100 epochs with a batch size of 200. A.4 Effect of Task Loss in Meta Learning In section 3, we show that the meta losses learned on different source classiï¬ers differ substantially if the source classiï¬ers are trained using different source loss functions. Here we further empirically verify that the learnt meta loss is not affected by the task loss used in meta learning (Lin Equation 1). Thus the learnt meta loss is determined by the source model. In Figure 5, we show the meta loss learnt on a ResNet-26 trained with Cross Entropy loss for two meta task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. We plot the meta loss as a function over one of its input prediction scores, while keeping other ï¬xed. We can see that the task loss barely affects the learnt meta loss. Similar observations can be made for the classiï¬er trained with squared loss Figure 6. 17Meta-Loss  Backpropogate  Figure 4: Meta-Loss learning procedure : The model predictions hÎ¸t(x) are passed through the parameterized loss function mÏ†t, which outputs a loss value. We optimize Ï† such that when optimizing the source model over the loss mÏ†t(hÎ¸t(x)), the updated Î¸t+1 has a better performance on the test domain. To do this, we take one gradient step over the meta-loss to get the update source model parameters Î¸t+1, and then update Ï†by evaluating Î¸t+1 on the labeled validation data using some task loss Ltask. Algorithm 2 Learning the Meta-Loss Input: Source trained classiï¬er hÎ¸0 . Randomly initialized meta-loss mÏ†0 . Task loss / Surrogate loss Ltask like cross-entropy or squared loss for meta learning N batches of test data Dtest = [(x1,y1),..., (xN,yN)] Hyperparams: learning rates Î±and Î². for epoch= 0,1,2,... do for n= 0,1,...N âˆ’1 do Î¸t+1 â†Î¸t âˆ’Î± âˆ‚mÏ†t(hÎ¸t(xn)) âˆ‚Î¸t Sample (xr,yr) âˆ¼Dtest. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xr),yr) âˆ‚Ï†t A.5 Test-Time Adaptation Detail For completeness, we also give the test-time adaptation setup in Algorithm 3. A.6 ImageNet results on each severity level In continuation with results shown in Table 2 in Section 5.3, Table 4 shows the mean errors averaged across the 15 corruption types for each of the severity level on ImageNet-C, for a source classiï¬er trained with PolyLoss (Ïµ= 8). A.7 Square Loss Trained Source Classiï¬er In Section 5.3, we brieï¬‚y discussed that similar to the other source training losses like cross-entropy and polyloss, our proposed conjugate loss outperforms the baselines when the source classiï¬er is 18(a)  (b) Figure 5: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Cross Entropy. Here we show meta loss trained by two different task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. (a)  (b) Figure 6: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Squared Loss. Here we show meta loss trained by two different task losses: Cross Entropy Figure 6a and Squared Loss Figure 6b. Algorithm 3 Test-Time Adaptation Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y), An unsupervised loss function for test-time adaptation Ltta(x), N batches of test data Dtest = [x1,...,x N] Hyperparams: learning rate Î·. for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡Ltta(xn) Ë†yn = hÎ¸n+1 (xn) [Predictions for the nth batch] 19Corrution Severity Temperature Robust PL Entropy MEMO Softmax PL Conjugate 1 \u0017 34.27 33.17 34.39 32.49 32.26 \u0013 34.27 32.84 34.39 32.70 32.26 2 \u0017 41.25 39.04 40.38 37.78 37.40 \u0013 41.25 38.50 40.38 37.75 37.40 3 \u0017 47.37 44.04 45.67 42.30 41.72 \u0013 47.37 43.33 45.67 42.14 41.72 4 \u0017 56.63 51.88 54.49 49.61 48.84 \u0013 56.63 51.03 54.49 49.39 48.84 5 \u0017 67.11 62.53 66.13 60.94 59.90 \u0013 67.11 61.80 66.13 60.30 59.90 Mean \u0017 49.32 46.13 48.21 44.62 44.02 \u0013 49.32 45.50 48.21 44.45 44.02 Table 4: Mean Errors across the 15 noises for various severity level on the ImageNet-C dataset, with source model trained using Poly-1 Loss. Note that Temperature scaling helped only in the case of Entropy and Softmax PL. trained using a squared loss. Table 5 shows a detailed comparison with the baselines. We note that for the conjugate of squared loss, the temperature scaling can be wrapped into the learning rate as shown in Section 4.2. Further, on the CIFAR-10-C dataset we observe temperature scaling doesnâ€™t help any of the other baselines too, hence we do not include the temperature row in CIFAR-10-C. Dataset Temperature Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL CIFAR-10-C \u0017 13.71 (Â±0.07) 13.06 (Â±0.05) 13.24 (Â±0.02) 13.22 (Â±0.04) 14.85 (Â±0.08)12.99(Â±0.04) CIFAR-100-C \u0017 50.82 (Â±0.31) 44.53 (Â±0.13) 43.55 (Â±0.12) 51.35 (Â±0.04) 51.99 (Â±0.03)43.39(Â±0.11) \u0013 50.82 (Â±0.31) 43.99 (Â±0.15)43.21(Â±0.08) 51.35 (Â±0.04) 51.99 (Â±0.03) 43.39 (Â±0.11) Table 5: Mean Errors on the common corruptions datasets for source classiï¬er trained using squared loss. We note that temperature scaling didnâ€™t help on the CIFAR-10-C dataset. Source Classiï¬er Errors without adaptation : CIFAR-10-C (28.34%), CIFAR-100-C (68.79%) Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1 eâˆ’2, 2 SGD,5 eâˆ’3, 3 Adam,1eâˆ’3, 2 CIFAR-100-C \u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD,1eâˆ’2, 2 ImageNet-C \u0017 SGD,1eâˆ’2, 1 SGD,2.5 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1.5 SGD,1eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 Table 6: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 1, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using cross-entropy loss. A.8 Hyper-Parameters We share the exact hyper-parameters found using gridsearch over the 4 validation noises for the common corruptions dataset. 20Cross Entropy Classiï¬er Experiments In Section 5.2, Table 1 shows the results when adapting a cross entropy trained classiï¬er on various common corruptions dataset. Table 6 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. PolyLoss Classiï¬er Experiments In Section 5.3, Table 2 shows the results when adapting a polyloss trained classiï¬er on various common corruptions dataset. Table 7 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’3, 1 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1eâˆ’2, 3 SGD,1 eâˆ’2, 3 SGD,5 eâˆ’3, 3 SGD, 1eâˆ’3, 2 SGD, 1eâˆ’3, 1.5 CIFAR-100-C\u0017 SGD,1eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD, 1eâˆ’2, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 Adam,1eâˆ’3, 3 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD, 1eâˆ’2, 2.5 SGD, 1eâˆ’2, 1.5 ImageNet-C\u0017 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 2 SGD, 2.5eâˆ’3, 1 Table 7: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 2, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using poly-loss. Squared Loss Classiï¬er Experiments In Section 5.3, we brieï¬‚y discussed the results when adapt- ing a squared loss trained classiï¬er on various common corruptions dataset. Table 8 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss for the results in Table 5. Digit Adaptation Datasets For the experiments on digits adaptation tasks, we do not have any validation set. Hence, we donâ€™t use temperature scaling here (T = 1) and ï¬x the optimizer and LR as Adam and 1eâˆ’2 respectively for all the baselines. A.9 Additional Experiments on Digit Adaptation Datasets Similar to the setting of Table 1, we perform additional experiments on digit adaptation datasets when the source classiï¬er is trained using the cross-entropy loss. Note that when the source classiï¬er is trained using cross-entropy loss, the conjugate loss is equal to the softmax-entropy. In the absence of validation dataset in digit adaptation benchmarks, we used a ï¬xed learning rate of 0.01 for all the baselines, optimizer as Adam and an informed temperature scaling guess of T=2. Table 9 compares softmax-entropy minimization with various baselines. Here, again we observe that on SVHN â†’MNIST benchmark, without temperature scaling, MEMO (10.67% error) outperforms softmax-entropy (14.41% error). However, similar to the observations in Table 1, with temperature scaling, softmax-entropy minimization (9.26% error) is able to match the performance of MEMO (9.36% error). Further, on the SVHN â†’USPS benchmark, softmax-entropy (conjugate) and MEMO perform similar even without temperature scaling. A.10 Additional Meta Learning the TTA Loss Experiments In Section 3, we tried to learn a test-time adaptation (TTA) loss via meta-learning for adapting a CIFAR10 trained ResNet26 to distribution shifts on CIFAR10 corruptions. Figure 1 showed that the learnt meta-loss looks like a temperature scaled softmax-entropy. In this section, we show the learnt meta loss across a range of settings as described below : 1. Digit Adaptation: Figure 7a and 7b show the learnt meta-loss when adapting a SVHN trained ResNet26 to MNIST dataset and USPS dataset respectively. We observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 2. Various Noise Types: In Figure 8, we show the learnt meta-loss when adapting a ResNet26 trained on CIFAR10 dataset using cross-entropy loss, to various noise types like speckle, gaussian, saturate and spatter. The severity level is kept ï¬xed at the maximum i.e. 5. 21Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’4, 1 SGD,1eâˆ’2, 1 CIFAR-100-C\u0017 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam, 1eâˆ’4, 1 Adam, 1eâˆ’3, 1 \u0013 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 0.5 Adam,1eâˆ’3, 2 Adam,1eâˆ’3, 2 Adam, 1eâˆ’4, 2.5 Adam, 1eâˆ’3, 1 Table 8: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 5, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using squared loss. Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) SVHNâ†’MNIST \u0017 21.54 27.44 10.67 14.41 \u0013 21.54 13.26 9.36 9.26 SVHNâ†’USPS \u0017 26.06 26.81 22.72 22.57 \u0013 26.06 22.32 22.42 22.27 Table 9: Mean errors when adapting to digit adaptation benchmarks using a source classiï¬er trained via cross-entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. Again we observe that with the right temperature scaling, softmax-entropy minimization matches other approaches. For additional context, the source classiï¬er errors without adaptation are: SVHN â†’MNIST (34.17%), SVHN â†’USPS (31.84%). 20  10  0 10 20 prediction score 5 0 5 10loss value meta loss (error 10.44%) softmax entropy (error 14.41) fitted entropy (error 9.26) Meta Loss for SVHN -> MNIST (a) 20  10  0 10 20 prediction score 6 4 2 0 2 4 6 8 loss value meta loss (error 20.13%) softmax entropy (error 22.57) fitted entropy (error 22.22) Meta Loss for SVHN -> USPS adpatation (b) Figure 7: Visualizations of the learnt meta-loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with cross-entropy on the SVHN dataset. (a) The learnt meta-loss when adapting to the MNIST test dataset. (b) The learnt meta-loss when adapting to the USPS test dataset. 3. Various Severity Levels: In Figure 9, we vary the severity level of the noise, keeping the noise type ï¬xed. 4. Dataset and Architecture: In Figure 10, we compare the learnt meta-loss when adapting to speckle noise, for different source classiï¬er architectures (ResNet26 and ResNet50) and different source training dataset (CIFAR10 and CIFAR100). In all the cases, we again observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 5. Squared Loss : Finally, in Figure 11 we show the learnt meta-loss for classiï¬ers trained with squared loss function instead of cross-entropy. We observe that in this case, the learnt meta loss mimics a quadratic function as expected from the conjugate formulation. 22For each of the learnt meta losses, we also show the values (Î±,T,C ) we use to ï¬t the meta loss with softmax entropy function: Î±Â·H(softmax(x/T)) âˆ’C. Note that although the learnt meta-loss can be approximated by the conjugate, the parameters Î±,T,C differ across the settings. In the case of classiï¬ers trained with squared loss, we ï¬t the meta loss with a quadratic functionâˆ‘K i=1(AÂ·x2 i + C), where Kis the number of classes and xis the logit vector. Again, we also show the ï¬tted parameter value A,C. The meta loss follows the trend of a quadratic function. The ï¬tted quadratic function performs better or similar as the meta loss, while the parameters of the ï¬tted quadratic function remain different across the meta learning setup (base classiï¬er architectures and noise types). (a)  (b) (c)  (d) Figure 8: Visualization of meta loss (blue) learnt from various noise types in CIFAR-10-C validation set, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 23(a)  (b) (c)  (d) Figure 9: Visualization of meta loss (blue) learnt on speckle noise with different severity level for CIFAR-10-C, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 24(a)  (b) (c)  (d) Figure 10: Visualization of meta loss (blue) learnt across datasets (CIFAR-10-C/CIFAR-100-C) and base classiï¬er architectures (ResNet-26/ResNet-50), where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters ( Î±,T,C ) in the ï¬tted entropy. (a)  (b) Figure 11: Visualization of meta loss (blue), where base classiï¬er is trained with quadratic loss. We show the error of meta loss, softmax entropy and ï¬tted quadratic function for test-time adaptation on the corresponding noise types. We also show the parameters ( A,B,C ) in the ï¬tted quadratic function. 25",
      "meta_data": {
        "arxiv_id": "2207.09640v2",
        "authors": [
          "Sachin Goyal",
          "Mingjie Sun",
          "Aditi Raghunathan",
          "Zico Kolter"
        ],
        "published_date": "2022-07-20T04:02:19Z",
        "pdf_url": "https://arxiv.org/pdf/2207.09640v2.pdf"
      }
    },
    {
      "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
      "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
      "full_text": "Published as a conference paper at ICLR 2024 ACTIVE TEST-TIME ADAPTATION : T HEORETICAL ANALYSES AND AN ALGORITHM Shurui Guiâˆ— Texas A&M University College Station, TX 77843 shurui.gui@tamu.edu Xiner Li* Texas A&M University College Station, TX 77843 lxe@tamu.edu Shuiwang Ji Texas A&M University College Station, TX 77843 sji@tamu.edu ABSTRACT Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies. To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting. We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA. 1 I NTRODUCTION Deep learning has achieved remarkable success across various fields, attaining high accuracy in numerous applications (Krizhevsky et al., 2017; Simonyan and Zisserman, 2014). Nonetheless, When training and test data follow distinct distributions, models often experience significant performance degradation during test. This phenomenon, known as the distribution shift or out-of-distribution (OOD) problem, is extensively studied within the context of both domain generalization (DG) (Gulra- jani and Lopez-Paz, 2020; Koh et al., 2021; Gui et al., 2022) and domain adaptation (DA) (Ganin et al., 2016; Sun and Saenko, 2016). While these studies involve intensive training of models with considerable generalization abilities towards target domains, they overlook an important application property; namely, continuous adaptivity to real-time streaming data under privacy, resource, and efficiency constraints. This gap leads to the emergence of test-time adaptation (TTA) tasks, targeting on-the-fly adaptation to continuous new domains during the test phase or application deployment. The study of TTA encompasses two main categories; namely test-time training (TTT) methods (Sun et al., 2020; Liu et al., 2021c) and fully test-time adaptation (FTTA) (Niu et al., 2023; Wang et al., 2021). The TTT pipeline incorporates retraining on the source data, whereas FTTA methods adapt arbitrary pre-trained models to the given test mini-batch by conducting entropy minimization, without access to the source data. Nevertheless, most TTA methods can only handle corrupted distribution shifts (Hendrycks and Dietterich, 2019b) (e.g., Gaussian noise,) and rely heavily on human intuition or empirical studies. To bridge this gap, our paper focuses on tackling significant domain distribution shifts in real time with theoretical insights. We investigate FTTA, which is more general and adaptable than TTT, particularly under data ac- cessibility, privacy, and efficiency constraints. Traditional FTTA aims at adapting a pre-trained model to streaming test-time data from diverse domains under unsupervised settings. However, recent works (Lin et al., 2022; Pearl, 2009) prove that it is theoretically infeasible to achieve OOD generalization without extra information such as environment partitions. Since utilizing environment partitions requires heavy pretraining, contradicting the nature of TTA, we are motivated to incorporate extra information in a different way,i.e., integrating a limited number of labeled test-time samples to alleviate distribution shifts, following the active learning (AL) paradigm (Settles, 2009). To this end, we propose the novel problem setting of active test-time adaptation (ATTA) by incorporating âˆ—Equal contributions 1 arXiv:2404.05094v1  [cs.LG]  7 Apr 2024Published as a conference paper at ICLR 2024 AL within FTTA. ATTA faces two major challenges; namely, catastrophic forgetting (CF) (Kemker et al., 2018; Li and Hoiem, 2017) and real-time active sample selection. CF problem arises when a model continually trained on a sequence of domains experiences a significant performance drop on previously learned domains, due to the inaccessibility of the source data and previous test data. Real-time active sample selection requires AL algorithms to select informative samples from a small buffer of streaming test data for annotation, without a complete view of the test distribution. In this paper, we first formally define the ATTA setting. We then provide its foundational analysis under the learning theoryâ€™s paradigm to guarantee the mitigation of distribution shifts and avoid CF. Aligned with our empirical validations, while the widely used entropy minimization (Wang et al., 2021; Grandvalet and Bengio, 2004) can cause CF, it can conversely become the key to preventing CF problems with our sample selection and balancing techniques. Building on the analyses, we then introduce a simple yet effective ATTA algorithm, SimATTA, incorporating balanced sample selections and incremental clustering. Finally, we conducted a comprehensive experimental study to evaluate the proposed ATTA settings with three different settings in the order of low to high requirement restrictiveness, i.e., TTA, Enhanced TTA, and Active Domain Adaptation (ADA). Intensive experiments indicate that ATTA jointly equips with the efficiency of TTA and the effectiveness of ADA, rendering an uncompromising real-time distribution adaptation direction. Comparison to related studies. Compared to TTA methods, ATTA requires extra active labels, but the failure of TTA methods (Sec. 5.1) and the theoretical proof of Lin et al. (2022); Pearl (2009) justify its necessity and rationality. Compared to active online learning, ATTA focuses on lightweight real-time fine-tuning without round-wise re-trainings as Saran et al. (2023) and emphasizes the importance of CF avoidance instead of resetting models and losing learned distributions. In fact, active online learning is partially similar to our enhanced TTA setting (Sec. 5.2. Compared to ADA methods (Prabhu et al., 2021; Ning et al., 2021), ATTA does not presuppose access to source data, model parameters, or pre-collected target samples. Furthermore, without this information, ATTA can still perform on par with ADA methods (Sec. 5.3). The recent source-free active domain adaptation (SFADA) method SALAD (Kothandaraman et al., 2023) still requires access to model parameter gradients, pre-collected target data, and training of additional networks. Our ATTA, in contrast, with non-regrettable active sample selection on streaming data, is a much lighter and more realistic approach distinct from ADA and SFADA. More related-work discussions are provided in Appx. C. 2 T HE ACTIVE TEST-TIME ADAPTATION FORMULATION TTA methods aim to solve distribution shifts by dynamically optimizing a pre-trained model based on streaming test data. We introduce the novel problem setting of Active Test-Time Adaptation (ATTA), which incorporates active learning during the test phase. In ATTA, the model continuously selects the most informative instances from the test batch to be labeled by an explicit or implicit oracle (e.g., human annotations, self-supervised signals) and subsequently learned by the model, aiming to improve future adaptations. Considering the labeling costs in real-world applications, a â€œbudgetâ€ is established for labeled test instances. The model must effectively manage this budget distribution and ensure that the total number of label requests throughout the test phase does not surpass the budget. We now present a formal definition of the ATTA problem. Consider a pre-trained modelf(x; Ï•) with parameters Ï• trained on the source dataset DS = (x, y)|DS|, with each data sample x âˆˆ Xand a label y âˆˆ Y. We aim to adapt model parameters Î¸, initialized as Ï•, to an unlabeled test-time data stream. The streaming test data exhibit distribution shifts from the source data and varies continuously with time, forming multiple domains to which we must continuously adapt. The test phase commences at time step t = 1 and the streaming test data is formulated in batches. The samples are then actively selected, labeled (by the oracle) and collected as Dte(t) = ActAlg(Ute(t)), where ActAlg(Â·) denotes an active selection/labeling algorithm. The labeled samples Dte(t) are subsequently incorporated into the ATTA training setDtr(t). Finally, we conclude time step t by performing ATTA training, updating model parameters Î¸(t) using Dtr(t), with Î¸(t) initialized as the previous final state Î¸(t âˆ’ 1). Definition 1 (The ATTA problem). Given a model f(x; Î¸), with parameters Î¸, initialized with parameters Î¸(0) = Ï• obtained by pre-training on source domain data, and streaming test data batches Ute(t) continually changing over time, the ATTA task aims to optimize the model at any time stept (with test phase commencing at t = 1) as Î¸(t)âˆ— := argmin Î¸(t) (E(x,y,t)âˆˆDtr(t)[â„“CE (f(x; Î¸(t)), y)] + E(x,t)âˆˆUte(t)[â„“U (f(x; Î¸(t)))]), (1) 2Published as a conference paper at ICLR 2024 where Dtr(t) = ( âˆ…, t = 0 Dtr(t âˆ’ 1) âˆª Dte(t), t â‰¥ 1, s.t. |Dtr(t)| â‰¤ B, (2) Dte(t) = ActAlg(Ute(t)) is actively selected and labeled, â„“CE is the cross entropy loss, â„“U is an unsupervised learning loss, and B is the budget. 3 T HEORETICAL STUDIES In this section, we conduct an in-depth theoretical analysis of TTA based on learning theories. We mainly explore two questions: How can significant distribution shifts be effectively addressed under the TTA setting? How can we simultaneously combat the issue of CF? Sec. 3.1 provides a solution with theoretical guarantees to the first question, namely, active TTA (ATTA), along with the conditions under which distribution shifts can be well addressed. Sec. 3.2 answers the second question with an underexplored technique, i.e., selective entropy minimization, building upon the learning bounds established in Sec. 3.1. We further validate these theoretical findings through experimental analysis. Collectively, we present a theoretically supported ATTA solution that effectively tackles both distribution shift and CF. 3.1 A LLEVIATING DISTRIBUTION SHIFTS THROUGH ACTIVE TEST-TIME ADAPTATION Traditional TTA is performed in unsupervised or self-supervised context. In contrast, ATTA introduces supervision into the adaptation setting. In this subsection, we delve into learning bounds and establish generalization bounds to gauge the efficacy of ATTA in solving distribution shifts. We scrutinize the influence of active learning and evidence that the inclusion of labeled test instances markedly enhances overall performances across incremental test domains. Following Kifer et al. (2004), we examine statistical guarantees for binary classification. A hypothesis is a function h : X â†’ {0, 1}, which can serve as the prediction function within this context. In the ATTA setting, the mapping ofh varies with time as h(x, t). We use Hâˆ†H-distance following Ben- David et al. (2010), which essentially provides a measure to quantify the distribution shift between two distributions D1 and D2, and can also be applied between datasets. The probability that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} according to distribution D is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source data is inaccessible under ATTA settings, we consider the existence of source dataset DS for accurate theoretical analysis. Thus, we initialize Dtr as Dtr(0) = DS. For every time step t, the test and training data can be expressed asUte(t) and Dtr(t) = DS âˆªDte(1) âˆªDte(2) âˆªÂ·Â·Â·âˆª Dte(t). Building upon two lemmas (provided in Appx. D), we establish bounds on domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesish at time t. Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Â·Â·Â· , Ute(t), Â·Â·Â· , Si are unlabeled samples of sizem sampled from each of thet+1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î» = (Î»0, Â·Â·Â· , Î»t). If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w = (w0, Â·Â·Â· , wt) on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. The adaptation performance on a test domain is majorly bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. Further theoretical analysis are in Appx. D. 3Published as a conference paper at ICLR 2024 Figure 1: (a) Empirical validation of Thm. 1. We train a series of models on N = 2000 samples from the PACS (Li et al., 2017) dataset given differentÎ»0 and w0 and display the test domain loss of each model. Red points are the test loss minimums given a fixed Î»0. The orange line is the reference where w0 = Î»0. We observe that w0 with loss minimums are located closed to the orange line but slightly smaller than Î»0, which validates our findings in Eq. (4). (b) Empirical analysis with an uncertainty balancing. Given source pre-trained models, we fine-tune the models on 500 samples with different Î»0 and w0, and display the combined error surface of test and source error. Although a small Î»0 is good for test domain error, it can lead to non-trivial source error exacerbation. Therefore, we can observe that the global loss minimum (green X) locates in a relatively high-Î»0 region. If we consider the multiple test data distributions as a single test domain,i.e., St i=1 Ute(i), Thm. 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . Given the optimal test/source hypothesis hâˆ— T (t) = arg minhâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), we have |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (3.a), with approximatelyB = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (4) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. The following theorem offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (5) Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. All proofs are provided in Appx. E. Finally, we support the theoretical findings with experimental analysis and show the numerical results of applying the principles on real-world datasets, as shown in Fig. 1. For rigorous analysis, note that our theoretical results rest on the underlying condition that N should at least be of the same scale as d, according to the principles of VC-dimension theory. The empirical alignment of our experiments with the theoretical framework can be attributed to the assumption that fine-tuning a model is roughly equivalent to learning a model with a relatively small d. Experiment details and other validations can be found in Appx. H. 4Published as a conference paper at ICLR 2024 3.2 M ITIGATING CATASTROPHIC FORGETTING WITH BALANCED ENTROPY MINIMIZATION Catastrophic forgetting (CF), within the realm of Test-Time Adaptation (TTA), principally manifests as significant declines in overall performance, most notably in the source domain. Despite the lack of well-developed learning theories for analyzing training with series data, empirical studies have convincingly illustrated the crucial role of data sequential arrangement in model learning, thereby accounting for the phenomenon of CF. Traditionally, the mitigation of CF in adaptation tasks involves intricate utilization of source domain data. However, under FTTA settings, access to the source dataset is unavailable, leaving the problem of CF largely unexplored in the data-centric view. Table 1: Correlation analysis of high/low en- tropy samples and domains. We use a source pre-trained model to select samples with low- est/highest entropy, and 1.retrain the model on 2000 samples; 2.fine-tune the model on 300 sam- ples. We report losses on source/test domains for each setting, showing that low-entropy samples form distributions close to the source domain. Sample type Retrain Fine-tune ÏµS ÏµT ÏµS ÏµT Low entropy 0.5641 0.8022 0.0619 1.8838 High entropy 2.5117 0.3414 0.8539 0.7725 To overcome this challenge of source dataset ab- sence, we explore the acquisition of â€œsource-likeâ€ data. In TTA scenarios, it is generally assumed that the amount of source data is considerably large. We also maintain this assumption in ATTA, practically assuming the volume of source data greatly surpasses the test-time budget. As a re- sult, we can safely assume that the pre-trained model is well-trained on abundant source do- main data DS. Given this adequately trained source model, we can treat it as a â€œtrueâ€ source data labeling function f(x; Ï•). The model es- sentially describes a distribution, DÏ•,S(X, Y) = {(x, Ë†y) âˆˆ (X, Y) | Ë†y = f(x; Ï•), xâˆˆ DS}. The entropy of the model prediction is defined as H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc), Ë†y = f(x; Ï•), where c denotes the class. Lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction, which can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model recognizes the sample as being similar to those it was trained on. Thus entropy can be used as an indicator of how closely a sample x aligns with the model distribution DÏ•,S. Since the model distribution is approximately the source distribution, selecting (and labeling) low-entropy samples using f(x; Ï•) essentially provides an estimate of sampling from the source dataset. Therefore, in place of the inaccessible DS, we can feasibly include the source-like dataset into the ATTA training data at each time stept: DÏ•,S(t) = {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el}, (6) where el is the entropy threshold. The assumption that DÏ•,S(t) is an approximation of DS can be empirically validated, as shown by the numerical results on PACS in Tab. 1. In contrast, high-entropy test samples typically deviate more from the source data, from which we select Dte(t) for active labeling. Following the notations in Thm. 1, we are practically minimizing the empirical weighted error of hypothesis h(t) as Ë†Ïµâ€² w(h(t)) = tX j=0 wjË†Ïµj(h(t)) = w0 Î»0N X xâˆˆDÏ•,S(t) |h(x, t) âˆ’ f(x; Ï•)| + tX j=1 wj Î»jN X x,yâˆˆDte(j) |h(x, t) âˆ’ y|. (7) By substituting DS with DÏ•,S(t) in Thm. 1, the bounds of Thm. 1 continue to hold for the test domains. In the corollary below, we bound the source error for practical ATTA at each time stept. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Thm. 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Thm. 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Further analysis and proofs are in Appx. D and E. The following corollary provides direct theoretical support that our strategy conditionally reduces the error bound on the source domain. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Thm. 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight 5Published as a conference paper at ICLR 2024 <latexit sha1_base64=\"NxhXSyFABPQk4q8627/odirDspg=\">AAAB9XicbVDLSgMxFM34rPVVdekmWARXZab4WhbcuKzYF7S1ZNI7bWgmMyR3lDL0P9y4UMSt/+LOvzHTdqGtBwKHc87l3hw/lsKg6347K6tr6xubua389s7u3n7h4LBhokRzqPNIRrrlMwNSKKijQAmtWAMLfQlNf3ST+c1H0EZEqobjGLohGygRCM7QSg/3mIWFGtAaGOwVim7JnYIuE29OimSOaq/w1elHPAlBIZfMmLbnxthNmUbBJUzyncRAzPiIDaBtqWIhmG46vXpCT63Sp0Gk7VNIp+rviZSFxoxD3yZDhkOz6GXif147weC6mwoVJwiKzxYFiaQY0awC2hcaOMqxJYxrYW+lfMg042iLytsSvMUvL5NGueRdli7uysXK+byOHDkmJ+SMeOSKVMgtqZI64USTZ/JK3pwn58V5dz5m0RVnPnNE/sD5/AFnsJJq</latexit> Streaming Test <latexit sha1_base64=\"a41BOKrutEYSWO9+8CjkPZKHvb8=\">AAAB73icbVBNS8NAEJ3Ur1q/qh69BIvgqSTiR48FLx4r2A9oQ9lsN+3SzSbuToQQ+ie8eFDEq3/Hm//GTZuDtj4YeLw3w8w8PxZco+N8W6W19Y3NrfJ2ZWd3b/+genjU0VGiKGvTSESq5xPNBJesjRwF68WKkdAXrOtPb3O/+8SU5pF8wDRmXkjGkgecEjRSbzAhmKWzyrBac+rOHPYqcQtSgwKtYfVrMIpoEjKJVBCt+64To5cRhZwKNqsMEs1iQqdkzPqGShIy7WXze2f2mVFGdhApUxLtufp7IiOh1mnom86Q4EQve7n4n9dPMGh4GZdxgkzSxaIgETZGdv68PeKKURSpIYQqbm616YQoQtFElIfgLr+8SjoXdfe6fnV/WWs2ijjKcAKncA4u3EAT7qAFbaAg4Ble4c16tF6sd+tj0Vqyiplj+APr8wfpIY/e</latexit> Ë†y <latexit sha1_base64=\"SJEOE2ZYxLL1SU/QahOlMH6fop4=\">AAAB8HicbVBNSwMxEM3Wr1q/qh69BItQL2VX/Oix4MVjBbettEvJptk2NMkuyaxQlv4KLx4U8erP8ea/MW33oK0PBh7vzTAzL0wEN+C6305hbX1jc6u4XdrZ3ds/KB8etUycasp8GotYd0JimOCK+cBBsE6iGZGhYO1wfDvz209MGx6rB5gkLJBkqHjEKQErPfr9DNi0Cuf9csWtuXPgVeLlpIJyNPvlr94gpqlkCqggxnQ9N4EgIxo4FWxa6qWGJYSOyZB1LVVEMhNk84On+MwqAxzF2pYCPFd/T2REGjORoe2UBEZm2ZuJ/3ndFKJ6kHGVpMAUXSyKUoEhxrPv8YBrRkFMLCFUc3srpiOiCQWbUcmG4C2/vEpaFzXvunZ1f1lp1PM4iugEnaIq8tANaqA71EQ+okiiZ/SK3hztvDjvzseiteDkM8foD5zPH2KnkB4=</latexit> U te ( t ) <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model SimATTA <latexit sha1_base64=\"bhVea6W/pzUPuDRNfs2xbDF7qAk=\">AAAB73icbVC7SgNBFL3rM8ZX1NJmMAhWYTf4KgM2FhYRzAOSJcxOZpMhs7PrzF0hhPyEjYUitv6OnX/jbLKFJh4YOJxzD3PvCRIpDLrut7Oyura+sVnYKm7v7O7tlw4OmyZONeMNFstYtwNquBSKN1Cg5O1EcxoFkreC0U3mt564NiJWDzhOuB/RgRKhYBSt1L6jQRYd9Eplt+LOQJaJl5My5Kj3Sl/dfszSiCtkkhrT8dwE/QnVKJjk02I3NTyhbEQHvGOpohE3/mS275ScWqVPwljbp5DM1N+JCY2MGUeBnYwoDs2il4n/eZ0Uw2t/IlSSIlds/lGYSoIxyY4nfaE5Qzm2hDIt7K6EDammDG1FRVuCt3jyMmlWK95l5eK+Wq6d53UU4BhO4Aw8uIIa3EIdGsBAwjO8wpvz6Lw4787HfHTFyTNH8AfO5w/1SI/i</latexit> Labeling <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"ipQ+JKlINPDcPjrbUYUkqyyzp40=\">AAAB+nicbVC7TsMwFHXKq5RXCiOLRYXEQpVUvMZKLIxF0IfURpXj3LRWHSeyHVBV+iksDCDEypew8Te4aQZoOZKlo3Puy8dPOFPacb6twsrq2vpGcbO0tb2zu2eX91sqTiWFJo15LDs+UcCZgKZmmkMnkUAin0PbH13P/PYDSMVica/HCXgRGQgWMkq0kfp2+S6bdNqQoCUxQ4K+XXGqTga8TNycVFCORt/+6gUxTSMQmnKiVNd1Eu1NiNSMcpiWeqmChNARGUDXUEEiUN4kO32Kj40S4DCW5gmNM/V3x4RESo0j31RGRA/VojcT//O6qQ6vvAkTSapB0PmiMOVYx3iWAw6YBKr52BBCJTO3YjokklBt0iqZENzFLy+TVq3qXlTPb2uV+lkeRxEdoiN0glx0ieroBjVQE1H0iJ7RK3qznqwX6936mJcWrLznAP2B9fkDSAyT+w==</latexit> Source-Pretrained <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model <latexit sha1_base64=\"5LNAmmVR/AN9Lc2T+FRV/is2yz8=\">AAAB8nicbVDLSgNBEJyNrxhfUY9eBoPgKewGX8eACB48RDAP2CxhdjKbDJmdWWZ6lbDkM7x4UMSrX+PNv3GS7EETCxqKqm66u8JEcAOu++0UVlbX1jeKm6Wt7Z3dvfL+QcuoVFPWpEoo3QmJYYJL1gQOgnUSzUgcCtYOR9dTv/3ItOFKPsA4YUFMBpJHnBKwkn+nnvCNBK2Sca9ccavuDHiZeDmpoByNXvmr21c0jZkEKogxvucmEGREA6eCTUrd1LCE0BEZMN9SSWJmgmx28gSfWKWPI6VtScAz9fdERmJjxnFoO2MCQ7PoTcX/PD+F6CrIuExSYJLOF0WpwKDw9H/c55pREGNLCNXc3orpkGhCwaZUsiF4iy8vk1at6l1Uz+9rlfpZHkcRHaFjdIo8dInq6BY1UBNRpNAzekVvDjgvzrvzMW8tOPnMIfoD5/MHKbiRJQ==</latexit> Low Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"wuZucU3JbeEJSquG2WgqGdYMCR8=\">AAAB83icbVDLSgMxFL3js9ZX1aWbYBFclZnia1kQocsK9gHtUDJppg3NJCHJCGXob7hxoYhbf8adf2PazkJbD1w4nHMv994TKc6M9f1vb219Y3Nru7BT3N3bPzgsHR23jEw1oU0iudSdCBvKmaBNyyynHaUpTiJO29H4bua3n6g2TIpHO1E0TPBQsJgRbJ3Uq7PhCN0Lq6Wa9Etlv+LPgVZJkJMy5Gj0S1+9gSRpQoUlHBvTDXxlwwxrywin02IvNVRhMsZD2nVU4ISaMJvfPEXnThmgWGpXwqK5+nsiw4kxkyRynQm2I7PszcT/vG5q49swY0KllgqyWBSnHFmJZgGgAdOUWD5xBBPN3K2IjLDGxLqYii6EYPnlVdKqVoLrytVDtVy7zOMowCmcwQUEcAM1qEMDmkBAwTO8wpuXei/eu/exaF3z8pkT+APv8wfIYpF9</latexit> High Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"1BO6D/gzkeZNQ7HNIaph5NqELCI=\">AAAB8nicbVDLSgMxFM3UV62vqks3wSK4KjPF17LgRncV7AOmQ8mkd9rQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3kHtPmHCmjet+O6W19Y3NrfJ2ZWd3b/+genjU0TJVFNpUcql6IdHAmYC2YYZDL1FA4pBDN5zc5n73CZRmUjyaaQJBTEaCRYwSYyX/XlAFMQhD+KBac+vuHHiVeAWpoQKtQfWrP5Q0zdOUE619z01MkBFlGOUwq/RTDQmhEzIC31JBYtBBNl95hs+sMsSRVPYJg+fq70RGYq2ncWgnY2LGetnLxf88PzXRTZAxkaQGBF18FKUcG4nz+/GQKaCGTy0hVDG7K6Zjogg1tqWKLcFbPnmVdBp176p++dCoNS+KOsroBJ2ic+Sha9REd6iF2ogiiZ7RK3pzjPPivDsfi9GSU2SO0R84nz9y2ZFU</latexit> Incremental <latexit sha1_base64=\"Jmobmj50NeE6y3ftB4xt5xZD5Eg=\">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8dALh4jmAcmS5id9CZDZmeXmVkhLP6FFw+KePVvvPk3TpI9aGJBQ1HVTXdXkAiujet+O4W19Y3NreJ2aWd3b/+gfHjU1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfM7j6g0j+W9mSboR3QkecgZNVZ6aIhUG1Rcjgblilt15yCrxMtJBXI0B+Wv/jBmaYTSMEG17nluYvyMKsOZwKdSP9WYUDahI+xZKmmE2s/mFz+RM6sMSRgrW9KQufp7IqOR1tMosJ0RNWO97M3E/7xeasIbP+MySQ1KtlgUpoKYmMzeJ0OukBkxtYQyxe2thI2posymoEs2BG/55VXSrlW9q+rlXa1Sv8jjKMIJnMI5eHANdbiFJrSAgYRneIU3RzsvzrvzsWgtOPnMMfyB8/kDzgaQ+A==</latexit> Clustering <latexit sha1_base64=\"c4xrXg0yZYBSSDLHCxlf45OWNzg=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBA8hd2Aj2PAi8eI5gHJEmYnnWTIzOwyMyuEJR/hxYMiXv0eb/6Nk2QPmljQUFR1090VJYIb6/vf3tr6xubWdmGnuLu3f3BYOjpumjjVDBssFrFuR9Sg4AoblluB7UQjlZHAVjS+nfmtJ9SGx+rRThIMJR0qPuCMWie1HqhMBJpeqexX/DnIKglyUoYc9V7pq9uPWSpRWSaoMZ3AT2yYUW05EzgtdlODCWVjOsSOo4pKNGE2P3dKzp3SJ4NYu1KWzNXfExmVxkxk5DoltSOz7M3E/7xOagc3YcZVklpUbLFokApiYzL7nfS5RmbFxBHKNHe3EjaimjLrEiq6EILll1dJs1oJriqX99VyrZrHUYBTOIMLCOAaanAHdWgAgzE8wyu8eYn34r17H4vWNS+fOYE/8D5/AF7Wj40=</latexit> Samples <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"KzBZ8R84UC9mpPFQBWeRHFxcqjw=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKVI8FLx4rmLbQhrLZbNq1m92wuxFK6H/w4kERr/4fb/4bt20O2vpg4PHeDDPzwpQzbVz32yltbG5t75R3K3v7B4dH1eOTjpaZItQnkkvVC7GmnAnqG2Y47aWK4iTktBtObud+94kqzaR4MNOUBgkeCRYzgo2VOn4aYUOH1ZpbdxdA68QrSA0KtIfVr0EkSZZQYQjHWvc9NzVBjpVhhNNZZZBpmmIywSPat1TghOogX1w7QxdWiVAslS1h0EL9PZHjROtpEtrOBJuxXvXm4n9ePzPxTZAzkWaGCrJcFGccGYnmr6OIKUoMn1qCiWL2VkTGWGFibEAVG4K3+vI66TTqXrPevG/UWldFHGU4g3O4BA+uoQV30AYfCDzCM7zCmyOdF+fd+Vi2lpxi5hT+wPn8AYuwjxQ=</latexit> Update <latexit sha1_base64=\"y2NH6tDs2GygUDqZYglGwvR4SpA=\">AAAB+nicbVBNSwMxEJ2tX7V+bfXoJVgEQSi7PVSPFS8eK9oPaEvJptk2NMkuSVYpa3+KFw+KePWXePPfmLZ70NYHA4/3ZpiZF8ScaeN5305ubX1jcyu/XdjZ3ds/cIuHTR0litAGiXik2gHWlDNJG4YZTtuxolgEnLaC8fXMbz1QpVkk780kpj2Bh5KFjGBjpb5bvMMi5lSjc3QlyShSuu+WvLI3B1olfkZKkKHed7+6g4gkgkpDONa643ux6aVYGUY4nRa6iaYxJmM8pB1LJRZU99L56VN0apUBCiNlSxo0V39PpFhoPRGB7RTYjPSyNxP/8zqJCS97KZNxYqgki0VhwpGJ0CwHNGCKEsMnlmCimL0VkRFWmBibVsGG4C+/vEqalbJfLVdvK6Wal8WRh2M4gTPw4QJqcAN1aACBR3iGV3hznpwX5935WLTmnGzmCP7A+fwBUnKTWg==</latexit> Samples + Anchors <latexit sha1_base64=\"u0BDOcH87PXd3DsT+o414+7cHnI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBsAq7FjGdARvLBMwFkhBmZ2eTMbMzy8ysEJaU9jYWitj6Cql8CDufwZdwcik0+sPAx/+fw5xz/JgzbVz308msrK6tb2Q3c1vbO7t7+f2DhpaJIrROJJeq5WNNORO0bpjhtBUriiOf06Y/vJrmzTuqNJPixoxi2o1wX7CQEWys1eiQQBrdyxfcojsT+gveAgqX75Pa1/3xpNrLf3QCSZKICkM41rrtubHpplgZRjgd5zqJpjEmQ9ynbYsCR1R309m0Y3RqnQCFUtknDJq5PztSHGk9inxbGWEz0MvZ1PwvaycmLHdTJuLEUEHmH4UJR0ai6eooYIoSw0cWMFHMzorIACtMjD1Qzh7BW175LzTOi16pWKq5hUoZ5srCEZzAGXhwARW4hirUgcAtPMATPDvSeXRenNd5acZZ9BzCLzlv33Yvk3g=</latexit> Â·Â·Â· <latexit sha1_base64=\"+7L/8ObZcl+JIZaSFhVO3t+lUUE=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2bvizjWb9YcituBrJMvDkp1Y6CDPV+8as7iFgScoVMUmM6nhtjL6UaBZN8UugmhseUPdIh71iqaMhNL82unZBTqwxIEGlbCkmm/p5IaWjMOPRtZ0hxZBa9qfif10kwuOqlQsUJcsVmi4JEEozI9HUyEJozlGNLKNPC3krYiGrK0AZUsCF4iy8vk+Z5xatWqnc2jQuYIQ/HcAJl8OASanALdWgAgwd4hld4cyLnxXl3PmatOWc+cwh/4Hz+AFjYkTs=</latexit> D l ( t ) <latexit sha1_base64=\"9C0bB8PYImk9DX0HLfGvGd44PFA=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2b/qiMZ/1iya24Gcgy8eakVDsKMtT7xa/uIGJJyBUySY3peG6MvZRqFEzySaGbGB5T9kiHvGOpoiE3vTS7dkJOrTIgQaRtKSSZ+nsipaEx49C3nSHFkVn0puJ/XifB4KqXChUnyBWbLQoSSTAi09fJQGjOUI4toUwLeythI6opQxtQwYbgLb68TJrnFa9aqd7ZNC5ghjwcwwmUwYNLqMEt1KEBDB7gGV7hzYmcF+fd+Zi15pz5zCH8gfP5A1K8kTc=</latexit> D h ( t ) <latexit sha1_base64=\"eNrtnhPGeU8n4BRDMStm5cjQ4ts=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDbbTbt0s4m7E6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSKQw6Lrfzsbm1vbObmGvuH9weHRcOjltmzjVjLdYLGPdDajhUijeQoGSdxPNaRRI3gkmjbnfeeLaiFg94DThfkRHSoSCUbRS1zNIGlTKQansVtwFyDrxclKGHM1B6as/jFkacYVMUmN6npugn1GNgkk+K/ZTwxPKJnTEe5YqGnHjZ4t7Z+TSKkMSxtqWQrJQf09kNDJmGgW2M6I4NqveXPzP66UY3vqZUEmKXLHlojCVBGMyf54MheYM5dQSyrSwtxI2ppoytBEVbQje6svrpF2teLVK7b5arl/ncRTgHC7gCjy4gTrcQRNawEDCM7zCm/PovDjvzseydcPJZ87gD5zPH1Naj3k=</latexit> 1st Call <latexit sha1_base64=\"mxsL+XuWb2hqFND+pzTctrB1rcY=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDababt0s4m7G6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSATXxnW/nY3Nre2d3cJecf/g8Oi4dHLa1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfc7T6g0j+WDmSboR3Qk+ZAzaqzUrcqQNKgQg1LZrbgLkHXi5aQMOZqD0lc/jFkaoTRMUK17npsYP6PKcCZwVuynGhPKJnSEPUsljVD72eLeGbm0SkiGsbIlDVmovycyGmk9jQLbGVEz1qveXPzP66VmeOtnXCapQcmWi4apICYm8+dJyBUyI6aWUKa4vZWwMVWUGRtR0Ybgrb68TtrViler1O6r5fp1HkcBzuECrsCDG6jDHTShBQwEPMMrvDmPzovz7nwsWzecfOYM/sD5/AE0o49l</latexit> 2nd Call <latexit sha1_base64=\"oSA1OFmXXL9y3PJtqoVxTIG9mto=\">AAAB8HicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaElCY2UwkQ8DF7K3zMGGvb3L7p6REH6FjYXG2Ppz7Pw3LnCFgi+Z5OW9mczMCxLBtXHdbye3sbm1vZPfLeztHxweFY9PWjpOFcMmi0WsOgHVKLjEpuFGYCdRSKNAYDsY1+d++xGV5rG8N5ME/YgOJQ85o8ZKD7f4ZEidCtEvltyyuwBZJ15GSpCh0S9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50cfCMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia89qdcJqlByZaLwlQQE5P592TAFTIjJpZQpri9lbARVZQZm1HBhuCtvrxOWpWyVy1X7yqlWiWLIw9ncA6X4MEV1OAGGtAEBhE8wyu8Ocp5cd6dj2VrzslmTuEPnM8fSFeQCA==</latexit> Next Call Figure 2: Overview of the SimATTA framework. and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (8) Corollary 4 validates that the selected low-entropy samples can mitigate the CF problem under the assumption that these samples are source-like, which is also empirically validated in Fig. 1. Note that our strategy employs entropy minimization in a selective manner, aiming to solve CF rather than the main adaptation issue. While many FTTA works use entropy minimization to adapt across domains without guarantees, our use is more theoretically-sound. 4 A N ATTA ALGORITHM Building on our theoretical findings, we introduce a simple yet effective ATTA method, known as SimATTA, that innovatively integrates incremental clustering and selective entropy minimization techniques, as illustrated in Fig. 2. We start with an overview of our methodology, including the learning framework and the comprehensive sample selection strategies. We then proceed to discuss the details of the incremental clustering technique designed for real-time sample selections. 4.1 A LGORITHM OVERVIEW Let (x, y) be a labeled sample and f(Â·; Î¸) be our neural network, where Ë†y = f(x; Î¸) and Î¸ represents the parameters. We have a model pre-trained on source domains with the pre-trained parameters Ï•. We initialize model parameters as Î¸(0) = Ï• and aim to adapt the model f(Â·; Î¸) in real-time. During the test phase, the model continuously predicts labels for streaming-in test data and concurrently gets fine-tuned. We perform sample selection to enable active learning. As discussed in Sec. 3.2, we empirically consider informative high-entropy samples for addressing distribution shifts and source-like low-entropy samples to mitigate CF. As shown in Alg. 1, at each time step t, we first partition unlabeled test samples Ute(t) into high entropy and low entropy datasets, Uh(t) and Ul(t), using an entropy threshold. The source-pretrained model f(Â·; Ï•) is frozen to predict pseudo labels for low entropy data. We obtain labeled low-entropy data Dl(t) by labeling Ul(t) with f(Â·; Ï•) and combining it with Dl(t âˆ’ 1). In contrast, the selection of high-entropy samples for active labeling is less straightforward. Since the complete test dataset is inaccessible for analyzing the target domain distribution, real-time sample selection is required. We design an incremental clustering sample selection technique to reduce sample redundancy and increase distribution coverage, detailed in Sec. 4.2. The incremental clustering algorithm outputs the labeled test samples Dh(t), also referred to as anchors, given Dh(t âˆ’1) and Uh(t). After sample selection, the model undergoes test-time training using the labeled test anchors Dh(t) and pseudo-labeled source-like anchors Dl(t). Following the analyses in Sec. 3.1, the training weights and sample numbers should satisfy w(t) â‰ˆ Î»(t) for Dh(t) and Dl(t) for optimal results. The analyses and results in Sec. 3.2 further indicate that balancing the source and target ratio is the key to mitigating CF. However, when source-like samples significantly outnumber test samples, the optimal w(t) for test domains can deviate from Î»(t) according to Eq. (4). 4.2 I NCREMENTAL CLUSTERING We propose incremental clustering, a novel continual clustering technique designed to select informa- tive samples in unsupervised settings under the ATTA framework. The primary goal of this strategy is to store representative samples for distributions seen so far. Intuitively, we apply clusters to cover all seen distributions while adding new clusters to cover newly seen distributions. During this process with new clusters added, old clusters may be merged due to the limit of the cluster budget. Since 6Published as a conference paper at ICLR 2024 Algorithm 1 SIMATTA: A SIMPLE ATTA ALGORITHM Require: A fixed source pre-trained model f(Â·; Ï•) and a real-time adapting model f(Â·; Î¸(t)) with Î¸(0) = Ï•. Streaming test data Ute(t) at time step t. Entropy of predictions H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc). Low entropy and high entropy thresholds el and eh. The number of cluster centroid budget NC (t) at time step t. Centroid increase number k. Learning step size Î·. 1: for t = 1, . . . , Tdo 2: Model inference on Ute(t) using f(Â·; Î¸(t âˆ’ 1)). 3: Dl(t) â† Dl(t âˆ’ 1) âˆª {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el} 4: Uh(t) â† {x|x âˆˆ Ute(t), H(f(x; Î¸)) > eh} 5: Dh(t) â† Dh(t âˆ’ 1) âˆª {(x, y)|âˆ€x âˆˆ IC(Dh(t âˆ’ 1), Uh(t), NC(t)), y= Oracle(x)} 6: Î»(t) â† |Dl(t)|/(|Dl(t)| + |Dh(t)|), |Dh(t)|/(|Dl(t)| + |Dh(t)|) 7: w(t) â† GetW(Î»(t)) â–· Generally, GetW(Î»(t)) = Î»(t) is a fair choice. 8: Î¸(t) â† Î¸(t âˆ’ 1) 9: for (xl, yl) in Dl and (xh, yh) in Dh do 10: Î¸(t) â† Î¸(t) âˆ’ Î·w0âˆ‡â„“CE (f(xl; Î¸(t)), yl) âˆ’ Î·(1 âˆ’ w0)âˆ‡â„“CE (f(xh; Î¸(t)), yh) 11: end for 12: NC (t + 1) â† UpdateCentroidNum(NC (t)) â–· Naive choice: NC (t + 1) â† NC (t) + k. 13: end for clusters cannot be stored efficiently, we store the representative samples of clusters, named anchors, instead. In this work, we adopt weighted K-means (Krishna and Murty, 1999) as our base clustering method due to its popularity and suitability for new setting explorations. When we apply clustering with new samples, a previously selected anchor should not weigh the same as new samples since the anchor is a representation of a cluster,i.e., a representation of many samples. Instead, the anchor should be considered as a barycenter with a weight of the sum of its clusterâ€™s sample weights. For a newly added cluster, its new anchor has the weight of the whole cluster. For clusters containing multiple old anchors, i.e., old clusters, the increased weights are distributed equally among these anchors. These increased weights are contributed by new samples that are close to these old anchors. Intuitively, this process of clustering is analogous to the process of planet formation. Where there are no planets, new planets (anchors) will be formed by the aggregation of the surrounding material (samples). Where there are planets, the matter is absorbed by the surrounding planets. This example is only for better understanding without specific technical meanings. Specifically, we provide the detailed Alg. 2 for incremental clustering. In each iteration, we apply weighted K-Means for previously selected anchors Danc and the new streaming-in unlabeled data Unew. We first extract all sample features using the model from the previous step f(Â·; Î¸(t âˆ’ 1)), and then cluster these weighted features. The initial weights of the new unlabeled samples are 1, while anchors inherit weights from previous iterations. After clustering, clusters including old anchors are old clusters, while clusters only containing new samples are newly formed ones. For each new cluster, we select the centroid-closest sample as the new anchor to store. As shown in line 10 of Alg. 2, for both old and new clusters, we distribute the sample weights in this cluster as its anchorsâ€™ weights. With incremental clustering, although we can control the number of clusters in each iteration, we cannot control the number of new clusters/new anchors. This indirect control makes the increase of new anchors adaptive to the change of distributions, but it also leads to indirect budget control. Therefore, in experimental studies, we set the budget limit, but the actual anchor budget will not reach this limit. The overall extra storage requirement is O(B) since the number of saved unlabeled samples is proportional to the number of saved labeled samples (anchors). 5 E XPERIMENTAL STUDIES In this study, we aim to validate the effectiveness of our proposed method, as well as explore the various facets of the ATTA setting. Specifically, we design experiments around the following research questions: RQ1: Can TTA methods address domain distribution shifts? RQ2: Is ATTA as efficient as TTA? RQ3: How do the components of SimATTA perform? RQ4: Can ATTA perform on par with stronger Active Domain Adaptation (ADA) methods? We compare ATTA with three settings, TTA (Tab. 2), enhanced TTA (Tab. 3 and 5), and ADA (Tab. 4). Datasets. To assess the OOD performance of the TTA methods, we benchmark them using datasets from DomainBed (Gulrajani and Lopez-Paz, 2020) and Hendrycks and Dietterich (2019a). We employ PACS (Li et al., 2017), VLCS (Fang et al., 2013), Office-Home (Venkateswara et al., 2017), and Tiny-ImageNet-C datasets for our evaluations. For each dataset, we designate one domain as 7Published as a conference paper at ICLR 2024 Table 2: TTA comparisons on PACS and VLCS.This table includes the two data stream mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. PACS Domain-wise data stream Post-adaptation Random data stream Post-adaptation P â†’Aâ†’ â†’Câ†’ â†’S P A C S â†’1â†’ â†’2â†’ â†’3â†’ â†’4 P A C S BN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 Tent (steps=1) N/A 67.29 64.59 44.67 97.60 66.85 64.08 42.58 56.35 54.09 51.83 48.58 97.19 63.53 60.75 41.56Tent (steps=10) N/A 67.38 57.85 20.23 62.63 34.52 40.57 13.59 47.36 31.01 22.84 20.33 50.78 23.68 20.95 19.62EATA N/A 67.04 64.72 50.27 98.62 66.50 62.46 48.18 57.31 56.06 58.17 59.78 98.62 69.63 65.70 54.26CoTTA N/A 65.48 62.12 53.17 98.62 65.48 63.10 53.78 56.06 54.33 57.16 57.42 98.62 65.97 62.97 54.62SAR (steps=1) N/A 66.75 63.82 49.58 98.32 66.94 62.93 45.74 56.78 56.35 56.68 56.70 98.44 68.16 64.38 52.53SAR (steps=10) N/A 69.38 68.26 49.02 96.47 62.16 56.19 54.62 53.51 51.15 51.78 45.60 94.13 56.64 56.02 36.37 SimATTA (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00SimATTA (B â‰¤500) N/A 77.93 76.02 76.30 98.62 88.33 83.49 83.74 68.46 78.22 80.91 85.49 99.16 86.67 84.77 87.71 VLCS Domain-wise data stream Post-adaptation Random data stream Post-adaptation C â†’Lâ†’ â†’Sâ†’ â†’V C L S V â†’1â†’ â†’2â†’ â†’3â†’ â†’4 C L S V BN w/o adapt 100.00 33.55 41.10 49.05 100.00 33.55 41.10 49.05 41.23 41.23 41.23 41.23 100.00 33.55 41.10 49.05BN w/ adapt 85.16 37.31 33.27 52.16 85.16 37.31 33.27 52.16 40.91 40.91 40.91 40.91 85.16 37.31 33.27 52.16 Tent (steps=1) N/A 38.55 34.40 53.88 84.73 43.86 33.61 53.11 44.85 44.29 47.38 44.98 85.30 43.49 37.81 53.35Tent (steps=10) N/A 45.41 31.44 32.32 42.54 37.65 27.79 33.12 46.13 42.31 43.51 39.48 52.01 40.32 33.64 40.37EATA N/A 37.24 33.15 52.58 84.10 37.69 32.39 52.49 43.77 42.48 43.34 41.55 83.32 36.67 31.47 52.55CoTTA N/A 37.39 32.54 52.25 82.12 37.65 33.12 52.90 43.69 42.14 43.21 42.32 81.98 37.99 33.52 53.23SAR (steps=1) N/A 36.18 34.43 52.46 83.96 39.72 36.53 52.37 43.64 43.04 44.20 41.93 85.09 40.70 36.44 53.02SAR (steps=10) N/A 35.32 34.10 51.66 82.12 41.49 33.94 53.08 43.56 42.05 42.53 41.16 85.09 37.58 33.12 52.01 SimATTA (B â‰¤300) N/A 62.61 65.08 74.38 99.93 69.50 66.67 77.34 62.33 69.33 73.20 71.93 99.93 69.43 72.46 80.39SimATTA (B â‰¤500) N/A 63.52 68.01 76.13 99.51 70.56 73.10 78.35 62.29 70.45 73.50 72.02 99.43 70.29 72.55 80.18 the source domain and arrange the samples from the other domains to form the test data stream. For DomainBed datasets, we adopt two stream order strategies. The first order uses a domain-wise data stream, i.e., we finish streaming samples from one domain before starting streaming another domain. The second order is random, where we shuffle samples from all target domains and partition them into four splits 1, 2, 3, and 4, as shown in Tab. 2. More dataset details are provided in Appx. G.1. Baselines. For baseline models, we start with the common source-only models, which either utilize pre-calculated batch statistics (BN w/o adapt) or test batch statistics (BN w/ adapt). For comparison with other TTA methods, we consider four state-of-the-art TTA methods: Tent (Wang et al., 2021), EATA (Niu et al., 2022), CoTTA (Wang et al., 2022a), and SAR (Niu et al., 2023). The three of them except Tent provide extra design to avoid CF. To compare with ADA methods, we select algorithms that are partially comparable with our method, i.e., they should be efficient (e.g., uncertainty-based) without the requirements of additional networks. Therefore, we adopt random, entropy (Wang and Shang, 2014), k-means (Krishna and Murty, 1999), and CLUE (Prabhu et al., 2021) for comparisons. Settings. For TTA, we compare with general TTA baselines in streaming adaptation using the two aforementioned data streaming orders, domain-wise and random. We choose P in PACS and C in VLCS as source domains. For domain-wise data stream, we use order A â†’ C â†’ S for PACS and L â†’ S â†’ V for VLCS. We report the real-time adaptation accuracy results for each split of the data stream, as well as the accuracy on each domain after all adaptations through the data stream (under â€œpost-adaptationâ€ columns). Enhanced TTA is built on TTA with access to extra random sample labels. TTA baselines are further fine-tuned with these random samples. To further improve enhanced TTA, we use long-term label storage and larger unlabeled sample pools. To its extreme where the model can access the whole test set samples, the setting becomes similar to ADA, thus we also use ADA methods for comparisons. ADA baselines have access to all samples in the pre-collected target datasets but not source domain data, whereas our method can only access the streaming test data. 5.1 T HE FAILURE OF TEST-TIME ADAPTATION The failure of TTA methods on domain distribution shifts is one of the main motivations of the ATTA setting. As shown in Tab. 2, TTA methods cannot consistently outperform eventhe simplest baseline \"BN w/ adapt\" which uses test time batch statistics to make predictions, evidencing that current TTA methods cannot solve domain distribution shifts (RQ1). Additionally, Tent (step=10) exhibits significant CF issues, where \"step=10\" indicates 10 test-time training updates, i.e., 10 gradient backpropagation iterations. This failure of TTA methods necessitates the position of ATTA. In contrast, SimATTA, with a budget B less than 300, outperforms all TTA methods on both source and target domains by substantial margins. Moreover, compared to the source-only baselines, our method improves the target domain performances significantly with negligible source performance loss, showing that ATTA is a more practically effective setting for real-world distribution shifts. 5.2 E FFICIENCY & ENHANCED TTA SETTING COMPARISONS To validate the efficiency of ATTA and broaden the dataset choice, we conduct this study on Tiny- ImageNet-C which, though does not focus on domain shifts, is much larger than PACS and VLCS. we 8Published as a conference paper at ICLR 2024 Table 3: Comparisons with Enhanced TTA on Tiny-ImageNet-C (severity level 5). Tiny-ImageNet-C Time (sec)Noise Blur Weather Digital Gauss. Shot Impul. Defoc. Glass Motion Zoom Snow Frost Fog Contr. Elastic Pixel JPEG Avg. Tent (step=1) 68.83 9.32 11.97 8.86 10.43 7.00 12.20 14.34 13.58 15.46 13.55 3.99 13.31 17.79 18.61 12.17Tent (step=10) 426.90 0.86 0.63 0.52 0.52 0.55 0.54 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.54EATA 93.14 3.98 3.33 2.18 4.80 2.37 11.02 11.41 14.06 15.26 9.65 1.36 9.88 14.24 12.12 8.26CoTTA 538.78 5.63 7.12 6.31 8.05 5.74 9.68 10.55 11.75 12.00 11.15 4.17 5.35 7.82 8.90 8.16SAR (step=1) 113.76 8.90 3.11 1.67 1.55 1.47 1.35 1.19 1.03 1.04 0.93 0.83 1.00 0.74 0.77 1.83SAR (step=10) 774.11 2.67 3.26 2.38 1.64 1.85 2.49 3.16 3.81 2.72 3.12 0.81 3.47 4.04 1.76 2.66 SimATTA (step=10) 736.289.68 19.40 12.14 30.28 17.03 42.36 43.10 31.96 40.08 29.243.21 34.56 45.24 45.74 28.86 enhance the TTA setting by fine-tuning baselines on randomly selected labeled samples. Specifically, the classifier of ResNet18-BN is pre-adapted to the brightness corruption (source domain) before test-time adapting. SimATTAâ€™s label budget is around 4,000, while all other TTA methods have budget 4,500 for randomly selected labeled samples. The data stream order is shown in Tab. 3. Time is measured across all corrupted images in the Noise and Blur noise types, and the values represent the average time cost for adapting 10,000 images. The results clearly evidence the efficiency of ATTA (RQ2), while substantially outperforming all enhanced TTA baselines. Simply accessing labeled samples cannot benefit TTA methods to match ATTA. With 10 training updates (step=10) for each batch, FTTA methods would suffer from severe CF problem. In contrast, ATTA covers a statistically significant distribution, achieving stronger performances with 10 training updates or even more steps till approximate convergences. In fact, longer training on Tent (step=10) leads to worse results (compared to step=1), which further motivates the design of the ATTA setting. The reason for higher absolute time cost in Tab. 3 is due to differences in training steps. In this experiment, SimATTA has a training step of 10, and similar time cost as SAR per step. Note that if the enhanced TTA setting is further improved to maintain distributions with a balanced CF mitigation strategy and an incremental clustering design, the design approaches ATTA. Specifically, we compare SimATTA with its variants as the ablation study (RQ3) in Appx. I.2. 5.3 C OMPARISONS TO A STRONGER SETTING : ACTIVE DOMAIN ADAPTATION Table 4: Comparisons to ADA baselines. Source domains are denoted as \"(S)\". Results are average accuracies (with standard deviations). PACS P (S) A C S Random (B= 300) 96.21 (0.80) 81.19 (0.48) 80.75 (1.27) 84.34 (0.18)Entropy (B= 300) 96.31 (0.64)88.00 (1.46)82.48 (1.71) 80.55 (1.01)Kmeans (B= 300) 93.71 (1.50) 79.31 (4.01) 79.64 (1.44) 83.92 (0.65)CLUE (B= 300) 96.69 (0.17)83.97 (0.57)84.77 (0.88) 86.91 (0.26) SimATTA (B â‰¤300) 98.89 (0.09)84.69 (0.22)83.09 (0.83)83.76 (2.24) VLCS C (S) L S V Random (B= 300) 96.21 (1.65) 66.67 (1.70) 70.72 (0.30) 72.14 (1.71)Entropy (B= 300) 97.74 (1.56) 69.29 (2.26)69.25 (4.77) 75.26 (3.07)Kmeans (B= 300) 98.61 (0.27)67.57 (1.64)70.77 (0.01)74.49 (0.97)CLUE (B= 300) 85.70 (10.09) 65.29 (1.49) 69.42 (2.64) 69.09 (6.05) SimATTA (B â‰¤300) 99.93 (0.00) 69.47 (0.03)69.57 (2.90)78.87 (1.53) In addtion to the above comparisons with (en- hanced) TTA, which necessitate the requirement of extra information in the ATTA setting, we com- pare ATTA with a stronger setting Active Domain Adaptation (ADA) to demonstrate another supe- riority of ATTA, i.e., weaker requirements for comparable performances (RQ4). ADA baselines are able to choose the global best active samples, while ATTA has to choose samples from a small sample buffer (e.g., a size of 100) and discard the rest. Tab. 4 presents the post-adaptation model per- formance results. All ADA results are averaged from 3 random runs, while ATTA results are the post-adaptation performances averaged from the two data stream orders. As can be observed, despite the lack of a pre-collected target dataset, SimATTA produces better or competitive results against ADA methods. Moreover, without source data access, SimATTAâ€™s design for CF allows it to maintain superior source domain performances over ADA methods. Further experimental studies including the Office-Home dataset are provided in Appx. I. In conclusion, the significant improvement compared to weaker settings (TTA, enhanced TTA) and the comparable performance with the stronger setting, ADA, rendering ATTA a setting that is as efficient as TTA and as effective as ADA. This implies its potential is worthy of future explorations. 6 C ONCLUSION AND DISCUSSION Thereâ€™s no denying that OOD generalization can be extremely challenging without certain information, often relying on various assumptions easily compromised by different circumstances. Thus, itâ€™s prudent to seek methods to achieve significant improvements with minimal cost, e.g., DG methods leveraging environment partitions and ATTA methods using budgeted annotations. As justified in our theoretical and experimental studies, ATTA stands as a robust approach to achieve real-time OOD generalization. Although SimATTA sets a strong baseline for ATTA, thereâ€™s considerable scope for further investigation within the ATTA setting. One potential direction involves developing alternatives to prevent CF in ATTA scenarios. While selective entropy minimization on low-entropy samples has prove to be empirically effective, it relies on the quality of the pre-trained model and training on incorrectly predicted low-entropy samples may reinforce the errors. It might not be cost-effective to expend annotation budgets on low-entropy samples, but correcting them could be a viable alternative solution. We anticipate that our work will spur numerous further explorations in this field. 9Published as a conference paper at ICLR 2024 ACKNOWLEDGMENTS This work was supported in part by National Science Foundation grant IIS-2006861 and National Institutes of Health grant U01AG070112. REFERENCES Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, and Mario Marchand. Domain- adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014. Lucas Baier, Tim SchlÃ¶r, Jakob SchÃ¶ffer, and Niklas KÃ¼hl. Detecting concept drift with neural network model uncertainty. In Hawaii International Conference on System Sciences, 2021. URL https://api.semanticscholar.org/CorpusID:235731947. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79:151â€“175, 2010. Davide Cacciarelli and Murat Kulahci. A survey on online active learning, 2023. Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, and Pheng-Ann Heng. Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part V 24, pages 225â€“235. Springer, 2021. Li Chen, Tutian Tang, Zhitian Cai, Yang Li, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, and Yu Qiao. Level 2 autonomous driving on a single device: Diving into the devils of openpilot. arXiv preprint arXiv:2206.08176, 2022a. Weijie Chen, Luojun Lin, Shicai Yang, Di Xie, Shiliang Pu, and Yueting Zhuang. Self-supervised noisy label learning for source-free unsupervised domain adaptation. In 2022 IEEE/RSJ In- ternational Conference on Intelligent Robots and Systems (IROS) , pages 10185â€“10192. IEEE, 2022b. Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. Advances in Neural Information Processing Systems, 33:21061â€“21071, 2020. David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models. Journal of artificial intelligence research, 4:129â€“145, 1996. Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, AleÅ¡ Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366â€“3385, 2021. Yuhe Ding, Lijun Sheng, Jian Liang, Aihua Zheng, and Ran He. Proxymix: Proxy-based mixup training with label refinery for source-free domain adaptation. arXiv preprint arXiv:2205.14566, 2022. Cian Eastwood, Ian Mason, Christopher KI Williams, and Bernhard SchÃ¶lkopf. Source-free adaptation to measurement shift via bottom-up feature restoration. arXiv preprint arXiv:2107.05446, 2021. Jiahao Fan, Hangyu Zhu, Xinyu Jiang, Long Meng, Chen Chen, Cong Fu, Huan Yu, Chenyun Dai, and Wei Chen. Unsupervised domain adaptation by statistics alignment for deep sleep staging networks. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30:205â€“216, 2022. Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision, pages 1657â€“1664, 2013. Yuqi Fang, Pew-Thian Yap, Weili Lin, Hongtu Zhu, and Mingxia Liu. Source-free unsupervised domain adaptation: A survey. arXiv preprint arXiv:2301.00265, 2022. Francois Fleuret et al. Uncertainty reduction for model adaptation in semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9613â€“9623, 2021. 10Published as a conference paper at ICLR 2024 Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180â€“1189. PMLR, 2015. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096â€“2030, 2016. Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004. Shurui Gui, Chaoyue Wang, Qihua Chen, and Dacheng Tao. Featureflow: Robust video interpolation via structure-to-texture generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14004â€“14013, 2020. Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL https://openreview.net/forum?id=8hHg-zs_p-h. Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770â€“778, 2016. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. March 2019a. doi: 10.48550/ARXIV .1903.12261. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019b. Steven CH Hoi, Rong Jin, Jianke Zhu, and Michael R Lyu. Semisupervised svm batch mode active learning with applications to image retrieval. ACM Transactions on Information Systems (TOIS), 27(3):1â€“29, 2009. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 17853â€“17862, 2023. Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. Model adaptation: Historical contrastive learning for unsupervised domain adaptation without source data. Advances in Neural Information Processing Systems, 34:3635â€“3649, 2021. Masato Ishii and Masashi Sugiyama. Source-free domain adaptation via distributional alignment by matching batch normalization statistics. arXiv preprint arXiv:2101.10842, 2021. Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. Advances in Neural Information Processing Systems, 34:2427â€“2440, 2021. Suyog Dutt Jain and Kristen Grauman. Active image segmentation propagation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2864â€“2873, 2016. Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. Contrastive adaptation network for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4893â€“4902, 2019. Ashish Kapoor, Kristen Grauman, Raquel Urtasun, and Trevor Darrell. Active learning with gaussian processes for object categorization. In 2007 IEEE 11th international conference on computer vision, pages 1â€“8. IEEE, 2007. Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu. Test-time adaptable neural networks for robust medical image segmentation. Medical Image Analysis, 68:101907, 2021. 11Published as a conference paper at ICLR 2024 Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and Christopher Kanan. Measuring catastrophic forgetting in neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018. Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In VLDB, volume 4, pages 180â€“191. Toronto, Canada, 2004. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114 (13):3521â€“3526, 2017. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal- subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637â€“5664. PMLR, 2021. Divya Kothandaraman, Sumit Shekhar, Abhilasha Sancheti, Manoj Ghuhan, Tripti Shukla, and Dinesh Manocha. Salad: Source-free active label-agnostic domain adaptation for classification, segmentation and detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 382â€“391, 2023. K Krishna and M Narasimha Murty. Genetic k-means algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29(3):433â€“439, 1999. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu- tional neural networks. Communications of the ACM, 60(6):84â€“90, 2017. David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrap- olation (REx). In International Conference on Machine Learning , pages 5815â€“5826. PMLR, 2021. Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In Proceedings of the IEEE/CVF winter conference on applications of computer vision, pages 615â€“625, 2021. David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine learning proceedings 1994, pages 148â€“156. Elsevier, 1994. Aodong Li, Alex Boyd, Padhraic Smyth, and Stephan Mandt. Detecting and adapting to irregular distribution shifts in bayesian online learning. Advances in neural information processing systems, 34:6816â€“6828, 2021a. Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542â€“5550, 2017. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9641â€“9650, 2020. Xianfeng Li, Weijie Chen, Di Xie, Shicai Yang, Peng Yuan, Shiliang Pu, and Yueting Zhuang. A free lunch for unsupervised domain adaptive object detection without source data. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 8474â€“8481, 2021b. Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935â€“2947, 2017. Jian Liang, Dapeng Hu, Ran He, and Jiashi Feng. Distill and fine-tune: Effective adaptation from a black-box source model. arXiv preprint arXiv:2104.01539, 1(3), 2021. Jian Liang, Dapeng Hu, Jiashi Feng, and Ran He. Dine: Domain adaptation from single and multiple black-box predictors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8003â€“8013, 2022. 12Published as a conference paper at ICLR 2024 Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without environment partition? Advances in Neural Information Processing Systems, 35:24529â€“24542, 2022. Xiaofeng Liu, Fangxu Xing, Chao Yang, Georges El Fakhri, and Jonghye Woo. Adapting off-the- shelf source segmenter for target medical image segmentation. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part II 24, pages 549â€“559. Springer, 2021a. Xinyu Liu and Yixuan Yuan. A source-free domain adaptive polyp detection framework with style diversification flow. IEEE Transactions on Medical Imaging, 41(7):1897â€“1908, 2022. Yuang Liu, Wei Zhang, Jun Wang, and Jianyong Wang. Data-free knowledge transfer: A survey. arXiv preprint arXiv:2112.15278, 2021b. Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems, 34:21808â€“21820, 2021c. Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97â€“105. PMLR, 2015. David Lopez-Paz and Marcâ€™Aurelio Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017. Chaochao Lu, Yuhuai Wu, JosÃ© Miguel HernÃ¡ndez-Lobato, and Bernhard SchÃ¶lkopf. Invariant causal representation learning for out-of-distribution generalization. In International Conference on Learning Representations, 2021. Xinhong Ma, Junyu Gao, and Changsheng Xu. Active universal domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8968â€“8977, 2021. Haitao Mao, Lun Du, Yujia Zheng, Qiang Fu, Zelin Li, Xu Chen, Shi Han, and Dongmei Zhang. Source free unsupervised graph domain adaptation. arXiv preprint arXiv:2112.00955, 2021. Christoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, and Jean Oh. Core challenges of social robot navigation: A survey. ACM Transactions on Human-Robot Interaction, 12(3):1â€“39, 2023. Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Munan Ning, Donghuan Lu, Dong Wei, Cheng Bian, Chenglang Yuan, Shuang Yu, Kai Ma, and Yefeng Zheng. Multi-anchor active domain adaptation for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9112â€“9122, 2021. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In International conference on machine learning, pages 16888â€“16905. PMLR, 2022. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. InThe Eleventh International Con- ference on Learning Representations, 2023. URL https://openreview.net/forum?id=g2YraF75Tj. Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE transactions on neural networks, 22(2):199â€“210, 2010. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019. 13Published as a conference paper at ICLR 2024 Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53â€“69, 2015. Judea Pearl. Causality. Cambridge university press, 2009. Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal of machine Learning research, 12:2825â€“2830, 2011. Jonas Peters, Peter BÃ¼hlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947â€“1012, 2016. Jonas Peters, Dominik Janzing, and Bernhard SchÃ¶lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017. Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, and Judy Hoffman. Active domain adaptation via clustering uncertainty-weighted embeddings. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8505â€“8514, 2021. Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. arXiv preprint arXiv:2010.05761, 2020. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019. Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normal- ization help optimization? Advances in neural information processing systems, 31, 2018. Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford, and Jordan T. Ash. Streaming active learning with deep neural networks. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 30005â€“30021. PMLR, 23â€“29 Jul 2023. URL https://proceedings.mlr. press/v202/saran23a.html. Harald Schafer, Eder Santana, Andrew Haden, and Riccardo Biasini. A commute in data: The comma2k19 dataset, 2018. Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for informa- tion extraction. In Advances in Intelligent Data Analysis: 4th International Conference, IDA 2001 Cascais, Portugal, September 13â€“15, 2001 Proceedings 4, pages 309â€“318. Springer, 2001. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539â€“11551, 2020. Burr Settles. Active learning literature survey. 2009. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji, and Manmohan Chandraker. Active adversarial domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 739â€“748, 2020. Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443â€“450. Springer, 2016. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229â€“9248. PMLR, 2020. 14Published as a conference paper at ICLR 2024 Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472â€“7481, 2018. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE international conference on computer vision, pages 4068â€“4076, 2015. Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7167â€“7176, 2017. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018â€“5027, 2017. Sudheendra Vijayanarasimhan and Ashish Kapoor. Visual recognition and detection under bounded computational resources. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 1006â€“1013. IEEE, 2010. Dan Wang and Yi Shang. A new active labeling method for deep learning. In 2014 International joint conference on neural networks (IJCNN), pages 112â€“119. IEEE, 2014. Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test- time adaptation by entropy minimization. InInternational Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c. Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing, 312: 135â€“153, 2018. Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201â€“7211, 2022a. Rui Wang, Zuxuan Wu, Zejia Weng, Jingjing Chen, Guo-Jun Qi, and Yu-Gang Jiang. Cross-domain contrastive learning for unsupervised domain adaptation. IEEE Transactions on Multimedia , 2022b. Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):1â€“46, 2020. Binhui Xie, Longhui Yuan, Shuang Li, Chi Harold Liu, Xinjing Cheng, and Guoren Wang. Active learning for domain adaptation: An energy-based approach. InProceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8708â€“8716, 2022. Zhao Xu, Kai Yu, V olker Tresp, Xiaowei Xu, and Jizhi Wang. Representative sampling for text classification using support vector machines. In Advances in Information Retrieval: 25th European Conference on IR Research, ECIR 2003, Pisa, Italy, April 14â€“16, 2003. Proceedings 25, pages 393â€“407. Springer, 2003. Baoyao Yang, Hao-Wei Yeh, Tatsuya Harada, and Pong C Yuen. Model-induced generalization error bound for information-theoretic representation learning in source-data-free unsupervised domain adaptation. IEEE Transactions on Image Processing, 31:419â€“432, 2021a. Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu Sebe, and Elisa Ricci. Transformer-based source-free domain adaptation. arXiv preprint arXiv:2105.14138, 2021b. Jianfei Yang, Xiangyu Peng, Kai Wang, Zheng Zhu, Jiashi Feng, Lihua Xie, and Yang You. Divide to adapt: Mitigating confirmation bias for domain adaptation of black-box predictors. arXiv preprint arXiv:2205.14467, 2022. H Yao, Yuhong Guo, and Chunsheng Yang. Source-free unsupervised domain adaptation with surrogate data generation. In Proceedings of NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021. 15Published as a conference paper at ICLR 2024 Hao-Wei Yeh, Baoyao Yang, Pong C Yuen, and Tatsuya Harada. Sofa: Source-data-free feature alignment for unsupervised domain adaptation. InProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 474â€“483, 2021. Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. Hu Yu, Jie Huang, Yajing Liu, Qi Zhu, Man Zhou, and Feng Zhao. Source-free domain adaptation for real-world image dehazing. In Proceedings of the 30th ACM International Conference on Multimedia, pages 6645â€“6654, 2022. Haojian Zhang, Yabin Zhang, Kui Jia, and Lei Zhang. Unsupervised domain adaptation of black-box source models. arXiv preprint arXiv:2101.02839, 2021. Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. Advances in Neural Information Processing Systems, 35:38629â€“38642, 2022a. Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan. Adanpc: Exploring non-parametric classifier for test-time adaptation. In International Conference on Machine Learning, pages 41647â€“41676. PMLR, 2023. Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2339â€“2348, 2022b. Bowen Zhao, Chen Chen, and Shu-Tao Xia. Delta: degradation-free fully test-time adaptation. arXiv preprint arXiv:2301.13018, 2023a. Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023b. Chunting Zhou, Xuezhe Ma, Paul Michel, and Graham Neubig. Examining and combating spurious features under distribution shift. In International Conference on Machine Learning, pages 12857â€“ 12867. PMLR, 2021. 16Published as a conference paper at ICLR 2024 Active Test-Time Adaptation: Foundational Analyses and An Algorithm Supplementary Material A B ROADER IMPACTS The field of domain generalization primarily concentrates on enhancing a modelâ€™s generalization abilities by preparing it thoroughly before deployment. However, it is equally important for deep learning applications to have the capacity for real-time adaptation, as no amount of preparation can account for all possible scenarios. Consequently, domain generalization and test-time adaptation are complementary strategies: the former is more weighty and extensive, while the latter is more agile, lightweight and privacy-friendly. This work delves into the development of a real-time model adaptation strategy that can be applied to any pre-trained models, including large language models, to enhance their adaptive capabilities. Our research does not involve any human subjects or dataset releases, nor does it raise any ethical concerns. Since this work does not directly tie to specific applications, we do not foresee any immediate negative societal impacts. Nonetheless, we acknowledge that any technological advancement may carry potential risks, and we encourage the continued assessment of the broader impacts of real-time adaptation methodologies in various contexts. B FAQ & D ISCUSSIONS To facilitate the reviewing process, we summarize the answers to the questions that arose during the discussion of an earlier version of this paper. The major updates of this version are reorganized theoretical studies, incremental clustering details, experimental reorganization, and additional datasets and settings . We include more related field comparisons to distinguish different settings. We also cover the position of this paper in literature and the main claims of this paper. Finally, we will frankly acknowledge the limitations of this paper, explain and justify the scope of coverage, and provide possible future directions. Q1: What is the relationship between the proposed ATTA protocol and stream based active learning (Saran et al., 2023)? A: We would like to discuss the difference between our work and the referenced work. 1. Real-time Training Distinction: Saran et al. (2023) doesnâ€™t operate in real-time capacity. This is evident from their experiments, where their model is trained only after completing a round. In contrast, our work involves training the model post each batch. This positions Saran et al. (2023)â€™s work as an intrinsic active learning technique, while our approach leans towards TTA methods. 2. Continual Training Nuance: Following the point above, Saran et al. (2023) stands out of the scope of continual training. As they mentioned â€˜each time new data are acquired, the ResNet is reset to the ImageNet pre-trained weights before being updatedâ€˜, Saran et al. (2023) starts afresh with each iteration and is out of scope for CF discussions. Contrarily, our model is continuously trained on varying distributions, compelling us to address the CF issue while preserving advantages derived from various stored distributions. 3. Comparative Complexity: Given the aforementioned distinctions, itâ€™s evident that our task presents a greater challenge compared to theirs. In addition, we have included comparisons with stronger active learning settings in Sec. 5.3. Q2: What are the insights from the theoretically foundational analysis? A: 1. It sets a well-defined formulation and grounded theoretical framework for the ATTA setting. 2. While entropy minimizations can cause CF, balancing the learning rate and number of high/low entropy samples is conversely the key solution to both distribution shifts and 17Published as a conference paper at ICLR 2024 CF by corresponding benefits. Though adding low-entropy data is intuitive, it is crucial in that this simple operation can make methods either too conservative or too aggressive without the correct balancing conditions. 3. The studies in Sec. 3.1 directly present a feasible and guaranteed solution for imple- menting ATTA to tackle shifts while avoiding CF. The aligned empirical validations of Sec. 3.2 also instruct the implementation of SimATTA. Q3: In test-time adaptation, one important issue is that the number of testing samples in a batch may be small, which means the sample size m will also be very small. May it affect the theorem and make them become very loose? A: We consider this issue jointly from theoretical and empirical validations. 1. It is true that the theoretical bounds can be loose given a small size of m unlabeled test samples. This situation of the error bound is mathematically ascribed to the quotient between the VC-dimension d of the hypothesis class and m. Under the VC-dimension theory, the ResNet18 model we adopt should have d â‰« m. However, practically we perform fine-tuning on pre-trained models instead of training from scratch, which significantly reduces the scale of parameter update. In this case, an assumption can be established that fine-tuning a model is roughly equivalent to learning a model with a relatively small d (Appx. H). This assumption is potentially underpinned by the empirical alignment of our validation experiments with the theoretical framework (Fig. 1). To this end, experiments indicate thatd and m are practically of similar scale for our settings. This prevents our theoretical bounds from being very loose and meaningless in reality. 2. Regarding cases that our assumption does not apply, this issue would appear inevitable, since it is rigorously inherent in the estimation error of our streaming and varying test distributions. The distribution of a test stream can be hardly monitored when only a limited batch is allowed, which we consider as a limitation of TTA settings. Moreover, this issue directly implies the necessity of using a buffer for unlabeled samples. A good practice is to maintain a relatively comparable sample buffer scale. Q4: What distribution shifts can ATTA solve? A: We would like to follow (but not limited to) the work (Zhao et al., 2023b) to discuss the distribution shifts ATTA can solve. 1. As elucidated in Sec. 3.1 and Sec. 5, ATTA can solve domain generalization shifts. Domain generalization shifts include complex shifts on the joint data distribution P(X, Y), given X as the covariates and Y as the label variable. Since P(X, Y) = P(X)P(Y |X), ATTA can handle covariate shift (P(X)), label shift (P(Y )), and conditional shift (P(Y |X)). The shifts on both covariate and conditional distributions can cover the shift on labels, but they (covariate + conditional shifts) are more complicated than pure label shifts, where only the marginal label distribution changes while the conditional distribution remains. Note that the conditional shifts are generally caused by spurious correlations, where the independent causal mechanism assumption (Pearl, 2009) holds or no concept drifts exist. 2. In our framework, the distribution support of X at different time steps can be different, but we donâ€™t cover the situation where the support of Y changes, i.e., class-incremental problems. Q5: It is unclear how many samples are selected in each minibatch of testing samples. How the total budget is distributed across the whole testing data stream? A: The number of selected samples for each minibatch is decided jointly by the incremental clustering and the cluster centroid number NC (t). Intuitively, this sample selection is a dynamic process, with NC (t) restricting the budget and incremental clustering performing sample selection. For each batch, we increase applicable clustering centroids as a maximum limit, while the exact number of the selected samples is given by the incremental clustering by how many clusters are located in the scope of new distributions. e.g., if the incoming batch does not introduce new data distributions, then we select zero samples even with increased NC (t). In contrast, if the incoming batch contains data located in multiple new distributions, the incremental clustering tends to select more samples than the NC (t) limit, thus forcing to merging of multiple previous clusters into one new cluster. 18Published as a conference paper at ICLR 2024 The incremental clustering is detailed in Sec. 4.2, and NC (t) is naively increased by a constant hyper-parameter k. Therefore, the budget is adaptively distributed according to the data streaming distribution with budgets controlled by k, which is also the reason why we compare methods under a budget limit. Q6: Could compared methods have access to a few ground-truth labels as well? Making other algorithms be able to use the same amount of ground-truth labels randomly will produce fairer comparisons. A: 1. The enhanced TTA setting is exactly the setup we provide to produce fairer comparisons. See Tab. 3 and Tab. 5 for comparison results. 2. ATTA also compares to a stronger setting ADA which can access the whole test datasets multiple times. Table 5: The table demonstrates the comparisons on PACS where all enhanced TTA baselines have 300 budgets to randomly select labeled samples. The training steps of these labeled samples are the same as the original TTA method training steps. For accumulated sample selection, please refer to our ablation studies. Method Domain-wise data stream A VG Random data stream A VG Pâ†’ â†’Aâ†’ â†’Câ†’ â†’S P A C S 1 2 3 4 P A C S Source onlyBN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 TTA Tent (steps=1) N/A 70.07 68.43 64.42 97.72 74.17 72.61 68.92 61.20 62.36 66.59 67.32 98.14 74.37 70.26 66.07Tent (steps=10) N/A 76.27 63.78 49.35 59.46 38.62 48.46 55.03 56.20 53.22 52.55 55.55 58.32 47.56 60.75 58.00EATA N/A 69.53 66.94 61.42 98.56 69.38 66.60 64.83 60.34 59.81 64.38 65.02 98.68 73.78 68.30 59.74CoTTA N/A 66.55 63.14 59.91 90.12 61.67 66.68 67.68 57.26 57.36 63.46 65.64 92.22 71.53 70.44 62.41SAR (steps=1) N/A 66.60 63.78 50.34 98.38 67.87 64.04 49.48 57.21 56.06 56.78 57.14 98.38 68.80 64.59 53.02SAR (steps=10) N/A 69.09 66.55 49.07 96.23 62.50 59.34 46.53 49.76 52.74 48.51 49.06 95.39 57.13 54.61 38.76 Ours (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00 Q7: What is the position of ATTA? A: Comparisons with different settings are challenging. In this work, the design of our experiments (Sec. 5) is to overcome this challenge by comparing both weaker settings and stronger settings. While the significant performance over weaker settings renders the necessity of extra information, the comparable performance with stronger settings provides the potential to relax restricted requirements. Intuitively, ATTA is the most cost-effective option in the consideration of both efficiency and effectiveness. We further provide the following ATTA summary: ATTA, which incorporates active learning in FTTA, is the light, real-time, source-free, widely applicable setting to achieve high generalization performances for test-time adaptation. 1. Necessity: From the causality perspective, new information is necessary (Lin et al., 2022; Pearl, 2009; Peters et al., 2017) to attain generalizable over distribution shifts which are insurmountable within the current TTA framework. 2. Effectiveness: Compared to FTTA methods, ATTA produces substantially better perfor- mances, on-par with the costly active domain adaptation (ADA) methods as shown in Table 3 in the paper. 3. Efficiency: Relative to ADA methods, ATTA possesses superior efficiency, similar to general FTTA methods, as shown in Tab. 3. 4. Applicability: ATTA is a model-agnostic setting. (1) Compared to domain generalization methods, ATTA do not require re-training and has the potential to apply to any pre-trained models. One interesting future direction is designing ATTA methods for large language models (LLMs), where re-trainings are extremely expensive and source data may be in- accessible. (2) Compared to FTTA methods, ATTA can protect model parameters from corrupting while learning new distributions by fine-tuning pre-trained models, rendering it more feasible and practical. In comparison with existing works, ATTA is motivated to mitigate the limitations of previous settings: 1. FTTA: Limited generalization performance. 19Published as a conference paper at ICLR 2024 2. TTT: Not source-free; limited generalization performance. 3. ADA & domain adaptation/generalization: Expensive re-trainings; limited applicability to pre-trained models. 4. Online active learning: It does not maintain and protect adaptation performances for multiple distributions in one model and does not consider the CF problem. Q8: What is the potential practical utility of ATTA? A: 1. Empirically, our method can generally finish a round of sample selection/training of 100 frames in 5s, i.e., 20 frames per sec, which is more than enough to handle multiple practical situations. Experiments on time complexity are provided in Tab. 3, where SimATTA has comparable time efficiency. 2. As a case analysis, the autopilot system (Hu et al., 2023; Chen et al., 2022a) presents an application scenario requiring high-speed low-latency adaptations, while these adaptations are largely underexplored. When entering an unknown environment, e.g., a construction section, a system of ATTA setting can require the driver to take over the wheel. During the period of manual operation when the driver is handling the wheel, steering signals are generated, and the in-car system quickly adaptations. The system doesnâ€™t need to record 60 frames per second, since only the key steering operations and the corresponding dash cam frames are necessary, which can be handled by ATTA algorithms processing at 20 frames per sec. In this case, the human annotations are necessary and indirect. ATTA makes use of this information and adapts in the short term instead of collecting videos and having a long-round fine-tuning (Schafer et al., 2018). 3. In addition, many scenarios applicable for ATTA are less speed-demanding than the case above. One example is a personalized chatbot that subtly prompts and gathers user labels during user interaction. In a home decoration setting, applications can request that users scan a few crucial areas to ensure effective adaptation. Social robots (Mavrogiannis et al., 2023), e.g., vacuum robots, often require users to label critical obstacles theyâ€™ve encountered. 4. Compared with ADA, ATTA stands out as the tailored solution for the above scenarios. It does not require intensive retraining or server-dependent fine-tuning, offering both speed and computational efficiency. Meanwhile, akin to other TTA methods, ATTA also ensures user privacy. While it might marginally exceed the cost of standard TTA methods, the superior generalization ability makes it a compelling choice and justifies the additional expense. Q9: What can be covered by this paper? A: This paper endeavors to establish the foundational framework for a novel setting referred to as ATTA. We target (1) positioning the ATTA setting, (2) solving the two major and basic challenges of ATTA,i.e., the mitigation of distribution shifts and the avoidance of catastrophic forgetting (CF). We achieve the first goal by building the problem formulation and analyses, and further providing extensive qualitative and well-organized experimental comparisons with TTA, enhanced TTA, and ADA settings. These efforts position ATTA as the most cost-effective option between TTA and ADA, where ATTA inherits the efficiency of TTA and the effectiveness of ADA. With our theoretical analyses and the consistent algorithm design, we validate the success of our second goal through significant empirical performances. Q10: What are not covered by this paper? A: Constructing a new setting involves multifaceted complexities. Although there are various potential applications discussed above including scaling this setting up for large models and datasets, we cannot cover them in this single piece of work. There are three main reasons. First, the topics covered by a single paper are limited. Formally establishing ATTA setting and addressing its major challenges of ATTA takes precedence over exploring practical applications. Secondly, given the interrelations between ATTA and other settings, our experimental investigations are predominantly comparative, utilizing the most representative datasets from TTA and domain adaptation to showcase persuasive results. Thirdly, many practical applications necessitate task-specific configurations, rendering them unsuitable for establishing a universal learning setting. While the current focus is on laying down the foundational aspects of ATTA, the exploration of more specialized applications remains a prospective avenue for future work in the ATTA domain. 20Published as a conference paper at ICLR 2024 C R ELATED WORKS The development of deep learning witnesses various applications (He et al., 2016; Gui et al., 2020). To tackle OOD problem, various domain generalization works emerge (Krueger et al., 2021; Sagawa et al., 2019). C.1 U NSUPERVISED DOMAIN ADAPTATION Unsupervised Domain Adaptation (UDA) (Pan et al., 2010; Patel et al., 2015; Wilson and Cook, 2020; Wang and Deng, 2018) aims at mitigating distribution shifts between a source domain and a target domain, given labeled source domain samples and unlabeled target samples. UDA methods generally rely on feature alignment techniques to eliminate distribution shifts by aligning feature distributions between source and target domains. Typical feature alignment techniques include discrepancy minimization (Long et al., 2015; Sun and Saenko, 2016; Kang et al., 2019) and adversarial training (Ganin and Lempitsky, 2015; Tsai et al., 2018; Ajakan et al., 2014; Ganin et al., 2016; Tzeng et al., 2015; 2017). Nevertheless, alignments are normally not guaranteed to be correct, leading to the alignment distortion problem as noted by Ning et al. (2021). Source-free Unsupervised Domain Adaptation (SFUDA) (Fang et al., 2022; Liu et al., 2021b) algorithms aim to adapt a pre-trained model to unlabeled target domain samples without access to source samples. Based on whether the algorithm can access model parameters, these algorithms are categorized into white-box and black-box methods. White-box SFUDA typically considers data recovery (generation) and fine-tuning methods. The former focuses on recovering source- like data (Ding et al., 2022; Yao et al., 2021), e.g., training a Generative Adversarial Network (GAN) (Kurmi et al., 2021; Li et al., 2020), while the latter employs various techniques (Mao et al., 2021), such as knowledge distillation (Chen et al., 2022b; Liu and Yuan, 2022; Yang et al., 2021b; Yu et al., 2022), statistics-based domain alignment (Ishii and Sugiyama, 2021; Liu et al., 2021a; Fan et al., 2022; Eastwood et al., 2021), contrastive learning (Huang et al., 2021; Wang et al., 2022b), and uncertainty-based adaptation (Gawlikowski et al., 2021; Fleuret et al., 2021; Chen et al., 2021; Li et al., 2021b). Black-box SFUDA cannot access model parameters and often relies on self-supervised knowledge distillation (Liang et al., 2022; 2021), pseudo-label denoising (Zhang et al., 2021; Yang et al., 2022), or generative distribution alignment (Yeh et al., 2021; Yang et al., 2021a). C.2 T EST-TIME ADAPTATION Test-time Adaptation (TTA), especially Fully Test-time Adaptation (FTTA) algorithms (Wang et al., 2021; Iwasawa and Matsuo, 2021; Karani et al., 2021; Nado et al., 2020; Schneider et al., 2020; Wang et al., 2022a; Zhao et al., 2023a; Niu et al., 2022; Zhang et al., 2022a; Niu et al., 2023; You et al., 2021; Zhang et al., 2022b), can be considered as realistic and lightweight methods for domain adaptation. Built upon black-box SFUDA, FTTA algorithms eliminate the requirement of a pre-collected target dataset and the corresponding training phase. Instead, they can only access an unlabeled data stream and apply real-time adaptation and training. In addition to FTTA, Test-time Training (TTT) (Sun et al., 2020; Liu et al., 2021c) often relies on appending the original network with a self-supervised task. TTT methods require retraining on the source dataset to transfer information through the self-supervised task. Although they do not access the source dataset during the test-time adaptation phase, TTT algorithms are not off-the-shelf source-free methods. TTA is a promising and critical direction for real-world applications, but current entropy minimization-based methods can be primarily considered as feature calibrations that require high-quality pseudo-labels. This requirement, however, can be easily violated under larger distribution shifts. Current TTA algorithms, inheriting UDA drawbacks, cannot promise good feature calibration results, which can be detrimental in real-world deployments. For instance, entropy minimization on wrongly predicted target domain samples with relatively low entropy can only exacerbate spurious correla- tions (Chen et al., 2020). Without extra information, this problem may be analogous to applying causal inference without intervened distributions, which is intrinsically unsolvable (Peters et al., 2016; Pearl, 2009). This paper aims to mitigate this issue with minimal labeled target domain samples. To minimize the cost, we tailor active learning techniques for TTA settings. It is worth noting that a recent work AdaNPC (Zhang et al., 2023) is essentially a domain gener- alization method with a TTA phase attached, while our ATTA is built based on the FTTA setting. Specifically, Current FTTA methods and our work cannot access the source domain. In contrast, 21Published as a conference paper at ICLR 2024 AdaNPC accesses source data to build its memory bank, circumventing the catastrophic forgetting problem. Furthermore, AdaNPC requires multiple source domains and training before performing TTA. Thus AdaNPC uses additional information on domain labels and retraining resources for its memory bank, undermining the merits of FTTA. Regarding theoretical bounds, their target domain is bounded by source domain error and model estimations (in big-O expression), while we consider active sample learning and time variables for varying test distributions. C.3 C ONTINUAL DOMAIN ADAPTATION Many domain adaptation methods focus on improving target domain performance, neglecting the performance on the source domain, which leads to the CF problem (Kemker et al., 2018; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lopez-Paz and Ranzato, 2017; De Lange et al., 2021; Wang et al., 2022a; Niu et al., 2022). This issue arises when a neural network, after being trained on a sequence of domains, experiences a significant degradation in its performance on previously learned domains as it continues to learn new domains. Continual learning, also known as lifelong learning, addresses this problem. Recent continual domain adaptation methods have made significant progress by employing gradient regularization, random parameter restoration, buffer sample mixture, and more. Although the CF problem is proposed in the continual learning field, it can occur in any source-free OOD settings since the degradation caused by CF is attributed to the networkâ€™s parameters being updated to optimize performance on new domains, which may interfere with the representations learned for previous domains. C.4 A CTIVE DOMAIN ADAPTATION Active Domain Adaptation (ADA) (Prabhu et al., 2021; Ning et al., 2021; Su et al., 2020; Ma et al., 2021; Xie et al., 2022) extends semi-supervised domain adaptation with active learning strate- gies (Cohn et al., 1996; Settles, 2009), aiming to maximize target domain performance with a limited annotation budget. Therefore, the key challenge of active learning algorithms is selecting the most informative unlabeled data in target domains (Kapoor et al., 2007). Sample selection strategies are of- ten based on uncertainty (Lewis and Catlett, 1994; Scheffer et al., 2001), diversity (Jain and Grauman, 2016; Hoi et al., 2009), representativeness (Xu et al., 2003), expected error minimization (Vijaya- narasimhan and Kapoor, 2010), etc. Among these methods, uncertainty and diversity-based methods are simple and computationally efficient, making them the most suitable choices to tailor for TTA settings. Adapting these strategies is non-trivial because, compared to typical active domain adaptation, our proposed Active Test-time Adaptation (ATTA) setting does not provide access to source data, model parameters, or pre-collected target samples. This requirement demands that our active sample selection algorithm select samples for annotation during data streaming. Consequently, this active sampling selection process is non-regrettable, i.e., we can only meet every sample once in a short period. To avoid possible confusion, compared to the recent Source-free Active Domain Adaptation (SFADA) method SALAD (Kothandaraman et al., 2023), we do not require access to model parameter gradients, training additional neural networks, or pre-collected target datasets. Therefore, our ATTA setting is quite different, much lighter, and more realistic than ADA and SFADA. C.5 A CTIVE ONLINE LEARNING The most related branch of active online learning (AOL) (Cacciarelli and Kulahci, 2023) is active online learning on drifting data stream (Zhou et al., 2021; Baier et al., 2021; Li et al., 2021a). Generally, these methods include two components, namely, detection and adaptation. Compared with ATTA, there are several distinctions. First, this line of studies largely focuses on the distribution shift detection problem, while ATTA focuses on multi-domain adaptations. Second, AOL on drifting data stream aims to detect and adapt to one current distribution in the stream, without considering preserving the adaptation abilities of multiple past distributions by maintaining and fine-tuning the original pre-trained models. In contrast, ATTAâ€™s goal is to achieve the OOD generalization optimums adaptable across multiple source and target distributions, leading to the consideration of CF problems. Third, while AOL requires one-by-one data input and discard, ATTA maintains a buffer for incoming data before selection decisions. This is because ATTA targets maintaining the original model without corrupting and replacing it, such that making statistically meaningful and high-quality decisions is 22Published as a conference paper at ICLR 2024 critical for ATTA. In contrast, AOL allows resetting and retraining new models, whose target is more lean to cost saving and one-by-one manner. D F URTHER THEORETICAL STUDIES In this section, we refine the theoretical studies with supplement analysis and further results. We use the H-divergence and Hâˆ†H-distance definitions following (Ben-David et al., 2010). Definition 2 (H-divergence). For a function class H and two distributions D1 and D2 over a domain X, the H-divergence between D1 and D2 is defined as dH(D1, D2) = sup hâˆˆH |Pxâˆ¼D1 [h(x) = 1] âˆ’ Pxâˆ¼D2 [h(x) = 1]|. The Hâˆ†H-distance is defined base on H-divergence. We use the Hâˆ†H-distance definition follow- ing (Ben-David et al., 2010). Definition 3 (Hâˆ†H-distance). For two distributions D1 and D2 over a domain X and a hypothesis class H, the Hâˆ†H-distance between D1 and D2 w.r.t. H is defined as dHâˆ†H(D1, D2) = sup h,hâ€²âˆˆH Pxâˆ¼D1 [h(x) Ì¸= hâ€²(x)] + Pxâˆ¼D2 [h(x) Ì¸= hâ€²(x)]. (9) The Hâˆ†H-distance essentially provides a measure to quantify the distribution shift between two distributions. It measures the maximum difference of the disagreement between two hypotheses in H for two distributions, providing a metrics to quantify the distribution shift between D1 and D2. H-divergence and Hâˆ†H-distance have the advantage that they can be applied between datasets, i.e., estimated from finite samples. Specifically, let S1, S2 be unlabeled samples of size m sampled from D1 and D2; then we have estimated Hâˆ†H-distance Ë†dH(S1, S2). This estimation can be bounded based on Theorem 3.4 of Kifer et al. (2004), which we state here for completeness. Theorem 5. Let A be a collection of subsets of some domain measure space, and assume that the VC-dimension is some finite d. Let P1 and P2 be probability distributions over that domain and S1, S2 finite samples of sizes m1, m2 drawn i.i.d. according P1, P2 respectively. Then Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16, (10) where Pm1+m2 is the m1 + m2â€™th power of P - the probability that P induces over the choice of samples. Theorem 5 bounds the probability for relativized discrepancy, and its applications in below lemmas and Theorem 1 help us bound the quantified distribution shifts between domains. The probability, according to a distribution D, that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source domain dataset is inaccessible under ATTA settings, we consider the existence of the source dataset DS for the purpose of accurate theoretical analysis. Thus, we initialize Dtr(0) as DS, i.e., Dtr(0) = DS. For every time step t, the test and training data can be expressed as Ute(t) and Dtr(t) = DS âˆª Dte(1) âˆª Dte(2) âˆª Â·Â·Â· âˆªDte(t). (11) We use N to denote the total number of samples in Dtr(t) and Î» = (Î»0, Î»1, Â·Â·Â· , Î»t) to represent the ratio of sample numbers in each component subset. In particular, we have |DS| |Dtr(t)| = Î»0, |Dte(1)| |Dtr(t)| = Î»1, Â·Â·Â· , |Dte(t)| |Dtr(t)| = Î»t, (12) where Pt i=0 Î»i = 1. Therefore, at time step t, the model has been trained on labeled data Dtr(t), which contains t + 1 components consisting of a combination of data from the source domain and multiple test-time domains. For each domain the model encounters, DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), let Ïµj(h(t)) denote the error of hypothesis h at time t on the jth domain. Specifically, Ïµ0(h(t)) = ÏµS(h(t)) represents the error of h(t) on the source data DS, and Ïµj(h(t)) for j â‰¥ 1 denotes the error of h(t) on test data Ute(j). Our optimization minimizes a convex combination of training error over the labeled samples from all domains. Formally, given the vector w = (w0, w1, Â·Â·Â· , wt) of domain error 23Published as a conference paper at ICLR 2024 weights with Pt j=0 wj = 1 and the sample number from each component Nj = Î»jN, we minimize the empirical weighted error of h(t) as Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Nj X Nj |h(x, t) âˆ’ g(x)|. (13) Note that w, Î» and N are also functions of t, which we omit for simplicity. We now establish two lemmas as the preliminary for Theorem 1. In the following lemma, we bound the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)). Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. In the following lemma, we provide an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. The proofs for both lemmas are provided in Appx. E. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Lemma 6 bounds the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)), which is majorly influenced by the estimatedHâˆ†H-distance and the quality of discrepancy estimation. During the ATTA process, the streaming test data can form multiple domains and distributions. However, if we consider all data during the test phase as a single test domain,i.e., St i=1 Ute(i), we can simplify Lemma 6 to obtain an upper bound for the test error ÏµT as |Ïµw(h(t)) âˆ’ ÏµT (h(t))| â‰¤w0 ï£« ï£­1 2 Ë†dHâˆ†H(S0, ST ) + 2 s 2d log(2m) + log 2 Î´ m + Î³ ï£¶ ï£¸, (14) where Î³ = min hâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}, and ST is sampled from St i=1 Ute(i). To understand Lamma 7, we need to understand Hoeffdingâ€™s Inequality, which we state below as a Proposition for completeness. Proposition 8 (Hoeffdingâ€™s Inequality). Let X be a set, D1, . . . , Dt be probability distributions on X, and f1, . . . , ft be real-valued functions on X such that fi : X â†’ [ai, bi] for i = 1, . . . , t. Then for any Ïµ >0, P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! (15) where E[fi(x)] is the expected value of fi(x). Lamma 7 provides an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Theorem 1 essentially bounds the performance of ATTA on the source and each test domains. The adaptation performance on a test domain is majorly 24Published as a conference paper at ICLR 2024 bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. If we consider the multiple data distributions during the test phase as a single test domain, i.e., St i=1 Ute(i), Theorem 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . With the optimal test/source hypothesis hâˆ— T (t) = arg min hâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (16.a), with approximately B = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (17) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. When the budget is sufficiently large or the source data amount is not sufficiently large compared to the distribution shift A, the optimal wâˆ— 0 for the test error bound is wâˆ— 0 = 0, i.e., using no source data since possible error reduction from the data addition is always less than the error increase caused by large divergence between the source data and the test data. Theorem 2 offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Following Theorem 1, when no active learning is included during TTA,i.e., w0 = Î»0 = 1, the upper boundw0A+ q w2 0 Î»0 + (1âˆ’w0)2 1âˆ’Î»0 B â‰¥ A+B; when enabling ATTA, withw0 = Î»0 Ì¸= 1, we can easily achieve an upper bound w0A + B < A+ B. Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. Entropy quantifies the amount of information contained in a probability distribution. In the context of a classification model, lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction. When a model assigns low entropy to a sample, this high confidence can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model â€œrecognizesâ€ the sample as being similar to those it was trained on, hence the high confidence in its prediction. While entropy is not a direct measure of distributional distance, it can be used as an indicator of how closely a sample aligns with the modelâ€™s learned distribution. This interpretation is more about model confidence and the implied proximity rather than a strict mathematical measure of distributional distance. The pre-trained model is well-trained on abundant source domain data, and thus the model distribution is approximately the source distribution. Selecting low-entropy samples using essentially provides an estimate of sampling from the source dataset. Thus, DÏ•,S(t), based on well-aligned with the modelâ€™s learned distribution is an approximation of DS. When we consider the CF problem and feasibly include the source-like dataset DÏ•,S(t) into the ATTA training data in place of the inaccessible DS in Eq. (11), we can also derive bounds on the domain errors under this practical ATTA setting when minimizing the empirical weighted errorÏµâ€² w(h(t)) using the hypothesis h at time t, similar to Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domainsDÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is 25Published as a conference paper at ICLR 2024 N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµâ€² w(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Other derived results following Theorem 1 also apply for this practical ATTA setting. Further empirical validations for our theoretical results are provided in Appx. H. E P ROOFS This section presents comprehensive proofs for all the lemmas, theorems, and corollaries mentioned in this paper, along with the derivation of key intermediate results. Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Proof. First we prove that given unlabeled samples of size m S1, S2 sampled from two distributions D1 and D2, we have dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (18) We start with Theorem 3.4 of Kifer et al. (2004): Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16. (19) In Eq. 19, â€™dâ€™ is the VC-dimension of a collection of subsets of some domain measure space A, while in our case, d is the VC-dimension of hypothesis space H. Following (Ben-David et al., 2010), the Hâˆ†H space is the set of disagreements between every two hypotheses inH, which can be represented as a linear threshold network of depth 2 with 2 hidden units. Therefore, the VC-dimension of Hâˆ†H is at most twice the VC-dimension of H, and the VC-dimension of our domain measure space is 2d for Eq. 19 to hold. Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2m)2deâˆ’m1Ïµ2/16 + (2m)2deâˆ’m2Ïµ2/16. We rewrite the inequality as Î´ (2m)2d = eâˆ’m1Ïµ2/16 + eâˆ’m2Ïµ2/16; taking the logarithm of both sides, we get log Î´ (2m)2d = âˆ’m1 Ïµ2 16 + log(1 +eâˆ’(m1âˆ’m2) Ïµ2 16 ). 26Published as a conference paper at ICLR 2024 Assuming m1 = m2 = m and defining a = Ïµ2 16 , we have log Î´ (2m)2d = âˆ’ma + log 2; rearranging the equation, we then get ma + log(Î´/2) = 2d log(2m). Now, we can solve for a: a = 2d log(2m) + log 2 Î´ m . Recall that a = Ïµ2 16 , so we get: Ïµ = 4âˆša Ïµ = 4 s 2d log(2m) + log 2 Î´ m . With probability of at least 1 âˆ’ Î´, we have |Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| â‰¤4 s 2d log(2m) + log 2 Î´ m ; therefore, dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (20) Now we prove Lemma 6. We use the triangle inequality for classification error in the derivation. For the domain error of hypothesis h at time t on the jth domain Ïµj(h(t)), given the definition of Ïµw(h(t)), |Ïµw(h(t)) âˆ’ Ïµj(h(t))| = | tX i=0 wiÏµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi|Ïµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(|Ïµi(h(t)) âˆ’ Ïµi(h(t), hâˆ— i (t))| + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + |Ïµj(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t))|) â‰¤ tX i=0 wi(Ïµi(hâˆ— i (t)) + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + Ïµj(hâˆ— i (t))) â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|), where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. By the definition of Hâˆ†H-distance and our proved Eq. 20, |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| â‰¤sup h,hâ€²âˆˆH |Ïµi(h(t), hâ€²(t)) âˆ’ Ïµj(h(t), hâ€²(t))| = sup h,hâ€²âˆˆH Pxâˆ¼Di[h(x) Ì¸= hâ€²(x)] + Pxâˆ¼Dj [h(x) Ì¸= hâ€²(x)] = 1 2dHâˆ†H(Di, Dj) â‰¤ 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m , 27Published as a conference paper at ICLR 2024 where Di, Dj denote the ith and jth domain. Therefore, |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|) â‰¤ tX i=0 wi(Î³i + 1 2dHâˆ†H(Di, Dj)) â‰¤ tX i=0 wi(Î³i + 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m ). Since Ïµi(h(t)) âˆ’ Ïµj(h(t)) = 0 when i = j, we derive |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. This completes the proof. Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Proof. We apply Hoeffdingâ€™s Inequality in our proof: P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! . (21) In the jth domain, there are Î»jN samples. With the true labeling function g(x), for each of the Î»jN samples x, let there be a real-valued function fi(x) fi(x) = wj Î»j |h(x, t) âˆ’ g(x)|, where fi(x) âˆˆ [0, wj Î»j ]. Incorporating all the domains, we get Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Î»jN X Î»jN |h(x, t) âˆ’ g(x)| = 1 N tX j=0 Î»jNX i=1 fi(x), which corresponds to the 1 t Pt i=1 fi(x) part in Hoeffdingâ€™s Inequality. Due to the linearity of expectations, we can calculate the sum of expectations as 1 N tX j=0 Î»jNX i=1 E[fi(x)] = 1 N ( tX j=0 Î»jN wj Î»j Ïµj(h(t))) = tX j=0 wjÏµj(h(t)) = Ïµw(h(t)), which corresponds to the 1 t Pt i=1 Exâˆ¼Di[fi(x)] part in Hoeffdingâ€™s Inequality. Therefore, we can apply Hoeffdingâ€™s Inequality as P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2N2Ïµ2/( NX i=0 range2(fi(x))) ! = 2 exp   âˆ’2N2Ïµ2/( tX j=0 Î»jN(wj Î»j )2) ! = 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . This completes the proof. 28Published as a conference paper at ICLR 2024 Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. Proof. First we prove that for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (22) We apply Theorem 3.2 of Kifer et al. (2004) and Lemma 7, P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . We rewrite the inequality as Î´ (2N)d = e âˆ’2NÏµ2/(Pt j=0 w2 j Î»j ) , taking the logarithm of both sides, we get log Î´ (2N)d = âˆ’2NÏµ2/( tX j=0 w2 j Î»j ). Rearranging the equation, we then get Ïµ2 = ( tX j=0 w2 j Î»j )d log(2N) âˆ’ log(Î´) 2N . Therefore, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (23) 29Published as a conference paper at ICLR 2024 Based on Eq. 23, we now prove Theorem 1. For the empirical domain error of hypothesis h at time t on the jth domain Ïµj(Ë†h(t)), applying Lemma 6, Eq. 23, and the definition of hâˆ— j (t), we get Ïµj(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— j (t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµj(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k where k > 0, we have the assumption that kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H(D(kâ€²), Ute(t + k)) â‰¤ Î´D. Here, we slightly abuse the notation D(kâ€²) to represent Ds if kâ€² = 0 and Ute(kâ€²) if kâ€² > 0. Then we get Ïµt+k(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, St+k) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2( Ë†dHâˆ†H(Si, Skâ€² ) + Ë†dHâˆ†H(Skâ€² , St+k)) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 30Published as a conference paper at ICLR 2024 â‰¤ Ë†Ïµw(hâˆ— t+k(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµt+k(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. with probability of at least 1âˆ’Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 , Î³i = minhâˆˆH{Ïµi(h(t))+ Ïµt+k(h(t))}, and 0 â‰¤ Î´D â‰ª +âˆž. This completes the proof. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (24) Proof. From Theorem 1, we can derive the bound for the test error where the test-time data are considered as a single test domain: |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t) = w0( Ë†dHâˆ†H(S0, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N ; and we simplify the above equation as |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (25) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Since we have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (26) 31Published as a conference paper at ICLR 2024 where Formula 26 obtains the minimum value if and only if w0 = Î»0; when enabling ATTA with any Î»0 Ì¸= 1, we can get EBT (w, Î», N, t) = w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¥ w0A + B, (27) where the minimum value EBT (w, Î», N, t)min = w0A + B can be obtained with condition w0 = Î»0 Ì¸= 1. When no active learning is included, i.e., for weight and sample ratio vectors wâ€² and Î»â€², wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, we have EBT (wâ€², Î»â€², N, t) = wâ€² 0A + s wâ€²2 0 Î»â€² 0 + (1 âˆ’ wâ€² 0)2 1 âˆ’ Î»â€² 0 B = A + B. (28) Since for EBT (w, Î», N, t)min = w0A + B, w0 < 1 and A, B >0 hold, we derive EBT (w, Î», N, t)min = w0A + B < A+ B = EBT (wâ€², Î»â€², N, t). (29) This completes the proof. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Theorem 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Theorem 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Proof. For the empirical source error on DS of hypothesis h at time t, similar to Theorem 1, we apply Lemma 6, Eq. 23 to get ÏµS(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— S(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ ÏµS(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 32Published as a conference paper at ICLR 2024 = ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. This completes the proof. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Theorem 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (30) Proof. From Theorem 1, considering the test-time data as a single test domain, we can derive the bound for the source error on DS: |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N , where ST is sampled fromSt i=1 Ute(i), Î³ = minhâˆˆH{Ïµ0(h(t))+ÏµS(h(t))}, and Î³â€² = minhâˆˆH{ÏµT (h(t))+ ÏµS(h(t))}. We have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (31) where the equality and the minimum value are obtained if and only if w0 = Î»0. When DÏ•,S(t) is not included,i.e., with the weight and sample ratio vectorswâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0, using the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , we have EBS(wâ€², Î»â€², N, t) = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B. When DÏ•,S(t) is included with Î»0 Ì¸= 0, EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¤ w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B, 33Published as a conference paper at ICLR 2024 Algorithm 2 INCREMENTAL CLUSTERING (IC) Require: Given previously selected anchors, new unlabeled samples, and the cluster budget as Danc, Unew, and NC . Global anchor weights wanc = (wanc 1 , . . . , wanc |Danc|)âŠ¤. 1: For simplicity, we consider anchor weights wanc as a global vector. 2: function IC(Danc, Unew, NC ) 3: wsp â† Concat(wanc, 1âŠ¤ |Unew|) â–· Assign all new samples with weight 1. 4: Î¦ â† Extract the features from the penultimate layer of model f on x âˆˆ Danc âˆª Unew in order. 5: clusters â† Weighted-K-Means(Î¦, wsp, NC) 6: new_clusters â† {clusteri | âˆ€clusteri âˆˆ clusters, âˆ€x âˆˆ Danc, x /âˆˆ clustersi} 7: Xnew_anchors â† {the closest sample x to the centroid of clusteri | âˆ€clusteri âˆˆ new_clusters} 8: Xanchors â† {x âˆˆ Danc} âˆªXnew_anchors 9: wanc â† Concat(wanc, 0âŠ¤ |Xnew_anchors|) â–· Initialize new anchor weights. 10: for wanc i âˆˆ wanc, wanc i â† wanc i + # sample of clusterj # anchor in clusterj , wanc i âˆˆ clusterj â–· Weight accumulation. 11: Return Xanchors 12: end function where the minimum value can be obtained with condition w0 = Î»0 Ì¸= 0. In practical learning scenarios, we generally assume adaptation tasks are solvable; therefore, there should be a prediction function that performs well on two distinct domains. In this case, Î³ and Î³â€² should be relatively small, so we can assume Î³ â‰ˆ Î³â€². If Ë†dHâˆ†H(S0, SS) < Ë†dHâˆ†H(SS, ST ), then we have EBS(w, Î», N, t)min = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B < Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B = EBS(wâ€², Î»â€², N, t). Therefore, we derive EBS(w, Î», N, t)min < EBS(wâ€², Î»â€², N, t). (32) This completes the proof. F I NCREMENTAL CLUSTERING F.1 A LGORITHM DETAILS We provide the detailed algorithm for incremental clustering as Alg. 2. F.2 V ISUALIZATION To better illustrate the incremental clustering algorithm, we provide visualization results on PACS to demonstrate the process. As shown in Fig. 3, the initial step of IC is a normal K-Means clustering step, and ten anchors denoted as \"X\" are selected. The weights of all samples in a clusters is aggregated into the corresponding anchorâ€™s weight. Therefore, these ten samples (anchors) are given larger sizes visually (i.e., larger weights) than that of other new test samples in the first IC step (Fig. 4). During the first IC step, several distributions are far away from the existed anchors and form clusters 1,7,9 and 10, which leads to 4 new selected anchors. While the number of cluster centroid is only increased by 1, 4 of the existing anchors are clustered into the same cluster 8 (purple). Thus IC produces 4 new anchors instead of 1. Similarly, in the second IC step (Fig. 5), the new streaming-in test samples introduce a new distribution; IC produces 3 new clusters (4, 8, and 11) and the corresponding number of anchors to cover them. The number of centroid is only increased by 1, which implies that there are two original-cluster-merging events. More IC step visualization results are provided in Fig. 6 and 7. 34Published as a conference paper at ICLR 2024 Figure 3: Initial IC step: normal clustering. Left: Clustering results. Right: Selecting new anchors. Figure 4: The first IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 5: The second IC step. Left: Weighted clustering results. Right: Selecting new anchors. 35Published as a conference paper at ICLR 2024 Figure 6: The third IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 7: The fourth IC step. Left: Weighted clustering results. Right: Selecting new anchors. 36Published as a conference paper at ICLR 2024 G E XPERIMENT DETAILS In this section, we provide more experimental details including the details of the datasets and training settings. G.1 D ETAILS ABOUT THE DATASETS We adopt datasets PACS, VLCS, and Office-Home from DomainBed (Gulrajani and Lopez-Paz, 2020) with the same domain splits. All available licenses are mentioned below. â€¢ PACS (Li et al., 2017) includes four domains: art, cartoons, photos, and sketches. PACS is a 7-class classification dataset with 9,991 images of dimension (3, 224, 224). â€¢ VLCS (Fang et al., 2013) contains photographic domains: Caltech101, LabelMe, SUN09, and VOC2007. This dataset includes 10,729 images of dimension (3, 224, 224) with 5 classes. â€¢ Office-Home (Venkateswara et al., 2017) is a 65-class dataset, including domains: art, clipart, product, and real. VLCS includes 10,729 images of dimension (3, 224, 244). (License) â€¢ Tiny-ImageNet-C is a 200-class dataset, including 15 corrupt types. Tiny-ImageNet-C includes 150,000 images of dimension (3, 224, 244). Since the class number 200 is less than ImageNet (1000), the modelâ€™s last layer classifier needs to be adapted. In this work, we use the brightness corruption domain to adapt. In the source pretraining phase, we adopt the most ImageNet-like domain as our source domain. For PACS and Office-Home, we use domains \"photos\" and \"real\" as the source domains, respectively, while for VLCS, Caltech101 is assigned to apply the source pretraining. We freeze the random seeds to generate the sample indices order for the two test data streams, namely, the domain-wise data stream and the random data stream. For PACS, the domain-wise data stream inputs samples from domain art, cartoons, to sketches, while we shuffle all samples from these three domains in the random data stream. For VLCS, we stream the domains in the order: LabelMe, SUN09, and VOC2007, as the domain-wise data stream. For Office-Home, the domain-wise data stream order becomes art, clipart, and product. G.2 T RAINING AND OPTIMIZATION SETTINGS In this section, we extensively discuss the model architectures, optimization settings, and method settings. G.2.1 A RCHITECTURES PACS & VLCS. We adopt ResNet-18 as our model encoder followed by a linear classifier. The initial parameters of ResNet-18 are ImageNet pre-trained weights. In our experiment, we remove the Dropout layer since we empirically found that using the Dropout layer might degrade the optimization process when the sample number is small. The specific implementation of the network is closely aligned with the implementation in DomainBed (Gulrajani and Lopez-Paz, 2020). Office-Home. We employ ResNet-50 as our model encoder for Office-Home. Except for the architecture, the other model settings are aligned with the ResNet-18. Tiny-ImageNet-C ResNet-18 is adapted from ImageNet to Tiny-ImageNet-C by training the last linear layer. G.2.2 T RAINING & OPTIMIZATION In this section, we describe the training configurations for both the source domain pre-training and test-time adaptation procedures. Source domain pre-training. For the PACS and VLCS datasets, models are fine-tuned on the selected source domains for 3,000 iterations. The Adam optimizer is utilized with a learning rate 37Published as a conference paper at ICLR 2024 of 10âˆ’4. In contrast, for the Office-Home dataset, the model is fine-tuned for a longer duration of 10,000 iterations with a slightly adjusted learning rate of 5 Ã— 10âˆ’5. Test-time adaptation. For test-time adaptation across PACS and VLCS, the pre-trained source model is further fine-tuned using the SGD optimizer with a learning rate of 10âˆ’3. While on Office-Home and Tiny-ImageNet-C, a learning rate of 10âˆ’4 is adopted. For all TTA baselines, barring specific exceptions, we faithfully adhere to the original implementation settings. A noteworthy exception is the EATA method, which requires a cosine similarity threshold. The default threshold of the original EATA implementation was not suitable for the three datasets used in our study, necessitating an adjustment. We empirically set this threshold to 0.5 for training. Unlike Tent and SAR, which only require the optimization of batch normalization layers (Santurkar et al., 2018), SimATTA allows the training of all parameters in the networks. In experiments, we use a tolerance count (tol) to control the training process. SimATTA will stop updating once the loss does not descrease for more than 5 steps. However, for Tiny-ImageNet-C, SimATTA uses â€˜steps=10â€˜ for time comparisons since other methods apply at most 10 steps. G.2.3 M ETHOD SETTINGS Tent. In our experiments, we apply the official implementation of Tent1. Specifically, we evaluate Tent with 1 test-time training step and 10 steps, respectively. EATA.Our EATA implementation follows its official code2. In our experiments, EATA has 2000 fisher training samples, E0 = 0.4 Ã— log(# class), Ïµ <0.5. CoTTA. For CoTTA, we strictly follow all the code and settings from its official implementation3. SAR. With SARâ€™s official implementation4, we set E0 = 0 .4 Ã— log(# class) and e0 = 0 .1 in our experiments. ADA baselines. For ADA baselines, we follow the architecture of the official implementation of CLUE (Prabhu et al., 2021)5. SimATTA Implementation. Our implementation largely involves straightforward hyperparameter settings. The higher entropy bound eh = 10âˆ’2 should exceed the lower entropy bound el, but equal values are acceptable. Empirically, the lower entropy bound el can be set to 10âˆ’3 for VLCS and Office-Home, or 10âˆ’4 for PACS. The choice of el is largely dependent on the number of source-like samples obtained. A lower el may yield higher-accuracy low-entropy samples, but this could lead to unstable training due to sample scarcity. Though experimentation with different hyperparameters is encouraged, our findings suggest that maintaining a non-trivial number of low-entropy samples and setting an appropriateÎ»0 are of primary importance. If Î»0 < 0.5, CF may ensue, which may negate any potential improvement. Regarding the management of budgets, numerous strategies can be adopted. In our experiments, we utilized a simple hyperparameter k, varying from 1 to 3, to regulate the increasing rate of budget consumption. This strategy is fairly elementary and can be substituted by any adaptive techniques. G.3 S OFTWARE AND HARDWARE We conduct our experiments with PyTorch (Paszke et al., 2019) and scikit-learn (Pedregosa et al., 2011) on Ubuntu 20.04. The Ubuntu server includes 112 Intel(R) Xeon(R) Gold 6258R CPU @2.70GHz, 1.47TB memory, and NVIDIA A100 80GB PCIe graphics cards. The training process costs graphics memory less than 10GB, and it requires CPU computational resources for scikit-learn K-Means clustering calculations. Our implementation also includes a GPU-based PyTorch K-Means method for transferring calculation loads from CPUs to GPUs. However, for consistency, the results of our experiments are obtained with the original scikit-learn K-Means implementation. 1https://github.com/DequanWang/tent 2https://github.com/mr-eggplant/EATA 3https://github.com/qinenergy/cotta 4https://github.com/mr-eggplant/SAR 5https://github.com/virajprabhu/CLUE 38Published as a conference paper at ICLR 2024 Figure 8: Target loss surface on 2000 samples without source pre-training. The red points denote the loss minimum for a fixed Î»0. The orange line denote the place where w0 = Î»0. Figure 9: Target loss surface on 2000 samples with source pre-training. H E MPIRICAL VALIDATIONS FOR THEORETICAL ANALYSIS In this section, we undertake empirical validation of our learning theory, which encompasses multiple facets awaiting verification. In contemporary computer vision fields, pre-trained models play a pivotal role, and performance would significantly decline without the use of pre-trained features. The learning theory suggests that given the vast VC-dimension of complete ResNets, without substantial data samples, the training error cannot be theoretically tight-bounded. However, we show empirically in the following experiments that fine-tuning pre-trained models is behaviorally akin to training a model with a low VC-dimension. Training on 2000 Samples Without Source Domain Pre-training. For an ImageNet pre-trained ResNet-18 model, we trained it using 2000 samples from the PACS dataset. To ascertain the optimal value wâˆ— 0 in Equation 4, we trained multiple models for different w0 and Î»0 pairings. For each pair, we derived the target domain loss (from art, cartoons, and sketches) post-training and plotted this loss on the z-axis. With w0 and Î»0 serving as the xy-axes, we drafted the target domain loss ÏµT surface in Figure 8. As the results show, given a Î»0, the optimal wâˆ— 0 typically aligns with the line Î»0 = w0, with a slight downward shift, which aligns with Equation 4. 39Published as a conference paper at ICLR 2024 Figure 10: Target loss surface on 500 samples with source pre-training. Figure 11: Source loss surface on 500 samples with source pre-training. 40Published as a conference paper at ICLR 2024 Figure 12: Target and source loss surface on 500 samples with source pre-training. Table 6: TTA comparisons on Office-Home. This table includes the two data stream settings mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. Office-Home Domain-wise data stream Post-adaptation Random data stream Post-adaptation R â†’Aâ†’ â†’Câ†’ â†’P R A C P 1 2 3 4 R A C P BN w/o adapt 93.78 42.93 37.62 59.90 93.78 42.93 37.62 59.90 46.82 46.82 46.82 46.82 93.78 42.93 37.62 59.90BN w/ adapt 92.38 49.69 39.43 63.53 92.38 49.69 39.43 63.53 50.88 50.88 50.88 50.88 92.38 49.69 39.43 63.53 Tent (steps=1) N/A 49.61 39.31 63.87 92.47 49.57 39.89 63.89 49.95 50.27 50.23 52.06 92.40 49.24 39.68 63.98Tent (steps=10) N/A 49.61 39.04 61.41 87.08 44.79 38.37 60.49 50.05 49.31 48.74 47.79 85.31 42.85 37.89 58.71EATA N/A 49.65 39.04 63.53 91.60 49.61 38.65 63.48 49.73 50.27 49.45 51.07 91.05 49.11 38.26 62.99CoTTA N/A 49.61 38.76 61.84 87.81 44.95 35.92 59.04 49.84 49.84 48.95 50.43 86.99 43.68 34.73 57.56SAR (steps=1) N/A 49.65 39.24 63.53 92.45 49.73 39.36 63.69 49.84 50.05 49.91 51.67 92.38 49.57 39.50 63.87SAR (steps=10) N/A 49.53 38.81 61.50 88.94 46.15 37.04 59.41 50.09 50.30 49.77 49.22 89.14 46.23 36.31 59.45 SimATTA (B â‰¤300) N/A 56.20 48.38 71.66 95.75 60.07 52.62 74.70 58.57 60.88 62.91 63.67 95.89 62.01 54.98 74.70SimATTA (B â‰¤500) N/A 58.71 51.11 74.36 96.03 62.05 57.41 76.98 58.85 62.63 63.41 64.31 95.91 63.78 57.87 77.09 Training on 2000 Samples with Source Domain Pre-training. To further assess the effects of source pre-training, we repeated the same experiment on a source pre-trained ResNet-18. The results are depicted in Figure 9. This experiment provides empirical guidance on selecting w0 in source domain pre-trained situations. The findings suggest that the optimal wâˆ— 0 non-trivially shifts away from the line Î»0 = w0 towards lower-value regions. Considering the source pre-training process as using a greater quantity of source domain samples, it implies that when the number of source samples greatly exceeds target samples, a lower w0 can enhance target domain results. Training on 500 Samples with Source Domain Pre-training. We proceed to fine-tune the source domain pre-trained ResNet-18 using only 500 samples, thereby simulating active TTA settings. We train models with various w0 and Î»0 pairings, then graph the target domain losses, source domain losses, and the combined losses. As shown in Figure 10, the target losses still comply with our theoretical deductions where the local minima are close to the line Î»0 = w0 and marginally shift towards lower values. Considering the challenge of CF, the source domain results in Figure 11 suggest a reverse trend compared to the target domain, where lower Î»0 and w0 values yield superior target domain results but inferior source domain results. Thus, to curb CF, the primary strategy is to maintain a relatively higher Î»0. When considering both target and source domains, a balance emerges as depicted in Figure 12. The global minimum is located in the middle region, demonstrating the trade-off between the target domain and source domain performance. I A DDITIONAL EXPERIMENT RESULTS In this section, we provide additional experiment results. The Office-Home results and ablation studies will be presented in a similar way as the main paper. In the full results Sec. I.3, we will post more detailed experimental results with specific budget numbers and intermediate performance during the test-time adaptation. 41Published as a conference paper at ICLR 2024 Table 7: Comparisons to ADA baselines on Office-Home. The source domain is denoted as \"(S)\" in the table. Results are average accuracies with standard deviations). Office-Home R (S) A C P Random (B = 300) 95.04 (0.20) 57.54 (1.16) 53.43 (1.17) 73.46 (0.97) Entropy (B = 300) 94.39 (0.49) 61.21 (0.71) 56.53 (0.71) 72.31 (0.28) Kmeans (B = 300) 95.09 (0.14) 57.37 (0.90) 51.74 (1.34) 71.81 (0.39) CLUE (B = 300) 95.20 (0.23) 60.18 (0.98) 58.05 (0.43) 73.72 (0.70) Ours (B â‰¤300) 95.82 (0.07) 61.04 (0.97) 53.80 (1.18) 74.70 (0.00) I.1 R ESULTS ON OFFICE -HOME We conduct experiments on Office-Home and get the test-time performances and post-adaptation performances for two data streams. As shown in Tab. 6, SimATTA can outperform all TTA baselines with huge margins. Compared to ADA baselines under the source-free settings, as shown in Tab. 7, SimATTA obtains comparable results. I.2 A BLATION STUDIES Figure 13: Ablation study on PACS and VLCS.\"IC=0\" denotes removing incremental clustering (IC) selection. \"LE=0\" denotes removing the low-entropy (LE) sample training. Domain-wise stream and random stream are applied on first and second rows, respectively. The accuracy values are averaged across all splits/domains. In this section, we explore three variations of our method to examine the individual impacts of its components. The first variant replaces the incremental clustering selection with entropy selection, 42Published as a conference paper at ICLR 2024 where only the samples with the highest entropy are chosen. The second variant eliminates low- entropy sample training. The third variation combines the first and second variants. We perform this ablation study on the PACS and VLCS as outlined in Fig. 13. We denote the use of incremental clustering (IC) and low-entropy training (LE) respectively as IC=1 and LE=1. The experiments essentially reveals the effectiveness of incremental clustering and low-entropy- sample training. As we have detailed in Sec. 3.2, these techniques are designed to to select informative samples, increase distribution coverage, and mitigate catastrophic forgetting. These designs appositely serve the ATTA setting where the oracle has costs and the budget is limited. Therefore, their effectiveness is prominent particularly when the budget is small. As the results show, when the budget B â‰¤100 or B â‰¤300, removing the components observably impairs performances. When B gets large, more active samples cover a larger distribution; thus the performance gap from random selection and informative selection gets smaller. In the extreme case where B â†’ âˆž, all samples are selected and thus the superiority of our meticulously-designed techniques are not manifested. Specifically, our analysis yields several insights. First, SimATTA (LE=1, IC=1) comprehensively outperforms other variants on both datasets, different streams, and different budgets. Second, variants without low-entropy training (LE=0, IC=0/1) easily fail to produce stable results (e.g., domain-wise stream in VLCS). Third, SimATTAâ€™s performance surpasses this variant on PACSâ€™s domain-wise stream clearly especially when the budgets are low. This indicates these variants fail to retrieve the most informative style shift (PACSâ€™s shifts) samples, which implies the advantage of incremental clustering when the budget is tight. In addition, these results show that IC has its unique advantage on domain-wise streams where distributions change abruptly instead of random streams. Therefore, compared to PACSâ€™s domain- wise stream results, the reason for the smaller performance improvement of SimATTA over the variant (LE=1, IC=0) on VLCSâ€™s domain-wise stream is that images in VLCS are all photos that do not include those severe style shifts in PACS (i.e., art, cartoons, and sketches). That is, when the shift is not severe, we donâ€™t need IC to cover very different distributions, and selecting samples using entropy can produce good results. In brief, IC is extraordinary for severe distribution shifts and quick adaptation. It is worth mentioning that low budget comparison is essential to show the informative sample retrieval ability, since as the budget increases, all AL techniques will tend to perform closely. I.3 C OMPLETE EXPERIMENT RESULTS We provide complete experimental results in this section. As shown in Tab. 8, we present the full results for two data streams. The test-time adaptation accuracies are shown in the \"Current domain\" row, while the \"Budgets\" row denotes the used budget by the end of the domain. The rest four rows denote the four domain test results by the end of the real-time adaptation of the current domain, where the first column results are the test accuracy before the test-time adaptation phase. N/A represents \"do not apply\". Table 8: Tent (steps=1) on PACS. Tent (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.29 64.59 44.67 56.35 54.09 51.83 48.58 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.38 97.60 98.56 98.08 97.72 97.19 A 59.38 69.09 68.95 66.85 68.07 67.33 65.58 63.53 C 28.03 64.04 65.19 64.08 64.85 65.19 62.97 60.75 S 42.91 53.65 47.39 42.58 54.57 49.83 44.13 41.56 J C HALLENGES AND PERSPECTIVES Despite advancements, test-time adaptation continues to pose considerable challenges. As previously discussed, without supplementary information and assumptions, the ability to guarantee model generalization capabilities is limited. However, this is not unexpected given that recent progress 43Published as a conference paper at ICLR 2024 Table 9: Tent (steps=10) on PACS. Tent (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.38 57.85 20.23 47.36 31.01 22.84 20.33 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 95.45 87.43 62.63 93.83 81.32 65.39 50.78 A 59.38 64.94 55.03 34.52 55.32 40.28 28.27 23.68 C 28.03 55.89 56.70 40.57 54.52 39.68 27.22 20.95 S 42.91 36.96 26.27 13.59 32.25 23.16 20.95 19.62 Table 10: EATA on PACS. EATA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.04 64.72 50.27 57.31 56.06 58.17 59.78 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.62 98.50 98.62 98.68 98.62 98.50 98.62 A 59.38 68.90 68.16 66.50 68.65 68.95 69.34 69.63 C 28.03 63.74 65.36 62.46 65.19 66.00 65.57 65.70 S 42.91 54.01 52.89 48.18 55.71 55.64 54.09 54.26 Table 11: CoTTA on PACS. CoTTA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 65.48 62.12 53.17 56.06 54.33 57.16 57.42 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.62 98.62 98.62 98.62 98.56 98.62 A 59.38 65.82 65.87 65.48 66.02 65.87 66.31 65.97 C 28.03 62.63 63.05 63.10 63.01 62.88 63.01 62.97 S 42.91 53.88 54.03 53.78 54.67 55.31 55.10 54.62 Table 12: SAR (steps=1) on PACS. SAR (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 66.75 63.82 49.58 56.78 56.35 56.68 56.70 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.50 98.32 98.74 98.56 98.50 98.44 A 59.38 68.02 68.07 66.94 67.87 68.65 68.55 68.16 C 28.03 62.84 64.97 62.93 63.82 64.89 64.46 64.38 S 42.91 53.47 52.07 45.74 54.92 55.46 53.68 52.53 Table 13: SAR (steps=10) on PACS. SAR (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 69.38 68.26 49.02 53.51 51.15 51.78 45.60 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.20 95.39 96.47 97.13 97.78 97.72 94.13 A 59.38 72.36 66.60 62.16 62.74 64.94 66.11 56.64 C 28.03 63.44 68.30 56.19 59.77 61.73 62.03 56.02 S 42.91 53.37 44.59 54.62 41.00 49.66 48.79 36.37 44Published as a conference paper at ICLR 2024 Table 14: SimATTA (B â‰¤300) on PACS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 76.86 70.90 75.39 69.47 76.49 82.45 82.22 Budgets N/A 75 145 223 66 142 203 267 P 99.70 98.44 98.86 98.80 97.96 98.68 99.04 98.98 A 59.38 80.71 82.32 84.47 73.97 80.52 81.10 84.91 C 28.03 48.12 82.00 82.25 72.35 81.06 83.36 83.92 S 42.91 32.78 56.25 81.52 79.49 83.10 84.78 86.00 Table 15: SimATTA (B â‰¤500) on PACS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 77.93 76.02 76.30 68.46 78.22 80.91 85.49 Budgets N/A 121 230 358 102 221 343 425 P 99.70 98.92 98.86 98.62 98.20 99.46 99.10 99.16 A 59.38 87.01 87.60 88.33 73.39 79.20 84.91 86.67 C 28.03 54.78 83.96 83.49 68.43 74.40 84.22 84.77 S 42.91 46.37 63.53 83.74 81.34 81.04 86.66 87.71 Table 16: Tent (steps=1) on VLCS. Tent (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 38.55 34.40 53.88 44.85 44.29 47.38 44.98 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.81 85.44 84.73 84.95 85.16 85.80 85.30 L 33.55 40.02 43.11 43.86 39.68 41.98 43.11 43.49 S 41.10 33.39 35.41 33.61 36.29 37.90 38.27 37.81 V 49.08 53.20 54.06 53.11 53.76 54.18 53.76 53.35 Table 17: Tent (steps=10) on VLCS. Tent (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 45.41 31.44 32.32 46.13 42.31 43.51 39.48 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 73.07 48.34 42.54 74.13 62.19 56.54 52.01 L 33.55 46.61 38.44 37.65 44.88 45.93 43.41 40.32 S 41.10 31.75 28.82 27.79 35.37 36.14 35.28 33.64 V 49.08 48.05 40.14 33.12 50.50 44.49 42.48 40.37 Table 18: EATA on VLCS. EATA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.24 33.15 52.58 43.77 42.48 43.34 41.55 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 85.16 85.02 84.10 84.73 84.52 84.10 83.32 L 33.55 37.16 37.24 37.69 37.09 36.78 36.90 36.67 S 41.10 33.39 33.49 32.39 33.33 32.54 31.84 31.47 V 49.08 51.87 52.16 52.49 52.07 52.43 52.64 52.55 45Published as a conference paper at ICLR 2024 Table 19: CoTTA on VLCS. CoTTA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.39 32.54 52.25 43.69 42.14 43.21 42.32 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 81.55 81.98 82.12 82.61 82.47 82.12 81.98 L 33.55 37.20 37.91 37.65 38.48 38.22 38.40 37.99 S 41.10 30.71 32.78 33.12 34.00 33.70 33.97 33.52 V 49.08 52.01 52.64 52.90 53.64 53.14 53.08 53.23 Table 20: SAR (steps=1) on VLCS. SAR (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 36.18 34.43 52.46 43.64 43.04 44.20 41.93 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.31 84.17 83.96 85.09 85.23 85.23 85.09 L 33.55 35.62 38.29 39.72 38.55 39.34 40.21 40.70 S 41.10 33.24 36.41 36.53 34.37 35.62 36.29 36.44 V 49.08 51.75 52.61 52.37 52.90 52.75 53.05 53.02 Table 21: SAR (steps=10) on VLCS. SAR (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 35.32 34.10 51.66 43.56 42.05 42.53 41.16 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 83.96 83.04 82.12 84.03 84.24 85.23 85.09 L 33.55 34.07 35.92 41.49 39.53 38.37 37.65 37.58 S 41.10 31.93 34.89 33.94 35.19 32.94 33.88 33.12 V 49.08 51.33 51.51 53.08 52.78 52.34 51.78 52.01 Table 22: SimATTA (B â‰¤300) on VLCS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 62.61 65.08 74.38 62.33 69.33 73.20 71.93 Budgets N/A 79 175 272 71 135 208 262 C 100.00 99.51 98.52 99.93 99.86 99.79 100.00 99.93 L 33.55 68.11 69.92 69.50 62.61 66.64 68.45 69.43 S 41.10 55.24 68.89 66.67 65.54 69.29 71.79 72.46 V 49.08 66.08 70.94 77.34 73.79 76.87 78.82 80.39 Table 23: SimATTA (B â‰¤500) on VLCS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 63.52 68.01 76.13 62.29 70.45 73.50 72.02 Budgets N/A 113 266 446 107 203 283 356 C 100.00 99.29 98.59 99.51 99.93 99.86 99.86 99.43 L 33.55 62.95 70.63 70.56 66.57 67.09 67.24 70.29 S 41.10 51.31 73.83 73.10 65.33 71.79 72.91 72.55 V 49.08 59.36 71.65 78.35 73.58 77.84 80.01 80.18 46Published as a conference paper at ICLR 2024 Table 24: Tent (steps=1) on Office-Home. Tent (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.31 63.87 49.95 50.27 50.23 52.06 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.33 92.36 92.47 92.38 92.45 92.45 92.40 A 57.07 49.73 49.73 49.57 49.69 49.73 49.57 49.24 C 44.97 39.27 39.54 39.89 39.45 39.68 39.73 39.68 P 73.15 63.60 63.66 63.89 63.60 63.82 63.93 63.98 Table 25: Tent (steps=10) on Office-Home. Tent (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.04 61.41 50.05 49.31 48.74 47.79 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 91.99 89.14 87.08 92.08 90.80 88.59 85.31 A 57.07 49.94 46.77 44.79 49.44 48.21 45.69 42.85 C 44.97 38.58 39.11 38.37 40.18 40.02 38.63 37.89 P 73.15 63.28 61.03 60.49 64.36 63.64 61.12 58.71 Table 26: EATA on Office-Home. EATA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.04 63.53 49.73 50.27 49.45 51.07 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.36 92.17 91.60 92.38 92.22 91.71 91.05 A 57.07 49.57 49.53 49.61 49.69 49.40 49.36 49.11 C 44.97 39.08 39.01 38.65 39.27 39.01 38.42 38.26 P 73.15 63.42 63.42 63.48 63.51 63.37 63.33 62.99 Table 27: CoTTA on Office-Home. CoTTA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 38.76 61.84 49.84 49.84 48.95 50.43 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 90.38 88.02 87.81 90.48 89.37 88.00 86.99 A 57.07 48.58 45.53 44.95 47.34 46.35 44.62 43.68 C 44.97 36.66 35.58 35.92 37.55 36.40 35.44 34.73 P 73.15 60.40 57.74 59.04 61.12 59.63 58.35 57.56 Table 28: SAR (steps=1) on Office-Home. SAR (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.24 63.53 49.84 50.05 49.91 51.67 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.38 92.31 92.45 92.40 92.36 92.36 92.38 A 57.07 49.65 49.57 49.73 49.69 49.61 49.57 49.57 C 44.97 39.34 39.22 39.36 39.34 39.56 39.47 39.50 P 73.15 63.51 63.51 63.69 63.60 63.71 63.71 63.87 47Published as a conference paper at ICLR 2024 Table 29: SAR (steps=10) on Office-Home. SAR (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.53 38.81 61.50 50.09 50.30 49.77 49.22 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.20 92.06 88.94 92.40 92.47 91.53 89.14 A 57.07 49.40 49.77 46.15 49.81 50.02 48.91 46.23 C 44.97 39.20 38.63 37.04 39.50 39.29 38.65 36.31 P 73.15 63.53 62.69 59.41 64.18 64.18 62.83 59.45 Table 30: SimATTA (B â‰¤300) on Office-Home. SimATTA (B â‰¤300) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 56.20 48.38 71.66 58.57 60.88 62.91 63.67 Budgets N/A 75 187 277 79 147 216 278 R 96.44 95.43 95.43 95.75 95.91 95.96 96.01 95.89 A 57.07 57.56 59.50 60.07 58.34 59.91 61.15 62.01 C 44.97 42.25 52.46 52.62 51.66 52.30 54.75 54.98 P 73.15 68.84 70.13 74.70 72.45 73.10 74.50 74.70 Table 31: SimATTA (B â‰¤500) on Office-Home. SimATTA (B â‰¤500) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 58.71 51.11 74.36 58.85 62.63 63.41 64.31 Budgets N/A 107 284 440 126 248 361 467 R 96.44 95.69 95.71 96.03 96.26 96.19 95.87 95.91 A 57.07 61.43 61.43 62.05 58.18 61.15 61.52 63.78 C 44.97 46.41 57.73 57.41 53.17 55.14 56.79 57.87 P 73.15 70.74 71.98 76.98 73.51 74.18 75.78 77.09 48Published as a conference paper at ICLR 2024 in deep learning heavily relies on large-scale data. Consequently, two promising paths emerge: establishing credible assumptions and leveraging additional information. Firstly, developing credible assumptions can lead to comprehensive comparisons across various stud- ies. Given that theoretical guarantees highlight the inherent differences between methods primarily based on the application limits of their assumptions, comparing these assumptions becomes critical. Without such comparative studies, empirical evaluations may lack precise guidance and explanation. Secondly, while we acknowledge the value of real-world data (observations), discussions surrounding the use of extra information remain pertinent. Considerations include the strategies to acquire this supplementary information and the nature of the additional data needed. Despite the myriad of works on domain generalization, domain adaptation, and test-time adaptation, a comprehensive survey or benchmark encapsulating the aforementioned comparisons remains an unmet need. Moreover, potential future directions for out-of-distribution generalization extend beyond domain generalization and test-time adaptation. One promising avenue is bridging the gap between causal inference and deep learning, for instance, through causal representation learning. In conclusion, our hope is that this work not only offers a novel practical setting and algorithm but also illuminates meaningful future directions and research methodologies that can benefit the broader scientific community. 49",
      "meta_data": {
        "arxiv_id": "2404.05094v1",
        "authors": [
          "Shurui Gui",
          "Xiner Li",
          "Shuiwang Ji"
        ],
        "published_date": "2024-04-07T22:31:34Z",
        "pdf_url": "https://arxiv.org/pdf/2404.05094v1.pdf"
      }
    },
    {
      "title": "Unified Entropy Optimization for Open-Set Test-Time Adaptation",
      "abstract": "Test-time adaptation (TTA) aims at adapting a model pre-trained on the\nlabeled source domain to the unlabeled target domain. Existing methods usually\nfocus on improving TTA performance under covariate shifts, while neglecting\nsemantic shifts. In this paper, we delve into a realistic open-set TTA setting\nwhere the target domain may contain samples from unknown classes. Many\nstate-of-the-art closed-set TTA methods perform poorly when applied to open-set\nscenarios, which can be attributed to the inaccurate estimation of data\ndistribution and model confidence. To address these issues, we propose a simple\nbut effective framework called unified entropy optimization (UniEnt), which is\ncapable of simultaneously adapting to covariate-shifted in-distribution (csID)\ndata and detecting covariate-shifted out-of-distribution (csOOD) data.\nSpecifically, UniEnt first mines pseudo-csID and pseudo-csOOD samples from test\ndata, followed by entropy minimization on the pseudo-csID data and entropy\nmaximization on the pseudo-csOOD data. Furthermore, we introduce UniEnt+ to\nalleviate the noise caused by hard data partition leveraging sample-level\nconfidence. Extensive experiments on CIFAR benchmarks and Tiny-ImageNet-C show\nthe superiority of our framework. The code is available at\nhttps://github.com/gaozhengqing/UniEnt",
      "full_text": "Unified Entropy Optimization for Open-Set Test-Time Adaptation Zhengqing Gao1,2 Xu-Yao Zhang1,2* Cheng-Lin Liu1,2 1MAIS, Institute of Automation, Chinese Academy of Sciences 2School of Artificial Intelligence, University of Chinese Academy of Sciences gaozhengqing2021@ia.ac.cn {xyz, liucl}@nlpr.ia.ac.cn Abstract Test-time adaptation (TTA) aims at adapting a model pre-trained on the labeled source domain to the unlabeled target domain. Existing methods usually focus on improv- ing TTA performance under covariate shifts, while neglect- ing semantic shifts. In this paper, we delve into a real- istic open-set TTA setting where the target domain may contain samples from unknown classes. Many state-of- the-art closed-set TTA methods perform poorly when ap- plied to open-set scenarios, which can be attributed to the inaccurate estimation of data distribution and model confidence. To address these issues, we propose a sim- ple but effective framework called unified entropy optimiza- tion (UniEnt), which is capable of simultaneously adapt- ing to covariate-shifted in-distribution (csID) data and de- tecting covariate-shifted out-of-distribution (csOOD) data. Specifically, UniEnt first mines pseudo-csID and pseudo- csOOD samples from test data, followed by entropy min- imization on the pseudo-csID data and entropy maximiza- tion on the pseudo-csOOD data. Furthermore, we introduce UniEnt+ to alleviate the noise caused by hard data parti- tion leveraging sample-level confidence. Extensive exper- iments on CIFAR benchmarks and Tiny-ImageNet-C show the superiority of our framework. The code is available at https://github.com/gaozhengqing/UniEnt. 1. Introduction Deep neural networks (DNNs) have achieved great success in recent years when the training and test data are drawn i.i.d. from the same distribution. However, in many real- world applications, this strict assumption is difficult to hold. Models deployed in practice can encounter different types of distribution shifts. On the one hand, the model needs to be able to address semantic shifts, i.e., identify sam- ples from unknown classes, which has given rise to prob- lems such as out-of-distribution (OOD) detection [15, 16, *Corresponding author. Source BN Adapt CoTTA TENT EATA OSTTA 50 60 70 80 90 100AUROC (%) Closed-Set TTA Open-Set TTA + UniEnt (Ours) + UniEnt+ (Ours) Figure 1. Existing TTA methods exhibit performance degradation with unknown classes included, while our methods can improve them significantly. We compare BN Adapt [33], CoTTA [46], TENT [44], EATA [35], and OSTTA [27]. 19, 32, 56] and open-set recognition [4, 5, 21, 43]. On the other hand, the model needs to be robust to covariate shifts and have good generalization performance to differ- ent styles and domains. Many efforts have been devoted to reduce the performance gap of DNNs under covariate shifts, such as domain generalization [45, 47, 58, 59] and domain adaptation [11, 50]. Among various studies ad- dressing covariate shifts, test-time adaptation (TTA) has re- cently received increasing attention because its practicality: neither source domain data nor target domain labels are re- quired [27, 28, 33, 35, 44, 46]. Nevertheless, most of the existing TTA methods [33, 35, 44, 46] focus only on solving the covariate shift and ig- noring the semantic shift. We believe that this is imprac- tical since we cannot guarantee the test samples contain only the classes seen in the training phase. Many recent works [27, 28] have realized this and made some initial attempts. Figure 2 illustrates the differences between the traditional closed-set TTA and the novel open-set TTA set- arXiv:2404.06065v1  [cs.CV]  9 Apr 2024Semantic Shift Covariate Shift ID Covariate-shifted ID OOD Covariate-shifted OOD Closed-Set TTA Open-Set TTA Figure 2. Comparison between closed-set TTA and open-set TTA. tings. First, we need to clarify that in the literature on OOD detection, out refers specifically to â€œoutside the semantic spaceâ€, whereas in the literature on OOD generalization, out refers specifically to â€œoutside the covariate spaceâ€. Here we follow the terminology used in [56]. According to the dif- ferent types of distribution shifts, we divide the real-world data into four types: â€¢ In-distribution (ID) data is the most common data we typically use to train a model, with a limited number of classes. â€¢ Out-of-distribution (OOD) data contains some open classes that have not been seen before in ID data, with the same style and domain as ID data. â€¢ Covariate-shifted ID (csID) data and ID data have the same classes and differ in styles and domains. â€¢ Covariate-shifted OOD (csOOD) data is different from ID data in both classes and domains. The open-set TTA setting takes into account both csID data and csOOD data. Existing TTA methods make extensive use of entropy objective, which proves to be very effective. We first exper- imentally verify that existing TTA methods [27, 33, 35, 44, 46, 54] degrade the classification accuracy of known classes when open-set classes are included, which is consistent with the conclusions drawn from some recent studies [27, 28]. In addition, as shown in Fig. 1, the detection performance of unknown classes is also impaired, which has not re- ceived enough attention in previous studies. We attribute the performance degradation to the following two points. First, the presence of open-set samples leads to the incor- rect estimation of normalization statistics by the model, leading to errors in updating affine parameters. Second, entropy minimization on samples from unknown classes forces the model to output confident predictions, undermin- ing the modelâ€™s confidence and leading to a decrease in the modelâ€™s ability to distinguish between known classes and unknown classes. With the aforementioned causes in mind, we propose three techniques to enhance the robustness of existing TTA methods under open-set setting. We first propose a distribution-aware filter to preliminarily distinguish be- tween csID samples and csOOD samples. Specifically, we observe that the cosine similarity between the features ex- tracted by the source model and the source domain proto- types can reflect the semantic shift, and we use this property to distinguish samples. We then propose a unified entropy optimization framework (UniEnt) to address the aforemen- tioned challenges. UniEnt minimizes the entropy of csID samples while maximizing the entropy of csOOD samples simultaneously. Furthermore, we propose UniEnt+ using a sample-level weighting strategy to avoid the error caused by noisy data partition. We summarize the contributions of this paper as follows. â€¢ We first delve into the performance of existing methods under closed-set TTA and open-set TTA settings. We then summarize two reasons for the performance degradation of existing methods with open-set classes included. â€¢ We propose a unified entropy optimization framework, which consists of a distribution-aware filter to distin- guish csID and csOOD samples, entropy minimization on csID samples to obtain good classification performance on known classes and entropy maximization on csOOD samples to obtain good detection performance on un- known classes. â€¢ Our proposed framework can be flexibly applied to many existing TTA methods and substantially improves their performance under open-set setting. Comprehensive ex- periments demonstrate the effectiveness of our approach. 2. Related Work Test-time adaptation. Among all the approaches to solving covariate shifts, test-time adaptation has received much at- tention because of its challenging setting of accessing only the source model and unlabelled target data. Some of the initial work [24, 31, 33, 39, 44, 51] focused on improving TTA performance by estimating batch normalization statis- tics using test data and designing unsupervised objective functions, e.g., TENT [44] proposed to optimize the affine parameters of batch normalization by minimizing the en- tropy of model outputs. These works mainly focus on staticentropy maximization on csOOD samples entropy minimization on csID samples Bt gÎ¸0 Distribution-aware Filter ÂµcsIDÂµcsOOD N(ÂµcsID,Ïƒ2csID) N(ÂµcsOOD,Ïƒ2csOOD) S(x) Density Ï€(x) <0.5 Ï€(x) â‰¥0.5 Bt,csOOD Bt,csID fÎ¸t fÎ¸t marginal output distribution Lt,csOOD Lt,csID H( Â¯fÎ¸t) sharp â†’even minLt even â†’sharp marginal entropy maximization Figure 3. Illustration of the unified entropy optimization (UniEnt) framework. At timestamp t, mini-batch Bt may contain samples from csID and csOOD. First, we filter csOOD samples by csOOD score S(x). Then, we perform entropy minimization for csID samples and entropy maximization for csOOD samples, we also adopt marginal entropy maximization to pervent model collapse. After optimization, we can yield better classification and detection performance tradeoff. TTA and do not take into account the changes in the domain. After adapting to a target domain, the adapted model is reset to the one pretrained on the source domain to adapt to the next domain. Later, some work [35, 46] proposed the con- tinual TTA setting where the model needs to adapt to a se- ries of continuously changing target domains without know- ing the domain labels. This poses new challenges for TTA: catastrophic forgetting and error accumulation. CoTTA [46] addresses the above issues through teacher-student model structure with data augmentation and stochastic recovery, while EATA [35] addresses the above issues through sam- ple selection and anti-forgetting regularizer. Robust test-time adaptation. Recently, several works have paid more attention to the robustness of TTA methods. LAME [2], NOTE [12] and RoTTA [53] focus on the per- formance of TTA methods under non-i.i.d. correlated sam- pling of test data. SITA [24] and MEMO [57] explore tech- niques for performing TTA on a single image. ODS [60] addresses case with label shift. OSTTA [27] pays attention to the performance degradation caused by long-term TTA. OWTTT [28] and OSTTA [27] consider the scenarios where the test data includes unknown classes. SAR [36] com- prehensively analyzed the impact of mixed domain shifts, small batch sizes, and online imbalanced label distribu- tion shifts on TTA performance. It is worth noting that there are some differences between the settings proposed by OWTTT [28] and OSTTA [27], the samples of unknown classes in OWTTT [28] are drawn from OOD, while the samples of unknown classes in OSTTA [27] are drawn from csOOD. We adopt the setting proposed in OSTTA [27] be- cause of its practicality and challenging nature. First, the unknown class samples we encounter during TTA are likely to experience the same covariate shift. Second, it is more difficult to distinguish between csID samples and csOOD samples than between csID samples and OOD samples. OOD detection. For models deployed in real-world sce- narios, the ability of OOD detection is crucial. Recent stud- ies in OOD detection can be roughly divided into two cat- egories. The first type of approaches [15, 19, 20, 30, 32] is devoted to design sophisticated score functions and input- output transformations. MSP [15] uses the maximum soft- max probability to detect OOD samples. ODIN [30] and generalized ODIN [20] further introduces temperature scal- ing, input preprocessing and confidence decompose to im- prove OOD detection performance. The second type of approaches instead regularizes the model by exploring the additional outlier data [16, 23, 48, 52, 55]. For example, OE [16] encourages the model to output low-confidence predictions for anomalous data. WOODS [23] on the other hand utilizes unlabelled wild data to improve the detection performance. SCONE [1] considers both OOD detection and OOD generalization for the first time. It is worth not- ing that all the methods mentioned above are designed for the training phase. Recently, AUTO [49] propose to opti- mize the network using unlabeled test data at test time to imporve OOD detection performance. 3. Methodology 3.1. Problem Setup Let Ds = {xi, yi}Ns i=1 be the source domain dataset with la- bel space Ys = {1, Â·Â·Â· , Cs}, and Dt = {xj, yj}Nt j=1 be the target domain dataset with label space Yt = {1, Â·Â·Â· , Ct}, where Cs and Ct denote the number of classes in the source and target domain datasets, respectively. Cs is equal to Ct for closed-set TTA while Cs < Ct always holds for open- set TTA. Given a model fÎ¸0 pre-trained on Ds, TTA aims to adapt the model to Dt without target labels accessible.To be specific, we denote the mini-batch of test samples at timestamp t as Bt and the adapted model as fÎ¸t. The main objective of open-set TTA is to correctly predict the classes in Ys while reject the classes in Yt \\ Ys using the adapted model fÎ¸t, especially in the presence of large data distribu- tion shifts. 3.2. Preliminaries For closed-set TTA, a common practice [44] is to adapt the model by minimizing the unsupervised entropy objective: min Î¸t Lt = 1 âˆ¥Btâˆ¥ X xâˆˆBt H(fÎ¸t(x)) âˆ’ Î»H( Â¯fÎ¸t), (1) where H(fÎ¸t(x)) = âˆ’PC c=1 fc Î¸t(x) logfc Î¸t(x) denotes the entropy of the softmax output fÎ¸t(x), Â¯fÎ¸t = 1 âˆ¥Btâˆ¥ P xâˆˆBt fÎ¸t(x) represents the average softmax output over the mini-batch Bt, and Î» is a hyperparameter used to balance the two terms in the loss function. In previous stud- ies [3, 6, 29, 31], marginal entropy H( Â¯fÎ¸t) has been widely adopted to prevent model collapse, i.e., predicting all input samples to the same class. 3.3. Motivation There is no label of the test data to provide supervised im- formation during TTA, an entropy minimization or a self- training strategy is widely adopted in existing methods. While previous studies [27, 33, 35, 44, 46, 54] focused on improving the performance of closed-set TTA, we empir- ically find that they exhibit performance degradation with open-set samples included. As shown in Fig. 4, We first compare the performance of existing TTA methods under different settings. Specifically, we conduct closed-set ex- periments on CIFAR-100-C [14], i.e., updating the model and measuring the performance of the adapted model with only the test samples from known classes, and the open-set counterparts are extracted from Tab. 1. Experimental re- sults show that applying existing methods to open-set TTA leads to the degradation of both the classification perfor- mance on known classes and the detection performance on unknown classes. We argue the degradation is caused by the following two reasons. First, the introduce of samples from unknown classes leads to the incorrect estimation of normalization statistics by the model, which results in un- reliable updating of the model parameters. Second, entropy minimization-based methods achieved competitive closed- set results by making the model confident on the predic- tions. However, minimizing entropy on samples from un- known classes destroys the model confidence, which is an undesirable result. We believe that a good model confidence is very important, especially in open-set TTA, because it can tell us how much can we trust the adapted modelâ€™s predic- tions. Source BN Adapt CoTTA TENT EATA OSTTA 52 54 56 58 60 62 64 66Acc (%) Closed-Set TTA Open-Set TTA (a) Accâ†‘ Source BN Adapt CoTTA TENT EATA OSTTA 10 20 30 40 50 60 70 80 90 100FPR@TPR95 (%) Closed-Set TTA Open-Set TTA + UniEnt (Ours) + UniEnt+ (Ours) (b) FPR@TPR95â†“ Figure 4. Performance comparison of existing TTA methods under closed-set and open-set settings. 3.4. Distribution-aware Filter We first model the open-set data distribution as shown in Eq. (2): POPEN := Ï€PcsID + (1 âˆ’ Ï€)PcsOOD, (2) where Ï€ âˆˆ [0, 1]. Equation (2) contains two distributions that the model may encounter during TTA: â€¢ Covariate-shifted ID PcsID shares the label space with the training data, whereas the input space suffers from style and domain shifts. â€¢ Covariate-shifted OOD PcsOOD differs from those of the training data in both the label space and the input space. We define the csOOD score for each test sample as: S(x) = Î½ \u0012 max c gÎ¸0 (x) Â· pc âˆ¥gÎ¸0 (x)âˆ¥âˆ¥pcâˆ¥ \u0013 , (3) where Î½(Â·) denotes min-max normalization with the range of [0, 1], gÎ¸0 denotes the feature extractor of source domain pre-trained model, pc denotes the source domain prototype of class c. As shown in Fig. 5, we empirically found that S(x) can distinguish between csID samples and csOOD samples. To be more specific, the distribution of S(x) appears to be bimodal, and its two peaks indicate csID and csOOD modes, respectively. In order to select the optimal thresh- old, we model the distribution of S(x) as a Gaussian mix- ture model (GMM) with two components, where the com- ponent with larger mean corresponds to the csID samples, and vice versa: P(x) =Ï€(x)N(x | ÂµcsID, Ïƒ2 csID) + (1 âˆ’ Ï€(x))N(x | ÂµcsOOD, Ïƒ2 csOOD) , (4) where Ï€(x) denotes the probability thatS(x) belongs to the csID component, ÂµcsID, Ïƒ2 csID and ÂµcsOOD, Ïƒ2 csOOD represent the mean and variance of the csID and csOOD components, respectively. Further, Ï€(x) can be easily obtained using the EM algorithm.0.0 0.2 0.4 0.6 0.8 1.0 Covariate-shifted OOD Score S(x) 0 1 2 3 4 5 6 7 8 9Density Covariate-shifted ID Covariate-shifted OOD Covariate-shifted ID Covariate-shifted OOD Figure 5. The csOOD score S(x) presents a bimodal distribution. Then, we can split Bt into Bt,csID and Bt,csOOD through Eq. (5): Bt,csID = {x | x âˆˆ Bt âˆ§ Ï€(x) â‰¥ 0.5} Bt,csOOD = {x | x âˆˆ Bt âˆ§ Ï€(x) < 0.5}, (5) where Bt,csID and Bt,csOOD are the mini-batches of pseudo csID and pseudo csOOD samples at timestamp t, respec- tively. 3.5. Unified Entropy Optimization UniEnt. Based on the previous sections, we consider min- imizing the entropy of the modelâ€™s predictions of the sam- ples from known classes, which can solve the inaccurate estimation of the data distribution and yield more reliable adaptation. However, the samples from unknown classes have not been explored effectively. Inspired by previous work [16, 23, 49], we propose to make the model produce approximately uniform predictions via entropy maximiza- tion instead, which can solve the inaccurate estimation of the model confidence and help distinguish known classes samples from unknown classes samples. The overall test- time optimization objective can be written as: Lt,csID = 1 âˆ¥Bt,csIDâˆ¥ X xâˆˆBt,csID H(fÎ¸t(x)), (6) Lt,csOOD = 1 âˆ¥Bt,csOODâˆ¥ X xâˆˆBt,csOOD H(fÎ¸t(x)), (7) min Î¸t Lt = Lt,csID âˆ’ Î»1Lt,csOOD âˆ’ Î»2H( Â¯fÎ¸t), (8) where Î»1 and Î»2 are trade-off hyperparameters. UniEnt+. In the distribution-aware filter, we distinguish csID samples from csOOD samples roughly, which in- evitably introduces some noise. To address this problem, we propose a weighting scheme to achieve entropy mini- mization for known classes and entropy maximization for unknown classes at the same time. The objective can be reformulated as follows: min Î¸t Lt = 1 âˆ¥Btâˆ¥ X xâˆˆBt Ï€(x)H(fÎ¸t(x)) âˆ’ Î»1 1 âˆ¥Btâˆ¥ X xâˆˆBt (1 âˆ’ Ï€(x))H(fÎ¸t(x)) âˆ’ Î»2H( Â¯fÎ¸t) . (9) 4. Experiments 4.1. Setup Datasets. Following previous studies, we evaluate our pro- posed methods on the widely used corruption benchmark datasets: CIFAR-10-C, CIFAR-100-C, and Tiny-ImageNet- C [14]. Each dataset contains 15 types of corruptions with 5 severity levels, all our experiments are conducted under the most severe corruption level 5. Pre-trained models are trained on the clean training set and tested and adapted on the corrupted test set. Following OSTTA [27], we apply the same corruption type to the original SVHN [34] and ImageNet-O [18] test sets to generate the SVHN-C and ImageNet-O-C datasets. We use SVHN-C and ImageNet- O-C as the covariate shifted OOD datasets for CIFAR- 10/100-C and Tiny-ImageNet-C, respectively. Evaluation protocols. Following recent research [27, 35, 44, 46], we evaluate TTA methods under continuously changing domains without resetting the parameters after each domain. At test time, the corrupted images are pro- vided to the model in an online fashion. After encoun- tering a mini-batch of test data, the model makes predic- tions and updates parameters immediately. The predictions of test data arriving at timestamp t will not be affected by any test data arriving after timestamp t. We construct the mini-batch using the same number of csID samples and csOOD samples. Regarding the modelâ€™s adaptation per- formance on csID data, we use the accuracy metric. To evaluate whether the adapted model can detect csOOD data robustly, we measure the area under the receiver operating characteristic curve (AUROC) and the false positive rate of csOOD samples when the true positive rate of csID sam- ples is at 95% (FPR@TPR95). As we pursue a good trade- off between the classification accuracy on csID data and the detection accuracy on csOOD data, we also report the open- set classification rate (OSCR) [9] to measure the balanced performance. Baseline methods. We mainly compare our method with two types of pervious methods in TTA: 1) entropy-free methods: Source directly evaluates the test data using the source model without adaptation. BN Adapt [33]Method CIFAR-10-C CIFAR-100-C Average Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54]81.73 77.89 79.45 68.44 53.25 60.55 94.98 39.87 67.49 69.22 87.22 54.16BN Adapt [33]84.20 80.40 76.84 72.13 57.16 72.45 84.29 47.10 70.68 76.43 80.57 59.62CoTTA [46]85.77 85.89 72.40 77.26 56.46 77.04 80.96 48.95 71.12 81.47 76.68 63.11 TENT [44] 79.38 65.39 95.94 56.73 54.74 65.00 94.79 42.24 67.06 65.20 95.37 49.49+ UniEnt 84.31(+4.93)92.28(+26.89)36.74(-59.20)80.32(+23.59)59.07(+4.33)89.28(+24.28)51.14(-43.65)56.26(+14.02)71.69(+4.63)90.78(+25.59)43.94(-51.43)68.29(+18.81)+ UniEnt+84.03(+4.65)93.18(+27.79)32.74(-63.20)80.62(+23.89)58.58(+3.84)91.39(+26.39)41.09(-53.70)56.36(+14.12)71.31(+4.25)92.29(+27.09)36.92(-58.45)68.49(+19.01) EATA [35] 80.92 84.32 71.66 72.63 60.63 88.64 50.18 57.24 70.78 86.48 60.92 64.94+ UniEnt 84.31(+3.39)97.15(+12.83)13.25(-58.41)82.99(+10.36)59.75(-0.88)93.42(+4.78)30.36(-19.82)57.99(+0.75)72.03(+1.26)95.29(+8.81)21.81(-39.12)70.49(+5.55)+ UniEnt+85.18(+4.26)96.97(+12.65)14.28(-57.38)83.67(+11.04)59.71(-0.92)94.23(+5.59)26.87(-23.31)58.19(+0.95)72.45(+1.67)95.60(+9.12)20.58(-40.35)70.93(+6.00) OSTTA [27]84.44 72.74 77.02 65.17 60.03 75.37 82.75 51.35 72.24 74.06 79.89 58.26+ UniEnt 82.46 (-1.98)96.20(+23.46)16.37(-60.65)80.51(+15.34)58.69 (-1.34)94.84(+19.47)22.95(-59.80)57.28(+5.93)70.58 (-1.66)95.52(+21.47)19.66(-60.23)68.90(+10.64)+ UniEnt+84.30(-0.14)97.38(+24.64)11.56(-65.46)82.91(+17.74)58.93(-1.10)95.42(+20.05)20.59(-62.16)57.69(+6.34)71.62(-0.62)96.40(+22.35)16.08(-63.81)70.30(+12.04) Table 1. Results of different methods on CIFAR benchmarks. â†‘ indicates that larger values are better, and vice versa. All values are percentages. The bold values indicate the best results, and the underlined values indicate the second best results. Method Tiny-ImageNet-C Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54] 22.29 53.79 93.41 16.29 BN Adapt [33]37.00 61.06 90.90 28.50 TENT [44] 28.96 49.78 95.96 19.02 + UniEnt 37.23(+8.27)63.92(+14.14)89.72(-6.24) 30.18(+11.16) + UniEnt+ 37.31(+8.35)63.83(+14.05)89.12(-6.84) 30.12(+11.10) EATA [35] 37.09 57.55 93.22 27.91 + UniEnt 37.54(+0.45)64.34(+6.79) 89.23(-3.99) 30.59(+2.68) + UniEnt+ 38.65(+1.56)62.30(+4.75) 90.88(-2.34) 30.95(+3.04) OSTTA [27] 37.29 55.66 94.34 27.74 + UniEnt 33.72 (-3.57)62.69(+7.03) 89.67(-4.67) 26.63 (-1.11) + UniEnt+ 34.47(-2.82) 61.28(+5.62) 89.56(-4.78) 26.65(-1.09) Table 2. Results of different methods on Tiny-ImageNet-C. updates batch normalization statistics with the test data during TTA. CoTTA [46] adopts the teacher-student ar- chitecture to provide weight-averaged and augmentation- averaged pseudo-labels to reduce error accumulation, com- bined with stochastic restoration to avoid catastrophic for- getting. 2) entropy-based methods: TENT [44] estimates normalization statistics and optimizes channel-wise affine transformations through entropy minimization. EATA[35] selects reliable and non-redundant samples for model adap- tation, the former achieve prediction entropy lower than a pre-defined threshold and the latter have diverse model out- puts. In addition, the fisher regularization is introduced to prevent catastrophic forgetting. OSTTA [27] uses the wisdom of crowds to filter out the samples with lower confidence values in the adapted model than in the orig- inal model. Our methods can be easily applied to exist- ing entropy-based methods without additional modification. Regarding applying our methods to EATA and OSTTA, we apply the filtering methods and keep everything else the same. Implementation details. For experiments on CIFAR benchmarks, following pervious studies [6, 27, 31], we use the WideResNet [54] with 40 layers and widen factor of 2. The model pre-trained with AugMix [17] is avail- able from RobustBench [7]. For Tiny-ImageNet-C, we pre- train ResNet50 [13] on the Tiny-ImageNet [26] training set, as OSTTA [27] did. The model is initialized with the pre-trained weights on ImageNet [8] and optimized for 50 epochs using SGD [38] with a batch size of 256. The initial learning rate is set to 0.01 and adjust using a cosine anneal- ing schedule. During TTA, we use Adam [25] optimizer with the batch size of 200 for all experiments. The learn- ing rate is set to 0.001 and 0.01 for entropy-based methods (TENT [44], EATA [35], OSTTA) and CoTTA [46], respec- tively. We use the energy score [32] to measure the ability of the adapted model to detect unknown classes. Further- more, following T3A [22], we use the weights of the linear classifier as the source domain prototypes, and thus our ap- proach is source-free. Entropy-based methods update only the affine parameters, while CoTTA updates all parameters. 4.2. Results CIFAR benchmarks. We first conduct experiments on the most common CIFAR benchmarks, and the results are pre- sented in Tab. 1. From Tab. 1, we can see that UniEnt and UniEnt+ significantly improve the performance of three different existing TTA methods. For example, on CIFAR- 10-C, UniEnt improves the Acc, AUROC, FPR@TPR95 and OSCR of TENT [44] by 4.93%, 26.89%, 59.20% and 23.59% respectively, while UniEnt+ improves the Acc, AUROC, FPR@TPR95 and OSCR of TENT by 4.65%, 27.79%, 63.20% and 23.89% respectively. In more detail, we can observe that TENT [44] and OSTTA [27] perform even worse than Source and BN methods that do not update model parameters in some cases (OSCR decreases by 3.27% âˆ¼15.40%), which indi- cates that some existing TTA methods cannot effectively update model parameters with open-set classes included. This can be attributed to the fact that these methods ig- nore the distribution variations introduced by open-set sam- ples, resulting in the unreliable estimation of normalization statistics and model confidence. Tiny-ImageNet-C. We then conduct experiments on a more challenging dataset Tiny-ImageNet-C, and the results are summarized in Tab. 2. As shown in Tab. 2, consistent withMethod Lt,csID Lt,csOOD CIFAR-10-C CIFAR-100-C Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ TENT [44] âœ— âœ— 79.38 65.39 95.94 56.73 54.74 65.00 94.79 42.24 âœ“ âœ— 85.04(+5.66) 81.80(+16.41) 68.89(-27.05) 73.57(+16.84)59.30(+4.56) 86.09(+21.09) 63.65(-31.14) 55.55(+13.31) âœ“ âœ“ 84.31(+4.93)92.28(+26.89)36.74(-59.20)80.32(+23.59)59.07(+4.33)89.28(+24.28)51.14(-43.65)56.26(+14.02) EATA [35] âœ— âœ— 80.92 84.32 71.66 72.63 60.63 88.64 50.18 57.24 âœ“ âœ— 85.53(+4.61) 82.94 (-1.38) 67.95(-3.71) 74.85(+2.22) 60.46(-0.17) 88.53 (-0.11) 54.30 (+4.12) 57.26(+0.02) âœ“ âœ“ 84.31(+3.39)97.15(+12.83)13.25(-58.41)82.99(+10.36)59.75 (-0.88)93.42(+4.78) 30.36(-19.82) 57.99(+0.75) OSTTA [27] âœ— âœ— 84.44 72.74 77.02 65.17 60.03 75.37 82.75 51.35 âœ“ âœ— 84.86(+0.42) 84.96(+12.22) 62.66(-14.36) 75.84(+10.67)58.95(-1.08) 90.62(+15.25) 44.79(-37.96) 56.50(+5.15) âœ“ âœ“ 82.46 (-1.98)96.20(+23.46)16.37(-60.65)80.51(+15.34)58.69 (-1.34)94.84(+19.47)22.95(-59.80) 57.28(+5.93) Table 3. Ablation study on CIFAR benchmarks. We investigate the effectiveness ofLt,csID and Lt,csOOD in Eq. (8) for UniEnt. Method 0.1 0.2 0.5 1.0 âˆ† TENT [44]+ UniEnt (59.09, 89.11, 51.68, 56.20) (59.07, 89.28, 51.14, 56.26) (58.92, 89.59, 50.16, 56.22) (58.76, 89.95, 48.92, 56.21) (0.33, 0.84, 2.76, 0.06) + UniEnt+ (58.64, 91.18, 41.79, 56.34) (58.58, 91.39, 41.09, 56.36) (58.41, 91.68, 40.22, 56.33) (58.12, 91.89, 39.68, 56.13) (0.52, 0.71, 2.11, 0.23) EATA [35]+ UniEnt (59.50, 93.34, 30.72, 57.72) (59.75, 93.42, 30.36, 57.99) (59.37, 92.56, 34.98, 57.40) (59.58, 93.82, 28.29, 57.97) (0.38, 1.26, 6.69, 0.59) + UniEnt+ (59.73, 93.47, 30.25, 58.00) (59.81, 93.88, 27.84, 58.17) (59.71, 94.23, 26.87, 58.19) (59.62, 93.47, 30.37, 57.91) (0.19, 0.76, 3.50, 0.28) OSTTA [27]+ UniEnt (58.85, 93.89, 26.59, 57.14) (58.82, 94.32, 24.94, 57.24) (58.69, 94.84, 22.95, 57.28) (57.88, 94.80, 23.51, 56.51) (0.97, 0.95, 3.64, 0.77) + UniEnt+ (59.25, 94.19, 24.62, 57.54) (59.15, 94.84, 22.29, 57.69) (58.93, 95.42, 20.59, 57.69) (58.20, 95.65, 20.12, 57.06) (1.05, 1.46, 4.50, 0.63) Table 4. Performance of UniEnt and UniEnt+ with varying Î»1 on CIFAR-100-C. The values in the table are presented as (Acc, AUROC, FPR@TPR95, OSCR). âˆ† is the difference between the maximum and minimum values when Î»1 take different values. Smaller âˆ† values represent better robustness. previous analysis, UniEnt and UniEnt+ still achieve better performance. Numerically, UniEnt improves the Acc, AU- ROC, FPR@TPR95 and OSCR of TENT [44] by 8.27%, 14.14%, 6.24% and 11.16% respectively, while UniEnt+ improves the Acc, AUROC, FPR@TPR95 and OSCR of TENT by 8.35%, 14.05%, 6.84% and 11.10% respectively. 4.3. Analysis Ablation study. To verify the effectiveness of different components in Lt (Eq. (8)), we conduct extensive abla- tion studies on CIFAR benchmarks. The results are sum- marized in Tab. 3. Compared with the baselines without Lt,csID and Lt,csOOD (the same as TENT [44], EATA [35] and OSTTA [27]), introducing Lt,csID improves the clas- sification accuracy of known classes, which indicates that our proposed distribution-aware filter can well distinguish the samples of known classes from the samples of un- known classes. It is worth noting that the introduction of Lt,csID also leads to better detection performance of un- known classes, which is consistent with the findings ob- tained in a recent study [43]. With the addition of Lt,csOOD, the modelâ€™s detection performance of unknown classes has been further improved. Considering the trade-off between the two, UniEnt achieves the optimal OSCR values in most cases. Hyperparameter sensitivity. We perform sensitivity analyses on the hyperparameters Î»1 and Î»2, as summa- rized in Tab. 4 and Tab. 5. We first investigate the ef- fect of Î»1 on CIFAR-100-C, with Î»1 taking values from {0.1, 0.2, 0.5, 1.0} and Î»2 holds constant. The experimen- tal results show that our methods are robust to the value of Î»1, the gaps between the best and worst values of Acc, AU- ROC, FPR@TPR95 and OSCR are 1.05%, 1.46%, 6.69% and 0.77%, respectively. We then examine how Î»2 affects csID classification and csOOD detection, with Î»2 taking values from {0.1, 0.2, 0.5, 1.0} and Î»1 holds constant. It is easy to conclude from the results that a larger Î»2 leads to better csOOD detection performance, yet at the same time, it may lose some of the csID classification performance, and vice versa. Numerically, different values ofÎ»2 will result in the maximum performance differences of 15.49%, 7.51%, 35.06% and 15.41% for Acc, AUROC, FPR@TPR95 and OSCR, respectively. Performance under different number of unknown classes. The number of unknown classes is an impor- tant measure representing the complexity of the open- set. We examine the impact of different numbers of un- known classes. Specifically, we perform experiments on the CIFAR-10-C dataset and control the number of unknown classes to vary from 2 to 10, keeping the number of samples constant. From Tab. 6, we can see that TENT [44] fluc- tuates with different number of classes while the proposed UniEnt and UniEnt+ are more robust to different number of unknown classes. Performance under different ratios of csOOD to csID samples. We also perform experiments with different ratios of the number of csOOD samples to the number of csID samples, and the results are displayed in Tab. 7. We varyMethod 0.1 0.2 0.5 1.0 âˆ† TENT [44]+ UniEnt (59.44, 87.02, 60.32, 55.93) (59.07, 89.28, 51.14, 56.26) (58.09, 92.87, 33.24, 56.23) (56.62, 94.53, 25.26, 55.24) (2.82, 7.51, 35.06, 1.02) + UniEnt+ (59.19, 87.95, 57.31, 56.04) (58.58, 91.39, 41.09, 56.36) (56.71, 94.57, 25.02, 55.34) (53.13, 94.93, 24.19, 52.01) (6.06, 6.98, 33.12, 4.35) EATA [35]+ UniEnt (60.54, 88.14, 55.48, 57.15) (60.06, 89.45, 50.99, 57.16) (59.75, 93.42, 30.36, 57.99) (58.26, 95.07, 22.18, 57.02) (2.28, 6.93, 33.30, 0.97) + UniEnt+ (60.35, 89.49, 50.20, 57.44) (60.51, 91.03, 42.50, 58.02) (59.71, 94.23, 26.87, 58.19) (59.03, 95.28, 21.20, 57.81) (1.48, 5.79, 29.00, 0.75) OSTTA [27]+ UniEnt (58.69, 94.84, 22.95, 57.28) (56.63, 95.43, 21.02, 55.46) (49.85, 93.77, 32.12, 48.59) (43.89, 91.19, 47.50, 42.41) (14.80, 4.24, 26.48, 14.87) + UniEnt+ (59.15, 94.84, 22.29, 57.69) (57.55, 95.82, 18.91, 56.43) (50.31, 94.09, 30.05, 49.11) (43.66, 91.78, 43.35, 42.28) (15.49, 4.04, 24.44, 15.41) Table 5. Performance of UniEnt and UniEnt+ with varying Î»2 on CIFAR-100-C. âˆ† is the difference between the maximum and minimum values when Î»2 take different values. Method 2 4 6 8 10 âˆ† Source [54] 70.84 69.28 69.32 69.18 68.44 2.40 BN Adapt [33] 72.56 72.48 72.52 72.44 72.14 0.42 TENT [44] 49.51 48.29 51.74 49.53 50.97 3.45 + UniEnt 78.71 78.39 78.28 78.13 77.82 0.89 + UniEnt+ 78.65 78.23 78.23 78.07 77.68 0.97 Table 6. OSCR of UniEnt and UniEnt+ on CIFAR-10-C under different number of unknown classes. Method 0.2 0.4 0.6 0.8 1.0 âˆ† Source [54] 40.00 40.03 39.98 39.92 39.87 0.16 BN Adapt [33] 49.91 49.55 48.92 47.97 47.10 2.81 TENT [44] 47.68 44.12 44.06 42.90 42.16 5.52 + UniEnt 56.84 57.48 57.13 56.77 56.26 1.22 + UniEnt+ 57.15 57.59 57.24 56.88 56.33 1.26 Table 7. OSCR of UniEnt and UniEnt+ on CIFAR-100-C under different ratios of csOOD to csID samples. the data ratio from 0.2 to 1.0. It can be observed that our proposed methods are insensitive to the variation of the data ratio while TENT [44] is more sensitive, and thus can be applied to different data ratio cases. T-SNE visualization. To illustrate the effects of different methods on csID classification and csOOD detection, we vi- sualize the feature representations of CIFAR-10-C test sam- ples with SVHN-C test samples as csOOD samples via T- SNE [42] in Fig. 6. It can be observed that the features from known classes and unknown classes adapted by TENT [44] are mixed together, while UniEnt and UniEnt+ can better separate them. Furthremore, we observe that filtering out csOOD samples (w/ Lt,csID) can not only improve the clas- sification performance on known classes, but also the detec- tion performance on unknown classes. 5. Conclusion This paper presents a unified entropy optimization frame- work for open-set test-time adaptation that can be flexibly applied to various existing TTA methods. We first delve into the performance of existing methods under open-set TTA (a) TENT [44]  (b) TENT [44] w/ Lt,csID (c) TENT [44] w/ UniEnt  (d) TENT [44] w/ UniEnt+ Figure 6. T-SNE visualization on CIFAR-10-C test set with SVHN-C as csOOD. red â†’ blue denotes csID samples and yel- low denotes csOOD samples. setting, and attribute the performance degradation to the unreliable estimation of normalization statistics and model confidence. To address the above issues, we then pro- pose a distribution-aware filter to preliminary distinguish csID samples from csOOD samples, followed by entropy minimization on csID samples and entropy maximization on csOOD samples. In addition, we propose to leverage sample-level confidence to reduce the noise from hard data partition. Extensive experiments reveal that our methods outperform state-of-the-art TTA methods in open-set sce- narios. We hope that more studies can focus on the robust- ness of TTA methods under open-set, which can facilitate the application of these methods in real scenarios. Acknowledgements. This work has been supported by the National Science and Technology Major Project (2022ZD0116500), National Natural Sci- ence Foundation of China (U20A20223, 62222609, 62076236), CAS Project for Young Scientists in Ba- sic Research (YSBR-083), and Key Research Pro- gram of Frontier Sciences of CAS (ZDBS-LY-7004).References [1] Haoyue Bai, Gregory Canal, Xuefeng Du, Jeongyeol Kwon, Robert D Nowak, and Yixuan Li. Feed two birds with one scone: Exploiting wild data for both out-of-distribution gen- eralization and detection. In ICML, 2023. 3 [2] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In CVPR, 2022. 3 [3] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022. 4 [4] Guangyao Chen, Limeng Qiao, Yemin Shi, Peixi Peng, Jia Li, Tiejun Huang, Shiliang Pu, and Yonghong Tian. Learning open set network with discriminative reciprocal points. In ECCV, 2020. 1 [5] Guangyao Chen, Peixi Peng, Xiangqian Wang, and Yonghong Tian. Adversarial reciprocal points learning for open set recognition. IEEE TPAMI, 2021. 1 [6] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sun- grack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, 2022. 4, 6 [7] Francesco Croce, Maksym Andriushchenko, Vikash Se- hwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In NeurIPS Datasets and Benchmarks Track, 2021. 6, 1 [8] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 6 [9] Akshay Raj Dhamija, Manuel G Â¨unther, and Terrance Boult. Reducing network agnostophobia. In NeurIPS, 2018. 5 [10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, et al. An image is worth 16x16 words: Trans- formers for image recognition at scale. In ICLR, 2021. 1 [11] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Franc Â¸ois Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. JMLR, 2016. 1 [12] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Note: Robust continual test- time adaptation against temporal correlation. In NeurIPS, 2022. 3 [13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 6, 1 [14] Dan Hendrycks and Thomas Dietterich. Benchmarking neu- ral network robustness to common corruptions and perturba- tions. In ICLR, 2019. 4, 5, 1 [15] Dan Hendrycks and Kevin Gimpel. A baseline for detect- ing misclassified and out-of-distribution examples in neural networks. In ICLR, 2017. 1, 3, 2 [16] Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich. Deep anomaly detection with outlier exposure. In ICLR, 2019. 1, 3, 5 [17] Dan Hendrycks, Norman Mu, Ekin Dogus Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Aug- mix: A simple data processing method to improve robustness and uncertainty. In ICLR, 2020. 6, 1 [18] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Stein- hardt, and Dawn Song. Natural adversarial examples. In CVPR, 2021. 5, 1 [19] Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joseph Kwon, Mohammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. Scaling out-of-distribution detection for real-world settings. In ICML, 2022. 1, 3, 2 [20] Yen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting out-of-distribution image with- out learning from out-of-distribution data. In CVPR, 2020. 3 [21] Hongzhi Huang, Yu Wang, Qinghua Hu, and Ming-Ming Cheng. Class-specific semantic reconstruction for open set recognition. IEEE TPAMI, 2022. 1 [22] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier ad- justment module for model-agnostic domain generalization. In NeurIPS, 2021. 6 [23] Julian Katz-Samuels, Julia B Nakhleh, Robert Nowak, and Yixuan Li. Training ood detectors in their natural habitats. In ICML, 2022. 3, 5 [24] Ansh Khurana, Sujoy Paul, Piyush Rai, Soma Biswas, and Gaurav Aggarwal. Sita: Single image test-time adaptation. arXiv preprint arXiv:2112.02355, 2021. 2, 3 [25] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 , 2014. 6 [26] Ya Le and Xuan Yang. Tiny imagenet visual recognition challenge. 2015. 6 [27] Jungsoo Lee, Debasmit Das, Jaegul Choo, and Sungha Choi. Towards open-set test-time adaptation utilizing the wisdom of crowds in entropy minimization. In ICCV, 2023. 1, 2, 3, 4, 5, 6, 7, 8 [28] Yushu Li, Xun Xu, Yongyi Su, and Kui Jia. On the robust- ness of open-world test-time training: Self-training with dy- namic prototype expansion. In ICCV, 2023. 1, 2, 3 [29] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for un- supervised domain adaptation. In ICML, 2020. 4 [30] Shiyu Liang, Yixuan Li, and R Srikant. Enhancing the re- liability of out-of-distribution image detection in neural net- works. In ICLR, 2018. 3 [31] Hyesu Lim, Byeonggeun Kim, Jaegul Choo, and Sungha Choi. Ttn: A domain-shift aware batch normalization in test- time adaptation. In ICLR, 2023. 2, 4, 6 [32] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. In NeurIPS, 2020. 1, 3, 6, 2 [33] Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robust- ness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. 1, 2, 4, 5, 6, 8, 3[34] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis- sacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011. 5 [35] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, 2022. 1, 2, 3, 4, 5, 6, 7, 8 [36] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In ICLR, 2023. 3 [37] Ori Press, Steffen Schneider, Matthias K Â¨ummerer, and Matthias Bethge. Rdumb: A simple approach that questions our progress in continual test-time adaptation. arXiv:2306.05401, 2023. 1 [38] Sebastian Ruder. An overview of gradient descent optimiza- tion algorithms. arXiv preprint arXiv:1609.04747, 2016. 6, 1 [39] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. 2 [40] Rui Tian, Zuxuan Wu, Qi Dai, Han Hu, and Yugang Jiang. Deeper insights into vits robustness towards common cor- ruptions. arXiv:2204.12143, 2022. 1 [41] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv Â´e JÂ´egou. Training data-efficient image transformers & distillation through at- tention. In ICML, 2021. 1 [42] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. JMLR, 2008. 8 [43] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisser- man. Open-set recognition: A good closed-set classifier is all you need. In ICLR, 2022. 1, 7 [44] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 1, 2, 4, 5, 6, 7, 8, 3 [45] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. Generalizing to unseen domains: A survey on domain generalization. TKDE, 2022. 1 [46] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Con- tinual test-time domain adaptation. In CVPR, 2022. 1, 2, 3, 4, 5, 6 [47] Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. A fourier-based framework for domain generaliza- tion. In CVPR, 2021. 1 [48] Jingkang Yang, Haoqi Wang, Litong Feng, Xiaopeng Yan, Huabin Zheng, Wayne Zhang, and Ziwei Liu. Semantically coherent out-of-distribution detection. In ICCV, 2021. 3 [49] Puning Yang, Jian Liang, Jie Cao, and Ran He. Auto: Adap- tive outlier optimization for online test-time ood detection. arXiv preprint arXiv:2303.12267, 2023. 3, 5 [50] Yanchao Yang and Stefano Soatto. Fda: Fourier domain adaptation for semantic segmentation. In CVPR, 2020. 1 [51] Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. 2 [52] Qing Yu and Kiyoharu Aizawa. Unsupervised out-of- distribution detection by maximum classifier discrepancy. In ICCV, 2019. 3 [53] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test-time adaptation in dynamic scenarios. In CVPR, 2023. 3 [54] Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In BMVC, 2016. 2, 4, 6, 8, 1, 3 [55] Jingyang Zhang, Nathan Inkawhich, Randolph Linderman, Yiran Chen, and Hai Li. Mixture outlier exposure: Towards out-of-distribution detection in fine-grained environments. In WACV, 2023. 3 [56] Jingyang Zhang, Jingkang Yang, Pengyun Wang, Haoqi Wang, Yueqian Lin, Haoran Zhang, Yiyou Sun, Xuefeng Du, Kaiyang Zhou, Wayne Zhang, et al. Openood v1. 5: En- hanced benchmark for out-of-distribution detection. arXiv preprint arXiv:2306.09301, 2023. 1, 2 [57] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In NeurIPS, 2022. 3 [58] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 1 [59] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE TPAMI, 2022. 1 [60] Zhi Zhou, Lan-Zhe Guo, Lin-Han Jia, Dingchu Zhang, and Yu-Feng Li. Ods: Test-time adaptation in the presence of open-world data shift. In ICML, 2023. 3Unified Entropy Optimization for Open-Set Test-Time Adaptation Supplementary Material 6. Pseudo Code For a better understanding of our proposed methods, we summarize UniEnt and UniEnt+ as Algorithm 1 and Algo- rithm 2, respectively. Algorithm 1: UniEnt Input: Source model fÎ¸0 pre-trained on the source domain dataset, testing samples Bt = {x}, t= 1, Â·Â·Â· , T. for t â† 1 to T do for x âˆˆ Bt do Compute csOOD score for each testing sample via Eq. (3); end Obtain Ï€(x) via the EM algorithm; Split Bt into Bt,csID and Bt,csOOD via Eq. (5); Update model via Eq. (8); end Output: The predictions arg maxc fÎ¸t(x) for all x âˆˆ Bt, t= 1, Â·Â·Â· , T. Algorithm 2: UniEnt+ Input: Source model fÎ¸0 pre-trained on the source domain dataset, testing samples Bt = {x}, t= 1, Â·Â·Â· , T. for t â† 1 to T do for x âˆˆ Bt do Compute csOOD score for each testing sample via Eq. (3); end Obtain Ï€(x) via the EM algorithm; Update model via Eq. (9); end Output: The predictions arg maxc fÎ¸t(x) for all x âˆˆ Bt, t= 1, Â·Â·Â· , T. 7. More Analysis Scalability of large-scale datasets. To demonstrate that our methods can be used for large-scale datasets, we con- duct experiments on ImageNet-C [14]. Specifically, we use ResNet-50 [13] pre-trained with AugMix [17], the weights of which can be obtained from RobustBench [7]. For opti- mization, we use the SGD optimizer [38] with the learn- ing rate of 0.00025 and the batch size of 64. We apply Method ImageNet-C Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54] 28.21 49.63 94.74 19.81 BN Adapt [33]43.57 55.89 93.39 30.42 CoTTA [46] 47.67 55.58 94.51 33.80 TENT [44] 45.82 51.34 96.47 30.33 + UniEnt 47.53(+1.71)56.33(+4.99) 95.21(-1.26) 34.42(+4.09) + UniEnt+ 46.87(+1.05)55.86(+4.52) 95.10(-1.37) 33.73(+3.40) EATA [35] 51.40 53.10 95.18 34.87 + UniEnt 49.60 (-1.80)58.29(+5.19) 93.63(-1.55) 36.28(+1.41) + UniEnt+ 51.57(+0.17)59.45(+6.35) 93.60(-1.58) 38.27(+3.40) OSTTA [27] 47.91 52.93 96.15 32.77 + UniEnt 47.92(+0.01)56.02(+3.09) 95.23(-0.92) 34.47(+1.70) + UniEnt+ 47.47 (-0.44)55.67(+2.74) 95.16(-0.99) 34.03(+1.26) Table 8. Results of different methods on ImageNet-C. â†‘ indicates that larger values are better, and vice versa. All values are percent- ages. The bold values indicate the best results, and the underlined values indicate the second best results. The values in parentheses indicate the improvements of our methods over the baseline meth- ods. common corruptions and perturbations to ImageNet-O [18] through the official code of [14] to construct ImageNet-O- C as csOOD data. From Table 8, we can see that UniEnt and UniEnt+ consistently improve the performance of the existing baseline methods in the open-set setting. Scalability of model architecture. Recently, Vision Trans- former (ViT) [10] has demonstrated better performance than Convolutional Neural Network (CNN), we also perform ex- periments with ViT backbone on ImageNet-C. Specifically, we use DeiT-Base [41] designed in [40], which proposes many techniques in the training phase to improve the ro- bustness of the model to common corruptions. The pre- trained weights are also available from RobustBench. We update the affine parameters of the modelâ€™s layer normal- ization. Table 9 shows that our approaches are compatible with ViT. Performance under long-term open-set test-time adap- tation. Models deployed in real-world scenarios are ex- posed to test samples for long periods and need to make reliable predictions at any time. Recent work [27, 37] points out that most existing TTA methods perform poorly in long-term settings, even worse than non-updating mod- els. Following [27], we simulate long-term TTA by repeat- ing adaptation for 10 rounds. During adaptation, the domain changes continuously and the model is never reset. The re- sults are summarized in Table 10. We observe that in most cases the performance degradation of our methods is very slight compared to the baseline methods. Effects of learning rate and batch size. We explore theMethod ResNet-50 DeiT Base Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54] 28.21 49.63 94.74 19.81 56.59 56.01 91.55 36.13 CoTTA [46] 47.67 55.58 94.51 33.80 60.73 53.51 93.14 37.33 TENT [44] 45.82 51.34 96.47 30.33 62.85 59.51 93.47 43.52 + UniEnt 47.53(+1.71) 56.33(+4.99) 95.21(-1.26) 34.42(+4.09) 58.81(-4.04) 67.10(+7.59) 90.90(-2.57) 47.40(+3.88) + UniEnt+ 46.87(+1.05) 55.86(+4.52) 95.10(-1.37) 33.73(+3.40) 58.40 (-4.45)66.69(+7.18) 90.43(-3.04) 46.74(+3.22) EATA [35] 51.40 53.10 95.18 34.87 65.38 57.95 92.92 44.29 + UniEnt 49.60 (-1.80) 58.29(+5.19) 93.63(-1.55) 36.28(+1.41) 59.36 (-6.02)67.22(+9.27) 91.63(-1.29) 48.23(+3.94) + UniEnt+ 51.57(+0.17) 59.45(+6.35) 93.60(-1.58) 38.27(+3.40) 61.50(-3.88) 66.96(+9.01) 89.99(-2.93) 48.79(+4.50) OSTTA [27] 47.91 52.93 96.15 32.77 60.19 60.69 92.42 43.19 + UniEnt 47.92(+0.01) 56.02(+3.09) 95.23(-0.92) 34.47(+1.70) 58.73(-1.46) 67.62(+6.93) 90.51(-1.91) 47.64(+4.45) + UniEnt+ 47.47 (-0.44) 55.67(+2.74) 95.16(-0.99) 34.03(+1.26) 58.72 (-1.47)67.28(+6.59) 90.02(-2.40) 47.32(+4.13) Table 9. Results of different methods on ImageNet-C using diverse architectures. Method CIFAR-10-C CIFAR-100-C Average Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54]81.73 77.89 79.45 68.44 53.25 60.55 94.98 39.87 67.49 69.22 87.22 54.16BN Adapt [33]84.20 80.40 76.84 72.13 57.16 72.45 84.29 47.10 70.68 76.43 80.57 59.62CoTTA [46]85.77 85.89 72.40 77.26 56.46 77.04 80.96 48.95 71.12 81.47 76.68 63.11 TENT [44] 79.38 65.39 95.94 56.73 54.74 65.00 94.79 42.24 67.06 65.20 95.37 49.49+ UniEnt 84.31(+4.93)92.28(+26.89)36.74(-59.20)80.32(+23.59)59.07(+4.33)89.28(+24.28)51.14(-43.65)56.26(+14.02)71.69(+4.63)90.78(+25.59)43.94(-51.43)68.29(+18.81)+ UniEnt+84.03(+4.65)93.18(+27.79)32.74(-63.20)80.62(+23.89)58.58(+3.84)91.39(+26.39)41.09(-53.70)56.36(+14.12)71.31(+4.25)92.29(+27.09)36.92(-58.45)68.49(+19.01) EATA [35] 80.92 84.32 71.66 72.63 60.63 88.64 50.18 57.24 70.78 86.48 60.92 64.94+ UniEnt 84.31(+3.39)97.15(+12.83)13.25(-58.41)82.99(+10.36)59.75(-0.88)93.42(+4.78)30.36(-19.82)57.99(+0.75)72.03(+1.26)95.29(+8.81)21.81(-39.12)70.49(+5.55)+ UniEnt+85.18(+4.26)96.97(+12.65)14.28(-57.38)83.67(+11.04)59.71(-0.92)94.23(+5.59)26.87(-23.31)58.19(+0.95)72.45(+1.67)95.60(+9.12)20.58(-40.35)70.93(+6.00) OSTTA [27]84.44 72.74 77.02 65.17 60.03 75.37 82.75 51.35 72.24 74.06 79.89 58.26+ UniEnt 82.46 (-1.98)96.20(+23.46)16.37(-60.65)80.51(+15.34)58.69 (-1.34)94.84(+19.47)22.95(-59.80)57.28(+5.93)70.58 (-1.66)95.52(+21.47)19.66(-60.23)68.90(+10.64)+ UniEnt+84.30(-0.14)97.38(+24.64)11.56(-65.46)82.91(+17.74)58.93(-1.10)95.42(+20.05)20.59(-62.16)57.69(+6.34)71.62(-0.62)96.40(+22.35)16.08(-63.81)70.30(+12.04) (a) Results after 1 round of adaptation (i.e., short-term test-time adaptation). Method CIFAR-10-C CIFAR-100-C Average Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Accâ†‘ AUROCâ†‘ FPR@TPR95â†“ OSCRâ†‘ Source [54] 81.73 77.89 79.45 68.44 53.25 60.55 94.98 39.87 67.49 69.22 87.22 54.16BN Adapt [33]84.20 80.40 76.84 72.13 57.16 72.45 84.28 47.09 70.68 76.43 80.57 59.62CoTTA [46]35.90 47.27 97.52 19.95 13.34 48.34 91.61 8.19 24.62 47.81 94.57 14.07 TENT [44] 32.61 60.86 93.24 20.86 37.49 53.73 95.07 25.02 35.05 57.30 94.16 22.94+ UniEnt 84.07(+51.46)88.53(+27.67)51.48(-41.76)77.87(+57.01)57.93(+20.44)90.62(+36.89)46.18(-48.89)55.67(+30.65)71.00(+35.95)89.58(+32.28)48.83(-45.33)66.77(+43.83)+ UniEnt+84.17(+51.56)88.21(+27.35)52.57(-40.67)77.75(+56.89)57.92(+20.43)90.63(+36.90)45.10(-49.97)55.59(+30.57)71.05(+36.00)89.42(+32.13)48.84(-45.32)66.67(+43.73) EATA [35] 40.94 64.52 88.41 29.07 48.75 73.26 80.83 41.27 44.85 68.89 84.62 35.17+ UniEnt 81.22(+40.28)91.05(+26.53)30.59(-57.82)76.42(+47.35)57.07(+8.32)98.59(+25.33)5.85(-74.98)56.70(+15.43)69.15(+24.30)94.82(+25.93)18.22(-66.40)66.56(+31.39)+ UniEnt+80.41(+39.47)92.49(+27.97)30.00(-58.41)77.00(+47.93)58.02(+9.27)98.05(+24.79)7.92(-72.91)57.47(+16.20)69.22(+24.37)95.27(+26.38)18.96(-65.66)67.24(+32.07) OSTTA [27]83.83 71.93 76.12 63.90 57.39 75.46 82.47 49.61 70.61 73.70 79.30 56.76+ UniEnt 80.74 (-3.09)88.94(+17.01)35.66(-40.46)74.52(+10.62)56.13 (-1.26)95.20(+19.74)21.15(-61.32)54.89(+5.28)68.44 (-2.18)92.07(+18.38)28.41(-50.89)64.71(+7.95)+ UniEnt+82.42(-1.41)90.15(+18.22)31.18(-44.94)76.46(+12.56)57.45(+0.06)95.91(+20.45)17.33(-65.14)56.32(+6.71)69.94(-0.67)93.03(+19.34)24.26(-55.04)66.39(+9.64) (b) Results after 10 rounds of adaptation (i.e., long-term test-time adaptation). Table 10. Results of different methods on CIFAR benchmarks. impact of learning rate and batch size on our approaches in Table 11. A learning rate that is too large or too small can hurt performance, while a larger batch size results in bet- ter performance. Compared to TENT [44] and EATA [35], our methods are more robust to learning rate and batch size. Nonetheless, our methods share the same limitation as the baseline methods: they rely on a large batch size to esti- mate the distribution accurately. Moreover, we observe that OSTTA [27] is less sensitive to learning rate and batch size. Effects of OOD score. We use the energy score [32] to measure the modelâ€™s detection performance on csOOD data. From Table 12, we can make two observations. First, our methods consistently improve the performance using differ- ent OOD scores. Second, compared with MSP [15], using Max Logit [19] and Energy yields better detection perfor- mance.Method Learning rate âˆ†0.005 0.001 0.0005 0.0001 Source [54] 39.87 39.87 39.87 39.87 0.00BN Adapt [33]47.10 47.10 47.10 47.10 0.00 TENT [44] 10.60 42.24 42.38 48.36 37.76+ UniEnt 53.82(+43.22)56.20(+13.96)56.06(+13.68)54.51(+6.15)2.38+ UniEnt+ 54.44(+43.84)56.36(+14.12)56.27(+13.89)54.65(+6.29)1.92 EATA [35] 40.96 57.00 56.91 53.60 16.04+ UniEnt 49.36(+8.40)57.76(+0.76)57.10(+0.19)53.63(+0.03)8.40+ UniEnt+ 49.05(+8.09)58.07(+1.07)57.39(+0.48)53.40 (-0.20)9.02 OSTTA [27] 49.43 51.35 51.98 52.37 2.94+ UniEnt 51.41(+1.98)56.93(+5.58)57.22(+5.24)55.58(+3.21)5.81+ UniEnt+ 53.39(+3.96)57.69(+6.34)57.68(+5.70)56.06(+3.69)4.30 (a) OSCR w.r.t. learning rate Method Batch size âˆ†64 32 16 8 Source [54] 39.87 39.87 39.87 39.87 0.00BN Adapt [33]46.38 45.25 42.94 38.61 7.77 TENT [44] 33.27 8.10 2.51 0.95 32.32+ UniEnt 55.17(+21.90)53.05(+44.95)48.87(+46.36)31.47(+30.52)23.70+ UniEnt+55.17(+21.90)53.13(+45.03)49.27(+46.76)28.35(+27.40)26.82 EATA [35] 53.09 47.78 40.57 31.57 21.52+ UniEnt 57.08(+3.99)54.52(+6.74)50.71(+10.14)43.89(+12.32)13.19+ UniEnt+ 56.79(+3.70)54.29(+6.51)50.49(+9.92)43.17(+11.60)13.62 OSTTA [27] 50.35 48.82 46.07 39.75 10.60+ UniEnt 54.54(+4.19)50.49(+1.67)44.97 (-1.10)36.72 (-3.03)17.82+ UniEnt+ 55.76(+5.41)52.66(+3.84)47.94(+1.87)41.45(+1.70)14.31 (b) OSCR w.r.t. batch size Table 11. OSCR of different methods on CIFAR-100-C with diverse learning rates and batch sizes.âˆ† is the difference between the largest and smallest values. Smaller âˆ† values represent better robustness. Method OOD score âˆ† MSP [15] Max Logit [19] Energy [32] Source [54] 39.65 40.24 39.87 0.59 BN Adapt [33] 48.75 48.04 47.10 1.65 CoTTA [46] 49.44 49.73 48.99 0.74 TENT [44] 36.86 41.79 42.24 5.38 + UniEnt 55.42(+18.56)56.20(+14.41)56.26(+14.02)0.84 + UniEnt+ 55.24(+18.38)56.31(+14.52)56.36(+14.12)1.12 EATA [35] 55.20 57.52 57.55 2.35 + UniEnt 56.94(+1.74) 57.88(+0.36) 57.87(+0.32) 0.94 + UniEnt+ 57.37(+2.17) 58.33(+0.81) 58.33(+0.78) 0.96 OSTTA [27] 49.14 51.42 51.35 2.28 + UniEnt 56.52(+7.38) 57.23(+5.81) 57.25(+5.90) 0.73 + UniEnt+ 57.12(+7.98) 57.69(+6.27) 57.69(+6.34) 0.57 Table 12. OSCR of different methods on CIFAR-100-C using di- verse OOD scores.",
      "meta_data": {
        "arxiv_id": "2404.06065v1",
        "authors": [
          "Zhengqing Gao",
          "Xu-Yao Zhang",
          "Cheng-Lin Liu"
        ],
        "published_date": "2024-04-09T07:08:00Z",
        "pdf_url": "https://arxiv.org/pdf/2404.06065v1.pdf"
      }
    },
    {
      "title": "Towards Stable Test-time Adaptation in Dynamic Wild World",
      "abstract": "Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.",
      "meta_data": {
        "arxiv_id": "2302.12400v1",
        "authors": [
          "Shuaicheng Niu",
          "Jiaxiang Wu",
          "Yifan Zhang",
          "Zhiquan Wen",
          "Yaofo Chen",
          "Peilin Zhao",
          "Mingkui Tan"
        ],
        "published_date": "2023-02-24T02:03:41Z",
        "pdf_url": "https://arxiv.org/pdf/2302.12400v1.pdf"
      }
    },
    {
      "title": "Towards Stable Test-time Adaptation in Dynamic Wild World",
      "abstract": "Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.",
      "meta_data": {
        "arxiv_id": "2302.12400v1",
        "authors": [
          "Shuaicheng Niu",
          "Jiaxiang Wu",
          "Yifan Zhang",
          "Zhiquan Wen",
          "Yaofo Chen",
          "Peilin Zhao",
          "Mingkui Tan"
        ],
        "published_date": "2023-02-24T02:03:41Z",
        "pdf_url": "https://arxiv.org/pdf/2302.12400v1.pdf"
      }
    },
    {
      "title": "Test Time Adaptation via Conjugate Pseudo-labels",
      "abstract": "Test-time adaptation (TTA) refers to adapting neural networks to distribution\nshifts, with access to only the unlabeled test samples from the new domain at\ntest-time. Prior TTA methods optimize over unsupervised objectives such as the\nentropy of model predictions in TENT [Wang et al., 2021], but it is unclear\nwhat exactly makes a good TTA loss. In this paper, we start by presenting a\nsurprising phenomenon: if we attempt to meta-learn the best possible TTA loss\nover a wide class of functions, then we recover a function that is remarkably\nsimilar to (a temperature-scaled version of) the softmax-entropy employed by\nTENT. This only holds, however, if the classifier we are adapting is trained\nvia cross-entropy; if trained via squared loss, a different best TTA loss\nemerges. To explain this phenomenon, we analyze TTA through the lens of the\ntraining losses's convex conjugate. We show that under natural conditions, this\n(unsupervised) conjugate function can be viewed as a good local approximation\nto the original supervised loss and indeed, it recovers the best losses found\nby meta-learning. This leads to a generic recipe that can be used to find a\ngood TTA loss for any given supervised training loss function of a general\nclass. Empirically, our approach consistently dominates other baselines over a\nwide range of benchmarks. Our approach is particularly of interest when applied\nto classifiers trained with novel loss functions, e.g., the recently-proposed\nPolyLoss, where it differs substantially from (and outperforms) an\nentropy-based loss. Further, we show that our approach can also be interpreted\nas a kind of self-training using a very specific soft label, which we refer to\nas the conjugate pseudolabel. Overall, our method provides a broad framework\nfor better understanding and improving test-time adaptation. Code is available\nat https://github.com/locuslab/tta_conjugate.",
      "full_text": "Test-Time Adaptation via Conjugate Pseudo-labels Sachin Goyalâ‹†1 Mingjie Sunâ‹†1 Aditi Raghunathan1 Zico Kolter1,2 1Carnegie Mellon University, 2Bosch Center for AI {sachingo, mingjies, raditi, zkolter}@cs.cmu.edu Abstract Test-time adaptation (TTA) refers to adapting neural networks to distribution shifts, with access to only the unlabeled test samples from the new domain at test-time. Prior TTA methods optimize over unsupervised objectives such as the entropy of model predictions in TENT [50], but it is unclear what exactly makes a good TTA loss. In this paper, we start by presenting a surprising phenomenon: if we attempt to meta-learn the â€œbestâ€ possible TTA loss over a wide class of functions, then we recover a function that isremarkably similar to (a temperature-scaled version of) the softmax-entropy employed by TENT. This only holds, however, if the classiï¬er we are adapting is trained via cross-entropy loss; if the classiï¬er is trained via squared loss, a different â€œbestâ€ TTA loss emerges. To explain this phenomenon, we analyze test-time adaptation through the lens of the training lossesâ€™sconvex conjugate. We show that under natural conditions, this (unsupervised) conjugate function can be viewed as a good local approximation to the original supervised loss and indeed, it recovers the â€œbestâ€ losses found by meta-learning. This leads to a generic recipe that can be used to ï¬nd a good TTA loss for any given supervised training loss function of a general class. Empirically, our approach consistently dominates other TTA alternatives over a wide range of domain adaptation benchmarks. Our approach is particularly of interest when applied to classiï¬ers trained with novel loss functions, e.g., the recently-proposed PolyLoss [25] function, where it differs substantially from (and outperforms) an entropy-based loss. Further, we show that our conjugate based approach can also be interpreted as a kind of self-training using a very speciï¬c soft label, which we refer to as the conjugate pseudo-label. Overall, our method provides a broad framework for better understanding and improving test-time adaptation. Code is available at https://github.com/locuslab/ tta_conjugate. 1 Introduction Modern deep networks perform exceeding well on new test inputs that are close to the training distribution. However, this performance dramatically decreases on test inputs drawn from a different distribution. While there is a large body of work on improving the robustness of models, most robust training methods are highly specialized to the setting they cater to. For e.g., they assume pre-speciï¬ed perturbations, subpopulations, and spurious correlations, or access to unlabeled data from the target distribution, and most methods offer close to no improvement on general distribution shifts beyond what they were trained for [12, 21]. In practice, it is often cumbersome (or even impossible) to precisely characterize all possible distri- bution shifts a model could encounter and then train accordingly. Instead, a model already trained on some source data must be able to adapt at test-time to new inputs from a different domain. This setting of test-time adaptation (TTA) has gained interest in recent years [ 6, 47, 50, 54]. TTA is typically accomplished by updating the source model parameters via a few steps of optimization on an unsupervised objective involving the new test sample from the target distribution. The choice â‹† Equal Contribution 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv:2207.09640v2  [cs.LG]  23 Nov 2022of this unsupervised objective, which we call the TTA loss, dictates the success of the adaptation procedure. [47] uses a self-supervised objective on the test sample, [50] uses the entropy of model predictions, and several follow-ups have proposed variants or alternatives [ 40, 54]. However, it remains unclear as to how to choose or guide the selection of this TTA loss, and thus far the choice of these losses has remained largely heuristic in nature. In this work, we begin by presenting a set of intriguing experiments where we attempt to learn the â€œbestâ€ TTA loss for a given source classiï¬er and distribution shift. We parameterize the TTA loss by another neural network whose parameters are learnt via meta-learning [ 3, 9] where we differentiate through the adaptation process to ï¬nd the TTA loss that achieves the best adaptation on distribution shifts. Surprisingly, we ultimately learn a TTA loss that looksremarkably similar to (a temperature-scaled version of) the softmax-entropy loss, which was already proposed by [50]. Why did we recover the commonly used softmax-entropy loss despite the fact that the procedure is capable of learning a very general class of losses and the meta-learning process could potentially specialize to both the source classiï¬er and the distribution shift of interest? Furthermore, we ï¬nd that this pattern only holds when the loss used to train the source classiï¬er is cross-entropy loss; when a different loss such as squared loss is used instead, the meta-learning procedure recovers a TTA loss that itself looks more like a negative squared error, and is very different from the softmax-entropy loss (Section 3). In order to explain this phenomenon, we propose to consider TTA through the lens of the convex conjugate function. Speciï¬cally, given a hypothesis function h(x) and label y, several common losses (cross-entropy and the squared loss amongst them, but not limited to these) can be written in the form L(h(x),y) = f(h(x)) âˆ’yTh(x) for some function f. In these cases, we show that â€œnaturalâ€ TTA loss for such classiï¬ers is precisely the (negation of) the convex conjugate evaluated at the gradient of h, LTTA(x) = âˆ’fâˆ—(âˆ‡f(h(x)), where fâˆ—is the convex conjugate of f. This framework not only recovers the results of our meta-learning experiments, but also justiï¬es why some speciï¬c choices of TTA loss in the previous literature work well (e.g., this framework recovers TENTâ€™s choice of softmax-entropy for cross-entropy-trained classiï¬er). Moreover, it also provides a broad framework for what the TTA loss should be when the source model is trained using various different loss functions (for example the recently-proposed PolyLoss [25, 29]) as is becoming increasingly common in machine learning. Further, we show that our proposed conjugate adaptation loss is in fact a kind of self-training with pseudo-labels [42], a classic approach in machine learning. Various formulations of the pseudo-label have been proposed in the literature, and our conjugate analysis provides a general recipe for the â€œcorrectâ€ choice of soft pseudo-labels given byË†y(x) = âˆ‡f(h(x)). We thus refer to these as conjugate pseudo-labels (Conjugate PLâ€™s), and believe our work provides a broad framework for understanding adaptation with unlabeled data in general. Finally, we empirically verify the effectiveness of our proposed conjugate adaptation loss across several datasets and training losses, such as cross-entropy and squared loss, along with the recently- proposed PolyLoss [ 25] (which itself has shown higher standard test accuracy on a wide range of vision tasks). Over all models, datasets and training losses, we ï¬nd our proposed conjugate pseudo-labeling consistently outperforms prior TTA losses and improves TTA performance over the current state of the art. 2 Background and preliminaries. Test-time adaptation. We are interested in mapping an input xâˆˆRd to a label yâˆˆY. We learn a model hÎ¸ : Rd â†¦â†’R|Y|parameterized by Î¸that maps an input xto predictions hÎ¸(x). We assume access to a trained source model and adapt at test-time over the test input, before making the ï¬nal prediction. This is the standard test-time adaptation (TTA) setting [47, 50]. During TTA, we update the model parameters on an unsupervised objective L(x,hÎ¸). For example, in TENT [50], this loss is the entropy of the softmax-normalized predictions of the model. At each time step of adaptation, we observe a batch of test inputs and we take a gradient step towards optimizing the TTA loss on this test batch. As is standard, we measure the average online performance of models across all steps (number of test batch inputs seen) in the adaptation process. Meta learning the loss function. In order to explore the existence of different TTA losses, we employ the meta-learning procedure where we attempt to learn the TTA loss. We use a similar procedure as prior work on meta-learning loss functions [3, 37] and parameterize the loss function via a neural network mÏ† : R|Y| â†¦â†’R that takes in the model predictions/logits and outputs a loss value. We want to learn parameter Ï†such that when we update Î¸via the loss function mÏ†, our ï¬nal 2performance is optimal. In order to do so, let xbe the unlabeled test samples to adapt to, and ybe the corresponding labels. We update Î¸and Ï†alternatively as follows. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t , Ï†t+1 â†Ï†t âˆ’Î²âˆ‚L(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , (1) where Lis some supervised surrogate loss function such as cross-entropy. Please refer to Appendix A3 for further details regarding meta-learning setup. Note that the meta-learning process above assumes access to labels yof test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We discuss our ï¬ndings from this exploration in the next section. 3 Test-time Adaptation via Meta-Learnt Losses The objective used in TENT is the softmax-entropy of the model predictions which essentially makes the classiï¬er more conï¬dent in its current predictions. The same can be achieved by various other loss formulations such as those mentioned in [40]. With so many possible choices for the loss function, what should we use for TTA? In this section, we attempt to answer this empirically and present some intriguing observations. (a)  (b) Figure 1: Visualization of meta loss (blue) by varying one input prediction score. (a) For cross-entropy loss trained model, the learnt meta loss can be approximated with a scaled softmax-entropy function (dashed red). (b) When the source model is trained with a squared loss for classiï¬cation, the learnt meta loss (blue) can be ï¬tted closely with a quadratic function (dashed red), shown in Figure 1b. The range (max/min) of the prediction score (logit) in x-axis is chosen to cover the empirical range of the predicted logits. Experiment 1. We learn the TTA loss parameterized by a neural network via meta-learning as described in Section 2. Our source classiï¬er is a ResNet-26 trained on CIFAR-10 and we adapt to distribution shifts in CIFAR-10-C. We use the 4 labeled validation noises in CIFAR-10-C to learn the meta-loss network parameters and we denote the resulting learnt loss function by meta-TTA loss. We then adapt the source classiï¬er to the test set of 15 corruptions by optimizing the meta-TTA loss. Observations. First, we ï¬nd that TTA using meta-TTA loss performs better than TENT (12.35% vs 13.14%), suggesting that there are better TTA losses than previous losses based on softmax-entropy. However, on examining this meta-TTA loss, we ï¬nd a surprising observation. Figure 1a (blue curve) visualizes the learnt meta-loss over model predictions as we vary a single class prediction with the rest ï¬xed. Qualitatively, the learnt meta-loss looks very similar to softmax-entropy in one dimension. In fact, we can ï¬t it closely with a scaled softmax-entropy function (dashed red curve): Î±Â·H(softmax(hÎ¸(x)/T)), where Î±is a magnitude parameter and T is a temperature scaler. We want to test if the meta-loss is basically learning the softmax-entropy function. Hence, we perform test-time adaptation with the ï¬tted softmax-entropy function instead (dashed red curve) and achieve an error of 12.32%, essentially recovering the performance of meta-TTA. 3Despite the ability to represent many different loss functions and potentially specialize to the CIFAR- 10-C setting, the meta-loss procedure gave back the standard entropy objective.Do we always recover a loss that looks like softmax-entropy? Experiment 2. In an attempt to isolate when we get back the entropy objective, we vary several things. We tried different architectures for the source classiï¬er, different lossesLduring the meta- learning process (1) and different training losses for the source classiï¬er. Results. We observed that we consistently recovered the temperature scaled softmax-entropy function in all cases except when we varied the training loss for the source classiï¬er (Appendix A.10). On using the squared loss function [18], a strikingly different meta-TTA loss emerges. Figure 1b (blue curve) shows the learnt meta-loss (13.48% error) for this network. Here again, the meta-TTA loss outperforms entropy (14.57%) but it is not simply due to a scaling factor. The loss now looks like the negative squared error (red curve). Like previously, we tried ï¬tting a quadratic loss directly to the meta loss in Figure 1b, and this time we even slightly outperformed the meta-TTA loss. To summarize, we used a meta-learning procedure to search for the â€œbestâ€ TTA loss, where the loss itself was parameterized by a neural network that could potentially represent arbitrarily complex loss functions. However, we ended up with loss functions displaying remarkable structure: across different architectures and different variants of meta-learning, for a classiï¬er trained with cross-entropy, the meta-TTA loss was temperature scaled softmax-entropy and for a classiï¬er trained with squared loss, the meta-TTA loss was a negative squared loss. This is interesting from both a practical and conceptual standpoint where the â€œbestâ€ TTA loss depends on the loss used to train the source classiï¬er in a clean fashion. We attempt to understand and explain this phenomenon in the next section. 4 Conjugate Pseudo Labels Results in the previous section raise an obvious question: why does softmax-entropy as used in TENT seem to be the â€œbestâ€ possible test time adaptation loss for classiï¬ers trained via cross-entropy (at least, best in the sense that meta-learning consistently recovers something which essentially mimics softmax-entropy, even though meta-loss is parameterized by a neural network and hence could learn much more complex functions speciï¬c to the model and the particular shift)? And why, alternatively, does a quadratic TTA loss seem to perform best when the classiï¬er is trained via squared loss? In this section, we offer an explanation of this phenomenon via the construct of the convex conjugate function [1]. As we will see, our method recovers softmax-entropy and quadratic loss as the â€œnaturalâ€ objectives for classiï¬ers trained via cross-entropy and squared loss respectively. Furthermore, for classiï¬ers trained via other loss functions, as is becoming increasingly common in deep learning, our approach naturally suggests corresponding test-time adaptation losses, which we show in the next section to comparatively outperform alternatives. Thus, we argue that our framework overall provides a compelling recipe for specifying the â€œcorrectâ€ method for TTA for a large class of possible losses. 4.1 Losses and the convex conjugate We begin by formally considering loss functions between a hypothesis outputhÎ¸(x) (e.g., the logit outputs of a classiï¬er, or the direct prediction of a regressor) and targetythat take the following form L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yThÎ¸(x) (2) for some function f; when there is no risk of confusion, we will use hin place of hÎ¸(x) for simplicity of notation. While not every loss can be expressed in such a form, this captures a wide variety of common losses (possibly scaled by a constant value). For example, cross-entropy loss corresponds to the choice f(h) = log âˆ‘ iexp(hi) and where y denotes a one-hot encoding of the class label; similarly, squared loss corresponds to the choice f(h) = 1 2 âˆ¥hâˆ¥2 2. When training an over-parameterized classiï¬er, we can roughly view the training process as (approxi- mately) attaining the minimum over hypotheses hfor each training example min Î¸ 1 t tâˆ‘ i=1 L(hÎ¸(xi),yi) â‰ˆ1 t tâˆ‘ i=1 min h L(h,yi) (3) 4where t is the number of training samples. However, in the case of losses in the form (2), the minimization over hin this form represents a very speciï¬c and well-known optimization problem: it is known as the convex conjugate [1] of the function f min h L(h,y) = min h {f(h) âˆ’yTh}= âˆ’fâ‹†(y) (4) where fâ‹† denotes the convex conjugate of f. fâ‹† is a convex function in y(and indeed, is convex regardless of whether or not f is convex). Furthermore, for the case that f is convex differentiable, the optimality condition of this minimization problem is given by âˆ‡f(hopt) = y, so we also have that fâ‹†(y) = fâ‹†(âˆ‡f(hopt)) (5) where hopt refers to the optimal classiï¬er (used interchangeably with hÎ¸opt ). Putting this all together, we can state (admittedly, in a rather informal manner) that under the assumption that Î¸opt is chosen so as to approximately minimize the empirical loss on the source data in the over-parameterized setting, we have that for tinputs 1 t tâˆ‘ i=1 L(hÎ¸opt (xi),yi) â‰ˆ1 t tâˆ‘ i=1 âˆ’fâ‹†(âˆ‡f(hÎ¸opt (xi))) (6) i.e., the empirical loss can be approximated by the (negative) conjugate applied to the gradient of the f, at least in a region close to the optimal Î¸opt that minimizes the empirical loss. But the later expression has the notable beneï¬t that it does not require any label yi in order to compute the loss, and thus can be used as a basis for TTA on target domain of the hypothesis function hÎ¸opt . Deï¬nition 1 (conjugate adaptation loss) Consider a loss function that takes the form given in 2, used for training a hypothesis hÎ¸ in the over-parameterized regime. We deï¬ne the conjugate adaptation loss Lconj(hÎ¸(x)) : R|Y|â†¦â†’R as follows. Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))âŠ¤hÎ¸(x). (7) 4.2 Recovery of existing test-time adaptation strategies Cross-entropy The interesting aspect to this formalism is that when applied to classiï¬ers trained with cross-entropy, it recovers exactly the TENT approach to TTA : minimizing the softmax-entropy of hÎ¸(x). And indeed, this loss was also recovered when using meta-learning to learn the â€œoptimalâ€ test-time adaptation loss. To see this, note that for cross-entropy, we have thatf(h) = log âˆ‘ iexp(hi), giving the optimality condition y= âˆ‡f(hopt) = exp(hopt)âˆ‘ iexp(hopt i ) and the conjugate function fâ‹†(y) = { âˆ‘ iyilog yi if âˆ‘ iyi = 1 âˆž otherwise . (8) In other words, Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (9) i.e. softmax-entropy of the model prediction, which is exactly the TTA loss that TENT uses. Squared loss For the squared loss, we have thatf(h) = 1 2 âˆ¥hâˆ¥2 2, leading to the optimality condition y = hand conjugate function fâ‹†(y) = 1 2 âˆ¥yâˆ¥2 2. Hence, the adaptation loss in this case would be simply given by Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = âˆ’1 2 âˆ¥hâˆ¥2 2 which is also what we observed in the meta-learning experiments discussed in Section 3. 4.3 Conjugate pseudo-labels We now emphasize that by the nature of our approximations, there is an additional simple interpre- tation of the conjugate loss: it is also equal to the original loss (2) applied to the â€œpsuedo-labelsâ€ ËœyCPL Î¸ (x) = âˆ‡f(hÎ¸(x)), where CPL refers to conjugate pseudo-labels, i.e., Lconj(hÎ¸(x)) = âˆ’fâ‹†(âˆ‡f(hÎ¸(x))) = f(hÎ¸(x)) âˆ’âˆ‡f(hÎ¸(x))ThÎ¸(x) = L(hÎ¸(x),âˆ‡f(hÎ¸(x))). (10) 5This property is known as the Fenchel-Young inequality, that isf(x) + fâ‹†(u) â‰¥xTuholding with equality when u = âˆ‡f(x). In other words, our conjugate adaptation loss is precisely equivalent to self-training under the speciï¬c soft pseudo-labels given by ËœyCPL = âˆ‡f(hÎ¸(x)). And indeed, for many cases, this may be a more convenient form to compute than explicitly computing the conjugate function at all. For this reason, we refer to our method as that of conjugate pseudo-labels. In the case of cross-entropy loss, this approach then corresponds exactly to self-training using labels given by the softmax applied to the current hypothesis. We must emphasize, however, that while our conjugate formulation indeed has this â€œsimpleâ€ form for the case of cross-entropy loss, the real advantage comes in that it provides the â€œcorrectâ€pseudo-label for use with other losses, which may result in pseudo-labels different from the â€œcommonâ€ softmax operation. Example: conjugate pseudo-labels for PolyLoss. PolyLoss [25] is a recently-proposed simple alternative to cross-entropy loss than has been shown to improve performance across a wide variety of compute tasks. This loss is given by the form Lpoly(hÎ¸(x),y) = Lce(hÎ¸(x),y) + ÏµÂ·yT(1 âˆ’softmax(hÎ¸(x))) (11) We note that this can be put exactly into our conjugate form (equation 2) by writing the loss in a slightly more involved fashion, which we refer to as the expanded conjugate form Lpoly(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’yTg(hÎ¸(x)). (12) where f is the log-sum-exp function as before, and g(h) = hâˆ’Ïµ(1 âˆ’softmax(h)). In order to formally put this into the form of the previous loss function (equation 2), we can simply deï¬ne an alternative hypothesis as the function hâ€² Î¸(x) = g(hÎ¸(x)), and then deï¬ne PolyLoss in the conjugate form as Lpoly(hâ€² Î¸(x),y) = f(gâˆ’1(hâ€² Î¸(x))) âˆ’yThâ€² Î¸(x). (13) Typically, however, it is easier to simply operate on the expanded conjugate form, which yields the optimality condition for the pseudo-label âˆ‡f(hopt) = Dg(hopt)ËœyCPL Î¸ (x), where D is the Jacobian operator. For the case of PolyLoss, this leads to the conjugate pseudo-label of the following form: ËœyCPL Î¸ (x) = (I+ Ïµdiag(z) âˆ’ÏµzzT)âˆ’1z, z â‰¡softmax(hÎ¸(x)). Test-time adaptation. Finally, we note that the above discussion doesnâ€™t actually address any topics related to test-time adaptation to OOD data, but merely provides a generic characterization of a self- training procedure for generic loss functions of the form(2). However, the application toTTA on OOD data is fairly straightforward: as long as the learnt source parameters Î¸is a reasonable approximation to the true optimal Î¸opt on the shifted domain, self-training with the conjugate pseudo-labels provides a reasonable proxy for ï¬ne-tuning the network on the true OOD loss. We emphasize that, common to most approaches for TTA , there are still some amount of design decisions that must be put in place; these are detailed in Section 5.1. In practice, we observe OOD generalization typically beneï¬ts (across all baselines) from an additional â€œtemperatureâ€ scaling, i.e., applying the TTA loss to hÎ¸(x)/T for some ï¬xed temperature T, although it requires a held-out validation dataset for tuningT. However, we should emphasize that truly unsupervisedTTA would require making an informed guess for the value of these hyper-parameters. The full procedure for test time adaptation via conjugate pseudo-labels is shown in Algorithm 1. Algorithm 1 Conjugate pseudo-labeling (Conjugate PL) Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y) = f(hÎ¸(x)) âˆ’hÎ¸(x)âŠ¤y. N batches of test data Dtest = [x1,x2,...,x N] Hyperparams: learning rate Î·and temperature T. Let Â¯hÎ¸(x) def = hÎ¸(x)/T be the temperature scaled predictor. Let ËœyCPL Î¸ (x) denote the conjugate pseudo-label function ËœyCPL Î¸ (x) = âˆ‡(f(Â¯hÎ¸(x))). for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡L ( Â¯hÎ¸(xn),ËœyCPL Î¸ (xn) ) [Self-training with conjugate pseudo-labels] 65 Experiments In this section, we empirically evaluate the effectiveness and generality of the proposed conjugate pseudo-labeling procedure (Algorithm 1) for test-time adaptation on a variety of datasets. 5.1 Setup Datasets. We evaluate on the three common corruption benchmarks: adapting a classiï¬er trained on CIFAR-10 to CIFAR-10-C, CIFAR-100 to CIFAR-100-C and ImageNet to ImageNet-C [ 15]. Following the previous works [47, 50], we report the error averaged across corruptions at the highest severity for CIFAR-10/100-C and averaged across corruptions and severity level for ImageNet-C. We also evaluate on three domain adaptation datasets: adapting a classiï¬er trained on SVHN to MNIST, an ImageNet classiï¬er to ImageNet-R [16] and adapting from synthetic to real data in VISDA-C [38]. Models and Training losses. Following previous works on TTA[47, 50], we use ResNet-26 [14] as the source classiï¬er architecture for CIFAR-10/100 experiments, ResNet-18 for SVHN to MNIST and a ResNet-50 for ImageNet and source synthetic data on VisDA-C. We consider source classiï¬ers trained via the following loss functions: the de-facto cross-entropy, recently proposed polyloss [25] and squared loss [18]. Baselines. Our proposed conjugate pseudo-label is the classic approach of self-training with a speciï¬c form of pseudo-labels. In self-training, we replace the label ywith a pseudo-label Ëœy(x) and adapt by optimizing the loss function L(hÎ¸(x),Ëœy(x)). Note that we could either instantaneously update the pseudo-labels using the current classiï¬er, or generate pseudo-labels once with just the source classiï¬er. Instantaneous updates have been shown to work better for domain adaptation [7, 40], and we perform instantaneous updates for all methods. While we propose using ËœyCPL(x) = âˆ‡f(hÎ¸(x)) (See Section 4.3), we compare to the standard pseudo-labels used in the literature: â€¢ (i) the â€œhardâ€ pseudo-label (hard PL) where Ëœy(x) = arg maxi ( hÎ¸(x) ) i is the most likely class as predicted by hÎ¸. As is common in the self-training literature, we perform conï¬dence thresholding. â€¢ (ii) The â€œsoftâ€ pseudo-label (soft PL) where Ëœy(x) is obtained by applying a softmax function to the model predictions hÎ¸(x). We also compare with the following recently proposed test-time adaptation methods. â€¢ Entropy Minimization (ENT) [50] minimizes the entropy of model predictions. â€¢ Robust Pseudo-Label [40] where we minimize a robust classiï¬cation loss, Lrpl = qâˆ’1(1 âˆ’p(i|x)q) where i= argmaxjp(j|x) and qâˆˆ[0,1]. â€¢ MEMO [54] minimizes entropy of a modelâ€™s outputs across different augmentations of a test input. We implement a batch version, where we see multiple test points at once, for fair comparisons. TTA methodology. Following [ 50] and [40], we ï¬ne-tune by updating the learnable scale and shift parameters of the batch normalization layers across all adaptation losses. For each batch, batch normalization statistics is also updated, as suggested in [41]. We report performance at the end of one round of test-time adaptation over the entire test set. We tune the learning rate (LR) and temperature (T) on the validation noises in the corruption benchmark by grid-search. LR is selected from {1eâˆ’1,1eâˆ’2,... 1eâˆ’4}and T from {1,2 ... 5}. All the experiments have been performed on A6000 GPUâ€™s. On domain adaptation benchmarks, where there is no held-out target domain, we set T to be 1 and use the LR suggested by [ 6, 50]. We use the same hyperparameter tuning protocol across all methods. We single out temperature as a very important hyperparameter, as we discuss in the results below. 5.2 Results on classiï¬ers trained with cross-entropy We study the effectiveness of our proposed conjugate pseudo-labels when the source classiï¬er is trained via cross-entropy loss. In this case, baselines Softmax PL and ENT are the same as Conjugate PL. Thus we omit them in our results. Table 1, reports the performance of various TTA methods. When the source classiï¬er is trained via cross-entropy, our conjugate pseudo-label algorithm exactly corresponds to entropy minimization with an additional temperature scaling. Entropy minimization as 7Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 13.95 (Â±0.06) 13.97 ( Â±0.04) 12.60(Â±0.04) 13.07 (Â±0.05) \u0013 13.95 (Â±0.06) 12.85 ( Â±0.04) 12.51(Â±0.01) 12.51(Â±0.03) CIFAR-100-C \u0017 45.22 (Â±0.4) 39.80 ( Â±0.18) 38.52(Â±0.16) 41.15 (Â±0.25) \u0013 45.22 (Â±0.4) 36.37 ( Â±0.10) 37.38 ( Â±0.06) 36.10(Â±0.07) ImageNet-C \u0017 45.43(Â±0.05) 45.68 ( Â±0.01) 48.91( Â±0.03) 45.82(Â±0.01) \u0013 45.43 (Â±0.05) 45.61 ( Â±0.01) 48.91( Â±0.04) 45.36(Â±0.01) Table 1: Mean errors when adapting to corruptions using a source classiï¬er trained via cross- entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. With the right temperature scaling, softmax-entropy minimization matches or outperforms other approaches. Prior reported gains of other methods over softmax-entropy minimization disappear when we use temperature scaling. For additional context, the source classiï¬er errors without adaptation are: CIFAR-10-C (29.54%), CIFAR-100-C (62.26%), ImageNet-C (61.89%) proposed in prior work [50] does not tune the temperature parameter, and some newer objectives such as robust PL or MEMO outperform vanilla entropy minimization. For example, on CIFAR-100-C, vanilla ENT obtaines 41.15% average error, while robust PL improves this to39.80% and MEMO to 38.52%. However, with the right temperature scaling, entropy minimization obtains 36.10% error which outperforms the newer objectives (with and without temperature scaling). A similar observation holds for CIFAR-10-C and ImageNet-C as well. Essentially, the gains over vanilla entropy minimization vanish when we do temperature scaling, and entropy minimization (i.e. conjugate pseudo-labeling corresponding to cross-entropy) turns out to be the best objective after all. 5.3 Results on classiï¬ers trained with polyloss and squared loss In the case of cross-entropy, conjugate pseudo-labeling reduces to the familiar notion of entropy minimization. We now explore the performance of our method on different loss functions where the conjugate pseudo-labels differ substantially from entropy minimization (section 4.3). Table 2 presents the results on the corruption benchmarks and Table 3 presents the results on the other domain adaptation datasets for source classiï¬ers trained with PolyLoss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C \u0017 13.81(Â±0.12) 14.23(Â±0.02) 13.46(Â±0.06) 13.23(Â±0.07) 14.64(Â±0.11) 13.02(Â±0.09) \u0013 13.81(Â±0.12) 12.45(Â±0.05) 12.23(Â±0.06) 12.33(Â±0.04) 12.26(Â±0.04) 12.08(Â±0.05) CIFAR-100-C\u0017 40.47(Â±0.05) 42.86(Â±0.11) 40.12(Â±0.08) 39.90(Â±0.05) 41.00(Â±0.11) 38.17(Â±0.17) \u0013 40.47(Â±0.05) 39.80(Â±0.08) 38.23(Â±0.05) 39.23(Â±0.04) 37.04(Â±0.06) 36.83(Â±0.08) ImageNet-C \u0017 45.44(Â±0.21) 46.27(Â±0.03) 46.10(Â±0.03) 48.21(Â±0.05) 44.63(Â±0.03) 44.01(Â±0.01) \u0013 45.44(Â±0.21) 46.27(Â±0.03) 45.50(Â±0.02) 48.21(Â±0.04) 44.45(Â±0.03) 44.01(Â±0.01) Table 2: Mean errors when adapting to corruptions using a source classiï¬er trained via recently proposed Poly-1 Loss [ 25]. Conjugate pseudo-labeling consistently outperforms all previous ap- proaches. For additional context, source classiï¬er errors without adaptation : CIFAR-10-C (30.22%), CIFAR-100-C (63.91%) and ImageNet-C (62.18%). First, we note that, across all datasets in Table 2 and Table 3, our conjugate PL approach outperforms all other TTA losses. With polyloss classiï¬ers, entropy minimization is no longer the best methodâ€”on CIFAR-100-C, entropy minimization achieves38.23% error while our conjugate PL achieves36.83%. We see similar consistent gains on CIFAR-10-C, ImageNet-C, ImageNet-R and VisDA-C. On digit adaptation tasks from SVHN to MNIST/USPS/MNISTM, where there is a larger shift between source and target, the gains are especially pronounced. Figure 2 compares how the task loss (polyloss Ïµ= 6) on the test data decreases as we adapt the model through conjugate PL and other baselines. We use CIFAR-10-C as an example. Observe that our proposed conjugate PL indeed reduces the task loss the most among other baselines. 8Dataset Source Error Hard PL Robust PL EntropySoftmax PL Conjugate PL Ours SVHNâ†’MNIST 28.33 20.21 19.73 14.28 16.54 10.73 SVHNâ†’USPS 31.58 23.32 26.12 23.12 24.07 21.62 SVHNâ†’MNISTM61.69 50.73 51.35 49.33 50.47 47.59 ImageNet-R 64.19 58.52 59.46 58.25 56.62 55.63 VisDA-C 58.13 40.43 45.44 44.11 39.63 38.42 Table 3: Target error when adapting models trained via polyloss on source domains across different domain adaptation bench- marks. Conjugate pseudo-labeling offers consistent and substan- tial gains over previous approaches across three datasets. Figure 2: Task Loss (PolyLoss Ïµ= 6) evaluated on CIFAR-10-C test data during test-time adaptation. Furthermore, on CIFAR-10-C and ImageNet-C, we ï¬nd that adapting polyloss classiï¬ers via conjugate PL improves the performance over all methods applied to cross-entropy trained source classiï¬ers. For e.g., on ImageNet-C, the performance improves from 45.34% to 44.01%. However, this is only true when using the proposed conjugate PL. If we just did softmax-entropy minimization (even with temperature scaling), the ï¬nal adapted performance of a polyloss classiï¬er (45.5%) is in fact worse than that of a cross-entropy classiï¬er (45.34%). Our results suggest that as we develop new training losses that improve the source classiï¬ers, it is important to adapt via conjugate pseudo-labeling to reap the maximum gains. Similarly, we experiment with the case when the source classiï¬er is trained using squared loss on the CIFAR-10 and CIFAR-100 datasets, and observe consistent gains using the proposed conjugate pseudo-labels over the baselines. For example, on CIFAR-10-C, TTA using conjugate PL gives and error of 12.87%, outperforming baselines like ENT (13.24%) and Softmax PL (31.81%). Table 5 in Appendix A.7 shows the detailed results. Comparing Table 1 and Table 2, we see that the relative ordering between the various baselines differs. This is further evidence that the adaptation loss has to depend on the training loss, and we believe our conjugate pseudo-label approach captures this appropriately by offering consistent gains across the various settings we experimented with. 6 Related Works Test-time adaptation methods. In recent years, the setting of test-time adaptation has gained a lot of interest with a host of different approaches proposed in the literature. One family of TTA approaches update the source classiï¬er by minimizing an unsupervised loss on the target distribution [4, 6, 20, 22, 35, 36, 40, 43, 44, 50, 51, 54]. TENT [ 50] proposes to minimize the entropy of model predictions at test time. Several follow ups like [ 6, 35, 40, 44, 54] propose alternative TTA objectives, e.g. robust pseudo-labelling [40], likelihood ratio loss [35], entropy of marginal probability averaged across augmentations [54] and self-supervised contrastive losses [6, 49]. However, most of these objectives are heuristically designed or chosen. In this paper, we provide a principled approach of designing unsupervised objectives for TTA . Another family of approaches for test-time adaptation such as [ 2, 8, 13, 31, 34, 47] leverage an auxiliary self-supervised task (e.g. rotation prediction [ 47], masked autoencoders [10]) to update model parameters on each test sample. Crucially, these methods require modifying the source model training by augmenting the supervised training objective with an auxiliary self-supervised loss. Hence it cannot be applied to typical standard classiï¬ers that are trained by minimizing a supervised loss on the source data. Source-free domain adaptation. A very related setting to test-time adaptation is source-free domain adaptation, where a trained source classiï¬er must be adapted to a target distribution of interest, although the entire target unlabeled data is available at once. SHOT [28] proposes to optimize the source hypothesis (i.e. feature extractor) with a combination of entropy minimization, diversity and self-training on pseudo-labels on the unlabeled target data. [53] promotes feature clustering on features from target distributions. [24, 26] use generative modeling to estimate the underlying source distributions for enforcing feature invariance. Such approaches typically require multiple epochs over the target data and cannot be easily adopted to work in an online fashion. 9Unsupervised domain adaptation. The most canonical setting of domain adaptation involves access to labeled source data and unlabeled target data, all during training. The availability of source and target data during training lends itself to approaches that â€œalignâ€ the source and target representations in some way: [ 32, 33, 45, 48] match distribution statistics, [ 11] uses a discriminator, [ 46] uses self-supervised learning. However, such approaches require access to source data which might not always be feasible due to data privacy and efï¬ciency issues. Pseudo-labels and self-training. Self-training is a classic idea for leveraging unlabeled data, devel- oped ï¬rst for the semi-supervised setting. Self-training generates pseudo-labels on the unlabeled data, allowing us to use any â€œsupervisedâ€ loss on this pseudo-labeled data. Self-training has shown promising results in various settings like semi-supervised learning [ 19] and improving adversarial robustness [ 5]. Self-training has also been gaining attention in the setting of unsupervised domain adaptation [28, 39], where pseudo-labels generated on the unlabeled data from target domain is used to supervise the adaptation process. [ 7, 23, 52] provide theoretical insights into how self-training with pseudo-labels can help under distribution shift. TENT [50] (i.e entropy minimization) can be viewed as a form of self-training with instantaneous softmax pseudo-labels. Our work provides a general framework for the choice of soft pseudo-labels based on the conjugate analysis of the source training objective. Some prior works like [7, 17, 27, 30, 55, 56] have documented the improvement in performance when using instantaneous pseudo-labels over pre-computed pseudo-labels, and thus lend further support to the beneï¬ts of our proposed conjugate pseudo-labeling approach. The ex- periment results presented in this work supporting conjugate pseudo-labels suggest that conjugate pseudo-labels is a promising direction of pseudo-labeling in a broader context. 7 Conclusion, Limitations and Future Directions In this work, we proposed a general test-time adaptation loss, based on the convex conjugate formulation which in turn was motivated by the intriguing meta learning experiments. The fact that meta-learning recovers the proposed loss hints at some kind of optimality of the loss. In Section 4, we prove that for a broad set of loss functions, the proposed (unsupervised) conjugate loss is close to the oracle supervised loss. However, this still does not completely answer what the optimal test-time adaptation loss is and why. The meta-learning framework in this work was constrained to learn functions over the logits of each individual input. It can be expanded to more involved setups, where we consider functions over the intermediate representations too and also consider learning functions over a batch of input while accounting for their interactions. Beyond the choice of the adaptation loss itself, achieving good test-time adaptation generally involves several heuristics like updating only the batch norm parameters [50]. While our work was motivated by the loss function, via the meta-learning experiments, we discovered that temperature scaling is another important hyper-parameter that improves the performance of all previous baselines as well. At a high level, test-time adaptation has to be appropriately regularized to prevent the updates over batches from taking the model too far: updating only a few batch norm parameters is one way to do that, and perhaps temperature scaling provides a similar beneï¬cial regularization effect by making the network predictions on unlabeled inputs less conï¬dent. Understanding the role of these heuristics more concretely is an interesting direction for future work. It also remains an open problem to understand under what sort of real-world distribution shifts would self-training based approaches would help. Finally, it is also worth extending and applying the conjugate pseudo-labeling to other settings like semi-supervised learning. 8 Acknowledgments We thank Shubhang Bhatnagar and Asher Trockman for helping with running the ImageNet experi- ments. We thank Zhili Feng for useful feedback. Sachin Goyal and Mingjie Sun were supported by funding from the Bosch Center for Artiï¬cial Intelligence. Aditi Raghunathan was supported by an Open Philanthropy AI Fellowship. 10References [1] https://en.wikipedia.org/wiki/Convex_conjugate. [2] Pratyay Banerjee, Tejas Gokhale, and Chitta Baral. Self-supervised test-time learning for reading comprehension. In Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2021. [3] Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette, Ludovic Righetti, Gaurav Sukhatme, and Franziska Meier. Meta-learning via learned loss. arXiv preprint arXiv:1906.05374, 2019. [4] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [5] Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Un- labeled data improves adversarial robustness. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÃ©-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips. cc/paper/2019/file/32e0bd1497aa43e02a42f47d9d6515ad-Paper.pdf. [6] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [7] Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. In Advances in Neural Information Processing Systems, 2020. [8] Mohammad Zalbagi Darestani, Jiayu Liu, and Reinhard Heckel. Test-time training can close the natural distribution shift performance gap in deep learning based compressed sensing. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [9] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adap- tation of deep networks. In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017. [10] Yossi Gandelsaman, Yu Sun, Xinlei Chen, and Alexei A. Efros. Test-time training with masked autoencoders. In Advances in Neural Information Processing Systems, 2022. [11] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1â€“35, 2016. [12] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. InInternational Conference on Learning Representations, 2021. [13] Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Alenya, Pieter Abbeel, Alexei A. Efros, Lerrel Pinto, and Xiaolong Wang. Self-supervised policy adaptation during deployment. In International Conference on Learning Representations, 2021. [14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [15] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019. [16] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In In IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [17] Yosuke Higuchi, Niko Moritz, Jonathan Le Roux, and Takaaki Hori. Advancing momentum pseudo-labeling with conformer and initialization strategy. In IEEE International Conference on Acoustics, Speech and Signal Processing, 2022. 11[18] Like Hui and Mikhail Belkin. Evaluation of neural architectures trained with square loss vs cross-entropy in classiï¬cation tasks. In International Conference on Learning Representations, 2021. [19] Dong hyun Lee. Pseudo-label: The simple and efï¬cient semi-supervised learning method for deep neural networks. [20] Yusuke Iwasawa and Yutaka Matsuo. Test-time classiï¬er adjustment module for model-agnostic domain generalization. In Advances in Neural Information Processing Systems, 2021. [21] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton A. Earnshaw, Imran S. Haque, Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. Wilds: A benchmark of in-the-wild distribution shifts. In Proceedings of the 38th International Conference on Machine Learning (ICML), 2021. [22] Takeshi Kojima, Yutaka Matsuo, and Yusuke Iwasawa. Robustifying vision transformer without retraining from scratch by test-time class-conditional feature alignment. In International Joint Conference on Artiï¬cial Intelligence, 2022. [23] Ananya Kumar, Tengyu Ma, and Percy Liang. Understanding self-training for gradual domain adaptation. In Proceedings of the 37 th International Conference on Machine Learning (ICML), 2020. [24] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In IEEE Winter Conference on Applications of Computer Vision (WACV), 2021. [25] Zhaoqi Leng, Mingxing Tan, Chenxi Liu, Ekin Dogus Cubuk, Jay Shi, Shuyang Cheng, and Dragomir Anguelov. Polyloss: A polynomial expansion perspective of classiï¬cation loss functions. In International Conference on Learning Representations, 2022. [26] Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsuper- vised domain adaptation without source data. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [27] Xinzhe Li, Qianru Sun, Yaoyao Liu, Qin Zhou, Shibao Zheng, Tat-Seng Chua, and Bernt Schiele. Learning to self-train for semi-supervised few-shot classiï¬cation. In Advances in Neural Information Processing Systems, 2019. [28] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. InProceedings of the 37th International Conference on Machine Learning (ICML), 2020. [29] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r. Focal loss for dense object detection. In IEEE/CVF International Conference on Computer Vision (ICCV), 2017. [30] Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training for domain adaptation. In Advances in Neural Information Processing Systems, 2021. [31] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In Advances in Neural Information Processing Systems, 2021. [32] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S. Yu. Transfer feature learning with joint distribution adaptation. In IEEE/CVF International Conference on Computer Vision (ICCV), 2013. [33] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. Learning transferable features with deep adaptation networks. In Proceedings of the 32nd International Conference on Machine Learning, 2015. [34] Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf. Consistent video depth estimation. In SIGGRAPH, 2020. 12[35] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and Jan Hendrik Metzen. Test-Time Adaptation to Distribution Shift by Conï¬dence Maximization and Input Transformation. arXiv preprint arXiv: 2106.14999, 2021. [36] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efï¬cient test-time model adaptation without forgetting. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. [37] Junhyuk Oh, Matteo Hessel, Wojciech M. Czarnecki, Zhongwen Xu, Hado P van Hasselt, Satinder Singh, and David Silver. Discovering reinforcement learning algorithms. In Advances in Neural Information Processing Systems, 2020. [38] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. Visda: The visual domain adaptation challenge, 2017. [39] Viraj Prabhu, Shivam Khare, Deeksha Kartik, and Judy Hoffman. Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [40] Evgenia Rusak, Steffen Schneider, George Pachitariu, Luisa Eck, Peter Vincent Gehler, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. If your data distribution shifts, use self- learning, 2022. URL https://openreview.net/forum?id=1oEvY1a67c1. [41] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In Advances in Neural Information Processing Systems, 2020. [42] H. Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transac- tions on Information Theory, 1965. [43] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test-time prompt tuning for zero-shot generalization in vision-language models. In Advances in Neural Information Processing Systems, 2022. [44] Prabhu Teja Sivaprasad and FranÃ§ois Fleuret. Test time adaptation through perturbation robust- ness. arXiv preprint arXiv: 2110.10232, 2021. [45] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment for unsupervised domain adaptation. arXiv preprint arXiv: 1612.01939, 2016. [46] Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A. Efros. Unsupervised domain adaptation through self-supervision. arXiv preprint arXiv:1909.11825, 2019. [47] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Proceedings of the 36th International Conference on Machine Learning (ICML), 2019. [48] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014. [49] Dequan Wang, Shaoteng Liu, Sayna Ebrahimi, Evan Shelhamer, and Trevor Darrell. On-target adaptation. arXiv preprint arXiv: 2109.01087, 2021. [50] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. [51] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [52] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. In-n-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness. In International Conference on Learning Representations, 2021. 13[53] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021. [54] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In Advances in Neural Information Processing Systems, 2022. [55] Yang Zou, Zhiding Yu, B. V . K. Vijaya Kumar, and Jinsong Wang. Domain adaptation for semantic segmentation via class-balanced self-training. European Conference on Computer Vision, 2018. [56] Yang Zou, Zhiding Yu, Xiaofeng Liu, B. V . K. Vijaya Kumar, and Jinsong Wang. Conï¬dence regularized self-training. In IEEE/CVF International Conference on Computer Vision (ICCV), 2019. 14A Appendix A.1 Conjugate Derivations Cross-Entropy Loss : L(h,y) = âˆ’ câˆ‘ i=1 yilog exp(hi)âˆ‘c j=1 exp(hj) = âˆ’ câˆ‘ i=1 yi âˆ—hi + log câˆ‘ j=1 exp(hj) = f(h) âˆ’yâŠ¤h, (14) where f(h) is log âˆ‘c j=1 exp(hj) and the constraint that âˆ‘c i=1 yi = 1. Now, the conjugate fâ‹†(y) is given by : fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {log câˆ‘ j=1 exp(hj) âˆ’yTh} (15) with the constraint âˆ‘c i=1 yi = 1. At the optimality, yi = (âˆ‡f(h))i = exp(hi)âˆ‘ jexp(hj) (16) Then, fâ‹†(y) = âˆ’log câˆ‘ j=1 exp(hj) + câˆ‘ i=1 hi exp(hi)âˆ‘ jexp(hj) = âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj), (17) if the constraint âˆ‘c i=1 yi = 1 is satisï¬ed, otherwise fâ‹†(y) = âˆžby duality. This in turn gives, the conjugate loss for cross-entropy (when the constraint is satisï¬ed) : Lconj(h) = âˆ’fâ‹†(y) = âˆ’fâ‹†(âˆ‡f(h)) = âˆ’ âˆ‘ i exp(hi)âˆ‘ jexp(hj) log exp(hi)âˆ‘ jexp(hj) (18) Squared Loss : L(h,y) = 1 2||hâˆ’y||2 2 â‰ˆ1 2||h||2 2 âˆ’yâŠ¤h [ignoring the constant term] = f(h) âˆ’yâŠ¤h, (19) Now, the conjugate fâ‹†(y) is given by: fâ‹†(y) = âˆ’min h {f(h) âˆ’yTh}= âˆ’min h {1 2||h||2 2 âˆ’yTh} = âˆ’1 2||h||2 2 (20) A.2 Experiments on Binary Classiï¬cation with Exponential Loss Here we present the results on a binary classiï¬cation task over a synthetic dataset of 100 dimensional gaussian clusters. 15Dataset Creation For the binary classiï¬cation task, we create a synthetic dataset similar to [23]. Speciï¬cally, let the data X âˆ¼ N(Âµ,Î£) âˆˆ R100 and labels Y âˆˆ {âˆ’1,+1}. We sample Âµ âˆ¼ N(k,I100). For Î£, similar to [ 23], we sample a diagonal matrix D, where each entry is sampled uniformly from a speciï¬ed range, and a rotation matrix U from a HAAR distribution, giving Î£ = UDUT. For the source data, we sample Âµâˆ’1 s ,Âµ+1 s ,Î£âˆ’1 s ,Î£+1 s as speciï¬ed above with k= 0. Now to create a distribution shifted data of various severity, we sampleÂµâˆ’1 t ,Âµ+1 t ,Î£âˆ’1 t ,Î£+1 t as speciï¬ed above with k= 1, which are then used to sample the shifted data as follows : Âµ1 Î» = Î»Âµ1 t + (1 âˆ’Î»)Âµ1 s Âµâˆ’1 Î» = Î»Âµâˆ’1 t + (1 âˆ’Î»)Âµâˆ’1 s Î£1 Î» = Î»Î£1 t + (1 âˆ’Î»)Î£1 s Î£âˆ’1 Î» = Î»Î£âˆ’1 t + (1 âˆ’Î»)Î£âˆ’1 s XÎ» âˆ¼N(ÂµÎ»,Î£Î») In the following experiments, easy shift refers to Î»= 0.6, moderate shift to Î»= 0.65 and hard shift to Î»= 0.7. Exponential Loss for Binary Classiï¬cation Let zbe the classiï¬cation score hÎ¸(x). For logistic training loss, conjugate adaptation loss would default to entropy with sigmoid probability. Thus, here we experiment with a different but also commonly used surrogate loss to 0/1 loss: exponential loss, which is deï¬ned as: Lexp(z,y) = exp(âˆ’yz) (21) where yâˆˆ{âˆ’1,+1}. It can be rewritten in the expanded conjugate form of: Lexp(z,y) = 1 2 Â· ( ez + eâˆ’z) âˆ’1 2 Â·yÂ· ( ez âˆ’eâˆ’z) (22) For exponential loss, the conjugate pseudo-label function and the conjugate pseudo-label loss are: yCPL exp (z) = ez âˆ’eâˆ’z ez + eâˆ’z, LCPL exp (z) = 2 ez + eâˆ’z (23) The model is adapted on shifted gaussian clusters and we compare the conjugate loss with two baseline approaches: 1) Hard pseudo-labelling exp(âˆ’yhard pl Â·z); 2) Entropy applied to sigmoid probability P(y= +1) = Ïƒ(z). The losses are compared on three degrees of shift (easy, moderate and hard), which is controlled by the drifted distance of Gaussian clusters. The results are shown in Figure 3, where we plot the accuracy curve with respect to adaptation iterations. With easy and moderate shift, conjugate loss (green) generalizes faster to shifted test data; with hard shift, only conjugate loss improves model accuracy on shifted test data while entropy (blue) deteriorates model performance. Figure 3: Test-time adaptation result on synthetic data with three shift levels ranging from easy, moderate and hard (detailed in section A.2). The source model is a linear classiï¬er trained with exponential loss Lexp = eâˆ’yhÎ¸(x). Adaptation with the conjugate loss generalizes better compared to baseline losses. 16A.3 Meta Learning Experiment Details In section 3 we talked about learning the meta-loss function parameterized by a neural network mÏ† : R|Y|â†¦â†’R, that takes in the model predictions/logits and outputs a loss value. Here we discuss the architecture chosen and the implementation details. Further, in Appendix A.4 we empirically show that the learnt meta-loss is not affected by the choice of task loss / surrogate loss used in meta learning (Lin Equation 1). Note that the task loss / surrogate loss function is used to update the meta-loss mÏ† during meta-learning. The surrogate loss is calculated on updated source modelâ€™s predictions on labeled samples from test domain. The surrogate loss tries to update the meta-loss in the outer loop such that when meta-loss is later used to update the source model in the inner loop, the source model generalizes better to the test domain. Architecture and Implementation Details Figure 4 gives an overall schema for meta-learning the loss function and algorithm 2 gives the pseudo-code for meta-learning the loss function. Below we describe this in further detail. We use a transformer (denoted by T) with a MLP (denoted by P) over the output of transformer as the architecture for mÏ†, i.e. mÏ†(x) = P(T(x)). Speciï¬cally, for a given source trained model hÎ¸ and input xâˆ¼Dtest : 1. Let hÎ¸(x) âˆˆR|Y|be the model predictions/logits, where |Y|denotes the number of classes. 2. Let hj Î¸(x) âˆˆR,âˆ€j âˆˆ|Y| be the prediction corresponding to class j. 3. The input to transformer is then given by z âˆˆR|Y|Ã—(1+e), where zj âˆˆR1+e,âˆ€j âˆˆ|Y| is the concatenation of hj Î¸(x) and the learnable positional embedding pej âˆˆRe. 4. The transformer output is given by w= T(z) âˆˆRd, where ddenotes the feed-forward dimension of the transformer. 5. The transformer output wis ï¬nally passed through a MLP to get the meta-loss valuemÏ†(hÎ¸(x)) = P(w) âˆˆR 6. The source model is updated by optimizing over the meta-loss. Î¸t+1 â†Î¸t âˆ’Î±âˆ‚mÏ†t(hÎ¸t(x)) âˆ‚Î¸t (24) 7. The updated source model is then used to update the meta-loss by optimizing over some supervised loss function Ltask. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xâ€²),yâ€²) âˆ‚Ï†t , where (xâ€²,yâ€²) âˆ¼Dtest (25) Note that the last step assumes access to labels of test inputs. In this paper, we do not propose meta-learning the TTA loss as an approach. Rather, we use meta-learning to explore what the â€œbestâ€ TTA losses look like. We select the trasformer input embedding dimension (1 + e) from {16,32,64}and transformer feed-forward dimension dfrom {32,64,128}. The number of transformer layers and the hidden layers in MLP are selected from {1,2}. We use Adam optimizer with a learning rate of 1eâˆ’3 for learning the meta-loss (i.e. the transformer + MLP). We train the meta-loss for 100 epochs with a batch size of 200. A.4 Effect of Task Loss in Meta Learning In section 3, we show that the meta losses learned on different source classiï¬ers differ substantially if the source classiï¬ers are trained using different source loss functions. Here we further empirically verify that the learnt meta loss is not affected by the task loss used in meta learning (Lin Equation 1). Thus the learnt meta loss is determined by the source model. In Figure 5, we show the meta loss learnt on a ResNet-26 trained with Cross Entropy loss for two meta task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. We plot the meta loss as a function over one of its input prediction scores, while keeping other ï¬xed. We can see that the task loss barely affects the learnt meta loss. Similar observations can be made for the classiï¬er trained with squared loss Figure 6. 17Meta-Loss  Backpropogate  Figure 4: Meta-Loss learning procedure : The model predictions hÎ¸t(x) are passed through the parameterized loss function mÏ†t, which outputs a loss value. We optimize Ï† such that when optimizing the source model over the loss mÏ†t(hÎ¸t(x)), the updated Î¸t+1 has a better performance on the test domain. To do this, we take one gradient step over the meta-loss to get the update source model parameters Î¸t+1, and then update Ï†by evaluating Î¸t+1 on the labeled validation data using some task loss Ltask. Algorithm 2 Learning the Meta-Loss Input: Source trained classiï¬er hÎ¸0 . Randomly initialized meta-loss mÏ†0 . Task loss / Surrogate loss Ltask like cross-entropy or squared loss for meta learning N batches of test data Dtest = [(x1,y1),..., (xN,yN)] Hyperparams: learning rates Î±and Î². for epoch= 0,1,2,... do for n= 0,1,...N âˆ’1 do Î¸t+1 â†Î¸t âˆ’Î± âˆ‚mÏ†t(hÎ¸t(xn)) âˆ‚Î¸t Sample (xr,yr) âˆ¼Dtest. Ï†t+1 â†Ï†t âˆ’Î²âˆ‚Ltask(hÎ¸t+1 (xr),yr) âˆ‚Ï†t A.5 Test-Time Adaptation Detail For completeness, we also give the test-time adaptation setup in Algorithm 3. A.6 ImageNet results on each severity level In continuation with results shown in Table 2 in Section 5.3, Table 4 shows the mean errors averaged across the 15 corruption types for each of the severity level on ImageNet-C, for a source classiï¬er trained with PolyLoss (Ïµ= 8). A.7 Square Loss Trained Source Classiï¬er In Section 5.3, we brieï¬‚y discussed that similar to the other source training losses like cross-entropy and polyloss, our proposed conjugate loss outperforms the baselines when the source classiï¬er is 18(a)  (b) Figure 5: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Cross Entropy. Here we show meta loss trained by two different task losses: Cross Entropy Figure 5a and Squared Loss Figure 5b. (a)  (b) Figure 6: Visualizations of meta loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with Squared Loss. Here we show meta loss trained by two different task losses: Cross Entropy Figure 6a and Squared Loss Figure 6b. Algorithm 3 Test-Time Adaptation Input: Source classiï¬er Î¸0 trained using loss L(hÎ¸(x),y), An unsupervised loss function for test-time adaptation Ltta(x), N batches of test data Dtest = [x1,...,x N] Hyperparams: learning rate Î·. for n= 0,1,...N âˆ’1 do Î¸n+1 = Î¸n âˆ’Î·âˆ‡Ltta(xn) Ë†yn = hÎ¸n+1 (xn) [Predictions for the nth batch] 19Corrution Severity Temperature Robust PL Entropy MEMO Softmax PL Conjugate 1 \u0017 34.27 33.17 34.39 32.49 32.26 \u0013 34.27 32.84 34.39 32.70 32.26 2 \u0017 41.25 39.04 40.38 37.78 37.40 \u0013 41.25 38.50 40.38 37.75 37.40 3 \u0017 47.37 44.04 45.67 42.30 41.72 \u0013 47.37 43.33 45.67 42.14 41.72 4 \u0017 56.63 51.88 54.49 49.61 48.84 \u0013 56.63 51.03 54.49 49.39 48.84 5 \u0017 67.11 62.53 66.13 60.94 59.90 \u0013 67.11 61.80 66.13 60.30 59.90 Mean \u0017 49.32 46.13 48.21 44.62 44.02 \u0013 49.32 45.50 48.21 44.45 44.02 Table 4: Mean Errors across the 15 noises for various severity level on the ImageNet-C dataset, with source model trained using Poly-1 Loss. Note that Temperature scaling helped only in the case of Entropy and Softmax PL. trained using a squared loss. Table 5 shows a detailed comparison with the baselines. We note that for the conjugate of squared loss, the temperature scaling can be wrapped into the learning rate as shown in Section 4.2. Further, on the CIFAR-10-C dataset we observe temperature scaling doesnâ€™t help any of the other baselines too, hence we do not include the temperature row in CIFAR-10-C. Dataset Temperature Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL CIFAR-10-C \u0017 13.71 (Â±0.07) 13.06 (Â±0.05) 13.24 (Â±0.02) 13.22 (Â±0.04) 14.85 (Â±0.08)12.99(Â±0.04) CIFAR-100-C \u0017 50.82 (Â±0.31) 44.53 (Â±0.13) 43.55 (Â±0.12) 51.35 (Â±0.04) 51.99 (Â±0.03)43.39(Â±0.11) \u0013 50.82 (Â±0.31) 43.99 (Â±0.15)43.21(Â±0.08) 51.35 (Â±0.04) 51.99 (Â±0.03) 43.39 (Â±0.11) Table 5: Mean Errors on the common corruptions datasets for source classiï¬er trained using squared loss. We note that temperature scaling didnâ€™t help on the CIFAR-10-C dataset. Source Classiï¬er Errors without adaptation : CIFAR-10-C (28.34%), CIFAR-100-C (68.79%) Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) CIFAR-10-C \u0017 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1 eâˆ’2, 2 SGD,5 eâˆ’3, 3 Adam,1eâˆ’3, 2 CIFAR-100-C \u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD,1eâˆ’2, 2 ImageNet-C \u0017 SGD,1eâˆ’2, 1 SGD,2.5 eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1.5 SGD,1eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 Table 6: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 1, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using cross-entropy loss. A.8 Hyper-Parameters We share the exact hyper-parameters found using gridsearch over the 4 validation noises for the common corruptions dataset. 20Cross Entropy Classiï¬er Experiments In Section 5.2, Table 1 shows the results when adapting a cross entropy trained classiï¬er on various common corruptions dataset. Table 6 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. PolyLoss Classiï¬er Experiments In Section 5.3, Table 2 shows the results when adapting a polyloss trained classiï¬er on various common corruptions dataset. Table 7 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss. Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’3, 1 SGD,1eâˆ’3, 1 SGD,1 eâˆ’3, 1 SGD,5 eâˆ’3, 1 SGD, 1eâˆ’3, 1 SGD, 1eâˆ’3, 1 \u0013 SGD,1eâˆ’3, 1 SGD,1eâˆ’2, 3 SGD,1 eâˆ’2, 3 SGD,5 eâˆ’3, 3 SGD, 1eâˆ’3, 2 SGD, 1eâˆ’3, 1.5 CIFAR-100-C\u0017 SGD,1eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD, 1eâˆ’2, 1 SGD, 1eâˆ’2, 1 \u0013 SGD,1eâˆ’2, 1 Adam,1eâˆ’3, 3 SGD,1 eâˆ’2, 2 SGD,1 eâˆ’2, 2 SGD, 1eâˆ’2, 2.5 SGD, 1eâˆ’2, 1.5 ImageNet-C\u0017 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 SGD, 2.5eâˆ’3, 1 \u0013 SGD,1eâˆ’2, 1 SGD,2.5eâˆ’3, 1 SGD,2.5eâˆ’3, 1.5 SGD,5eâˆ’3, 1 SGD, 2.5eâˆ’3, 2 SGD, 2.5eâˆ’3, 1 Table 7: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 2, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using poly-loss. Squared Loss Classiï¬er Experiments In Section 5.3, we brieï¬‚y discussed the results when adapt- ing a squared loss trained classiï¬er on various common corruptions dataset. Table 8 gives the optimizer, learning rate and optimal temperature for each of the baseline and our proposed conjugate loss for the results in Table 5. Digit Adaptation Datasets For the experiments on digits adaptation tasks, we do not have any validation set. Hence, we donâ€™t use temperature scaling here (T = 1) and ï¬x the optimizer and LR as Adam and 1eâˆ’2 respectively for all the baselines. A.9 Additional Experiments on Digit Adaptation Datasets Similar to the setting of Table 1, we perform additional experiments on digit adaptation datasets when the source classiï¬er is trained using the cross-entropy loss. Note that when the source classiï¬er is trained using cross-entropy loss, the conjugate loss is equal to the softmax-entropy. In the absence of validation dataset in digit adaptation benchmarks, we used a ï¬xed learning rate of 0.01 for all the baselines, optimizer as Adam and an informed temperature scaling guess of T=2. Table 9 compares softmax-entropy minimization with various baselines. Here, again we observe that on SVHN â†’MNIST benchmark, without temperature scaling, MEMO (10.67% error) outperforms softmax-entropy (14.41% error). However, similar to the observations in Table 1, with temperature scaling, softmax-entropy minimization (9.26% error) is able to match the performance of MEMO (9.36% error). Further, on the SVHN â†’USPS benchmark, softmax-entropy (conjugate) and MEMO perform similar even without temperature scaling. A.10 Additional Meta Learning the TTA Loss Experiments In Section 3, we tried to learn a test-time adaptation (TTA) loss via meta-learning for adapting a CIFAR10 trained ResNet26 to distribution shifts on CIFAR10 corruptions. Figure 1 showed that the learnt meta-loss looks like a temperature scaled softmax-entropy. In this section, we show the learnt meta loss across a range of settings as described below : 1. Digit Adaptation: Figure 7a and 7b show the learnt meta-loss when adapting a SVHN trained ResNet26 to MNIST dataset and USPS dataset respectively. We observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 2. Various Noise Types: In Figure 8, we show the learnt meta-loss when adapting a ResNet26 trained on CIFAR10 dataset using cross-entropy loss, to various noise types like speckle, gaussian, saturate and spatter. The severity level is kept ï¬xed at the maximum i.e. 5. 21Dataset T Hard PL Robust PL ENT MEMO Softmax PL Conjugate PL (Ours) CIFAR-10-C\u0017 SGD,1eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1 eâˆ’2, 1 SGD,1eâˆ’2, 1 SGD,1 eâˆ’4, 1 SGD,1eâˆ’2, 1 CIFAR-100-C\u0017 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 1 Adam, 1eâˆ’4, 1 Adam, 1eâˆ’3, 1 \u0013 Adam,1eâˆ’3, 1 Adam,1eâˆ’3, 0.5 Adam,1eâˆ’3, 2 Adam,1eâˆ’3, 2 Adam, 1eâˆ’4, 2.5 Adam, 1eâˆ’3, 1 Table 8: Hyper-parameters (Optimizer, Learning Rate, Temperature) for the results in Table 5, where we showed the mean errors on the common corruptions dataset for a source classiï¬er trained using squared loss. Dataset Temperature (T) Hard PL Robust PL MEMO Conjugate PL (ENT) SVHNâ†’MNIST \u0017 21.54 27.44 10.67 14.41 \u0013 21.54 13.26 9.36 9.26 SVHNâ†’USPS \u0017 26.06 26.81 22.72 22.57 \u0013 26.06 22.32 22.42 22.27 Table 9: Mean errors when adapting to digit adaptation benchmarks using a source classiï¬er trained via cross-entropy loss. Here, conjugate pseudo-labeling becomes softmax-entropy minimization. Again we observe that with the right temperature scaling, softmax-entropy minimization matches other approaches. For additional context, the source classiï¬er errors without adaptation are: SVHN â†’MNIST (34.17%), SVHN â†’USPS (31.84%). 20  10  0 10 20 prediction score 5 0 5 10loss value meta loss (error 10.44%) softmax entropy (error 14.41) fitted entropy (error 9.26) Meta Loss for SVHN -> MNIST (a) 20  10  0 10 20 prediction score 6 4 2 0 2 4 6 8 loss value meta loss (error 20.13%) softmax entropy (error 22.57) fitted entropy (error 22.22) Meta Loss for SVHN -> USPS adpatation (b) Figure 7: Visualizations of the learnt meta-loss by varying one input dimension (prediction score). The source model is a ResNet-26 trained with cross-entropy on the SVHN dataset. (a) The learnt meta-loss when adapting to the MNIST test dataset. (b) The learnt meta-loss when adapting to the USPS test dataset. 3. Various Severity Levels: In Figure 9, we vary the severity level of the noise, keeping the noise type ï¬xed. 4. Dataset and Architecture: In Figure 10, we compare the learnt meta-loss when adapting to speckle noise, for different source classiï¬er architectures (ResNet26 and ResNet50) and different source training dataset (CIFAR10 and CIFAR100). In all the cases, we again observe that the learnt meta-loss can be well approximated by a temperature scaled softmax-entropy. 5. Squared Loss : Finally, in Figure 11 we show the learnt meta-loss for classiï¬ers trained with squared loss function instead of cross-entropy. We observe that in this case, the learnt meta loss mimics a quadratic function as expected from the conjugate formulation. 22For each of the learnt meta losses, we also show the values (Î±,T,C ) we use to ï¬t the meta loss with softmax entropy function: Î±Â·H(softmax(x/T)) âˆ’C. Note that although the learnt meta-loss can be approximated by the conjugate, the parameters Î±,T,C differ across the settings. In the case of classiï¬ers trained with squared loss, we ï¬t the meta loss with a quadratic functionâˆ‘K i=1(AÂ·x2 i + C), where Kis the number of classes and xis the logit vector. Again, we also show the ï¬tted parameter value A,C. The meta loss follows the trend of a quadratic function. The ï¬tted quadratic function performs better or similar as the meta loss, while the parameters of the ï¬tted quadratic function remain different across the meta learning setup (base classiï¬er architectures and noise types). (a)  (b) (c)  (d) Figure 8: Visualization of meta loss (blue) learnt from various noise types in CIFAR-10-C validation set, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 23(a)  (b) (c)  (d) Figure 9: Visualization of meta loss (blue) learnt on speckle noise with different severity level for CIFAR-10-C, where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters (Î±,T,C ) in the ï¬tted entropy. 24(a)  (b) (c)  (d) Figure 10: Visualization of meta loss (blue) learnt across datasets (CIFAR-10-C/CIFAR-100-C) and base classiï¬er architectures (ResNet-26/ResNet-50), where base classiï¬ers are trained with cross-entropy loss. We show the error of meta loss, softmax entropy and ï¬tted entropy for test-time adaptation on the corresponding noise types. We also show the parameters ( Î±,T,C ) in the ï¬tted entropy. (a)  (b) Figure 11: Visualization of meta loss (blue), where base classiï¬er is trained with quadratic loss. We show the error of meta loss, softmax entropy and ï¬tted quadratic function for test-time adaptation on the corresponding noise types. We also show the parameters ( A,B,C ) in the ï¬tted quadratic function. 25",
      "meta_data": {
        "arxiv_id": "2207.09640v2",
        "authors": [
          "Sachin Goyal",
          "Mingjie Sun",
          "Aditi Raghunathan",
          "Zico Kolter"
        ],
        "published_date": "2022-07-20T04:02:19Z",
        "pdf_url": "https://arxiv.org/pdf/2207.09640v2.pdf"
      }
    },
    {
      "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
      "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
      "full_text": "Published as a conference paper at ICLR 2024 ACTIVE TEST-TIME ADAPTATION : T HEORETICAL ANALYSES AND AN ALGORITHM Shurui Guiâˆ— Texas A&M University College Station, TX 77843 shurui.gui@tamu.edu Xiner Li* Texas A&M University College Station, TX 77843 lxe@tamu.edu Shuiwang Ji Texas A&M University College Station, TX 77843 sji@tamu.edu ABSTRACT Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies. To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting. We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA. 1 I NTRODUCTION Deep learning has achieved remarkable success across various fields, attaining high accuracy in numerous applications (Krizhevsky et al., 2017; Simonyan and Zisserman, 2014). Nonetheless, When training and test data follow distinct distributions, models often experience significant performance degradation during test. This phenomenon, known as the distribution shift or out-of-distribution (OOD) problem, is extensively studied within the context of both domain generalization (DG) (Gulra- jani and Lopez-Paz, 2020; Koh et al., 2021; Gui et al., 2022) and domain adaptation (DA) (Ganin et al., 2016; Sun and Saenko, 2016). While these studies involve intensive training of models with considerable generalization abilities towards target domains, they overlook an important application property; namely, continuous adaptivity to real-time streaming data under privacy, resource, and efficiency constraints. This gap leads to the emergence of test-time adaptation (TTA) tasks, targeting on-the-fly adaptation to continuous new domains during the test phase or application deployment. The study of TTA encompasses two main categories; namely test-time training (TTT) methods (Sun et al., 2020; Liu et al., 2021c) and fully test-time adaptation (FTTA) (Niu et al., 2023; Wang et al., 2021). The TTT pipeline incorporates retraining on the source data, whereas FTTA methods adapt arbitrary pre-trained models to the given test mini-batch by conducting entropy minimization, without access to the source data. Nevertheless, most TTA methods can only handle corrupted distribution shifts (Hendrycks and Dietterich, 2019b) (e.g., Gaussian noise,) and rely heavily on human intuition or empirical studies. To bridge this gap, our paper focuses on tackling significant domain distribution shifts in real time with theoretical insights. We investigate FTTA, which is more general and adaptable than TTT, particularly under data ac- cessibility, privacy, and efficiency constraints. Traditional FTTA aims at adapting a pre-trained model to streaming test-time data from diverse domains under unsupervised settings. However, recent works (Lin et al., 2022; Pearl, 2009) prove that it is theoretically infeasible to achieve OOD generalization without extra information such as environment partitions. Since utilizing environment partitions requires heavy pretraining, contradicting the nature of TTA, we are motivated to incorporate extra information in a different way,i.e., integrating a limited number of labeled test-time samples to alleviate distribution shifts, following the active learning (AL) paradigm (Settles, 2009). To this end, we propose the novel problem setting of active test-time adaptation (ATTA) by incorporating âˆ—Equal contributions 1 arXiv:2404.05094v1  [cs.LG]  7 Apr 2024Published as a conference paper at ICLR 2024 AL within FTTA. ATTA faces two major challenges; namely, catastrophic forgetting (CF) (Kemker et al., 2018; Li and Hoiem, 2017) and real-time active sample selection. CF problem arises when a model continually trained on a sequence of domains experiences a significant performance drop on previously learned domains, due to the inaccessibility of the source data and previous test data. Real-time active sample selection requires AL algorithms to select informative samples from a small buffer of streaming test data for annotation, without a complete view of the test distribution. In this paper, we first formally define the ATTA setting. We then provide its foundational analysis under the learning theoryâ€™s paradigm to guarantee the mitigation of distribution shifts and avoid CF. Aligned with our empirical validations, while the widely used entropy minimization (Wang et al., 2021; Grandvalet and Bengio, 2004) can cause CF, it can conversely become the key to preventing CF problems with our sample selection and balancing techniques. Building on the analyses, we then introduce a simple yet effective ATTA algorithm, SimATTA, incorporating balanced sample selections and incremental clustering. Finally, we conducted a comprehensive experimental study to evaluate the proposed ATTA settings with three different settings in the order of low to high requirement restrictiveness, i.e., TTA, Enhanced TTA, and Active Domain Adaptation (ADA). Intensive experiments indicate that ATTA jointly equips with the efficiency of TTA and the effectiveness of ADA, rendering an uncompromising real-time distribution adaptation direction. Comparison to related studies. Compared to TTA methods, ATTA requires extra active labels, but the failure of TTA methods (Sec. 5.1) and the theoretical proof of Lin et al. (2022); Pearl (2009) justify its necessity and rationality. Compared to active online learning, ATTA focuses on lightweight real-time fine-tuning without round-wise re-trainings as Saran et al. (2023) and emphasizes the importance of CF avoidance instead of resetting models and losing learned distributions. In fact, active online learning is partially similar to our enhanced TTA setting (Sec. 5.2. Compared to ADA methods (Prabhu et al., 2021; Ning et al., 2021), ATTA does not presuppose access to source data, model parameters, or pre-collected target samples. Furthermore, without this information, ATTA can still perform on par with ADA methods (Sec. 5.3). The recent source-free active domain adaptation (SFADA) method SALAD (Kothandaraman et al., 2023) still requires access to model parameter gradients, pre-collected target data, and training of additional networks. Our ATTA, in contrast, with non-regrettable active sample selection on streaming data, is a much lighter and more realistic approach distinct from ADA and SFADA. More related-work discussions are provided in Appx. C. 2 T HE ACTIVE TEST-TIME ADAPTATION FORMULATION TTA methods aim to solve distribution shifts by dynamically optimizing a pre-trained model based on streaming test data. We introduce the novel problem setting of Active Test-Time Adaptation (ATTA), which incorporates active learning during the test phase. In ATTA, the model continuously selects the most informative instances from the test batch to be labeled by an explicit or implicit oracle (e.g., human annotations, self-supervised signals) and subsequently learned by the model, aiming to improve future adaptations. Considering the labeling costs in real-world applications, a â€œbudgetâ€ is established for labeled test instances. The model must effectively manage this budget distribution and ensure that the total number of label requests throughout the test phase does not surpass the budget. We now present a formal definition of the ATTA problem. Consider a pre-trained modelf(x; Ï•) with parameters Ï• trained on the source dataset DS = (x, y)|DS|, with each data sample x âˆˆ Xand a label y âˆˆ Y. We aim to adapt model parameters Î¸, initialized as Ï•, to an unlabeled test-time data stream. The streaming test data exhibit distribution shifts from the source data and varies continuously with time, forming multiple domains to which we must continuously adapt. The test phase commences at time step t = 1 and the streaming test data is formulated in batches. The samples are then actively selected, labeled (by the oracle) and collected as Dte(t) = ActAlg(Ute(t)), where ActAlg(Â·) denotes an active selection/labeling algorithm. The labeled samples Dte(t) are subsequently incorporated into the ATTA training setDtr(t). Finally, we conclude time step t by performing ATTA training, updating model parameters Î¸(t) using Dtr(t), with Î¸(t) initialized as the previous final state Î¸(t âˆ’ 1). Definition 1 (The ATTA problem). Given a model f(x; Î¸), with parameters Î¸, initialized with parameters Î¸(0) = Ï• obtained by pre-training on source domain data, and streaming test data batches Ute(t) continually changing over time, the ATTA task aims to optimize the model at any time stept (with test phase commencing at t = 1) as Î¸(t)âˆ— := argmin Î¸(t) (E(x,y,t)âˆˆDtr(t)[â„“CE (f(x; Î¸(t)), y)] + E(x,t)âˆˆUte(t)[â„“U (f(x; Î¸(t)))]), (1) 2Published as a conference paper at ICLR 2024 where Dtr(t) = ( âˆ…, t = 0 Dtr(t âˆ’ 1) âˆª Dte(t), t â‰¥ 1, s.t. |Dtr(t)| â‰¤ B, (2) Dte(t) = ActAlg(Ute(t)) is actively selected and labeled, â„“CE is the cross entropy loss, â„“U is an unsupervised learning loss, and B is the budget. 3 T HEORETICAL STUDIES In this section, we conduct an in-depth theoretical analysis of TTA based on learning theories. We mainly explore two questions: How can significant distribution shifts be effectively addressed under the TTA setting? How can we simultaneously combat the issue of CF? Sec. 3.1 provides a solution with theoretical guarantees to the first question, namely, active TTA (ATTA), along with the conditions under which distribution shifts can be well addressed. Sec. 3.2 answers the second question with an underexplored technique, i.e., selective entropy minimization, building upon the learning bounds established in Sec. 3.1. We further validate these theoretical findings through experimental analysis. Collectively, we present a theoretically supported ATTA solution that effectively tackles both distribution shift and CF. 3.1 A LLEVIATING DISTRIBUTION SHIFTS THROUGH ACTIVE TEST-TIME ADAPTATION Traditional TTA is performed in unsupervised or self-supervised context. In contrast, ATTA introduces supervision into the adaptation setting. In this subsection, we delve into learning bounds and establish generalization bounds to gauge the efficacy of ATTA in solving distribution shifts. We scrutinize the influence of active learning and evidence that the inclusion of labeled test instances markedly enhances overall performances across incremental test domains. Following Kifer et al. (2004), we examine statistical guarantees for binary classification. A hypothesis is a function h : X â†’ {0, 1}, which can serve as the prediction function within this context. In the ATTA setting, the mapping ofh varies with time as h(x, t). We use Hâˆ†H-distance following Ben- David et al. (2010), which essentially provides a measure to quantify the distribution shift between two distributions D1 and D2, and can also be applied between datasets. The probability that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} according to distribution D is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source data is inaccessible under ATTA settings, we consider the existence of source dataset DS for accurate theoretical analysis. Thus, we initialize Dtr as Dtr(0) = DS. For every time step t, the test and training data can be expressed asUte(t) and Dtr(t) = DS âˆªDte(1) âˆªDte(2) âˆªÂ·Â·Â·âˆª Dte(t). Building upon two lemmas (provided in Appx. D), we establish bounds on domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesish at time t. Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Â·Â·Â· , Ute(t), Â·Â·Â· , Si are unlabeled samples of sizem sampled from each of thet+1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î» = (Î»0, Â·Â·Â· , Î»t). If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w = (w0, Â·Â·Â· , wt) on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. The adaptation performance on a test domain is majorly bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. Further theoretical analysis are in Appx. D. 3Published as a conference paper at ICLR 2024 Figure 1: (a) Empirical validation of Thm. 1. We train a series of models on N = 2000 samples from the PACS (Li et al., 2017) dataset given differentÎ»0 and w0 and display the test domain loss of each model. Red points are the test loss minimums given a fixed Î»0. The orange line is the reference where w0 = Î»0. We observe that w0 with loss minimums are located closed to the orange line but slightly smaller than Î»0, which validates our findings in Eq. (4). (b) Empirical analysis with an uncertainty balancing. Given source pre-trained models, we fine-tune the models on 500 samples with different Î»0 and w0, and display the combined error surface of test and source error. Although a small Î»0 is good for test domain error, it can lead to non-trivial source error exacerbation. Therefore, we can observe that the global loss minimum (green X) locates in a relatively high-Î»0 region. If we consider the multiple test data distributions as a single test domain,i.e., St i=1 Ute(i), Thm. 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . Given the optimal test/source hypothesis hâˆ— T (t) = arg minhâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), we have |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (3b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (3.a), with approximatelyB = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (4) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. The following theorem offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (5) Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. All proofs are provided in Appx. E. Finally, we support the theoretical findings with experimental analysis and show the numerical results of applying the principles on real-world datasets, as shown in Fig. 1. For rigorous analysis, note that our theoretical results rest on the underlying condition that N should at least be of the same scale as d, according to the principles of VC-dimension theory. The empirical alignment of our experiments with the theoretical framework can be attributed to the assumption that fine-tuning a model is roughly equivalent to learning a model with a relatively small d. Experiment details and other validations can be found in Appx. H. 4Published as a conference paper at ICLR 2024 3.2 M ITIGATING CATASTROPHIC FORGETTING WITH BALANCED ENTROPY MINIMIZATION Catastrophic forgetting (CF), within the realm of Test-Time Adaptation (TTA), principally manifests as significant declines in overall performance, most notably in the source domain. Despite the lack of well-developed learning theories for analyzing training with series data, empirical studies have convincingly illustrated the crucial role of data sequential arrangement in model learning, thereby accounting for the phenomenon of CF. Traditionally, the mitigation of CF in adaptation tasks involves intricate utilization of source domain data. However, under FTTA settings, access to the source dataset is unavailable, leaving the problem of CF largely unexplored in the data-centric view. Table 1: Correlation analysis of high/low en- tropy samples and domains. We use a source pre-trained model to select samples with low- est/highest entropy, and 1.retrain the model on 2000 samples; 2.fine-tune the model on 300 sam- ples. We report losses on source/test domains for each setting, showing that low-entropy samples form distributions close to the source domain. Sample type Retrain Fine-tune ÏµS ÏµT ÏµS ÏµT Low entropy 0.5641 0.8022 0.0619 1.8838 High entropy 2.5117 0.3414 0.8539 0.7725 To overcome this challenge of source dataset ab- sence, we explore the acquisition of â€œsource-likeâ€ data. In TTA scenarios, it is generally assumed that the amount of source data is considerably large. We also maintain this assumption in ATTA, practically assuming the volume of source data greatly surpasses the test-time budget. As a re- sult, we can safely assume that the pre-trained model is well-trained on abundant source do- main data DS. Given this adequately trained source model, we can treat it as a â€œtrueâ€ source data labeling function f(x; Ï•). The model es- sentially describes a distribution, DÏ•,S(X, Y) = {(x, Ë†y) âˆˆ (X, Y) | Ë†y = f(x; Ï•), xâˆˆ DS}. The entropy of the model prediction is defined as H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc), Ë†y = f(x; Ï•), where c denotes the class. Lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction, which can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model recognizes the sample as being similar to those it was trained on. Thus entropy can be used as an indicator of how closely a sample x aligns with the model distribution DÏ•,S. Since the model distribution is approximately the source distribution, selecting (and labeling) low-entropy samples using f(x; Ï•) essentially provides an estimate of sampling from the source dataset. Therefore, in place of the inaccessible DS, we can feasibly include the source-like dataset into the ATTA training data at each time stept: DÏ•,S(t) = {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el}, (6) where el is the entropy threshold. The assumption that DÏ•,S(t) is an approximation of DS can be empirically validated, as shown by the numerical results on PACS in Tab. 1. In contrast, high-entropy test samples typically deviate more from the source data, from which we select Dte(t) for active labeling. Following the notations in Thm. 1, we are practically minimizing the empirical weighted error of hypothesis h(t) as Ë†Ïµâ€² w(h(t)) = tX j=0 wjË†Ïµj(h(t)) = w0 Î»0N X xâˆˆDÏ•,S(t) |h(x, t) âˆ’ f(x; Ï•)| + tX j=1 wj Î»jN X x,yâˆˆDte(j) |h(x, t) âˆ’ y|. (7) By substituting DS with DÏ•,S(t) in Thm. 1, the bounds of Thm. 1 continue to hold for the test domains. In the corollary below, we bound the source error for practical ATTA at each time stept. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Thm. 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Thm. 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Further analysis and proofs are in Appx. D and E. The following corollary provides direct theoretical support that our strategy conditionally reduces the error bound on the source domain. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Thm. 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight 5Published as a conference paper at ICLR 2024 <latexit sha1_base64=\"NxhXSyFABPQk4q8627/odirDspg=\">AAAB9XicbVDLSgMxFM34rPVVdekmWARXZab4WhbcuKzYF7S1ZNI7bWgmMyR3lDL0P9y4UMSt/+LOvzHTdqGtBwKHc87l3hw/lsKg6347K6tr6xubua389s7u3n7h4LBhokRzqPNIRrrlMwNSKKijQAmtWAMLfQlNf3ST+c1H0EZEqobjGLohGygRCM7QSg/3mIWFGtAaGOwVim7JnYIuE29OimSOaq/w1elHPAlBIZfMmLbnxthNmUbBJUzyncRAzPiIDaBtqWIhmG46vXpCT63Sp0Gk7VNIp+rviZSFxoxD3yZDhkOz6GXif147weC6mwoVJwiKzxYFiaQY0awC2hcaOMqxJYxrYW+lfMg042iLytsSvMUvL5NGueRdli7uysXK+byOHDkmJ+SMeOSKVMgtqZI64USTZ/JK3pwn58V5dz5m0RVnPnNE/sD5/AFnsJJq</latexit> Streaming Test <latexit sha1_base64=\"a41BOKrutEYSWO9+8CjkPZKHvb8=\">AAAB73icbVBNS8NAEJ3Ur1q/qh69BIvgqSTiR48FLx4r2A9oQ9lsN+3SzSbuToQQ+ie8eFDEq3/Hm//GTZuDtj4YeLw3w8w8PxZco+N8W6W19Y3NrfJ2ZWd3b/+genjU0VGiKGvTSESq5xPNBJesjRwF68WKkdAXrOtPb3O/+8SU5pF8wDRmXkjGkgecEjRSbzAhmKWzyrBac+rOHPYqcQtSgwKtYfVrMIpoEjKJVBCt+64To5cRhZwKNqsMEs1iQqdkzPqGShIy7WXze2f2mVFGdhApUxLtufp7IiOh1mnom86Q4EQve7n4n9dPMGh4GZdxgkzSxaIgETZGdv68PeKKURSpIYQqbm616YQoQtFElIfgLr+8SjoXdfe6fnV/WWs2ijjKcAKncA4u3EAT7qAFbaAg4Ble4c16tF6sd+tj0Vqyiplj+APr8wfpIY/e</latexit> Ë†y <latexit sha1_base64=\"SJEOE2ZYxLL1SU/QahOlMH6fop4=\">AAAB8HicbVBNSwMxEM3Wr1q/qh69BItQL2VX/Oix4MVjBbettEvJptk2NMkuyaxQlv4KLx4U8erP8ea/MW33oK0PBh7vzTAzL0wEN+C6305hbX1jc6u4XdrZ3ds/KB8etUycasp8GotYd0JimOCK+cBBsE6iGZGhYO1wfDvz209MGx6rB5gkLJBkqHjEKQErPfr9DNi0Cuf9csWtuXPgVeLlpIJyNPvlr94gpqlkCqggxnQ9N4EgIxo4FWxa6qWGJYSOyZB1LVVEMhNk84On+MwqAxzF2pYCPFd/T2REGjORoe2UBEZm2ZuJ/3ndFKJ6kHGVpMAUXSyKUoEhxrPv8YBrRkFMLCFUc3srpiOiCQWbUcmG4C2/vEpaFzXvunZ1f1lp1PM4iugEnaIq8tANaqA71EQ+okiiZ/SK3hztvDjvzseiteDkM8foD5zPH2KnkB4=</latexit> U te ( t ) <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model SimATTA <latexit sha1_base64=\"bhVea6W/pzUPuDRNfs2xbDF7qAk=\">AAAB73icbVC7SgNBFL3rM8ZX1NJmMAhWYTf4KgM2FhYRzAOSJcxOZpMhs7PrzF0hhPyEjYUitv6OnX/jbLKFJh4YOJxzD3PvCRIpDLrut7Oyura+sVnYKm7v7O7tlw4OmyZONeMNFstYtwNquBSKN1Cg5O1EcxoFkreC0U3mt564NiJWDzhOuB/RgRKhYBSt1L6jQRYd9Eplt+LOQJaJl5My5Kj3Sl/dfszSiCtkkhrT8dwE/QnVKJjk02I3NTyhbEQHvGOpohE3/mS275ScWqVPwljbp5DM1N+JCY2MGUeBnYwoDs2il4n/eZ0Uw2t/IlSSIlds/lGYSoIxyY4nfaE5Qzm2hDIt7K6EDammDG1FRVuCt3jyMmlWK95l5eK+Wq6d53UU4BhO4Aw8uIIa3EIdGsBAwjO8wpvz6Lw4787HfHTFyTNH8AfO5w/1SI/i</latexit> Labeling <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( Â· ; âœ“ ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( Â· ; \u0000 ) <latexit sha1_base64=\"ipQ+JKlINPDcPjrbUYUkqyyzp40=\">AAAB+nicbVC7TsMwFHXKq5RXCiOLRYXEQpVUvMZKLIxF0IfURpXj3LRWHSeyHVBV+iksDCDEypew8Te4aQZoOZKlo3Puy8dPOFPacb6twsrq2vpGcbO0tb2zu2eX91sqTiWFJo15LDs+UcCZgKZmmkMnkUAin0PbH13P/PYDSMVica/HCXgRGQgWMkq0kfp2+S6bdNqQoCUxQ4K+XXGqTga8TNycVFCORt/+6gUxTSMQmnKiVNd1Eu1NiNSMcpiWeqmChNARGUDXUEEiUN4kO32Kj40S4DCW5gmNM/V3x4RESo0j31RGRA/VojcT//O6qQ6vvAkTSapB0PmiMOVYx3iWAw6YBKr52BBCJTO3YjokklBt0iqZENzFLy+TVq3qXlTPb2uV+lkeRxEdoiN0glx0ieroBjVQE1H0iJ7RK3qznqwX6936mJcWrLznAP2B9fkDSAyT+w==</latexit> Source-Pretrained <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model <latexit sha1_base64=\"5LNAmmVR/AN9Lc2T+FRV/is2yz8=\">AAAB8nicbVDLSgNBEJyNrxhfUY9eBoPgKewGX8eACB48RDAP2CxhdjKbDJmdWWZ6lbDkM7x4UMSrX+PNv3GS7EETCxqKqm66u8JEcAOu++0UVlbX1jeKm6Wt7Z3dvfL+QcuoVFPWpEoo3QmJYYJL1gQOgnUSzUgcCtYOR9dTv/3ItOFKPsA4YUFMBpJHnBKwkn+nnvCNBK2Sca9ccavuDHiZeDmpoByNXvmr21c0jZkEKogxvucmEGREA6eCTUrd1LCE0BEZMN9SSWJmgmx28gSfWKWPI6VtScAz9fdERmJjxnFoO2MCQ7PoTcX/PD+F6CrIuExSYJLOF0WpwKDw9H/c55pREGNLCNXc3orpkGhCwaZUsiF4iy8vk1at6l1Uz+9rlfpZHkcRHaFjdIo8dInq6BY1UBNRpNAzekVvDjgvzrvzMW8tOPnMIfoD5/MHKbiRJQ==</latexit> Low Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"wuZucU3JbeEJSquG2WgqGdYMCR8=\">AAAB83icbVDLSgMxFL3js9ZX1aWbYBFclZnia1kQocsK9gHtUDJppg3NJCHJCGXob7hxoYhbf8adf2PazkJbD1w4nHMv994TKc6M9f1vb219Y3Nru7BT3N3bPzgsHR23jEw1oU0iudSdCBvKmaBNyyynHaUpTiJO29H4bua3n6g2TIpHO1E0TPBQsJgRbJ3Uq7PhCN0Lq6Wa9Etlv+LPgVZJkJMy5Gj0S1+9gSRpQoUlHBvTDXxlwwxrywin02IvNVRhMsZD2nVU4ISaMJvfPEXnThmgWGpXwqK5+nsiw4kxkyRynQm2I7PszcT/vG5q49swY0KllgqyWBSnHFmJZgGgAdOUWD5xBBPN3K2IjLDGxLqYii6EYPnlVdKqVoLrytVDtVy7zOMowCmcwQUEcAM1qEMDmkBAwTO8wpuXei/eu/exaF3z8pkT+APv8wfIYpF9</latexit> High Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"1BO6D/gzkeZNQ7HNIaph5NqELCI=\">AAAB8nicbVDLSgMxFM3UV62vqks3wSK4KjPF17LgRncV7AOmQ8mkd9rQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3kHtPmHCmjet+O6W19Y3NrfJ2ZWd3b/+genjU0TJVFNpUcql6IdHAmYC2YYZDL1FA4pBDN5zc5n73CZRmUjyaaQJBTEaCRYwSYyX/XlAFMQhD+KBac+vuHHiVeAWpoQKtQfWrP5Q0zdOUE619z01MkBFlGOUwq/RTDQmhEzIC31JBYtBBNl95hs+sMsSRVPYJg+fq70RGYq2ncWgnY2LGetnLxf88PzXRTZAxkaQGBF18FKUcG4nz+/GQKaCGTy0hVDG7K6Zjogg1tqWKLcFbPnmVdBp176p++dCoNS+KOsroBJ2ic+Sha9REd6iF2ogiiZ7RK3pzjPPivDsfi9GSU2SO0R84nz9y2ZFU</latexit> Incremental <latexit sha1_base64=\"Jmobmj50NeE6y3ftB4xt5xZD5Eg=\">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8dALh4jmAcmS5id9CZDZmeXmVkhLP6FFw+KePVvvPk3TpI9aGJBQ1HVTXdXkAiujet+O4W19Y3NreJ2aWd3b/+gfHjU1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfM7j6g0j+W9mSboR3QkecgZNVZ6aIhUG1Rcjgblilt15yCrxMtJBXI0B+Wv/jBmaYTSMEG17nluYvyMKsOZwKdSP9WYUDahI+xZKmmE2s/mFz+RM6sMSRgrW9KQufp7IqOR1tMosJ0RNWO97M3E/7xeasIbP+MySQ1KtlgUpoKYmMzeJ0OukBkxtYQyxe2thI2posymoEs2BG/55VXSrlW9q+rlXa1Sv8jjKMIJnMI5eHANdbiFJrSAgYRneIU3RzsvzrvzsWgtOPnMMfyB8/kDzgaQ+A==</latexit> Clustering <latexit sha1_base64=\"c4xrXg0yZYBSSDLHCxlf45OWNzg=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBA8hd2Aj2PAi8eI5gHJEmYnnWTIzOwyMyuEJR/hxYMiXv0eb/6Nk2QPmljQUFR1090VJYIb6/vf3tr6xubWdmGnuLu3f3BYOjpumjjVDBssFrFuR9Sg4AoblluB7UQjlZHAVjS+nfmtJ9SGx+rRThIMJR0qPuCMWie1HqhMBJpeqexX/DnIKglyUoYc9V7pq9uPWSpRWSaoMZ3AT2yYUW05EzgtdlODCWVjOsSOo4pKNGE2P3dKzp3SJ4NYu1KWzNXfExmVxkxk5DoltSOz7M3E/7xOagc3YcZVklpUbLFokApiYzL7nfS5RmbFxBHKNHe3EjaimjLrEiq6EILll1dJs1oJriqX99VyrZrHUYBTOIMLCOAaanAHdWgAgzE8wyu8eYn34r17H4vWNS+fOYE/8D5/AF7Wj40=</latexit> Samples <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"KzBZ8R84UC9mpPFQBWeRHFxcqjw=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKVI8FLx4rmLbQhrLZbNq1m92wuxFK6H/w4kERr/4fb/4bt20O2vpg4PHeDDPzwpQzbVz32yltbG5t75R3K3v7B4dH1eOTjpaZItQnkkvVC7GmnAnqG2Y47aWK4iTktBtObud+94kqzaR4MNOUBgkeCRYzgo2VOn4aYUOH1ZpbdxdA68QrSA0KtIfVr0EkSZZQYQjHWvc9NzVBjpVhhNNZZZBpmmIywSPat1TghOogX1w7QxdWiVAslS1h0EL9PZHjROtpEtrOBJuxXvXm4n9ePzPxTZAzkWaGCrJcFGccGYnmr6OIKUoMn1qCiWL2VkTGWGFibEAVG4K3+vI66TTqXrPevG/UWldFHGU4g3O4BA+uoQV30AYfCDzCM7zCmyOdF+fd+Vi2lpxi5hT+wPn8AYuwjxQ=</latexit> Update <latexit sha1_base64=\"y2NH6tDs2GygUDqZYglGwvR4SpA=\">AAAB+nicbVBNSwMxEJ2tX7V+bfXoJVgEQSi7PVSPFS8eK9oPaEvJptk2NMkuSVYpa3+KFw+KePWXePPfmLZ70NYHA4/3ZpiZF8ScaeN5305ubX1jcyu/XdjZ3ds/cIuHTR0litAGiXik2gHWlDNJG4YZTtuxolgEnLaC8fXMbz1QpVkk780kpj2Bh5KFjGBjpb5bvMMi5lSjc3QlyShSuu+WvLI3B1olfkZKkKHed7+6g4gkgkpDONa643ux6aVYGUY4nRa6iaYxJmM8pB1LJRZU99L56VN0apUBCiNlSxo0V39PpFhoPRGB7RTYjPSyNxP/8zqJCS97KZNxYqgki0VhwpGJ0CwHNGCKEsMnlmCimL0VkRFWmBibVsGG4C+/vEqalbJfLVdvK6Wal8WRh2M4gTPw4QJqcAN1aACBR3iGV3hznpwX5935WLTmnGzmCP7A+fwBUnKTWg==</latexit> Samples + Anchors <latexit sha1_base64=\"u0BDOcH87PXd3DsT+o414+7cHnI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBsAq7FjGdARvLBMwFkhBmZ2eTMbMzy8ysEJaU9jYWitj6Cql8CDufwZdwcik0+sPAx/+fw5xz/JgzbVz308msrK6tb2Q3c1vbO7t7+f2DhpaJIrROJJeq5WNNORO0bpjhtBUriiOf06Y/vJrmzTuqNJPixoxi2o1wX7CQEWys1eiQQBrdyxfcojsT+gveAgqX75Pa1/3xpNrLf3QCSZKICkM41rrtubHpplgZRjgd5zqJpjEmQ9ynbYsCR1R309m0Y3RqnQCFUtknDJq5PztSHGk9inxbGWEz0MvZ1PwvaycmLHdTJuLEUEHmH4UJR0ai6eooYIoSw0cWMFHMzorIACtMjD1Qzh7BW175LzTOi16pWKq5hUoZ5srCEZzAGXhwARW4hirUgcAtPMATPDvSeXRenNd5acZZ9BzCLzlv33Yvk3g=</latexit> Â·Â·Â· <latexit sha1_base64=\"+7L/8ObZcl+JIZaSFhVO3t+lUUE=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2bvizjWb9YcituBrJMvDkp1Y6CDPV+8as7iFgScoVMUmM6nhtjL6UaBZN8UugmhseUPdIh71iqaMhNL82unZBTqwxIEGlbCkmm/p5IaWjMOPRtZ0hxZBa9qfif10kwuOqlQsUJcsVmi4JEEozI9HUyEJozlGNLKNPC3krYiGrK0AZUsCF4iy8vk+Z5xatWqnc2jQuYIQ/HcAJl8OASanALdWgAgwd4hld4cyLnxXl3PmatOWc+cwh/4Hz+AFjYkTs=</latexit> D l ( t ) <latexit sha1_base64=\"9C0bB8PYImk9DX0HLfGvGd44PFA=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2b/qiMZ/1iya24Gcgy8eakVDsKMtT7xa/uIGJJyBUySY3peG6MvZRqFEzySaGbGB5T9kiHvGOpoiE3vTS7dkJOrTIgQaRtKSSZ+nsipaEx49C3nSHFkVn0puJ/XifB4KqXChUnyBWbLQoSSTAi09fJQGjOUI4toUwLeythI6opQxtQwYbgLb68TJrnFa9aqd7ZNC5ghjwcwwmUwYNLqMEt1KEBDB7gGV7hzYmcF+fd+Zi15pz5zCH8gfP5A1K8kTc=</latexit> D h ( t ) <latexit sha1_base64=\"eNrtnhPGeU8n4BRDMStm5cjQ4ts=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDbbTbt0s4m7E6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSKQw6Lrfzsbm1vbObmGvuH9weHRcOjltmzjVjLdYLGPdDajhUijeQoGSdxPNaRRI3gkmjbnfeeLaiFg94DThfkRHSoSCUbRS1zNIGlTKQansVtwFyDrxclKGHM1B6as/jFkacYVMUmN6npugn1GNgkk+K/ZTwxPKJnTEe5YqGnHjZ4t7Z+TSKkMSxtqWQrJQf09kNDJmGgW2M6I4NqveXPzP66UY3vqZUEmKXLHlojCVBGMyf54MheYM5dQSyrSwtxI2ppoytBEVbQje6svrpF2teLVK7b5arl/ncRTgHC7gCjy4gTrcQRNawEDCM7zCm/PovDjvzseydcPJZ87gD5zPH1Naj3k=</latexit> 1st Call <latexit sha1_base64=\"mxsL+XuWb2hqFND+pzTctrB1rcY=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDababt0s4m7G6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSATXxnW/nY3Nre2d3cJecf/g8Oi4dHLa1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfc7T6g0j+WDmSboR3Qk+ZAzaqzUrcqQNKgQg1LZrbgLkHXi5aQMOZqD0lc/jFkaoTRMUK17npsYP6PKcCZwVuynGhPKJnSEPUsljVD72eLeGbm0SkiGsbIlDVmovycyGmk9jQLbGVEz1qveXPzP66VmeOtnXCapQcmWi4apICYm8+dJyBUyI6aWUKa4vZWwMVWUGRtR0Ybgrb68TtrViler1O6r5fp1HkcBzuECrsCDG6jDHTShBQwEPMMrvDmPzovz7nwsWzecfOYM/sD5/AE0o49l</latexit> 2nd Call <latexit sha1_base64=\"oSA1OFmXXL9y3PJtqoVxTIG9mto=\">AAAB8HicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaElCY2UwkQ8DF7K3zMGGvb3L7p6REH6FjYXG2Ppz7Pw3LnCFgi+Z5OW9mczMCxLBtXHdbye3sbm1vZPfLeztHxweFY9PWjpOFcMmi0WsOgHVKLjEpuFGYCdRSKNAYDsY1+d++xGV5rG8N5ME/YgOJQ85o8ZKD7f4ZEidCtEvltyyuwBZJ15GSpCh0S9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50cfCMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia89qdcJqlByZaLwlQQE5P592TAFTIjJpZQpri9lbARVZQZm1HBhuCtvrxOWpWyVy1X7yqlWiWLIw9ncA6X4MEV1OAGGtAEBhE8wyu8Ocp5cd6dj2VrzslmTuEPnM8fSFeQCA==</latexit> Next Call Figure 2: Overview of the SimATTA framework. and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (8) Corollary 4 validates that the selected low-entropy samples can mitigate the CF problem under the assumption that these samples are source-like, which is also empirically validated in Fig. 1. Note that our strategy employs entropy minimization in a selective manner, aiming to solve CF rather than the main adaptation issue. While many FTTA works use entropy minimization to adapt across domains without guarantees, our use is more theoretically-sound. 4 A N ATTA ALGORITHM Building on our theoretical findings, we introduce a simple yet effective ATTA method, known as SimATTA, that innovatively integrates incremental clustering and selective entropy minimization techniques, as illustrated in Fig. 2. We start with an overview of our methodology, including the learning framework and the comprehensive sample selection strategies. We then proceed to discuss the details of the incremental clustering technique designed for real-time sample selections. 4.1 A LGORITHM OVERVIEW Let (x, y) be a labeled sample and f(Â·; Î¸) be our neural network, where Ë†y = f(x; Î¸) and Î¸ represents the parameters. We have a model pre-trained on source domains with the pre-trained parameters Ï•. We initialize model parameters as Î¸(0) = Ï• and aim to adapt the model f(Â·; Î¸) in real-time. During the test phase, the model continuously predicts labels for streaming-in test data and concurrently gets fine-tuned. We perform sample selection to enable active learning. As discussed in Sec. 3.2, we empirically consider informative high-entropy samples for addressing distribution shifts and source-like low-entropy samples to mitigate CF. As shown in Alg. 1, at each time step t, we first partition unlabeled test samples Ute(t) into high entropy and low entropy datasets, Uh(t) and Ul(t), using an entropy threshold. The source-pretrained model f(Â·; Ï•) is frozen to predict pseudo labels for low entropy data. We obtain labeled low-entropy data Dl(t) by labeling Ul(t) with f(Â·; Ï•) and combining it with Dl(t âˆ’ 1). In contrast, the selection of high-entropy samples for active labeling is less straightforward. Since the complete test dataset is inaccessible for analyzing the target domain distribution, real-time sample selection is required. We design an incremental clustering sample selection technique to reduce sample redundancy and increase distribution coverage, detailed in Sec. 4.2. The incremental clustering algorithm outputs the labeled test samples Dh(t), also referred to as anchors, given Dh(t âˆ’1) and Uh(t). After sample selection, the model undergoes test-time training using the labeled test anchors Dh(t) and pseudo-labeled source-like anchors Dl(t). Following the analyses in Sec. 3.1, the training weights and sample numbers should satisfy w(t) â‰ˆ Î»(t) for Dh(t) and Dl(t) for optimal results. The analyses and results in Sec. 3.2 further indicate that balancing the source and target ratio is the key to mitigating CF. However, when source-like samples significantly outnumber test samples, the optimal w(t) for test domains can deviate from Î»(t) according to Eq. (4). 4.2 I NCREMENTAL CLUSTERING We propose incremental clustering, a novel continual clustering technique designed to select informa- tive samples in unsupervised settings under the ATTA framework. The primary goal of this strategy is to store representative samples for distributions seen so far. Intuitively, we apply clusters to cover all seen distributions while adding new clusters to cover newly seen distributions. During this process with new clusters added, old clusters may be merged due to the limit of the cluster budget. Since 6Published as a conference paper at ICLR 2024 Algorithm 1 SIMATTA: A SIMPLE ATTA ALGORITHM Require: A fixed source pre-trained model f(Â·; Ï•) and a real-time adapting model f(Â·; Î¸(t)) with Î¸(0) = Ï•. Streaming test data Ute(t) at time step t. Entropy of predictions H(Ë†y) = âˆ’P c p(Ë†yc) logp(Ë†yc). Low entropy and high entropy thresholds el and eh. The number of cluster centroid budget NC (t) at time step t. Centroid increase number k. Learning step size Î·. 1: for t = 1, . . . , Tdo 2: Model inference on Ute(t) using f(Â·; Î¸(t âˆ’ 1)). 3: Dl(t) â† Dl(t âˆ’ 1) âˆª {(x, f(x; Ï•))|x âˆˆ Ute(t), H(f(x; Ï•)) < el} 4: Uh(t) â† {x|x âˆˆ Ute(t), H(f(x; Î¸)) > eh} 5: Dh(t) â† Dh(t âˆ’ 1) âˆª {(x, y)|âˆ€x âˆˆ IC(Dh(t âˆ’ 1), Uh(t), NC(t)), y= Oracle(x)} 6: Î»(t) â† |Dl(t)|/(|Dl(t)| + |Dh(t)|), |Dh(t)|/(|Dl(t)| + |Dh(t)|) 7: w(t) â† GetW(Î»(t)) â–· Generally, GetW(Î»(t)) = Î»(t) is a fair choice. 8: Î¸(t) â† Î¸(t âˆ’ 1) 9: for (xl, yl) in Dl and (xh, yh) in Dh do 10: Î¸(t) â† Î¸(t) âˆ’ Î·w0âˆ‡â„“CE (f(xl; Î¸(t)), yl) âˆ’ Î·(1 âˆ’ w0)âˆ‡â„“CE (f(xh; Î¸(t)), yh) 11: end for 12: NC (t + 1) â† UpdateCentroidNum(NC (t)) â–· Naive choice: NC (t + 1) â† NC (t) + k. 13: end for clusters cannot be stored efficiently, we store the representative samples of clusters, named anchors, instead. In this work, we adopt weighted K-means (Krishna and Murty, 1999) as our base clustering method due to its popularity and suitability for new setting explorations. When we apply clustering with new samples, a previously selected anchor should not weigh the same as new samples since the anchor is a representation of a cluster,i.e., a representation of many samples. Instead, the anchor should be considered as a barycenter with a weight of the sum of its clusterâ€™s sample weights. For a newly added cluster, its new anchor has the weight of the whole cluster. For clusters containing multiple old anchors, i.e., old clusters, the increased weights are distributed equally among these anchors. These increased weights are contributed by new samples that are close to these old anchors. Intuitively, this process of clustering is analogous to the process of planet formation. Where there are no planets, new planets (anchors) will be formed by the aggregation of the surrounding material (samples). Where there are planets, the matter is absorbed by the surrounding planets. This example is only for better understanding without specific technical meanings. Specifically, we provide the detailed Alg. 2 for incremental clustering. In each iteration, we apply weighted K-Means for previously selected anchors Danc and the new streaming-in unlabeled data Unew. We first extract all sample features using the model from the previous step f(Â·; Î¸(t âˆ’ 1)), and then cluster these weighted features. The initial weights of the new unlabeled samples are 1, while anchors inherit weights from previous iterations. After clustering, clusters including old anchors are old clusters, while clusters only containing new samples are newly formed ones. For each new cluster, we select the centroid-closest sample as the new anchor to store. As shown in line 10 of Alg. 2, for both old and new clusters, we distribute the sample weights in this cluster as its anchorsâ€™ weights. With incremental clustering, although we can control the number of clusters in each iteration, we cannot control the number of new clusters/new anchors. This indirect control makes the increase of new anchors adaptive to the change of distributions, but it also leads to indirect budget control. Therefore, in experimental studies, we set the budget limit, but the actual anchor budget will not reach this limit. The overall extra storage requirement is O(B) since the number of saved unlabeled samples is proportional to the number of saved labeled samples (anchors). 5 E XPERIMENTAL STUDIES In this study, we aim to validate the effectiveness of our proposed method, as well as explore the various facets of the ATTA setting. Specifically, we design experiments around the following research questions: RQ1: Can TTA methods address domain distribution shifts? RQ2: Is ATTA as efficient as TTA? RQ3: How do the components of SimATTA perform? RQ4: Can ATTA perform on par with stronger Active Domain Adaptation (ADA) methods? We compare ATTA with three settings, TTA (Tab. 2), enhanced TTA (Tab. 3 and 5), and ADA (Tab. 4). Datasets. To assess the OOD performance of the TTA methods, we benchmark them using datasets from DomainBed (Gulrajani and Lopez-Paz, 2020) and Hendrycks and Dietterich (2019a). We employ PACS (Li et al., 2017), VLCS (Fang et al., 2013), Office-Home (Venkateswara et al., 2017), and Tiny-ImageNet-C datasets for our evaluations. For each dataset, we designate one domain as 7Published as a conference paper at ICLR 2024 Table 2: TTA comparisons on PACS and VLCS.This table includes the two data stream mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. PACS Domain-wise data stream Post-adaptation Random data stream Post-adaptation P â†’Aâ†’ â†’Câ†’ â†’S P A C S â†’1â†’ â†’2â†’ â†’3â†’ â†’4 P A C S BN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 Tent (steps=1) N/A 67.29 64.59 44.67 97.60 66.85 64.08 42.58 56.35 54.09 51.83 48.58 97.19 63.53 60.75 41.56Tent (steps=10) N/A 67.38 57.85 20.23 62.63 34.52 40.57 13.59 47.36 31.01 22.84 20.33 50.78 23.68 20.95 19.62EATA N/A 67.04 64.72 50.27 98.62 66.50 62.46 48.18 57.31 56.06 58.17 59.78 98.62 69.63 65.70 54.26CoTTA N/A 65.48 62.12 53.17 98.62 65.48 63.10 53.78 56.06 54.33 57.16 57.42 98.62 65.97 62.97 54.62SAR (steps=1) N/A 66.75 63.82 49.58 98.32 66.94 62.93 45.74 56.78 56.35 56.68 56.70 98.44 68.16 64.38 52.53SAR (steps=10) N/A 69.38 68.26 49.02 96.47 62.16 56.19 54.62 53.51 51.15 51.78 45.60 94.13 56.64 56.02 36.37 SimATTA (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00SimATTA (B â‰¤500) N/A 77.93 76.02 76.30 98.62 88.33 83.49 83.74 68.46 78.22 80.91 85.49 99.16 86.67 84.77 87.71 VLCS Domain-wise data stream Post-adaptation Random data stream Post-adaptation C â†’Lâ†’ â†’Sâ†’ â†’V C L S V â†’1â†’ â†’2â†’ â†’3â†’ â†’4 C L S V BN w/o adapt 100.00 33.55 41.10 49.05 100.00 33.55 41.10 49.05 41.23 41.23 41.23 41.23 100.00 33.55 41.10 49.05BN w/ adapt 85.16 37.31 33.27 52.16 85.16 37.31 33.27 52.16 40.91 40.91 40.91 40.91 85.16 37.31 33.27 52.16 Tent (steps=1) N/A 38.55 34.40 53.88 84.73 43.86 33.61 53.11 44.85 44.29 47.38 44.98 85.30 43.49 37.81 53.35Tent (steps=10) N/A 45.41 31.44 32.32 42.54 37.65 27.79 33.12 46.13 42.31 43.51 39.48 52.01 40.32 33.64 40.37EATA N/A 37.24 33.15 52.58 84.10 37.69 32.39 52.49 43.77 42.48 43.34 41.55 83.32 36.67 31.47 52.55CoTTA N/A 37.39 32.54 52.25 82.12 37.65 33.12 52.90 43.69 42.14 43.21 42.32 81.98 37.99 33.52 53.23SAR (steps=1) N/A 36.18 34.43 52.46 83.96 39.72 36.53 52.37 43.64 43.04 44.20 41.93 85.09 40.70 36.44 53.02SAR (steps=10) N/A 35.32 34.10 51.66 82.12 41.49 33.94 53.08 43.56 42.05 42.53 41.16 85.09 37.58 33.12 52.01 SimATTA (B â‰¤300) N/A 62.61 65.08 74.38 99.93 69.50 66.67 77.34 62.33 69.33 73.20 71.93 99.93 69.43 72.46 80.39SimATTA (B â‰¤500) N/A 63.52 68.01 76.13 99.51 70.56 73.10 78.35 62.29 70.45 73.50 72.02 99.43 70.29 72.55 80.18 the source domain and arrange the samples from the other domains to form the test data stream. For DomainBed datasets, we adopt two stream order strategies. The first order uses a domain-wise data stream, i.e., we finish streaming samples from one domain before starting streaming another domain. The second order is random, where we shuffle samples from all target domains and partition them into four splits 1, 2, 3, and 4, as shown in Tab. 2. More dataset details are provided in Appx. G.1. Baselines. For baseline models, we start with the common source-only models, which either utilize pre-calculated batch statistics (BN w/o adapt) or test batch statistics (BN w/ adapt). For comparison with other TTA methods, we consider four state-of-the-art TTA methods: Tent (Wang et al., 2021), EATA (Niu et al., 2022), CoTTA (Wang et al., 2022a), and SAR (Niu et al., 2023). The three of them except Tent provide extra design to avoid CF. To compare with ADA methods, we select algorithms that are partially comparable with our method, i.e., they should be efficient (e.g., uncertainty-based) without the requirements of additional networks. Therefore, we adopt random, entropy (Wang and Shang, 2014), k-means (Krishna and Murty, 1999), and CLUE (Prabhu et al., 2021) for comparisons. Settings. For TTA, we compare with general TTA baselines in streaming adaptation using the two aforementioned data streaming orders, domain-wise and random. We choose P in PACS and C in VLCS as source domains. For domain-wise data stream, we use order A â†’ C â†’ S for PACS and L â†’ S â†’ V for VLCS. We report the real-time adaptation accuracy results for each split of the data stream, as well as the accuracy on each domain after all adaptations through the data stream (under â€œpost-adaptationâ€ columns). Enhanced TTA is built on TTA with access to extra random sample labels. TTA baselines are further fine-tuned with these random samples. To further improve enhanced TTA, we use long-term label storage and larger unlabeled sample pools. To its extreme where the model can access the whole test set samples, the setting becomes similar to ADA, thus we also use ADA methods for comparisons. ADA baselines have access to all samples in the pre-collected target datasets but not source domain data, whereas our method can only access the streaming test data. 5.1 T HE FAILURE OF TEST-TIME ADAPTATION The failure of TTA methods on domain distribution shifts is one of the main motivations of the ATTA setting. As shown in Tab. 2, TTA methods cannot consistently outperform eventhe simplest baseline \"BN w/ adapt\" which uses test time batch statistics to make predictions, evidencing that current TTA methods cannot solve domain distribution shifts (RQ1). Additionally, Tent (step=10) exhibits significant CF issues, where \"step=10\" indicates 10 test-time training updates, i.e., 10 gradient backpropagation iterations. This failure of TTA methods necessitates the position of ATTA. In contrast, SimATTA, with a budget B less than 300, outperforms all TTA methods on both source and target domains by substantial margins. Moreover, compared to the source-only baselines, our method improves the target domain performances significantly with negligible source performance loss, showing that ATTA is a more practically effective setting for real-world distribution shifts. 5.2 E FFICIENCY & ENHANCED TTA SETTING COMPARISONS To validate the efficiency of ATTA and broaden the dataset choice, we conduct this study on Tiny- ImageNet-C which, though does not focus on domain shifts, is much larger than PACS and VLCS. we 8Published as a conference paper at ICLR 2024 Table 3: Comparisons with Enhanced TTA on Tiny-ImageNet-C (severity level 5). Tiny-ImageNet-C Time (sec)Noise Blur Weather Digital Gauss. Shot Impul. Defoc. Glass Motion Zoom Snow Frost Fog Contr. Elastic Pixel JPEG Avg. Tent (step=1) 68.83 9.32 11.97 8.86 10.43 7.00 12.20 14.34 13.58 15.46 13.55 3.99 13.31 17.79 18.61 12.17Tent (step=10) 426.90 0.86 0.63 0.52 0.52 0.55 0.54 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.54EATA 93.14 3.98 3.33 2.18 4.80 2.37 11.02 11.41 14.06 15.26 9.65 1.36 9.88 14.24 12.12 8.26CoTTA 538.78 5.63 7.12 6.31 8.05 5.74 9.68 10.55 11.75 12.00 11.15 4.17 5.35 7.82 8.90 8.16SAR (step=1) 113.76 8.90 3.11 1.67 1.55 1.47 1.35 1.19 1.03 1.04 0.93 0.83 1.00 0.74 0.77 1.83SAR (step=10) 774.11 2.67 3.26 2.38 1.64 1.85 2.49 3.16 3.81 2.72 3.12 0.81 3.47 4.04 1.76 2.66 SimATTA (step=10) 736.289.68 19.40 12.14 30.28 17.03 42.36 43.10 31.96 40.08 29.243.21 34.56 45.24 45.74 28.86 enhance the TTA setting by fine-tuning baselines on randomly selected labeled samples. Specifically, the classifier of ResNet18-BN is pre-adapted to the brightness corruption (source domain) before test-time adapting. SimATTAâ€™s label budget is around 4,000, while all other TTA methods have budget 4,500 for randomly selected labeled samples. The data stream order is shown in Tab. 3. Time is measured across all corrupted images in the Noise and Blur noise types, and the values represent the average time cost for adapting 10,000 images. The results clearly evidence the efficiency of ATTA (RQ2), while substantially outperforming all enhanced TTA baselines. Simply accessing labeled samples cannot benefit TTA methods to match ATTA. With 10 training updates (step=10) for each batch, FTTA methods would suffer from severe CF problem. In contrast, ATTA covers a statistically significant distribution, achieving stronger performances with 10 training updates or even more steps till approximate convergences. In fact, longer training on Tent (step=10) leads to worse results (compared to step=1), which further motivates the design of the ATTA setting. The reason for higher absolute time cost in Tab. 3 is due to differences in training steps. In this experiment, SimATTA has a training step of 10, and similar time cost as SAR per step. Note that if the enhanced TTA setting is further improved to maintain distributions with a balanced CF mitigation strategy and an incremental clustering design, the design approaches ATTA. Specifically, we compare SimATTA with its variants as the ablation study (RQ3) in Appx. I.2. 5.3 C OMPARISONS TO A STRONGER SETTING : ACTIVE DOMAIN ADAPTATION Table 4: Comparisons to ADA baselines. Source domains are denoted as \"(S)\". Results are average accuracies (with standard deviations). PACS P (S) A C S Random (B= 300) 96.21 (0.80) 81.19 (0.48) 80.75 (1.27) 84.34 (0.18)Entropy (B= 300) 96.31 (0.64)88.00 (1.46)82.48 (1.71) 80.55 (1.01)Kmeans (B= 300) 93.71 (1.50) 79.31 (4.01) 79.64 (1.44) 83.92 (0.65)CLUE (B= 300) 96.69 (0.17)83.97 (0.57)84.77 (0.88) 86.91 (0.26) SimATTA (B â‰¤300) 98.89 (0.09)84.69 (0.22)83.09 (0.83)83.76 (2.24) VLCS C (S) L S V Random (B= 300) 96.21 (1.65) 66.67 (1.70) 70.72 (0.30) 72.14 (1.71)Entropy (B= 300) 97.74 (1.56) 69.29 (2.26)69.25 (4.77) 75.26 (3.07)Kmeans (B= 300) 98.61 (0.27)67.57 (1.64)70.77 (0.01)74.49 (0.97)CLUE (B= 300) 85.70 (10.09) 65.29 (1.49) 69.42 (2.64) 69.09 (6.05) SimATTA (B â‰¤300) 99.93 (0.00) 69.47 (0.03)69.57 (2.90)78.87 (1.53) In addtion to the above comparisons with (en- hanced) TTA, which necessitate the requirement of extra information in the ATTA setting, we com- pare ATTA with a stronger setting Active Domain Adaptation (ADA) to demonstrate another supe- riority of ATTA, i.e., weaker requirements for comparable performances (RQ4). ADA baselines are able to choose the global best active samples, while ATTA has to choose samples from a small sample buffer (e.g., a size of 100) and discard the rest. Tab. 4 presents the post-adaptation model per- formance results. All ADA results are averaged from 3 random runs, while ATTA results are the post-adaptation performances averaged from the two data stream orders. As can be observed, despite the lack of a pre-collected target dataset, SimATTA produces better or competitive results against ADA methods. Moreover, without source data access, SimATTAâ€™s design for CF allows it to maintain superior source domain performances over ADA methods. Further experimental studies including the Office-Home dataset are provided in Appx. I. In conclusion, the significant improvement compared to weaker settings (TTA, enhanced TTA) and the comparable performance with the stronger setting, ADA, rendering ATTA a setting that is as efficient as TTA and as effective as ADA. This implies its potential is worthy of future explorations. 6 C ONCLUSION AND DISCUSSION Thereâ€™s no denying that OOD generalization can be extremely challenging without certain information, often relying on various assumptions easily compromised by different circumstances. Thus, itâ€™s prudent to seek methods to achieve significant improvements with minimal cost, e.g., DG methods leveraging environment partitions and ATTA methods using budgeted annotations. As justified in our theoretical and experimental studies, ATTA stands as a robust approach to achieve real-time OOD generalization. Although SimATTA sets a strong baseline for ATTA, thereâ€™s considerable scope for further investigation within the ATTA setting. One potential direction involves developing alternatives to prevent CF in ATTA scenarios. While selective entropy minimization on low-entropy samples has prove to be empirically effective, it relies on the quality of the pre-trained model and training on incorrectly predicted low-entropy samples may reinforce the errors. It might not be cost-effective to expend annotation budgets on low-entropy samples, but correcting them could be a viable alternative solution. We anticipate that our work will spur numerous further explorations in this field. 9Published as a conference paper at ICLR 2024 ACKNOWLEDGMENTS This work was supported in part by National Science Foundation grant IIS-2006861 and National Institutes of Health grant U01AG070112. REFERENCES Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, and Mario Marchand. Domain- adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014. Lucas Baier, Tim SchlÃ¶r, Jakob SchÃ¶ffer, and Niklas KÃ¼hl. Detecting concept drift with neural network model uncertainty. In Hawaii International Conference on System Sciences, 2021. URL https://api.semanticscholar.org/CorpusID:235731947. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79:151â€“175, 2010. Davide Cacciarelli and Murat Kulahci. A survey on online active learning, 2023. Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, and Pheng-Ann Heng. Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part V 24, pages 225â€“235. Springer, 2021. Li Chen, Tutian Tang, Zhitian Cai, Yang Li, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, and Yu Qiao. Level 2 autonomous driving on a single device: Diving into the devils of openpilot. arXiv preprint arXiv:2206.08176, 2022a. Weijie Chen, Luojun Lin, Shicai Yang, Di Xie, Shiliang Pu, and Yueting Zhuang. Self-supervised noisy label learning for source-free unsupervised domain adaptation. In 2022 IEEE/RSJ In- ternational Conference on Intelligent Robots and Systems (IROS) , pages 10185â€“10192. IEEE, 2022b. Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. Advances in Neural Information Processing Systems, 33:21061â€“21071, 2020. David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models. Journal of artificial intelligence research, 4:129â€“145, 1996. Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, AleÅ¡ Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366â€“3385, 2021. Yuhe Ding, Lijun Sheng, Jian Liang, Aihua Zheng, and Ran He. Proxymix: Proxy-based mixup training with label refinery for source-free domain adaptation. arXiv preprint arXiv:2205.14566, 2022. Cian Eastwood, Ian Mason, Christopher KI Williams, and Bernhard SchÃ¶lkopf. Source-free adaptation to measurement shift via bottom-up feature restoration. arXiv preprint arXiv:2107.05446, 2021. Jiahao Fan, Hangyu Zhu, Xinyu Jiang, Long Meng, Chen Chen, Cong Fu, Huan Yu, Chenyun Dai, and Wei Chen. Unsupervised domain adaptation by statistics alignment for deep sleep staging networks. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30:205â€“216, 2022. Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision, pages 1657â€“1664, 2013. Yuqi Fang, Pew-Thian Yap, Weili Lin, Hongtu Zhu, and Mingxia Liu. Source-free unsupervised domain adaptation: A survey. arXiv preprint arXiv:2301.00265, 2022. Francois Fleuret et al. Uncertainty reduction for model adaptation in semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9613â€“9623, 2021. 10Published as a conference paper at ICLR 2024 Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180â€“1189. PMLR, 2015. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096â€“2030, 2016. Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004. Shurui Gui, Chaoyue Wang, Qihua Chen, and Dacheng Tao. Featureflow: Robust video interpolation via structure-to-texture generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14004â€“14013, 2020. Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL https://openreview.net/forum?id=8hHg-zs_p-h. Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770â€“778, 2016. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. March 2019a. doi: 10.48550/ARXIV .1903.12261. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019b. Steven CH Hoi, Rong Jin, Jianke Zhu, and Michael R Lyu. Semisupervised svm batch mode active learning with applications to image retrieval. ACM Transactions on Information Systems (TOIS), 27(3):1â€“29, 2009. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 17853â€“17862, 2023. Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. Model adaptation: Historical contrastive learning for unsupervised domain adaptation without source data. Advances in Neural Information Processing Systems, 34:3635â€“3649, 2021. Masato Ishii and Masashi Sugiyama. Source-free domain adaptation via distributional alignment by matching batch normalization statistics. arXiv preprint arXiv:2101.10842, 2021. Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. Advances in Neural Information Processing Systems, 34:2427â€“2440, 2021. Suyog Dutt Jain and Kristen Grauman. Active image segmentation propagation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2864â€“2873, 2016. Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. Contrastive adaptation network for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4893â€“4902, 2019. Ashish Kapoor, Kristen Grauman, Raquel Urtasun, and Trevor Darrell. Active learning with gaussian processes for object categorization. In 2007 IEEE 11th international conference on computer vision, pages 1â€“8. IEEE, 2007. Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu. Test-time adaptable neural networks for robust medical image segmentation. Medical Image Analysis, 68:101907, 2021. 11Published as a conference paper at ICLR 2024 Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and Christopher Kanan. Measuring catastrophic forgetting in neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018. Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In VLDB, volume 4, pages 180â€“191. Toronto, Canada, 2004. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114 (13):3521â€“3526, 2017. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal- subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637â€“5664. PMLR, 2021. Divya Kothandaraman, Sumit Shekhar, Abhilasha Sancheti, Manoj Ghuhan, Tripti Shukla, and Dinesh Manocha. Salad: Source-free active label-agnostic domain adaptation for classification, segmentation and detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 382â€“391, 2023. K Krishna and M Narasimha Murty. Genetic k-means algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29(3):433â€“439, 1999. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu- tional neural networks. Communications of the ACM, 60(6):84â€“90, 2017. David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrap- olation (REx). In International Conference on Machine Learning , pages 5815â€“5826. PMLR, 2021. Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In Proceedings of the IEEE/CVF winter conference on applications of computer vision, pages 615â€“625, 2021. David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine learning proceedings 1994, pages 148â€“156. Elsevier, 1994. Aodong Li, Alex Boyd, Padhraic Smyth, and Stephan Mandt. Detecting and adapting to irregular distribution shifts in bayesian online learning. Advances in neural information processing systems, 34:6816â€“6828, 2021a. Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542â€“5550, 2017. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9641â€“9650, 2020. Xianfeng Li, Weijie Chen, Di Xie, Shicai Yang, Peng Yuan, Shiliang Pu, and Yueting Zhuang. A free lunch for unsupervised domain adaptive object detection without source data. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 8474â€“8481, 2021b. Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935â€“2947, 2017. Jian Liang, Dapeng Hu, Ran He, and Jiashi Feng. Distill and fine-tune: Effective adaptation from a black-box source model. arXiv preprint arXiv:2104.01539, 1(3), 2021. Jian Liang, Dapeng Hu, Jiashi Feng, and Ran He. Dine: Domain adaptation from single and multiple black-box predictors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8003â€“8013, 2022. 12Published as a conference paper at ICLR 2024 Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without environment partition? Advances in Neural Information Processing Systems, 35:24529â€“24542, 2022. Xiaofeng Liu, Fangxu Xing, Chao Yang, Georges El Fakhri, and Jonghye Woo. Adapting off-the- shelf source segmenter for target medical image segmentation. In Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part II 24, pages 549â€“559. Springer, 2021a. Xinyu Liu and Yixuan Yuan. A source-free domain adaptive polyp detection framework with style diversification flow. IEEE Transactions on Medical Imaging, 41(7):1897â€“1908, 2022. Yuang Liu, Wei Zhang, Jun Wang, and Jianyong Wang. Data-free knowledge transfer: A survey. arXiv preprint arXiv:2112.15278, 2021b. Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems, 34:21808â€“21820, 2021c. Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97â€“105. PMLR, 2015. David Lopez-Paz and Marcâ€™Aurelio Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017. Chaochao Lu, Yuhuai Wu, JosÃ© Miguel HernÃ¡ndez-Lobato, and Bernhard SchÃ¶lkopf. Invariant causal representation learning for out-of-distribution generalization. In International Conference on Learning Representations, 2021. Xinhong Ma, Junyu Gao, and Changsheng Xu. Active universal domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8968â€“8977, 2021. Haitao Mao, Lun Du, Yujia Zheng, Qiang Fu, Zelin Li, Xu Chen, Shi Han, and Dongmei Zhang. Source free unsupervised graph domain adaptation. arXiv preprint arXiv:2112.00955, 2021. Christoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, and Jean Oh. Core challenges of social robot navigation: A survey. ACM Transactions on Human-Robot Interaction, 12(3):1â€“39, 2023. Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Munan Ning, Donghuan Lu, Dong Wei, Cheng Bian, Chenglang Yuan, Shuang Yu, Kai Ma, and Yefeng Zheng. Multi-anchor active domain adaptation for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9112â€“9122, 2021. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In International conference on machine learning, pages 16888â€“16905. PMLR, 2022. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. InThe Eleventh International Con- ference on Learning Representations, 2023. URL https://openreview.net/forum?id=g2YraF75Tj. Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE transactions on neural networks, 22(2):199â€“210, 2010. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019. 13Published as a conference paper at ICLR 2024 Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53â€“69, 2015. Judea Pearl. Causality. Cambridge university press, 2009. Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal of machine Learning research, 12:2825â€“2830, 2011. Jonas Peters, Peter BÃ¼hlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947â€“1012, 2016. Jonas Peters, Dominik Janzing, and Bernhard SchÃ¶lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017. Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, and Judy Hoffman. Active domain adaptation via clustering uncertainty-weighted embeddings. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8505â€“8514, 2021. Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. arXiv preprint arXiv:2010.05761, 2020. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019. Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normal- ization help optimization? Advances in neural information processing systems, 31, 2018. Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford, and Jordan T. Ash. Streaming active learning with deep neural networks. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 30005â€“30021. PMLR, 23â€“29 Jul 2023. URL https://proceedings.mlr. press/v202/saran23a.html. Harald Schafer, Eder Santana, Andrew Haden, and Riccardo Biasini. A commute in data: The comma2k19 dataset, 2018. Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for informa- tion extraction. In Advances in Intelligent Data Analysis: 4th International Conference, IDA 2001 Cascais, Portugal, September 13â€“15, 2001 Proceedings 4, pages 309â€“318. Springer, 2001. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539â€“11551, 2020. Burr Settles. Active learning literature survey. 2009. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji, and Manmohan Chandraker. Active adversarial domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 739â€“748, 2020. Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443â€“450. Springer, 2016. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229â€“9248. PMLR, 2020. 14Published as a conference paper at ICLR 2024 Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472â€“7481, 2018. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE international conference on computer vision, pages 4068â€“4076, 2015. Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7167â€“7176, 2017. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018â€“5027, 2017. Sudheendra Vijayanarasimhan and Ashish Kapoor. Visual recognition and detection under bounded computational resources. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 1006â€“1013. IEEE, 2010. Dan Wang and Yi Shang. A new active labeling method for deep learning. In 2014 International joint conference on neural networks (IJCNN), pages 112â€“119. IEEE, 2014. Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test- time adaptation by entropy minimization. InInternational Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c. Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing, 312: 135â€“153, 2018. Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201â€“7211, 2022a. Rui Wang, Zuxuan Wu, Zejia Weng, Jingjing Chen, Guo-Jun Qi, and Yu-Gang Jiang. Cross-domain contrastive learning for unsupervised domain adaptation. IEEE Transactions on Multimedia , 2022b. Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):1â€“46, 2020. Binhui Xie, Longhui Yuan, Shuang Li, Chi Harold Liu, Xinjing Cheng, and Guoren Wang. Active learning for domain adaptation: An energy-based approach. InProceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8708â€“8716, 2022. Zhao Xu, Kai Yu, V olker Tresp, Xiaowei Xu, and Jizhi Wang. Representative sampling for text classification using support vector machines. In Advances in Information Retrieval: 25th European Conference on IR Research, ECIR 2003, Pisa, Italy, April 14â€“16, 2003. Proceedings 25, pages 393â€“407. Springer, 2003. Baoyao Yang, Hao-Wei Yeh, Tatsuya Harada, and Pong C Yuen. Model-induced generalization error bound for information-theoretic representation learning in source-data-free unsupervised domain adaptation. IEEE Transactions on Image Processing, 31:419â€“432, 2021a. Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu Sebe, and Elisa Ricci. Transformer-based source-free domain adaptation. arXiv preprint arXiv:2105.14138, 2021b. Jianfei Yang, Xiangyu Peng, Kai Wang, Zheng Zhu, Jiashi Feng, Lihua Xie, and Yang You. Divide to adapt: Mitigating confirmation bias for domain adaptation of black-box predictors. arXiv preprint arXiv:2205.14467, 2022. H Yao, Yuhong Guo, and Chunsheng Yang. Source-free unsupervised domain adaptation with surrogate data generation. In Proceedings of NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021. 15Published as a conference paper at ICLR 2024 Hao-Wei Yeh, Baoyao Yang, Pong C Yuen, and Tatsuya Harada. Sofa: Source-data-free feature alignment for unsupervised domain adaptation. InProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 474â€“483, 2021. Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. Hu Yu, Jie Huang, Yajing Liu, Qi Zhu, Man Zhou, and Feng Zhao. Source-free domain adaptation for real-world image dehazing. In Proceedings of the 30th ACM International Conference on Multimedia, pages 6645â€“6654, 2022. Haojian Zhang, Yabin Zhang, Kui Jia, and Lei Zhang. Unsupervised domain adaptation of black-box source models. arXiv preprint arXiv:2101.02839, 2021. Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. Advances in Neural Information Processing Systems, 35:38629â€“38642, 2022a. Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan. Adanpc: Exploring non-parametric classifier for test-time adaptation. In International Conference on Machine Learning, pages 41647â€“41676. PMLR, 2023. Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2339â€“2348, 2022b. Bowen Zhao, Chen Chen, and Shu-Tao Xia. Delta: degradation-free fully test-time adaptation. arXiv preprint arXiv:2301.13018, 2023a. Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023b. Chunting Zhou, Xuezhe Ma, Paul Michel, and Graham Neubig. Examining and combating spurious features under distribution shift. In International Conference on Machine Learning, pages 12857â€“ 12867. PMLR, 2021. 16Published as a conference paper at ICLR 2024 Active Test-Time Adaptation: Foundational Analyses and An Algorithm Supplementary Material A B ROADER IMPACTS The field of domain generalization primarily concentrates on enhancing a modelâ€™s generalization abilities by preparing it thoroughly before deployment. However, it is equally important for deep learning applications to have the capacity for real-time adaptation, as no amount of preparation can account for all possible scenarios. Consequently, domain generalization and test-time adaptation are complementary strategies: the former is more weighty and extensive, while the latter is more agile, lightweight and privacy-friendly. This work delves into the development of a real-time model adaptation strategy that can be applied to any pre-trained models, including large language models, to enhance their adaptive capabilities. Our research does not involve any human subjects or dataset releases, nor does it raise any ethical concerns. Since this work does not directly tie to specific applications, we do not foresee any immediate negative societal impacts. Nonetheless, we acknowledge that any technological advancement may carry potential risks, and we encourage the continued assessment of the broader impacts of real-time adaptation methodologies in various contexts. B FAQ & D ISCUSSIONS To facilitate the reviewing process, we summarize the answers to the questions that arose during the discussion of an earlier version of this paper. The major updates of this version are reorganized theoretical studies, incremental clustering details, experimental reorganization, and additional datasets and settings . We include more related field comparisons to distinguish different settings. We also cover the position of this paper in literature and the main claims of this paper. Finally, we will frankly acknowledge the limitations of this paper, explain and justify the scope of coverage, and provide possible future directions. Q1: What is the relationship between the proposed ATTA protocol and stream based active learning (Saran et al., 2023)? A: We would like to discuss the difference between our work and the referenced work. 1. Real-time Training Distinction: Saran et al. (2023) doesnâ€™t operate in real-time capacity. This is evident from their experiments, where their model is trained only after completing a round. In contrast, our work involves training the model post each batch. This positions Saran et al. (2023)â€™s work as an intrinsic active learning technique, while our approach leans towards TTA methods. 2. Continual Training Nuance: Following the point above, Saran et al. (2023) stands out of the scope of continual training. As they mentioned â€˜each time new data are acquired, the ResNet is reset to the ImageNet pre-trained weights before being updatedâ€˜, Saran et al. (2023) starts afresh with each iteration and is out of scope for CF discussions. Contrarily, our model is continuously trained on varying distributions, compelling us to address the CF issue while preserving advantages derived from various stored distributions. 3. Comparative Complexity: Given the aforementioned distinctions, itâ€™s evident that our task presents a greater challenge compared to theirs. In addition, we have included comparisons with stronger active learning settings in Sec. 5.3. Q2: What are the insights from the theoretically foundational analysis? A: 1. It sets a well-defined formulation and grounded theoretical framework for the ATTA setting. 2. While entropy minimizations can cause CF, balancing the learning rate and number of high/low entropy samples is conversely the key solution to both distribution shifts and 17Published as a conference paper at ICLR 2024 CF by corresponding benefits. Though adding low-entropy data is intuitive, it is crucial in that this simple operation can make methods either too conservative or too aggressive without the correct balancing conditions. 3. The studies in Sec. 3.1 directly present a feasible and guaranteed solution for imple- menting ATTA to tackle shifts while avoiding CF. The aligned empirical validations of Sec. 3.2 also instruct the implementation of SimATTA. Q3: In test-time adaptation, one important issue is that the number of testing samples in a batch may be small, which means the sample size m will also be very small. May it affect the theorem and make them become very loose? A: We consider this issue jointly from theoretical and empirical validations. 1. It is true that the theoretical bounds can be loose given a small size of m unlabeled test samples. This situation of the error bound is mathematically ascribed to the quotient between the VC-dimension d of the hypothesis class and m. Under the VC-dimension theory, the ResNet18 model we adopt should have d â‰« m. However, practically we perform fine-tuning on pre-trained models instead of training from scratch, which significantly reduces the scale of parameter update. In this case, an assumption can be established that fine-tuning a model is roughly equivalent to learning a model with a relatively small d (Appx. H). This assumption is potentially underpinned by the empirical alignment of our validation experiments with the theoretical framework (Fig. 1). To this end, experiments indicate thatd and m are practically of similar scale for our settings. This prevents our theoretical bounds from being very loose and meaningless in reality. 2. Regarding cases that our assumption does not apply, this issue would appear inevitable, since it is rigorously inherent in the estimation error of our streaming and varying test distributions. The distribution of a test stream can be hardly monitored when only a limited batch is allowed, which we consider as a limitation of TTA settings. Moreover, this issue directly implies the necessity of using a buffer for unlabeled samples. A good practice is to maintain a relatively comparable sample buffer scale. Q4: What distribution shifts can ATTA solve? A: We would like to follow (but not limited to) the work (Zhao et al., 2023b) to discuss the distribution shifts ATTA can solve. 1. As elucidated in Sec. 3.1 and Sec. 5, ATTA can solve domain generalization shifts. Domain generalization shifts include complex shifts on the joint data distribution P(X, Y), given X as the covariates and Y as the label variable. Since P(X, Y) = P(X)P(Y |X), ATTA can handle covariate shift (P(X)), label shift (P(Y )), and conditional shift (P(Y |X)). The shifts on both covariate and conditional distributions can cover the shift on labels, but they (covariate + conditional shifts) are more complicated than pure label shifts, where only the marginal label distribution changes while the conditional distribution remains. Note that the conditional shifts are generally caused by spurious correlations, where the independent causal mechanism assumption (Pearl, 2009) holds or no concept drifts exist. 2. In our framework, the distribution support of X at different time steps can be different, but we donâ€™t cover the situation where the support of Y changes, i.e., class-incremental problems. Q5: It is unclear how many samples are selected in each minibatch of testing samples. How the total budget is distributed across the whole testing data stream? A: The number of selected samples for each minibatch is decided jointly by the incremental clustering and the cluster centroid number NC (t). Intuitively, this sample selection is a dynamic process, with NC (t) restricting the budget and incremental clustering performing sample selection. For each batch, we increase applicable clustering centroids as a maximum limit, while the exact number of the selected samples is given by the incremental clustering by how many clusters are located in the scope of new distributions. e.g., if the incoming batch does not introduce new data distributions, then we select zero samples even with increased NC (t). In contrast, if the incoming batch contains data located in multiple new distributions, the incremental clustering tends to select more samples than the NC (t) limit, thus forcing to merging of multiple previous clusters into one new cluster. 18Published as a conference paper at ICLR 2024 The incremental clustering is detailed in Sec. 4.2, and NC (t) is naively increased by a constant hyper-parameter k. Therefore, the budget is adaptively distributed according to the data streaming distribution with budgets controlled by k, which is also the reason why we compare methods under a budget limit. Q6: Could compared methods have access to a few ground-truth labels as well? Making other algorithms be able to use the same amount of ground-truth labels randomly will produce fairer comparisons. A: 1. The enhanced TTA setting is exactly the setup we provide to produce fairer comparisons. See Tab. 3 and Tab. 5 for comparison results. 2. ATTA also compares to a stronger setting ADA which can access the whole test datasets multiple times. Table 5: The table demonstrates the comparisons on PACS where all enhanced TTA baselines have 300 budgets to randomly select labeled samples. The training steps of these labeled samples are the same as the original TTA method training steps. For accumulated sample selection, please refer to our ablation studies. Method Domain-wise data stream A VG Random data stream A VG Pâ†’ â†’Aâ†’ â†’Câ†’ â†’S P A C S 1 2 3 4 P A C S Source onlyBN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 TTA Tent (steps=1) N/A 70.07 68.43 64.42 97.72 74.17 72.61 68.92 61.20 62.36 66.59 67.32 98.14 74.37 70.26 66.07Tent (steps=10) N/A 76.27 63.78 49.35 59.46 38.62 48.46 55.03 56.20 53.22 52.55 55.55 58.32 47.56 60.75 58.00EATA N/A 69.53 66.94 61.42 98.56 69.38 66.60 64.83 60.34 59.81 64.38 65.02 98.68 73.78 68.30 59.74CoTTA N/A 66.55 63.14 59.91 90.12 61.67 66.68 67.68 57.26 57.36 63.46 65.64 92.22 71.53 70.44 62.41SAR (steps=1) N/A 66.60 63.78 50.34 98.38 67.87 64.04 49.48 57.21 56.06 56.78 57.14 98.38 68.80 64.59 53.02SAR (steps=10) N/A 69.09 66.55 49.07 96.23 62.50 59.34 46.53 49.76 52.74 48.51 49.06 95.39 57.13 54.61 38.76 Ours (B â‰¤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00 Q7: What is the position of ATTA? A: Comparisons with different settings are challenging. In this work, the design of our experiments (Sec. 5) is to overcome this challenge by comparing both weaker settings and stronger settings. While the significant performance over weaker settings renders the necessity of extra information, the comparable performance with stronger settings provides the potential to relax restricted requirements. Intuitively, ATTA is the most cost-effective option in the consideration of both efficiency and effectiveness. We further provide the following ATTA summary: ATTA, which incorporates active learning in FTTA, is the light, real-time, source-free, widely applicable setting to achieve high generalization performances for test-time adaptation. 1. Necessity: From the causality perspective, new information is necessary (Lin et al., 2022; Pearl, 2009; Peters et al., 2017) to attain generalizable over distribution shifts which are insurmountable within the current TTA framework. 2. Effectiveness: Compared to FTTA methods, ATTA produces substantially better perfor- mances, on-par with the costly active domain adaptation (ADA) methods as shown in Table 3 in the paper. 3. Efficiency: Relative to ADA methods, ATTA possesses superior efficiency, similar to general FTTA methods, as shown in Tab. 3. 4. Applicability: ATTA is a model-agnostic setting. (1) Compared to domain generalization methods, ATTA do not require re-training and has the potential to apply to any pre-trained models. One interesting future direction is designing ATTA methods for large language models (LLMs), where re-trainings are extremely expensive and source data may be in- accessible. (2) Compared to FTTA methods, ATTA can protect model parameters from corrupting while learning new distributions by fine-tuning pre-trained models, rendering it more feasible and practical. In comparison with existing works, ATTA is motivated to mitigate the limitations of previous settings: 1. FTTA: Limited generalization performance. 19Published as a conference paper at ICLR 2024 2. TTT: Not source-free; limited generalization performance. 3. ADA & domain adaptation/generalization: Expensive re-trainings; limited applicability to pre-trained models. 4. Online active learning: It does not maintain and protect adaptation performances for multiple distributions in one model and does not consider the CF problem. Q8: What is the potential practical utility of ATTA? A: 1. Empirically, our method can generally finish a round of sample selection/training of 100 frames in 5s, i.e., 20 frames per sec, which is more than enough to handle multiple practical situations. Experiments on time complexity are provided in Tab. 3, where SimATTA has comparable time efficiency. 2. As a case analysis, the autopilot system (Hu et al., 2023; Chen et al., 2022a) presents an application scenario requiring high-speed low-latency adaptations, while these adaptations are largely underexplored. When entering an unknown environment, e.g., a construction section, a system of ATTA setting can require the driver to take over the wheel. During the period of manual operation when the driver is handling the wheel, steering signals are generated, and the in-car system quickly adaptations. The system doesnâ€™t need to record 60 frames per second, since only the key steering operations and the corresponding dash cam frames are necessary, which can be handled by ATTA algorithms processing at 20 frames per sec. In this case, the human annotations are necessary and indirect. ATTA makes use of this information and adapts in the short term instead of collecting videos and having a long-round fine-tuning (Schafer et al., 2018). 3. In addition, many scenarios applicable for ATTA are less speed-demanding than the case above. One example is a personalized chatbot that subtly prompts and gathers user labels during user interaction. In a home decoration setting, applications can request that users scan a few crucial areas to ensure effective adaptation. Social robots (Mavrogiannis et al., 2023), e.g., vacuum robots, often require users to label critical obstacles theyâ€™ve encountered. 4. Compared with ADA, ATTA stands out as the tailored solution for the above scenarios. It does not require intensive retraining or server-dependent fine-tuning, offering both speed and computational efficiency. Meanwhile, akin to other TTA methods, ATTA also ensures user privacy. While it might marginally exceed the cost of standard TTA methods, the superior generalization ability makes it a compelling choice and justifies the additional expense. Q9: What can be covered by this paper? A: This paper endeavors to establish the foundational framework for a novel setting referred to as ATTA. We target (1) positioning the ATTA setting, (2) solving the two major and basic challenges of ATTA,i.e., the mitigation of distribution shifts and the avoidance of catastrophic forgetting (CF). We achieve the first goal by building the problem formulation and analyses, and further providing extensive qualitative and well-organized experimental comparisons with TTA, enhanced TTA, and ADA settings. These efforts position ATTA as the most cost-effective option between TTA and ADA, where ATTA inherits the efficiency of TTA and the effectiveness of ADA. With our theoretical analyses and the consistent algorithm design, we validate the success of our second goal through significant empirical performances. Q10: What are not covered by this paper? A: Constructing a new setting involves multifaceted complexities. Although there are various potential applications discussed above including scaling this setting up for large models and datasets, we cannot cover them in this single piece of work. There are three main reasons. First, the topics covered by a single paper are limited. Formally establishing ATTA setting and addressing its major challenges of ATTA takes precedence over exploring practical applications. Secondly, given the interrelations between ATTA and other settings, our experimental investigations are predominantly comparative, utilizing the most representative datasets from TTA and domain adaptation to showcase persuasive results. Thirdly, many practical applications necessitate task-specific configurations, rendering them unsuitable for establishing a universal learning setting. While the current focus is on laying down the foundational aspects of ATTA, the exploration of more specialized applications remains a prospective avenue for future work in the ATTA domain. 20Published as a conference paper at ICLR 2024 C R ELATED WORKS The development of deep learning witnesses various applications (He et al., 2016; Gui et al., 2020). To tackle OOD problem, various domain generalization works emerge (Krueger et al., 2021; Sagawa et al., 2019). C.1 U NSUPERVISED DOMAIN ADAPTATION Unsupervised Domain Adaptation (UDA) (Pan et al., 2010; Patel et al., 2015; Wilson and Cook, 2020; Wang and Deng, 2018) aims at mitigating distribution shifts between a source domain and a target domain, given labeled source domain samples and unlabeled target samples. UDA methods generally rely on feature alignment techniques to eliminate distribution shifts by aligning feature distributions between source and target domains. Typical feature alignment techniques include discrepancy minimization (Long et al., 2015; Sun and Saenko, 2016; Kang et al., 2019) and adversarial training (Ganin and Lempitsky, 2015; Tsai et al., 2018; Ajakan et al., 2014; Ganin et al., 2016; Tzeng et al., 2015; 2017). Nevertheless, alignments are normally not guaranteed to be correct, leading to the alignment distortion problem as noted by Ning et al. (2021). Source-free Unsupervised Domain Adaptation (SFUDA) (Fang et al., 2022; Liu et al., 2021b) algorithms aim to adapt a pre-trained model to unlabeled target domain samples without access to source samples. Based on whether the algorithm can access model parameters, these algorithms are categorized into white-box and black-box methods. White-box SFUDA typically considers data recovery (generation) and fine-tuning methods. The former focuses on recovering source- like data (Ding et al., 2022; Yao et al., 2021), e.g., training a Generative Adversarial Network (GAN) (Kurmi et al., 2021; Li et al., 2020), while the latter employs various techniques (Mao et al., 2021), such as knowledge distillation (Chen et al., 2022b; Liu and Yuan, 2022; Yang et al., 2021b; Yu et al., 2022), statistics-based domain alignment (Ishii and Sugiyama, 2021; Liu et al., 2021a; Fan et al., 2022; Eastwood et al., 2021), contrastive learning (Huang et al., 2021; Wang et al., 2022b), and uncertainty-based adaptation (Gawlikowski et al., 2021; Fleuret et al., 2021; Chen et al., 2021; Li et al., 2021b). Black-box SFUDA cannot access model parameters and often relies on self-supervised knowledge distillation (Liang et al., 2022; 2021), pseudo-label denoising (Zhang et al., 2021; Yang et al., 2022), or generative distribution alignment (Yeh et al., 2021; Yang et al., 2021a). C.2 T EST-TIME ADAPTATION Test-time Adaptation (TTA), especially Fully Test-time Adaptation (FTTA) algorithms (Wang et al., 2021; Iwasawa and Matsuo, 2021; Karani et al., 2021; Nado et al., 2020; Schneider et al., 2020; Wang et al., 2022a; Zhao et al., 2023a; Niu et al., 2022; Zhang et al., 2022a; Niu et al., 2023; You et al., 2021; Zhang et al., 2022b), can be considered as realistic and lightweight methods for domain adaptation. Built upon black-box SFUDA, FTTA algorithms eliminate the requirement of a pre-collected target dataset and the corresponding training phase. Instead, they can only access an unlabeled data stream and apply real-time adaptation and training. In addition to FTTA, Test-time Training (TTT) (Sun et al., 2020; Liu et al., 2021c) often relies on appending the original network with a self-supervised task. TTT methods require retraining on the source dataset to transfer information through the self-supervised task. Although they do not access the source dataset during the test-time adaptation phase, TTT algorithms are not off-the-shelf source-free methods. TTA is a promising and critical direction for real-world applications, but current entropy minimization-based methods can be primarily considered as feature calibrations that require high-quality pseudo-labels. This requirement, however, can be easily violated under larger distribution shifts. Current TTA algorithms, inheriting UDA drawbacks, cannot promise good feature calibration results, which can be detrimental in real-world deployments. For instance, entropy minimization on wrongly predicted target domain samples with relatively low entropy can only exacerbate spurious correla- tions (Chen et al., 2020). Without extra information, this problem may be analogous to applying causal inference without intervened distributions, which is intrinsically unsolvable (Peters et al., 2016; Pearl, 2009). This paper aims to mitigate this issue with minimal labeled target domain samples. To minimize the cost, we tailor active learning techniques for TTA settings. It is worth noting that a recent work AdaNPC (Zhang et al., 2023) is essentially a domain gener- alization method with a TTA phase attached, while our ATTA is built based on the FTTA setting. Specifically, Current FTTA methods and our work cannot access the source domain. In contrast, 21Published as a conference paper at ICLR 2024 AdaNPC accesses source data to build its memory bank, circumventing the catastrophic forgetting problem. Furthermore, AdaNPC requires multiple source domains and training before performing TTA. Thus AdaNPC uses additional information on domain labels and retraining resources for its memory bank, undermining the merits of FTTA. Regarding theoretical bounds, their target domain is bounded by source domain error and model estimations (in big-O expression), while we consider active sample learning and time variables for varying test distributions. C.3 C ONTINUAL DOMAIN ADAPTATION Many domain adaptation methods focus on improving target domain performance, neglecting the performance on the source domain, which leads to the CF problem (Kemker et al., 2018; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lopez-Paz and Ranzato, 2017; De Lange et al., 2021; Wang et al., 2022a; Niu et al., 2022). This issue arises when a neural network, after being trained on a sequence of domains, experiences a significant degradation in its performance on previously learned domains as it continues to learn new domains. Continual learning, also known as lifelong learning, addresses this problem. Recent continual domain adaptation methods have made significant progress by employing gradient regularization, random parameter restoration, buffer sample mixture, and more. Although the CF problem is proposed in the continual learning field, it can occur in any source-free OOD settings since the degradation caused by CF is attributed to the networkâ€™s parameters being updated to optimize performance on new domains, which may interfere with the representations learned for previous domains. C.4 A CTIVE DOMAIN ADAPTATION Active Domain Adaptation (ADA) (Prabhu et al., 2021; Ning et al., 2021; Su et al., 2020; Ma et al., 2021; Xie et al., 2022) extends semi-supervised domain adaptation with active learning strate- gies (Cohn et al., 1996; Settles, 2009), aiming to maximize target domain performance with a limited annotation budget. Therefore, the key challenge of active learning algorithms is selecting the most informative unlabeled data in target domains (Kapoor et al., 2007). Sample selection strategies are of- ten based on uncertainty (Lewis and Catlett, 1994; Scheffer et al., 2001), diversity (Jain and Grauman, 2016; Hoi et al., 2009), representativeness (Xu et al., 2003), expected error minimization (Vijaya- narasimhan and Kapoor, 2010), etc. Among these methods, uncertainty and diversity-based methods are simple and computationally efficient, making them the most suitable choices to tailor for TTA settings. Adapting these strategies is non-trivial because, compared to typical active domain adaptation, our proposed Active Test-time Adaptation (ATTA) setting does not provide access to source data, model parameters, or pre-collected target samples. This requirement demands that our active sample selection algorithm select samples for annotation during data streaming. Consequently, this active sampling selection process is non-regrettable, i.e., we can only meet every sample once in a short period. To avoid possible confusion, compared to the recent Source-free Active Domain Adaptation (SFADA) method SALAD (Kothandaraman et al., 2023), we do not require access to model parameter gradients, training additional neural networks, or pre-collected target datasets. Therefore, our ATTA setting is quite different, much lighter, and more realistic than ADA and SFADA. C.5 A CTIVE ONLINE LEARNING The most related branch of active online learning (AOL) (Cacciarelli and Kulahci, 2023) is active online learning on drifting data stream (Zhou et al., 2021; Baier et al., 2021; Li et al., 2021a). Generally, these methods include two components, namely, detection and adaptation. Compared with ATTA, there are several distinctions. First, this line of studies largely focuses on the distribution shift detection problem, while ATTA focuses on multi-domain adaptations. Second, AOL on drifting data stream aims to detect and adapt to one current distribution in the stream, without considering preserving the adaptation abilities of multiple past distributions by maintaining and fine-tuning the original pre-trained models. In contrast, ATTAâ€™s goal is to achieve the OOD generalization optimums adaptable across multiple source and target distributions, leading to the consideration of CF problems. Third, while AOL requires one-by-one data input and discard, ATTA maintains a buffer for incoming data before selection decisions. This is because ATTA targets maintaining the original model without corrupting and replacing it, such that making statistically meaningful and high-quality decisions is 22Published as a conference paper at ICLR 2024 critical for ATTA. In contrast, AOL allows resetting and retraining new models, whose target is more lean to cost saving and one-by-one manner. D F URTHER THEORETICAL STUDIES In this section, we refine the theoretical studies with supplement analysis and further results. We use the H-divergence and Hâˆ†H-distance definitions following (Ben-David et al., 2010). Definition 2 (H-divergence). For a function class H and two distributions D1 and D2 over a domain X, the H-divergence between D1 and D2 is defined as dH(D1, D2) = sup hâˆˆH |Pxâˆ¼D1 [h(x) = 1] âˆ’ Pxâˆ¼D2 [h(x) = 1]|. The Hâˆ†H-distance is defined base on H-divergence. We use the Hâˆ†H-distance definition follow- ing (Ben-David et al., 2010). Definition 3 (Hâˆ†H-distance). For two distributions D1 and D2 over a domain X and a hypothesis class H, the Hâˆ†H-distance between D1 and D2 w.r.t. H is defined as dHâˆ†H(D1, D2) = sup h,hâ€²âˆˆH Pxâˆ¼D1 [h(x) Ì¸= hâ€²(x)] + Pxâˆ¼D2 [h(x) Ì¸= hâ€²(x)]. (9) The Hâˆ†H-distance essentially provides a measure to quantify the distribution shift between two distributions. It measures the maximum difference of the disagreement between two hypotheses in H for two distributions, providing a metrics to quantify the distribution shift between D1 and D2. H-divergence and Hâˆ†H-distance have the advantage that they can be applied between datasets, i.e., estimated from finite samples. Specifically, let S1, S2 be unlabeled samples of size m sampled from D1 and D2; then we have estimated Hâˆ†H-distance Ë†dH(S1, S2). This estimation can be bounded based on Theorem 3.4 of Kifer et al. (2004), which we state here for completeness. Theorem 5. Let A be a collection of subsets of some domain measure space, and assume that the VC-dimension is some finite d. Let P1 and P2 be probability distributions over that domain and S1, S2 finite samples of sizes m1, m2 drawn i.i.d. according P1, P2 respectively. Then Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16, (10) where Pm1+m2 is the m1 + m2â€™th power of P - the probability that P induces over the choice of samples. Theorem 5 bounds the probability for relativized discrepancy, and its applications in below lemmas and Theorem 1 help us bound the quantified distribution shifts between domains. The probability, according to a distribution D, that an estimated hypothesis h disagrees with the true labeling function g : X â†’ {0, 1} is defined as Ïµ(h(t), g) = E(x)âˆ¼D[|h(x, t) âˆ’ g(x)|], which we also refer to as the error or risk Ïµ(h(t)). While the source domain dataset is inaccessible under ATTA settings, we consider the existence of the source dataset DS for the purpose of accurate theoretical analysis. Thus, we initialize Dtr(0) as DS, i.e., Dtr(0) = DS. For every time step t, the test and training data can be expressed as Ute(t) and Dtr(t) = DS âˆª Dte(1) âˆª Dte(2) âˆª Â·Â·Â· âˆªDte(t). (11) We use N to denote the total number of samples in Dtr(t) and Î» = (Î»0, Î»1, Â·Â·Â· , Î»t) to represent the ratio of sample numbers in each component subset. In particular, we have |DS| |Dtr(t)| = Î»0, |Dte(1)| |Dtr(t)| = Î»1, Â·Â·Â· , |Dte(t)| |Dtr(t)| = Î»t, (12) where Pt i=0 Î»i = 1. Therefore, at time step t, the model has been trained on labeled data Dtr(t), which contains t + 1 components consisting of a combination of data from the source domain and multiple test-time domains. For each domain the model encounters, DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), let Ïµj(h(t)) denote the error of hypothesis h at time t on the jth domain. Specifically, Ïµ0(h(t)) = ÏµS(h(t)) represents the error of h(t) on the source data DS, and Ïµj(h(t)) for j â‰¥ 1 denotes the error of h(t) on test data Ute(j). Our optimization minimizes a convex combination of training error over the labeled samples from all domains. Formally, given the vector w = (w0, w1, Â·Â·Â· , wt) of domain error 23Published as a conference paper at ICLR 2024 weights with Pt j=0 wj = 1 and the sample number from each component Nj = Î»jN, we minimize the empirical weighted error of h(t) as Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Nj X Nj |h(x, t) âˆ’ g(x)|. (13) Note that w, Î» and N are also functions of t, which we omit for simplicity. We now establish two lemmas as the preliminary for Theorem 1. In the following lemma, we bound the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)). Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. In the following lemma, we provide an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. The proofs for both lemmas are provided in Appx. E. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Lemma 6 bounds the difference between the weighted error Ïµw(h(t)) and the domain error Ïµj(h(t)), which is majorly influenced by the estimatedHâˆ†H-distance and the quality of discrepancy estimation. During the ATTA process, the streaming test data can form multiple domains and distributions. However, if we consider all data during the test phase as a single test domain,i.e., St i=1 Ute(i), we can simplify Lemma 6 to obtain an upper bound for the test error ÏµT as |Ïµw(h(t)) âˆ’ ÏµT (h(t))| â‰¤w0 ï£« ï£­1 2 Ë†dHâˆ†H(S0, ST ) + 2 s 2d log(2m) + log 2 Î´ m + Î³ ï£¶ ï£¸, (14) where Î³ = min hâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}, and ST is sampled from St i=1 Ute(i). To understand Lamma 7, we need to understand Hoeffdingâ€™s Inequality, which we state below as a Proposition for completeness. Proposition 8 (Hoeffdingâ€™s Inequality). Let X be a set, D1, . . . , Dt be probability distributions on X, and f1, . . . , ft be real-valued functions on X such that fi : X â†’ [ai, bi] for i = 1, . . . , t. Then for any Ïµ >0, P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! (15) where E[fi(x)] is the expected value of fi(x). Lamma 7 provides an upper bound on the difference between the true and empirical weighted errors Ïµw(h(t)) and Ë†Ïµw(h(t)). Thus, as wj deviates from Î»j, the feasible approximation Ë†Ïµw(h(t)) with a finite number of labeled samples becomes less reliable. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Theorem 1 essentially bounds the performance of ATTA on the source and each test domains. The adaptation performance on a test domain is majorly 24Published as a conference paper at ICLR 2024 bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, Ë†dHâˆ†H(Si, Sj), and Î³i, respectively. The ideal joint hypothesis error Î³i gauges the inherent adaptability between domains. If we consider the multiple data distributions during the test phase as a single test domain, i.e., St i=1 Ute(i), Theorem 1 can be reduced into bounds for the source domain error ÏµS and test domain error ÏµT . With the optimal test/source hypothesis hâˆ— T (t) = arg min hâˆˆH ÏµT (h(t)) and hâˆ— S(t) = arg minhâˆˆH ÏµS(h(t)), |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16a) |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤(1 âˆ’ w0)A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (16b) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (16.a), with approximately B = c1 p d/N, the optimal value wâˆ— 0 to tighten the test error bound is a function of Î»0 and A: wâˆ— 0 = Î»0 âˆ’ s A2N c2 1d âˆ’ A2NÎ»0(1 âˆ’ Î»0), for Î» 0 â‰¥ 1 âˆ’ d A2N , (17) where c1 is a constant. Note that Î»0 â‰¥ 1 âˆ’ d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. When the budget is sufficiently large or the source data amount is not sufficiently large compared to the distribution shift A, the optimal wâˆ— 0 for the test error bound is wâˆ— 0 = 0, i.e., using no source data since possible error reduction from the data addition is always less than the error increase caused by large divergence between the source data and the test data. Theorem 2 offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Following Theorem 1, when no active learning is included during TTA,i.e., w0 = Î»0 = 1, the upper boundw0A+ q w2 0 Î»0 + (1âˆ’w0)2 1âˆ’Î»0 B â‰¥ A+B; when enabling ATTA, withw0 = Î»0 Ì¸= 1, we can easily achieve an upper bound w0A + B < A+ B. Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. Entropy quantifies the amount of information contained in a probability distribution. In the context of a classification model, lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction. When a model assigns low entropy to a sample, this high confidence can be interpreted as the sample being well-aligned or fitting closely with the modelâ€™s learned distribution. In other words, the model â€œrecognizesâ€ the sample as being similar to those it was trained on, hence the high confidence in its prediction. While entropy is not a direct measure of distributional distance, it can be used as an indicator of how closely a sample aligns with the modelâ€™s learned distribution. This interpretation is more about model confidence and the implied proximity rather than a strict mathematical measure of distributional distance. The pre-trained model is well-trained on abundant source domain data, and thus the model distribution is approximately the source distribution. Selecting low-entropy samples using essentially provides an estimate of sampling from the source dataset. Thus, DÏ•,S(t), based on well-aligned with the modelâ€™s learned distribution is an approximation of DS. When we consider the CF problem and feasibly include the source-like dataset DÏ•,S(t) into the ATTA training data in place of the inaccessible DS in Eq. (11), we can also derive bounds on the domain errors under this practical ATTA setting when minimizing the empirical weighted errorÏµâ€² w(h(t)) using the hypothesis h at time t, similar to Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domainsDÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is 25Published as a conference paper at ICLR 2024 N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµâ€² w(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Other derived results following Theorem 1 also apply for this practical ATTA setting. Further empirical validations for our theoretical results are provided in Appx. H. E P ROOFS This section presents comprehensive proofs for all the lemmas, theorems, and corollaries mentioned in this paper, along with the derivation of key intermediate results. Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any Î´ âˆˆ (0, 1), for every h âˆˆ Hminimizing Ïµw(h(t)) on Dtr(t), we have |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. Proof. First we prove that given unlabeled samples of size m S1, S2 sampled from two distributions D1 and D2, we have dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (18) We start with Theorem 3.4 of Kifer et al. (2004): Pm1+m2 [|Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| > Ïµ] â‰¤ (2m)deâˆ’m1Ïµ2/16 + (2m)deâˆ’m2Ïµ2/16. (19) In Eq. 19, â€™dâ€™ is the VC-dimension of a collection of subsets of some domain measure space A, while in our case, d is the VC-dimension of hypothesis space H. Following (Ben-David et al., 2010), the Hâˆ†H space is the set of disagreements between every two hypotheses inH, which can be represented as a linear threshold network of depth 2 with 2 hidden units. Therefore, the VC-dimension of Hâˆ†H is at most twice the VC-dimension of H, and the VC-dimension of our domain measure space is 2d for Eq. 19 to hold. Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2m)2deâˆ’m1Ïµ2/16 + (2m)2deâˆ’m2Ïµ2/16. We rewrite the inequality as Î´ (2m)2d = eâˆ’m1Ïµ2/16 + eâˆ’m2Ïµ2/16; taking the logarithm of both sides, we get log Î´ (2m)2d = âˆ’m1 Ïµ2 16 + log(1 +eâˆ’(m1âˆ’m2) Ïµ2 16 ). 26Published as a conference paper at ICLR 2024 Assuming m1 = m2 = m and defining a = Ïµ2 16 , we have log Î´ (2m)2d = âˆ’ma + log 2; rearranging the equation, we then get ma + log(Î´/2) = 2d log(2m). Now, we can solve for a: a = 2d log(2m) + log 2 Î´ m . Recall that a = Ïµ2 16 , so we get: Ïµ = 4âˆša Ïµ = 4 s 2d log(2m) + log 2 Î´ m . With probability of at least 1 âˆ’ Î´, we have |Ï•A(S1, S2) âˆ’ Ï•A(P1, P2)| â‰¤4 s 2d log(2m) + log 2 Î´ m ; therefore, dHâˆ†H(D1, D2) â‰¤ Ë†dHâˆ†H(S1, S2) + 4 s 2d log(2m) + log 2 Î´ m . (20) Now we prove Lemma 6. We use the triangle inequality for classification error in the derivation. For the domain error of hypothesis h at time t on the jth domain Ïµj(h(t)), given the definition of Ïµw(h(t)), |Ïµw(h(t)) âˆ’ Ïµj(h(t))| = | tX i=0 wiÏµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi|Ïµi(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(|Ïµi(h(t)) âˆ’ Ïµi(h(t), hâˆ— i (t))| + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + |Ïµj(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t))|) â‰¤ tX i=0 wi(Ïµi(hâˆ— i (t)) + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| + Ïµj(hâˆ— i (t))) â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|), where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. By the definition of Hâˆ†H-distance and our proved Eq. 20, |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))| â‰¤sup h,hâ€²âˆˆH |Ïµi(h(t), hâ€²(t)) âˆ’ Ïµj(h(t), hâ€²(t))| = sup h,hâ€²âˆˆH Pxâˆ¼Di[h(x) Ì¸= hâ€²(x)] + Pxâˆ¼Dj [h(x) Ì¸= hâ€²(x)] = 1 2dHâˆ†H(Di, Dj) â‰¤ 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m , 27Published as a conference paper at ICLR 2024 where Di, Dj denote the ith and jth domain. Therefore, |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0 wi(Î³i + |Ïµi(h(t), hâˆ— i (t)) âˆ’ Ïµj(h(t), hâˆ— i (t))|) â‰¤ tX i=0 wi(Î³i + 1 2dHâˆ†H(Di, Dj)) â‰¤ tX i=0 wi(Î³i + 1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m ). Since Ïµi(h(t)) âˆ’ Ïµj(h(t)) = 0 when i = j, we derive |Ïµw(h(t)) âˆ’ Ïµj(h(t))| â‰¤ tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸, with probability of at least 1 âˆ’ Î´, where Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. This completes the proof. Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS âˆª Dte(1) âˆª Â·Â·Â· âˆªDte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is Î»j, then for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Proof. We apply Hoeffdingâ€™s Inequality in our proof: P  \f\f\f\f\f 1 t tX i=1 fi(x) âˆ’ 1 t tX i=1 Exâˆ¼Di[fi(x)] \f\f\f\f\f â‰¥ Ïµ ! â‰¤ 2 exp   âˆ’ 2t2Ïµ2 Pt i=1(bi âˆ’ ai)2 ! . (21) In the jth domain, there are Î»jN samples. With the true labeling function g(x), for each of the Î»jN samples x, let there be a real-valued function fi(x) fi(x) = wj Î»j |h(x, t) âˆ’ g(x)|, where fi(x) âˆˆ [0, wj Î»j ]. Incorporating all the domains, we get Ë†Ïµw(h(t)) = tX j=0 wjË†Ïµj(h(t)) = tX j=0 wj Î»jN X Î»jN |h(x, t) âˆ’ g(x)| = 1 N tX j=0 Î»jNX i=1 fi(x), which corresponds to the 1 t Pt i=1 fi(x) part in Hoeffdingâ€™s Inequality. Due to the linearity of expectations, we can calculate the sum of expectations as 1 N tX j=0 Î»jNX i=1 E[fi(x)] = 1 N ( tX j=0 Î»jN wj Î»j Ïµj(h(t))) = tX j=0 wjÏµj(h(t)) = Ïµw(h(t)), which corresponds to the 1 t Pt i=1 Exâˆ¼Di[fi(x)] part in Hoeffdingâ€™s Inequality. Therefore, we can apply Hoeffdingâ€™s Inequality as P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ 2 exp   âˆ’2N2Ïµ2/( NX i=0 range2(fi(x))) ! = 2 exp   âˆ’2N2Ïµ2/( tX j=0 Î»jN(wj Î»j )2) ! = 2 exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . This completes the proof. 28Published as a conference paper at ICLR 2024 Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is Î»i. If Ë†h(t) âˆˆ Hminimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), and hâˆ— j (t) = arg minhâˆˆH Ïµj(h(t)) is the optimal hypothesis on the jth domain, then for any Î´ âˆˆ (0, 1), with probability of at least 1 âˆ’ Î´, we have Ïµj(Ë†h(t)) â‰¤ Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k (k >0), assuming kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H (D(kâ€²), Ute(t + k)) â‰¤ Î´D, where 0 â‰¤ Î´D â‰ª +âˆž, then âˆ€Î´, with probability of at least 1 âˆ’ Î´, we have Ïµt+k(Ë†h(t)) â‰¤ Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. Proof. First we prove that for any Î´ âˆˆ (0, 1) and h âˆˆ H, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (22) We apply Theorem 3.2 of Kifer et al. (2004) and Lemma 7, P[|Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¥Ïµ] â‰¤ (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . Given Î´ âˆˆ (0, 1), we set the upper bound of the inequality to Î´, and solve for Ïµ: Î´ = (2N)d exp   âˆ’2NÏµ2/( tX j=0 w2 j Î»j ) ! . We rewrite the inequality as Î´ (2N)d = e âˆ’2NÏµ2/(Pt j=0 w2 j Î»j ) , taking the logarithm of both sides, we get log Î´ (2N)d = âˆ’2NÏµ2/( tX j=0 w2 j Î»j ). Rearranging the equation, we then get Ïµ2 = ( tX j=0 w2 j Î»j )d log(2N) âˆ’ log(Î´) 2N . Therefore, with probability of at least 1 âˆ’ Î´, we have |Ïµw(h(t)) âˆ’ Ë†Ïµw(h(t))| â‰¤ vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 . (23) 29Published as a conference paper at ICLR 2024 Based on Eq. 23, we now prove Theorem 1. For the empirical domain error of hypothesis h at time t on the jth domain Ïµj(Ë†h(t)), applying Lemma 6, Eq. 23, and the definition of hâˆ— j (t), we get Ïµj(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— j (t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµj(hâˆ— j (t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµj(hâˆ— j (t)) + 2 tX i=0,iÌ¸=j wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Sj) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + Ïµj(h(t))}. For future test domains j = t + k where k > 0, we have the assumption that kâ€² = argminkâ€²âˆˆ{0,1,...t} dHâˆ†H(D(kâ€²), Ute(t + k)) and min dHâˆ†H(D(kâ€²), Ute(t + k)) â‰¤ Î´D. Here, we slightly abuse the notation D(kâ€²) to represent Ds if kâ€² = 0 and Ute(kâ€²) if kâ€² > 0. Then we get Ïµt+k(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, St+k) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2( Ë†dHâˆ†H(Si, Skâ€² ) + Ë†dHâˆ†H(Skâ€² , St+k)) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 30Published as a conference paper at ICLR 2024 â‰¤ Ë†Ïµw(hâˆ— t+k(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµt+k(hâˆ— t+k(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, Skâ€² ) + 1 2Î´D + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ = Ïµt+k(hâˆ— t+k(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, Skâ€² ) + 4 s 2d log(2m) + log 2 Î´ m + Î´D + 2Î³i ï£¶ ï£¸ + 2C. with probability of at least 1âˆ’Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 , Î³i = minhâˆˆH{Ïµi(h(t))+ Ïµt+k(h(t))}, and 0 â‰¤ Î´D â‰ª +âˆž. This completes the proof. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), Â·Â·Â· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if Ë†h(t) âˆˆ H minimizes the empirical weighted error Ë†Ïµw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when no active learning is included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, then for any Î» Ì¸= Î»â€², there exists w s.t. EBT (w, Î», N, t) < EBT (wâ€², Î»â€², N, t). (24) Proof. From Theorem 1, we can derive the bound for the test error where the test-time data are considered as a single test domain: |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤EBT (w, Î», N, t) = w0( Ë†dHâˆ†H(S0, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N ; and we simplify the above equation as |ÏµT (Ë†h(t)) âˆ’ ÏµT (hâˆ— T (t))| â‰¤w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B, (25) where the distribution divergence termA = Ë†dHâˆ†H(S0, ST )+4 q 2d log(2m)+log 2 Î´ m +2Î³, the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , ST is sampled from St i=1 Ute(i), and Î³ = minhâˆˆH{Ïµ0(h(t)) + ÏµT (h(t))}. Since we have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (26) 31Published as a conference paper at ICLR 2024 where Formula 26 obtains the minimum value if and only if w0 = Î»0; when enabling ATTA with any Î»0 Ì¸= 1, we can get EBT (w, Î», N, t) = w0A + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¥ w0A + B, (27) where the minimum value EBT (w, Î», N, t)min = w0A + B can be obtained with condition w0 = Î»0 Ì¸= 1. When no active learning is included, i.e., for weight and sample ratio vectors wâ€² and Î»â€², wâ€² 0 = Î»â€² 0 = 1 and wâ€² i = Î»â€² i = 0 for i â‰¥ 1, we have EBT (wâ€², Î»â€², N, t) = wâ€² 0A + s wâ€²2 0 Î»â€² 0 + (1 âˆ’ wâ€² 0)2 1 âˆ’ Î»â€² 0 B = A + B. (28) Since for EBT (w, Î», N, t)min = w0A + B, w0 < 1 and A, B >0 hold, we derive EBT (w, Î», N, t)min = w0A + B < A+ B = EBT (wâ€², Î»â€², N, t). (29) This completes the proof. Corollary 3. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If Ë†h(t) âˆˆ Hminimizes Ë†Ïµâ€² w(h(t)) while other conditions remain identical to Theorem 1, then ÏµS(Ë†h(t)) â‰¤ ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C, with probability at least 1 âˆ’ Î´, where C follows Theorem 1 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. Proof. For the empirical source error on DS of hypothesis h at time t, similar to Theorem 1, we apply Lemma 6, Eq. 23 to get ÏµS(Ë†h(t)) â‰¤ Ïµw(Ë†h(t)) + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(Ë†h(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ë†Ïµw(hâˆ— S(t)) + vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ Ïµw(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ â‰¤ ÏµS(hâˆ— S(t)) + 2 vuut  tX i=0 w2 i Î»i !\u0012d log(2N) âˆ’ log(Î´) 2N \u0013 + 2 tX i=0 wi ï£« ï£­1 2 Ë†dHâˆ†H(Si, SS) + 2 s 2d log(2m) + log 2 Î´ m + Î³i ï£¶ ï£¸ 32Published as a conference paper at ICLR 2024 = ÏµS(hâˆ— S(t)) + tX i=0 wi ï£« ï£­Ë†dHâˆ†H(Si, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³i ï£¶ ï£¸ + 2C with probability of at least 1 âˆ’ Î´, where C = r\u0010Pt i=0 w2 i Î»i \u0011\u0010 d log(2N)âˆ’log(Î´) 2N \u0011 and Î³i = minhâˆˆH{Ïµi(h(t)) + ÏµS(h(t))}. This completes the proof. Corollary 4. At time step t, for ATTA data domains DÏ•,S(t), Ute(1), Ute(2), Â·Â·Â· , Ute(t), suppose that Ë†h(t) âˆˆ Hminimizes Ë†Ïµwâ€²(h(t)) under identical conditions to Theorem 2. Letâ€™s denote the source error upper bound with |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t). Let wâ€² and Î»â€² be the weight and sample ratio vectors when DÏ•,S(t) is not included, i.e., wâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0 . If Ë†dHâˆ†H(DS, DÏ•,S(t)) < Ë†dHâˆ†H(DS, St i=1 Ute(i)), then for any Î» Ì¸= Î»â€², there exists w s.t. EBS(w, Î», N, t) < EBS(wâ€², Î»â€², N, t). (30) Proof. From Theorem 1, considering the test-time data as a single test domain, we can derive the bound for the source error on DS: |ÏµS(Ë†h(t)) âˆ’ ÏµS(hâˆ— S(t))| â‰¤EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + 2 s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 r d log(2N) âˆ’ log(Î´) 2N , where ST is sampled fromSt i=1 Ute(i), Î³ = minhâˆˆH{Ïµ0(h(t))+ÏµS(h(t))}, and Î³â€² = minhâˆˆH{ÏµT (h(t))+ ÏµS(h(t))}. We have s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 = s (w0 âˆ’ Î»0)2 Î»0(1 âˆ’ Î»0) + 1 â‰¥ 1, (31) where the equality and the minimum value are obtained if and only if w0 = Î»0. When DÏ•,S(t) is not included,i.e., with the weight and sample ratio vectorswâ€² and Î»â€² s.t. wâ€² 0 = Î»â€² 0 = 0, using the empirical gap term B = 2 q d log(2N)âˆ’log(Î´) 2N , we have EBS(wâ€², Î»â€², N, t) = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B = Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B. When DÏ•,S(t) is included with Î»0 Ì¸= 0, EBS(w, Î», N, t) = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + s w2 0 Î»0 + (1 âˆ’ w0)2 1 âˆ’ Î»0 B â‰¤ w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B, 33Published as a conference paper at ICLR 2024 Algorithm 2 INCREMENTAL CLUSTERING (IC) Require: Given previously selected anchors, new unlabeled samples, and the cluster budget as Danc, Unew, and NC . Global anchor weights wanc = (wanc 1 , . . . , wanc |Danc|)âŠ¤. 1: For simplicity, we consider anchor weights wanc as a global vector. 2: function IC(Danc, Unew, NC ) 3: wsp â† Concat(wanc, 1âŠ¤ |Unew|) â–· Assign all new samples with weight 1. 4: Î¦ â† Extract the features from the penultimate layer of model f on x âˆˆ Danc âˆª Unew in order. 5: clusters â† Weighted-K-Means(Î¦, wsp, NC) 6: new_clusters â† {clusteri | âˆ€clusteri âˆˆ clusters, âˆ€x âˆˆ Danc, x /âˆˆ clustersi} 7: Xnew_anchors â† {the closest sample x to the centroid of clusteri | âˆ€clusteri âˆˆ new_clusters} 8: Xanchors â† {x âˆˆ Danc} âˆªXnew_anchors 9: wanc â† Concat(wanc, 0âŠ¤ |Xnew_anchors|) â–· Initialize new anchor weights. 10: for wanc i âˆˆ wanc, wanc i â† wanc i + # sample of clusterj # anchor in clusterj , wanc i âˆˆ clusterj â–· Weight accumulation. 11: Return Xanchors 12: end function where the minimum value can be obtained with condition w0 = Î»0 Ì¸= 0. In practical learning scenarios, we generally assume adaptation tasks are solvable; therefore, there should be a prediction function that performs well on two distinct domains. In this case, Î³ and Î³â€² should be relatively small, so we can assume Î³ â‰ˆ Î³â€². If Ë†dHâˆ†H(S0, SS) < Ë†dHâˆ†H(SS, ST ), then we have EBS(w, Î», N, t)min = w0( Ë†dHâˆ†H(S0, SS) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³) + (1 âˆ’ w0)( Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€²) + B < Ë†dHâˆ†H(SS, ST ) + 4 s 2d log(2m) + log 2 Î´ m + 2Î³â€² + B = EBS(wâ€², Î»â€², N, t). Therefore, we derive EBS(w, Î», N, t)min < EBS(wâ€², Î»â€², N, t). (32) This completes the proof. F I NCREMENTAL CLUSTERING F.1 A LGORITHM DETAILS We provide the detailed algorithm for incremental clustering as Alg. 2. F.2 V ISUALIZATION To better illustrate the incremental clustering algorithm, we provide visualization results on PACS to demonstrate the process. As shown in Fig. 3, the initial step of IC is a normal K-Means clustering step, and ten anchors denoted as \"X\" are selected. The weights of all samples in a clusters is aggregated into the corresponding anchorâ€™s weight. Therefore, these ten samples (anchors) are given larger sizes visually (i.e., larger weights) than that of other new test samples in the first IC step (Fig. 4). During the first IC step, several distributions are far away from the existed anchors and form clusters 1,7,9 and 10, which leads to 4 new selected anchors. While the number of cluster centroid is only increased by 1, 4 of the existing anchors are clustered into the same cluster 8 (purple). Thus IC produces 4 new anchors instead of 1. Similarly, in the second IC step (Fig. 5), the new streaming-in test samples introduce a new distribution; IC produces 3 new clusters (4, 8, and 11) and the corresponding number of anchors to cover them. The number of centroid is only increased by 1, which implies that there are two original-cluster-merging events. More IC step visualization results are provided in Fig. 6 and 7. 34Published as a conference paper at ICLR 2024 Figure 3: Initial IC step: normal clustering. Left: Clustering results. Right: Selecting new anchors. Figure 4: The first IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 5: The second IC step. Left: Weighted clustering results. Right: Selecting new anchors. 35Published as a conference paper at ICLR 2024 Figure 6: The third IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 7: The fourth IC step. Left: Weighted clustering results. Right: Selecting new anchors. 36Published as a conference paper at ICLR 2024 G E XPERIMENT DETAILS In this section, we provide more experimental details including the details of the datasets and training settings. G.1 D ETAILS ABOUT THE DATASETS We adopt datasets PACS, VLCS, and Office-Home from DomainBed (Gulrajani and Lopez-Paz, 2020) with the same domain splits. All available licenses are mentioned below. â€¢ PACS (Li et al., 2017) includes four domains: art, cartoons, photos, and sketches. PACS is a 7-class classification dataset with 9,991 images of dimension (3, 224, 224). â€¢ VLCS (Fang et al., 2013) contains photographic domains: Caltech101, LabelMe, SUN09, and VOC2007. This dataset includes 10,729 images of dimension (3, 224, 224) with 5 classes. â€¢ Office-Home (Venkateswara et al., 2017) is a 65-class dataset, including domains: art, clipart, product, and real. VLCS includes 10,729 images of dimension (3, 224, 244). (License) â€¢ Tiny-ImageNet-C is a 200-class dataset, including 15 corrupt types. Tiny-ImageNet-C includes 150,000 images of dimension (3, 224, 244). Since the class number 200 is less than ImageNet (1000), the modelâ€™s last layer classifier needs to be adapted. In this work, we use the brightness corruption domain to adapt. In the source pretraining phase, we adopt the most ImageNet-like domain as our source domain. For PACS and Office-Home, we use domains \"photos\" and \"real\" as the source domains, respectively, while for VLCS, Caltech101 is assigned to apply the source pretraining. We freeze the random seeds to generate the sample indices order for the two test data streams, namely, the domain-wise data stream and the random data stream. For PACS, the domain-wise data stream inputs samples from domain art, cartoons, to sketches, while we shuffle all samples from these three domains in the random data stream. For VLCS, we stream the domains in the order: LabelMe, SUN09, and VOC2007, as the domain-wise data stream. For Office-Home, the domain-wise data stream order becomes art, clipart, and product. G.2 T RAINING AND OPTIMIZATION SETTINGS In this section, we extensively discuss the model architectures, optimization settings, and method settings. G.2.1 A RCHITECTURES PACS & VLCS. We adopt ResNet-18 as our model encoder followed by a linear classifier. The initial parameters of ResNet-18 are ImageNet pre-trained weights. In our experiment, we remove the Dropout layer since we empirically found that using the Dropout layer might degrade the optimization process when the sample number is small. The specific implementation of the network is closely aligned with the implementation in DomainBed (Gulrajani and Lopez-Paz, 2020). Office-Home. We employ ResNet-50 as our model encoder for Office-Home. Except for the architecture, the other model settings are aligned with the ResNet-18. Tiny-ImageNet-C ResNet-18 is adapted from ImageNet to Tiny-ImageNet-C by training the last linear layer. G.2.2 T RAINING & OPTIMIZATION In this section, we describe the training configurations for both the source domain pre-training and test-time adaptation procedures. Source domain pre-training. For the PACS and VLCS datasets, models are fine-tuned on the selected source domains for 3,000 iterations. The Adam optimizer is utilized with a learning rate 37Published as a conference paper at ICLR 2024 of 10âˆ’4. In contrast, for the Office-Home dataset, the model is fine-tuned for a longer duration of 10,000 iterations with a slightly adjusted learning rate of 5 Ã— 10âˆ’5. Test-time adaptation. For test-time adaptation across PACS and VLCS, the pre-trained source model is further fine-tuned using the SGD optimizer with a learning rate of 10âˆ’3. While on Office-Home and Tiny-ImageNet-C, a learning rate of 10âˆ’4 is adopted. For all TTA baselines, barring specific exceptions, we faithfully adhere to the original implementation settings. A noteworthy exception is the EATA method, which requires a cosine similarity threshold. The default threshold of the original EATA implementation was not suitable for the three datasets used in our study, necessitating an adjustment. We empirically set this threshold to 0.5 for training. Unlike Tent and SAR, which only require the optimization of batch normalization layers (Santurkar et al., 2018), SimATTA allows the training of all parameters in the networks. In experiments, we use a tolerance count (tol) to control the training process. SimATTA will stop updating once the loss does not descrease for more than 5 steps. However, for Tiny-ImageNet-C, SimATTA uses â€˜steps=10â€˜ for time comparisons since other methods apply at most 10 steps. G.2.3 M ETHOD SETTINGS Tent. In our experiments, we apply the official implementation of Tent1. Specifically, we evaluate Tent with 1 test-time training step and 10 steps, respectively. EATA.Our EATA implementation follows its official code2. In our experiments, EATA has 2000 fisher training samples, E0 = 0.4 Ã— log(# class), Ïµ <0.5. CoTTA. For CoTTA, we strictly follow all the code and settings from its official implementation3. SAR. With SARâ€™s official implementation4, we set E0 = 0 .4 Ã— log(# class) and e0 = 0 .1 in our experiments. ADA baselines. For ADA baselines, we follow the architecture of the official implementation of CLUE (Prabhu et al., 2021)5. SimATTA Implementation. Our implementation largely involves straightforward hyperparameter settings. The higher entropy bound eh = 10âˆ’2 should exceed the lower entropy bound el, but equal values are acceptable. Empirically, the lower entropy bound el can be set to 10âˆ’3 for VLCS and Office-Home, or 10âˆ’4 for PACS. The choice of el is largely dependent on the number of source-like samples obtained. A lower el may yield higher-accuracy low-entropy samples, but this could lead to unstable training due to sample scarcity. Though experimentation with different hyperparameters is encouraged, our findings suggest that maintaining a non-trivial number of low-entropy samples and setting an appropriateÎ»0 are of primary importance. If Î»0 < 0.5, CF may ensue, which may negate any potential improvement. Regarding the management of budgets, numerous strategies can be adopted. In our experiments, we utilized a simple hyperparameter k, varying from 1 to 3, to regulate the increasing rate of budget consumption. This strategy is fairly elementary and can be substituted by any adaptive techniques. G.3 S OFTWARE AND HARDWARE We conduct our experiments with PyTorch (Paszke et al., 2019) and scikit-learn (Pedregosa et al., 2011) on Ubuntu 20.04. The Ubuntu server includes 112 Intel(R) Xeon(R) Gold 6258R CPU @2.70GHz, 1.47TB memory, and NVIDIA A100 80GB PCIe graphics cards. The training process costs graphics memory less than 10GB, and it requires CPU computational resources for scikit-learn K-Means clustering calculations. Our implementation also includes a GPU-based PyTorch K-Means method for transferring calculation loads from CPUs to GPUs. However, for consistency, the results of our experiments are obtained with the original scikit-learn K-Means implementation. 1https://github.com/DequanWang/tent 2https://github.com/mr-eggplant/EATA 3https://github.com/qinenergy/cotta 4https://github.com/mr-eggplant/SAR 5https://github.com/virajprabhu/CLUE 38Published as a conference paper at ICLR 2024 Figure 8: Target loss surface on 2000 samples without source pre-training. The red points denote the loss minimum for a fixed Î»0. The orange line denote the place where w0 = Î»0. Figure 9: Target loss surface on 2000 samples with source pre-training. H E MPIRICAL VALIDATIONS FOR THEORETICAL ANALYSIS In this section, we undertake empirical validation of our learning theory, which encompasses multiple facets awaiting verification. In contemporary computer vision fields, pre-trained models play a pivotal role, and performance would significantly decline without the use of pre-trained features. The learning theory suggests that given the vast VC-dimension of complete ResNets, without substantial data samples, the training error cannot be theoretically tight-bounded. However, we show empirically in the following experiments that fine-tuning pre-trained models is behaviorally akin to training a model with a low VC-dimension. Training on 2000 Samples Without Source Domain Pre-training. For an ImageNet pre-trained ResNet-18 model, we trained it using 2000 samples from the PACS dataset. To ascertain the optimal value wâˆ— 0 in Equation 4, we trained multiple models for different w0 and Î»0 pairings. For each pair, we derived the target domain loss (from art, cartoons, and sketches) post-training and plotted this loss on the z-axis. With w0 and Î»0 serving as the xy-axes, we drafted the target domain loss ÏµT surface in Figure 8. As the results show, given a Î»0, the optimal wâˆ— 0 typically aligns with the line Î»0 = w0, with a slight downward shift, which aligns with Equation 4. 39Published as a conference paper at ICLR 2024 Figure 10: Target loss surface on 500 samples with source pre-training. Figure 11: Source loss surface on 500 samples with source pre-training. 40Published as a conference paper at ICLR 2024 Figure 12: Target and source loss surface on 500 samples with source pre-training. Table 6: TTA comparisons on Office-Home. This table includes the two data stream settings mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. Office-Home Domain-wise data stream Post-adaptation Random data stream Post-adaptation R â†’Aâ†’ â†’Câ†’ â†’P R A C P 1 2 3 4 R A C P BN w/o adapt 93.78 42.93 37.62 59.90 93.78 42.93 37.62 59.90 46.82 46.82 46.82 46.82 93.78 42.93 37.62 59.90BN w/ adapt 92.38 49.69 39.43 63.53 92.38 49.69 39.43 63.53 50.88 50.88 50.88 50.88 92.38 49.69 39.43 63.53 Tent (steps=1) N/A 49.61 39.31 63.87 92.47 49.57 39.89 63.89 49.95 50.27 50.23 52.06 92.40 49.24 39.68 63.98Tent (steps=10) N/A 49.61 39.04 61.41 87.08 44.79 38.37 60.49 50.05 49.31 48.74 47.79 85.31 42.85 37.89 58.71EATA N/A 49.65 39.04 63.53 91.60 49.61 38.65 63.48 49.73 50.27 49.45 51.07 91.05 49.11 38.26 62.99CoTTA N/A 49.61 38.76 61.84 87.81 44.95 35.92 59.04 49.84 49.84 48.95 50.43 86.99 43.68 34.73 57.56SAR (steps=1) N/A 49.65 39.24 63.53 92.45 49.73 39.36 63.69 49.84 50.05 49.91 51.67 92.38 49.57 39.50 63.87SAR (steps=10) N/A 49.53 38.81 61.50 88.94 46.15 37.04 59.41 50.09 50.30 49.77 49.22 89.14 46.23 36.31 59.45 SimATTA (B â‰¤300) N/A 56.20 48.38 71.66 95.75 60.07 52.62 74.70 58.57 60.88 62.91 63.67 95.89 62.01 54.98 74.70SimATTA (B â‰¤500) N/A 58.71 51.11 74.36 96.03 62.05 57.41 76.98 58.85 62.63 63.41 64.31 95.91 63.78 57.87 77.09 Training on 2000 Samples with Source Domain Pre-training. To further assess the effects of source pre-training, we repeated the same experiment on a source pre-trained ResNet-18. The results are depicted in Figure 9. This experiment provides empirical guidance on selecting w0 in source domain pre-trained situations. The findings suggest that the optimal wâˆ— 0 non-trivially shifts away from the line Î»0 = w0 towards lower-value regions. Considering the source pre-training process as using a greater quantity of source domain samples, it implies that when the number of source samples greatly exceeds target samples, a lower w0 can enhance target domain results. Training on 500 Samples with Source Domain Pre-training. We proceed to fine-tune the source domain pre-trained ResNet-18 using only 500 samples, thereby simulating active TTA settings. We train models with various w0 and Î»0 pairings, then graph the target domain losses, source domain losses, and the combined losses. As shown in Figure 10, the target losses still comply with our theoretical deductions where the local minima are close to the line Î»0 = w0 and marginally shift towards lower values. Considering the challenge of CF, the source domain results in Figure 11 suggest a reverse trend compared to the target domain, where lower Î»0 and w0 values yield superior target domain results but inferior source domain results. Thus, to curb CF, the primary strategy is to maintain a relatively higher Î»0. When considering both target and source domains, a balance emerges as depicted in Figure 12. The global minimum is located in the middle region, demonstrating the trade-off between the target domain and source domain performance. I A DDITIONAL EXPERIMENT RESULTS In this section, we provide additional experiment results. The Office-Home results and ablation studies will be presented in a similar way as the main paper. In the full results Sec. I.3, we will post more detailed experimental results with specific budget numbers and intermediate performance during the test-time adaptation. 41Published as a conference paper at ICLR 2024 Table 7: Comparisons to ADA baselines on Office-Home. The source domain is denoted as \"(S)\" in the table. Results are average accuracies with standard deviations). Office-Home R (S) A C P Random (B = 300) 95.04 (0.20) 57.54 (1.16) 53.43 (1.17) 73.46 (0.97) Entropy (B = 300) 94.39 (0.49) 61.21 (0.71) 56.53 (0.71) 72.31 (0.28) Kmeans (B = 300) 95.09 (0.14) 57.37 (0.90) 51.74 (1.34) 71.81 (0.39) CLUE (B = 300) 95.20 (0.23) 60.18 (0.98) 58.05 (0.43) 73.72 (0.70) Ours (B â‰¤300) 95.82 (0.07) 61.04 (0.97) 53.80 (1.18) 74.70 (0.00) I.1 R ESULTS ON OFFICE -HOME We conduct experiments on Office-Home and get the test-time performances and post-adaptation performances for two data streams. As shown in Tab. 6, SimATTA can outperform all TTA baselines with huge margins. Compared to ADA baselines under the source-free settings, as shown in Tab. 7, SimATTA obtains comparable results. I.2 A BLATION STUDIES Figure 13: Ablation study on PACS and VLCS.\"IC=0\" denotes removing incremental clustering (IC) selection. \"LE=0\" denotes removing the low-entropy (LE) sample training. Domain-wise stream and random stream are applied on first and second rows, respectively. The accuracy values are averaged across all splits/domains. In this section, we explore three variations of our method to examine the individual impacts of its components. The first variant replaces the incremental clustering selection with entropy selection, 42Published as a conference paper at ICLR 2024 where only the samples with the highest entropy are chosen. The second variant eliminates low- entropy sample training. The third variation combines the first and second variants. We perform this ablation study on the PACS and VLCS as outlined in Fig. 13. We denote the use of incremental clustering (IC) and low-entropy training (LE) respectively as IC=1 and LE=1. The experiments essentially reveals the effectiveness of incremental clustering and low-entropy- sample training. As we have detailed in Sec. 3.2, these techniques are designed to to select informative samples, increase distribution coverage, and mitigate catastrophic forgetting. These designs appositely serve the ATTA setting where the oracle has costs and the budget is limited. Therefore, their effectiveness is prominent particularly when the budget is small. As the results show, when the budget B â‰¤100 or B â‰¤300, removing the components observably impairs performances. When B gets large, more active samples cover a larger distribution; thus the performance gap from random selection and informative selection gets smaller. In the extreme case where B â†’ âˆž, all samples are selected and thus the superiority of our meticulously-designed techniques are not manifested. Specifically, our analysis yields several insights. First, SimATTA (LE=1, IC=1) comprehensively outperforms other variants on both datasets, different streams, and different budgets. Second, variants without low-entropy training (LE=0, IC=0/1) easily fail to produce stable results (e.g., domain-wise stream in VLCS). Third, SimATTAâ€™s performance surpasses this variant on PACSâ€™s domain-wise stream clearly especially when the budgets are low. This indicates these variants fail to retrieve the most informative style shift (PACSâ€™s shifts) samples, which implies the advantage of incremental clustering when the budget is tight. In addition, these results show that IC has its unique advantage on domain-wise streams where distributions change abruptly instead of random streams. Therefore, compared to PACSâ€™s domain- wise stream results, the reason for the smaller performance improvement of SimATTA over the variant (LE=1, IC=0) on VLCSâ€™s domain-wise stream is that images in VLCS are all photos that do not include those severe style shifts in PACS (i.e., art, cartoons, and sketches). That is, when the shift is not severe, we donâ€™t need IC to cover very different distributions, and selecting samples using entropy can produce good results. In brief, IC is extraordinary for severe distribution shifts and quick adaptation. It is worth mentioning that low budget comparison is essential to show the informative sample retrieval ability, since as the budget increases, all AL techniques will tend to perform closely. I.3 C OMPLETE EXPERIMENT RESULTS We provide complete experimental results in this section. As shown in Tab. 8, we present the full results for two data streams. The test-time adaptation accuracies are shown in the \"Current domain\" row, while the \"Budgets\" row denotes the used budget by the end of the domain. The rest four rows denote the four domain test results by the end of the real-time adaptation of the current domain, where the first column results are the test accuracy before the test-time adaptation phase. N/A represents \"do not apply\". Table 8: Tent (steps=1) on PACS. Tent (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.29 64.59 44.67 56.35 54.09 51.83 48.58 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.38 97.60 98.56 98.08 97.72 97.19 A 59.38 69.09 68.95 66.85 68.07 67.33 65.58 63.53 C 28.03 64.04 65.19 64.08 64.85 65.19 62.97 60.75 S 42.91 53.65 47.39 42.58 54.57 49.83 44.13 41.56 J C HALLENGES AND PERSPECTIVES Despite advancements, test-time adaptation continues to pose considerable challenges. As previously discussed, without supplementary information and assumptions, the ability to guarantee model generalization capabilities is limited. However, this is not unexpected given that recent progress 43Published as a conference paper at ICLR 2024 Table 9: Tent (steps=10) on PACS. Tent (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.38 57.85 20.23 47.36 31.01 22.84 20.33 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 95.45 87.43 62.63 93.83 81.32 65.39 50.78 A 59.38 64.94 55.03 34.52 55.32 40.28 28.27 23.68 C 28.03 55.89 56.70 40.57 54.52 39.68 27.22 20.95 S 42.91 36.96 26.27 13.59 32.25 23.16 20.95 19.62 Table 10: EATA on PACS. EATA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 67.04 64.72 50.27 57.31 56.06 58.17 59.78 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.62 98.50 98.62 98.68 98.62 98.50 98.62 A 59.38 68.90 68.16 66.50 68.65 68.95 69.34 69.63 C 28.03 63.74 65.36 62.46 65.19 66.00 65.57 65.70 S 42.91 54.01 52.89 48.18 55.71 55.64 54.09 54.26 Table 11: CoTTA on PACS. CoTTA Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 65.48 62.12 53.17 56.06 54.33 57.16 57.42 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.62 98.62 98.62 98.62 98.56 98.62 A 59.38 65.82 65.87 65.48 66.02 65.87 66.31 65.97 C 28.03 62.63 63.05 63.10 63.01 62.88 63.01 62.97 S 42.91 53.88 54.03 53.78 54.67 55.31 55.10 54.62 Table 12: SAR (steps=1) on PACS. SAR (steps=1) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 66.75 63.82 49.58 56.78 56.35 56.68 56.70 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.50 98.32 98.74 98.56 98.50 98.44 A 59.38 68.02 68.07 66.94 67.87 68.65 68.55 68.16 C 28.03 62.84 64.97 62.93 63.82 64.89 64.46 64.38 S 42.91 53.47 52.07 45.74 54.92 55.46 53.68 52.53 Table 13: SAR (steps=10) on PACS. SAR (steps=10) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 69.38 68.26 49.02 53.51 51.15 51.78 45.60 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.20 95.39 96.47 97.13 97.78 97.72 94.13 A 59.38 72.36 66.60 62.16 62.74 64.94 66.11 56.64 C 28.03 63.44 68.30 56.19 59.77 61.73 62.03 56.02 S 42.91 53.37 44.59 54.62 41.00 49.66 48.79 36.37 44Published as a conference paper at ICLR 2024 Table 14: SimATTA (B â‰¤300) on PACS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 76.86 70.90 75.39 69.47 76.49 82.45 82.22 Budgets N/A 75 145 223 66 142 203 267 P 99.70 98.44 98.86 98.80 97.96 98.68 99.04 98.98 A 59.38 80.71 82.32 84.47 73.97 80.52 81.10 84.91 C 28.03 48.12 82.00 82.25 72.35 81.06 83.36 83.92 S 42.91 32.78 56.25 81.52 79.49 83.10 84.78 86.00 Table 15: SimATTA (B â‰¤500) on PACS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream P â†’Aâ†’ â†’ Câ†’ â†’ S 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 77.93 76.02 76.30 68.46 78.22 80.91 85.49 Budgets N/A 121 230 358 102 221 343 425 P 99.70 98.92 98.86 98.62 98.20 99.46 99.10 99.16 A 59.38 87.01 87.60 88.33 73.39 79.20 84.91 86.67 C 28.03 54.78 83.96 83.49 68.43 74.40 84.22 84.77 S 42.91 46.37 63.53 83.74 81.34 81.04 86.66 87.71 Table 16: Tent (steps=1) on VLCS. Tent (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 38.55 34.40 53.88 44.85 44.29 47.38 44.98 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.81 85.44 84.73 84.95 85.16 85.80 85.30 L 33.55 40.02 43.11 43.86 39.68 41.98 43.11 43.49 S 41.10 33.39 35.41 33.61 36.29 37.90 38.27 37.81 V 49.08 53.20 54.06 53.11 53.76 54.18 53.76 53.35 Table 17: Tent (steps=10) on VLCS. Tent (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 45.41 31.44 32.32 46.13 42.31 43.51 39.48 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 73.07 48.34 42.54 74.13 62.19 56.54 52.01 L 33.55 46.61 38.44 37.65 44.88 45.93 43.41 40.32 S 41.10 31.75 28.82 27.79 35.37 36.14 35.28 33.64 V 49.08 48.05 40.14 33.12 50.50 44.49 42.48 40.37 Table 18: EATA on VLCS. EATA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.24 33.15 52.58 43.77 42.48 43.34 41.55 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 85.16 85.02 84.10 84.73 84.52 84.10 83.32 L 33.55 37.16 37.24 37.69 37.09 36.78 36.90 36.67 S 41.10 33.39 33.49 32.39 33.33 32.54 31.84 31.47 V 49.08 51.87 52.16 52.49 52.07 52.43 52.64 52.55 45Published as a conference paper at ICLR 2024 Table 19: CoTTA on VLCS. CoTTA Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 37.39 32.54 52.25 43.69 42.14 43.21 42.32 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 81.55 81.98 82.12 82.61 82.47 82.12 81.98 L 33.55 37.20 37.91 37.65 38.48 38.22 38.40 37.99 S 41.10 30.71 32.78 33.12 34.00 33.70 33.97 33.52 V 49.08 52.01 52.64 52.90 53.64 53.14 53.08 53.23 Table 20: SAR (steps=1) on VLCS. SAR (steps=1) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 36.18 34.43 52.46 43.64 43.04 44.20 41.93 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.31 84.17 83.96 85.09 85.23 85.23 85.09 L 33.55 35.62 38.29 39.72 38.55 39.34 40.21 40.70 S 41.10 33.24 36.41 36.53 34.37 35.62 36.29 36.44 V 49.08 51.75 52.61 52.37 52.90 52.75 53.05 53.02 Table 21: SAR (steps=10) on VLCS. SAR (steps=10) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 35.32 34.10 51.66 43.56 42.05 42.53 41.16 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 83.96 83.04 82.12 84.03 84.24 85.23 85.09 L 33.55 34.07 35.92 41.49 39.53 38.37 37.65 37.58 S 41.10 31.93 34.89 33.94 35.19 32.94 33.88 33.12 V 49.08 51.33 51.51 53.08 52.78 52.34 51.78 52.01 Table 22: SimATTA (B â‰¤300) on VLCS. SimATTA (B â‰¤300) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 62.61 65.08 74.38 62.33 69.33 73.20 71.93 Budgets N/A 79 175 272 71 135 208 262 C 100.00 99.51 98.52 99.93 99.86 99.79 100.00 99.93 L 33.55 68.11 69.92 69.50 62.61 66.64 68.45 69.43 S 41.10 55.24 68.89 66.67 65.54 69.29 71.79 72.46 V 49.08 66.08 70.94 77.34 73.79 76.87 78.82 80.39 Table 23: SimATTA (B â‰¤500) on VLCS. SimATTA (B â‰¤500) Domain-wise data stream Random data stream C â†’Lâ†’ â†’ Sâ†’ â†’ V 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 63.52 68.01 76.13 62.29 70.45 73.50 72.02 Budgets N/A 113 266 446 107 203 283 356 C 100.00 99.29 98.59 99.51 99.93 99.86 99.86 99.43 L 33.55 62.95 70.63 70.56 66.57 67.09 67.24 70.29 S 41.10 51.31 73.83 73.10 65.33 71.79 72.91 72.55 V 49.08 59.36 71.65 78.35 73.58 77.84 80.01 80.18 46Published as a conference paper at ICLR 2024 Table 24: Tent (steps=1) on Office-Home. Tent (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.31 63.87 49.95 50.27 50.23 52.06 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.33 92.36 92.47 92.38 92.45 92.45 92.40 A 57.07 49.73 49.73 49.57 49.69 49.73 49.57 49.24 C 44.97 39.27 39.54 39.89 39.45 39.68 39.73 39.68 P 73.15 63.60 63.66 63.89 63.60 63.82 63.93 63.98 Table 25: Tent (steps=10) on Office-Home. Tent (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 39.04 61.41 50.05 49.31 48.74 47.79 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 91.99 89.14 87.08 92.08 90.80 88.59 85.31 A 57.07 49.94 46.77 44.79 49.44 48.21 45.69 42.85 C 44.97 38.58 39.11 38.37 40.18 40.02 38.63 37.89 P 73.15 63.28 61.03 60.49 64.36 63.64 61.12 58.71 Table 26: EATA on Office-Home. EATA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.04 63.53 49.73 50.27 49.45 51.07 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.36 92.17 91.60 92.38 92.22 91.71 91.05 A 57.07 49.57 49.53 49.61 49.69 49.40 49.36 49.11 C 44.97 39.08 39.01 38.65 39.27 39.01 38.42 38.26 P 73.15 63.42 63.42 63.48 63.51 63.37 63.33 62.99 Table 27: CoTTA on Office-Home. CoTTA Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.61 38.76 61.84 49.84 49.84 48.95 50.43 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 90.38 88.02 87.81 90.48 89.37 88.00 86.99 A 57.07 48.58 45.53 44.95 47.34 46.35 44.62 43.68 C 44.97 36.66 35.58 35.92 37.55 36.40 35.44 34.73 P 73.15 60.40 57.74 59.04 61.12 59.63 58.35 57.56 Table 28: SAR (steps=1) on Office-Home. SAR (steps=1) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.65 39.24 63.53 49.84 50.05 49.91 51.67 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.38 92.31 92.45 92.40 92.36 92.36 92.38 A 57.07 49.65 49.57 49.73 49.69 49.61 49.57 49.57 C 44.97 39.34 39.22 39.36 39.34 39.56 39.47 39.50 P 73.15 63.51 63.51 63.69 63.60 63.71 63.71 63.87 47Published as a conference paper at ICLR 2024 Table 29: SAR (steps=10) on Office-Home. SAR (steps=10) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 49.53 38.81 61.50 50.09 50.30 49.77 49.22 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.20 92.06 88.94 92.40 92.47 91.53 89.14 A 57.07 49.40 49.77 46.15 49.81 50.02 48.91 46.23 C 44.97 39.20 38.63 37.04 39.50 39.29 38.65 36.31 P 73.15 63.53 62.69 59.41 64.18 64.18 62.83 59.45 Table 30: SimATTA (B â‰¤300) on Office-Home. SimATTA (B â‰¤300) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 56.20 48.38 71.66 58.57 60.88 62.91 63.67 Budgets N/A 75 187 277 79 147 216 278 R 96.44 95.43 95.43 95.75 95.91 95.96 96.01 95.89 A 57.07 57.56 59.50 60.07 58.34 59.91 61.15 62.01 C 44.97 42.25 52.46 52.62 51.66 52.30 54.75 54.98 P 73.15 68.84 70.13 74.70 72.45 73.10 74.50 74.70 Table 31: SimATTA (B â‰¤500) on Office-Home. SimATTA (B â‰¤500) Domain-wise data stream Random data stream R â†’Aâ†’ â†’ Câ†’ â†’ P 1 â†’ â†’ 2â†’ â†’ 3â†’ â†’ 4â†’ Current domain N/A 58.71 51.11 74.36 58.85 62.63 63.41 64.31 Budgets N/A 107 284 440 126 248 361 467 R 96.44 95.69 95.71 96.03 96.26 96.19 95.87 95.91 A 57.07 61.43 61.43 62.05 58.18 61.15 61.52 63.78 C 44.97 46.41 57.73 57.41 53.17 55.14 56.79 57.87 P 73.15 70.74 71.98 76.98 73.51 74.18 75.78 77.09 48Published as a conference paper at ICLR 2024 in deep learning heavily relies on large-scale data. Consequently, two promising paths emerge: establishing credible assumptions and leveraging additional information. Firstly, developing credible assumptions can lead to comprehensive comparisons across various stud- ies. Given that theoretical guarantees highlight the inherent differences between methods primarily based on the application limits of their assumptions, comparing these assumptions becomes critical. Without such comparative studies, empirical evaluations may lack precise guidance and explanation. Secondly, while we acknowledge the value of real-world data (observations), discussions surrounding the use of extra information remain pertinent. Considerations include the strategies to acquire this supplementary information and the nature of the additional data needed. Despite the myriad of works on domain generalization, domain adaptation, and test-time adaptation, a comprehensive survey or benchmark encapsulating the aforementioned comparisons remains an unmet need. Moreover, potential future directions for out-of-distribution generalization extend beyond domain generalization and test-time adaptation. One promising avenue is bridging the gap between causal inference and deep learning, for instance, through causal representation learning. In conclusion, our hope is that this work not only offers a novel practical setting and algorithm but also illuminates meaningful future directions and research methodologies that can benefit the broader scientific community. 49",
      "meta_data": {
        "arxiv_id": "2404.05094v1",
        "authors": [
          "Shurui Gui",
          "Xiner Li",
          "Shuiwang Ji"
        ],
        "published_date": "2024-04-07T22:31:34Z",
        "pdf_url": "https://arxiv.org/pdf/2404.05094v1.pdf"
      }
    },
    {
      "title": "EcoTTA: Memory-Efficient Continual Test-Time Adaptation via Self-Distilled Regularization",
      "abstract": "This paper presents a simple yet effective approach that improves continual\ntest-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be\nconducted on edge devices with limited memory, so reducing memory is crucial\nbut has been overlooked in previous TTA studies. In addition, long-term\nadaptation often leads to catastrophic forgetting and error accumulation, which\nhinders applying TTA in real-world deployments. Our approach consists of two\ncomponents to address these issues. First, we present lightweight meta networks\nthat can adapt the frozen original networks to the target domain. This novel\narchitecture minimizes memory consumption by decreasing the size of\nintermediate activations required for backpropagation. Second, our novel\nself-distilled regularization controls the output of the meta networks not to\ndeviate significantly from the output of the frozen original networks, thereby\npreserving well-trained knowledge from the source domain. Without additional\nmemory, this regularization prevents error accumulation and catastrophic\nforgetting, resulting in stable performance even in long-term test-time\nadaptation. We demonstrate that our simple yet effective strategy outperforms\nother state-of-the-art methods on various benchmarks for image classification\nand semantic segmentation tasks. Notably, our proposed method with ResNet-50\nand WideResNet-40 takes 86% and 80% less memory than the recent\nstate-of-the-art method, CoTTA.",
      "full_text": "EcoTTA: Memory-Efficient Continual Test-time Adaptation via Self-distilled Regularization Junha Song1,2* , Jungsoo Lee 1, In So Kweon 2, Sungha Choi 1â€  1Qualcomm AI Researchâ€¡, 2KAIST Abstract This paper presents a simple yet effective approach that improves continual test-time adaptation (TTA) in a memory- efficient manner. TTA may primarily be conducted on edge devices with limited memory, so reducing memory is cru- cial but has been overlooked in previous TTA studies. In addition, long-term adaptation often leads to catastrophic forgetting and error accumulation, which hinders apply- ing TTA in real-world deployments. Our approach con- sists of two components to address these issues. First, we present lightweight meta networks that can adapt the frozen original networks to the target domain. This novel archi- tecture minimizes memory consumption by decreasing the size of intermediate activations required for backpropaga- tion. Second, our novel self-distilled regularization controls the output of the meta networks not to deviate significantly from the output of the frozen original networks, thereby preserving well-trained knowledge from the source domain. Without additional memory, this regularization prevents er- ror accumulation and catastrophic forgetting, resulting in stable performance even in long-term test-time adaptation. We demonstrate that our simple yet effective strategy out- performs other state-of-the-art methods on various bench- marks for image classification and semantic segmentation tasks. Notably, our proposed method with ResNet-50 and WideResNet-40 takes 86% and 80% less memory than the recent state-of-the-art method, CoTTA. 1. Introduction Despite recent advances in deep learning [15, 24, 23, 22], deep neural networks often suffer from performance degra- dation when the source and target domains differ signifi- cantly [8, 43, 38]. Among several tasks addressing such domain shifts, test-time adaptation (TTA) has recently re- ceived a significant amount of attention due to its practi- cality and wide applicability especially in on-device set- *Work done during an internship at Qualcomm AI Research. â€ Corresponding author. â€¡ Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc. Memory (MB) CIFAR100-C  Error (%) CIFAR10-C  Error (%) ResNet-50 WideResNet-40 CoTTA SWR&NSP TTT++ Con6nual TENT Single domain TENT EATA CoTTA SWR&NSP TTT++ EATA         NOTE Memory (MB)   0 450 900 1350 1800 Param Ac6va6on 86% 72% 0 100 200 300 400 Param Ac6va6on TENT/EATA  CoTTA  Ours 80% 59% (a) (b) Con6nual TENT Single domain TENT             ResNet-50 WideResNet-40 Ours (K=4) Ours (K=5) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Figure 1. (a) Memory cost comparison between TTA methods. The size of activations, not the parameters, is the primary mem- ory bottleneck during training. (b) CIFAR-C adaptation perfor- mance. We perform the continual online adaptation on CIFAR-C dataset. The x- and y-axis are the average error of all corruptions and the total memory consumption including the parameters and activations, respectively. Our approach, EcoTTA, achieves the best results while consuming the least amount of memory, where K is the model partition factor used in our method. tings [65, 42, 32, 16]. This task focuses on adapting the model to unlabeled online data from the target domain with- out access to the source data. While existing TTA methods show improved TTA per- formances, minimizing the sizes of memory resources have been relatively under-explored, which is crucial considering the applicability of TTA in on-device settings. For example, several studies [66, 42, 9] update entire model parameters 1 arXiv:2303.01904v4  [cs.CV]  23 May 2023TENTð·! EATAð·! weight regularization: freeze: update: meta networks (Ours) randomrestoration CoTTA Ours (EcoTTA)ð·!ð·!transformmovingaverage bnbnbnconv blockmain networksmain networkssource modelmain networksconv blockconv block teacher modelsource modelð·!:unlabeledonlinetestdata â€¦bn â€¦bn Figure 2. Architecture for test-time adaptation. We illustrate TTA methods: TENT [65], EATA [50], CoTTA [66], and Ours (EcoTTA). TENT and EATA update multiple batch norm layers, in which large activations have to be stored for gradient calculation. In CoTTA, an entire network is trained with additional strategies for continual adaptation that requires a significant amount of both memory and time. In contrast, our approach requires a minimum size of activations by updating onlya few layers. Also, stable long-term adaptation is performed by our proposed regularization, named self-distilled regularization. to achieve large performance improvements, which may be impractical when the available memory sizes are limited. Meanwhile, several TTA approaches update only the batch normalization (BN) parameters [65, 50, 17] to make the optimization efficient and stable However, even updating only BN parameters is not memory efficient enough since the amount of memory required for training models signifi- cantly depends on the size of intermediate activations rather than the learnable parameters [4, 14, 69]. Throughout the paper, activations refer to the intermediate features stored during the forward propagation, which are used for gradi- ent calculations during backpropagation. Fig. 1 (a) demon- strates such an issue. Moreover, a non-trivial number of TTA studies assume a stationary target domain [65, 42, 9, 57], but the target do- main may continuously change in the real world (e.g., con- tinuous changes in weather conditions, illuminations, and location [8] in autonomous driving). Therefore, it is nec- essary to consider long-term TTA in an environment where the target domain constantly varies. However, there exist two challenging issues: 1) catastrophic forgetting [66, 50] and 2) error accumulation. Catastrophic forgetting refers to degraded performance on the source domain due to long- term adaptation to target domains [66, 50]. Such an issue is important since the test samples in the real world may come from diverse domains, including the source and tar- get domains [50]. Also, since target labels are unavailable, TTA relies on noisy unsupervised losses, such as entropy minimization [19], so long-term continual TTA may lead to error accumulation [75, 2]. To address these challenges, we propose memory- Efficient continual Test-Time Adaptation (EcoTTA), a sim- ple yet effective approach for 1) enhancing memory effi- ciency and 2) preventing catastrophic forgetting and error accumulation. First, we present a memory-efficient archi- tecture consisting of frozen original networks and our pro- posed meta networks attached to the original ones. During the test time, we freeze the original networks to discard the intermediate activations that occupy a significant amount of memory. Instead, we only adapt lightweight meta networks to the target domain, composed of only one batch normal- ization and one convolution block. Surprisingly, updating only the meta networks, not the original ones, can result in significant performance improvement as well as consider- able memory savings. Moreover, we propose a self-distilled regularization method to prevent catastrophic forgetting and error accumulation. Our regularization leverages the pre- served source knowledge distilled from the frozen original networks to regularize the meta networks. Specifically, we control the output of the meta networks not to deviate from the one extracted by the original networks significantly. No- tably, our regularization leads to negligible overhead be- cause it requires no extra memory and is performed in par- allel with adaptation loss, such as entropy minimization. Recent TTA studies require access to the source databe- fore model deployments[42, 9, 34, 1, 40, 50]. Similarly, our method uses the source data to warm up the newly attached meta networks for a small number of epochs before model deployment. If the source dataset is publicly available or the owner of the pre-trained model tries to adapt the model to a target domain, access to the source data is feasible [9]. Here, we emphasize that pre-trained original networks are frozen throughout our process, and our method is applicable to any pre-trained model because it is agnostic to the archi- tecture and pre-training method of the original networks. Our paper presents the following contributions: â€¢ We present novel meta networks that help the frozen original networks adapt to the target domain. This architecture significantly minimize memory consump- tion up to 86% by reducing the activation sizes of the original networks. â€¢ We propose a self-distilled regularization that controls the output of meta networks by leveraging the output of frozen original networks to preserve the source knowl- edge and prevent error accumulation. â€¢ We improve both memory efficiency and TTA perfor- mance compared to existing state-of-the-art methods on 1) image classification task ( e.g., CIFAR10/100-C and ImageNet-C) and 2) semantic segmentation task (e.g., Cityscapes with weather corruption) 22. Related Work Mitigating domain shift. One of the fundamental issues of DNNs is the performance degradation due to the domain shift between the train (i.e. source) and test (i.e. target) dis- tributions. Several research fields attempt to address this problem, such as unsupervised domain adaptation [64, 6, 53, 56, 46, 58] and domain generalization [76, 8]. In par- ticular, domain generalization aims to learn invariant rep- resentation so as to cover the possible shifts of test data. They simulate the possible shifts using a single or multiple source dataset [76, 74, 39] or force to minimize the depen- dence on style information [52, 8]. However, it is challeng- ing to handle all potential test shifts using the given source datasets [20]. Thus, instead of enhancing generalization ability during the training time, TTA [65] overcomes the domain shift by directly adapting to the test data. Test-time adaptation. Test-time adaptation allows the model to adapt to the test data ( i.e., target domain) in a source-free and online manner [33, 62, 65]. Existing works improve TTA performance with sophisticated designs of un- supervised loss [48, 72, 42, 9, 45, 57, 5, 16, 1, 3, 12, 59] or enhance the usability of small batch sizes [36, 70, 31, 51, 40] considering streaming test data. They focus on improv- ing the adaptation performance with a stationary target do- main (i.e., single domain TTA setup). In such a setting, the model that finished adaptation to a given target domain is reset to the original model pre-trained with the source do- main in order to adapt to the next target domain. Recently, CoTTA [66] has proposed continual TTA setup to address TTA under a continuously changing target do- main which also involves a long-term adaptation. This setup frequently suffers from error accumulation [75, 2, 63] and catastrophic forgetting [66, 35, 50]. Specifically, perform- ing a long-term adaptation exposes the model to unsuper- vised loss from unlabeled test data for a long time, so er- rors are accumulated significantly. Also, the model focuses on learning new knowledge and forgets about the source knowledge, which becomes problematic when the model needs to correctly classify the test sample as similar to the source distribution. To address such issues, CoTTA [66] randomly restores the updated parameters to the source one, while EATA [50] proposed a weight regularization loss. Efficient on-device learning. Since the edge device is likely to be memory constrained ( e.g., a Raspberry Pi with 512MB and iPhone 13 with 4GB), it is necessary to take account of the memory usage when deploying the models on the device [41]. TinyTL [4], a seminal work in on- device learning, shows that the activation size, not learn- able parameters, bottlenecks the training memory. Follow- ing this, recent on-device learning studies [4, 68, 69] target- ing fine-tuning task attempt to decrease the size of interme- diate activations. In contrast, previous TTA studies [65, 50] have overlooked these facts and instead focused on reduc- ing learnable parameters. This paper, therefore, proposes a method that not only reduces the high activation sizes re- quired for TTA, but also improves adaptation performance. 3. Approach Fig. 3 illustrates our simple yet effective approach which only updates the newly added meta networks on the tar- get domain while regularizing them with the knowledge distilled from the frozen original network. This section describes how such a design promotes memory efficiency and prevents error accumulation and catastrophic forgetting which are frequently observed in long-term adaptation. 3.1. Memory-efficient Architecture Prerequisite. We first formulate the forward and the back- ward propagation. Assume that the ith linear layer in the model consists of weight W and bias b, and the input and output features of this layer are fi and fi+1, respectively. Given that the forward propagation of fi+1 = fiW + b, the backward propagation from the i+1th layer to the ith layer, and the weight gradient are respectively formulated as: âˆ‚L âˆ‚fi = âˆ‚L âˆ‚fi+1 WT , âˆ‚L âˆ‚W = fT i âˆ‚L âˆ‚fi+1 . (1) Eq. (1) means that the learnable layers whose weight W need to be updated must store intermediate activations fi to compute the weight gradient. In contrast, the backward propagation in frozen layers can be accomplished without saving the activations, only requiring its weightW. Further descriptions are provided in Appendix A. TinyTL [4] shows that activations occupy the majority of the memory required for training the model rather than learnable parameters. Due to this fact, updating the entire model (e.g., CoTTA [66]) requires a substantial amount of memory. Also, updating only parameters in batch normal- ization (BN) layers (e.g., TENT [65] and EATA [50]) is not an effective approach enough since they still save the large intermediate activations for multiple BN layers. While pre- vious studies fail to reduce memory by utilizing large ac- tivations, this work proposes a simple yet effective way to reduce a significant amount of memory by discarding them. Before deployment. As illustrated in Fig. 3 (a, b), we first take a pre-trained model using any pre-training method. We divide the encoder of the pre-trained model into K number of parts and attach lightweight meta networks to each part of the original network. The details of how to divide the model into K number of parts are explained in the next sec- tion. One group of meta network composes of one batch normalization layer and one convolution block ( i.e., Conv- BN-Relu). Before the deployment, we pre-train the meta networks on the source dataset Ds for a small number of 3: backpropagation: freeze: update: meta networks (Ours)ð·!:labeled source datað·\":unlabeled online test data Our proposed method (EcoTTA)Anypre-training method(a) partition (K=3)(b) attach and warm up meta networks Any pre-trained model (c) test-time adaptation Deploy=â€–ð‘¥%#-ð‘¥#â€–$ cross entropy ð·! K=3 entropy min. input convencoderclassifier ð‘¥%#%$ ð‘¥# convblockbn ð‘¥%# ð‘¥%#%$ ð‘¥#bn ð‘¥%# ð·\" self-distilled reg. convblock Figure 3. Overview of our approach. (a) The encoder of the pre-trained model is divided into K parts (i.e., model partition factor K). (b) Before deployment, the meta networks are attached to each part of the original networks and pre-trained with source dataset Ds. (c) After the model is deployed, only the meta networks are updated with unsupervised loss (i.e., entropy minimization) on target data Dt, while the original networks are frozen. To avoid error accumulation and catastrophic forgetting by the long-term adaptation, we regularize the output Ëœxk of each group of the meta networks leveraging the output xk of the frozen original network, which preserves the source knowledge. epochs (e.g., 10 epochs for CIFAR dataset) while freezing the original networks. Such a warm-up process is com- pleted before the model deployment, similarly done in sev- eral TTA works [9, 34, 40, 50]. Note that we do not require source dataset Ds during test time. Pre-trained model partition. Previous TTA studies ad- dressing domain shifts [9, 48] indicate that updating shal- low layers is more crucial for improving the adaptation per- formance than updating the deep layers. Inspired by such a finding, given that the encoder of the pre-trained model is split into model partition factor K ( e.g., 4 or 5), we par- tition the shallow parts of the encoder more ( i.e., densely) compared to the deep parts of it. Table 4c shows how per- formance changes as we vary the model partition factor K. After deployment. During the test-time adaptation, we only adapt meta networks to target domains while freezing the original networks. Following EATA [50], we use the entropy minimization H(Ë†y) = âˆ’P c p(Ë†y) logp(Ë†y) to the samples achieving entropy less than the pre-defined entropy threshold H0, where Ë†y is the prediction output of a test im- age from test dataset Dt and p(Â·) is the softmax function. Thus, the main task loss for adaptation is defined as Lent = I{H(Ë†y)<H0} Â· H(Ë†y), (2) where I{Â·} is an indicator function. In addition, in order to prevent catastrophic forgetting and error accumulation, we apply our proposed regularization loss Rk, which is de- scribed next in detail. Consequently, the overall loss of our method is formulated as, Ltotal Î¸ = Lent Î¸ + Î» KX k Rk Î¸k , (3) where Î¸ and Î¸k denotes parameters of all meta networks and those of k-th group of meta networks, respectively, and Î» is used to balance the scale of the two loss functions. Note that our architecture requires less memory than pre- vious works [66, 65] since we use frozen original networks and discard its intermediate activations. To be more spe- cific, our architecture uses 82% and 60% less memory on average than CoTTA and TENT/EATA. 3.2. Self-distilled Regularization The unsupervised loss from unlabeled test data Dt is likely to provide a false signal ( i.e., noise) to the model (Ë†y Ì¸= yt where yt is the ground truth test label). Previ- ous works have verified that long-term adaptation with un- supervised loss causes overfitting due to error accumula- tion [75, 2] and catastrophic forgetting [66, 35]. To prevent the critical issues, we propose a self-distilled regularization utilizing our architecture. As shown in Fig. 3, we regularize the output Ëœxk of each k-th group of the meta networks not to deviate from the outputxk of the k-th part of frozen orig- inal networks. Our regularization loss which computes the mean absolute error (i.e., L1 loss) is formulated as follows: Rk Î¸k = âˆ¥Ëœxk âˆ’ xkâˆ¥1 . (4) Since the original networks are not updated, the output xk,kâˆ¼K extracted from them can be considered as contain- ing the knowledge learned from the source domain. Taking advantage of this fact, we let the output of meta networks Ëœxk be regularized with knowledge distilled from the origi- nal networks. By preventing the adapted model to not sig- nificantly deviate from the original model, we can prevent 1) catastrophic forgetting by maintaining the source domain knowledge and 2) error accumulation by utilizing the class discriminability of the original model. Remarkably, unlike previous works [66, 50], our regularization does not require saving additional original networks, which accompanies ex- tra memory usage. Moreover, it only needs a negligible 4WideResNet-40 (AugMix) WideResNet-28 ResNet-50Method Avg. errâ†“ Mem. (MB) Avg. errâ†“ Mem. (MB) Avg. errâ†“ Mem. (MB) Source 36.7 11 43.5 58 48.8 91BN Stats Adapt [49] 15.4 11 20.9 58 16.6 91Single do. TENT [65] 12.7 188 19.2 646 15.0 925Continual TENT 13.3 188 20.0 646 15.2 925TTT++ [42] 14.6 391 20.3 1405 16.1 1877SWR&NSP [9] 12.1400 17.2 1551 15.4 1971NOTE [17] 13.4 188 20.2 646 - -EATA [50] 13.0 188 18.6 646 14.2 925CoTTA [66] 14.0 409 17.0 1697 14.4 2066Ours (K=4)12.2 80(80, 58%â†“) 16.9404(76, 38%â†“) 14.4296(86, 68%â†“) Ours (K=5)12.1 92(77, 51%â†“) 16.8471(72, 27%â†“) 14.1498(76, 46%â†“) (a) CIFAR10-C with severity level 5 WideResNet-40 (AugMix) ResNet-50Method Avg. errâ†“ Mem. (MB) Avg. errâ†“ Mem. (MB) Source 69.7 11 73.8 91BN Stats Adapt [49] 41.1 11 44.5 91Single do. TENT [65] 36.7 188 40.1 926Continual TENT 38.3 188 45.9 926TTT++ [42] 41.0 391 44.2 1876SWR&NSP [9] 36.6 400 44.1 1970NOTE [17] 42.8 188 - -EATA [50] 37.1 188 39.9 926CoTTA [66] 38.1 409 40.2 2064Ours (K=4)36.4 80(80, 58%â†“) 39.5296(86, 68%â†“) Ours (K=5)36.3 92(77, 51%â†“) 39.3498(76, 46%â†“) (b) CIFAR100-C with severity level 5 Table 1. Comparison of error rate ( %) on CIFAR-C. We report an average error of 15 corruptions on continual TTA and a memory requirement including model parameters and activation sizes. The lowest error is in bold, and the second lowest error is underlined. The memory reduction rates compared to CoTTA and TENT are presented sequentially. WideResNet-40 was pre-trained with AugMix [26] that is a data processing to increase the robustness of the model. Source denotes the pre-trained model without adaptation. Single domain (in short, single do.) TENT resets the model when adapting to a new target domain, so the domain labeles are required. ResNet-50 (AugMix) ResNet-50(MB)Total Mem.â†“Method Avg. errâ†“ Avg. errâ†“ Source 74.36 82.35 91BN Stats Adapt [49] 57.87 72.18 91Continual TENT [65] 56.1 (0.6) 66.2 (1.1) 1486EATA [50] 54.9 (2.3) 63.8 (2.7) 1486CoTTA [66] 54.6(3.9) 62.6(3.1) 3132Ours (K=4) 55.2 (3.0) 64.6 (3.2)438(86, 72%â†“) Ours (K=5) 54.4(2.7) 63.4(3.0) 747(75, 51%â†“) Table 2. Comparison of error rate ( %) on ImageNet-C with severity level 5. Standard deviation for ten diverse corruption se- quences is denoted by the parentheses values. The total memory refers to the sum of model parameters and activations. Avg. err (%) CIFAR10-C CIFAR100-CMethod Mem. (MB)single do. continual single do. continual BN Stats Adapt [49] 91 16.6 16.6 44.5 44.5TinyTLâ€ [4] 379 15.8 21.9 40.5 77.4RepNetâ€ [69] 508 15.2 20.9 41.5 52.1AuxAdaptâ€ [73] 207 16.0 16.7 44.0 45.8Ours (K=4) 296 14.4 14.4 39.5 39.2 Table 3. Comparison with methods for on-device learning. The backbone is ResNet-50. â€  denotes our own re-implemented mod- els. single do. indicates the singe domain TTA setup. amount of computational overhead because it is performed in parallel with the entropy minimization loss Lent. 4. Classification Experiments We evaluate our approach to image classification tasks based on the continual test-time adaptation setup with three datasets: CIFAR10-C, CIFAR100-C, and ImageNet-C. Experimental setup. Following CoTTA [66], we conduct most experiments on the continual TTA task, where we continually adapt the deployed model to each corruption type sequentially without resetting the model. This task is more challenging but more realistic than single domain TTA task [65] in which the adapted model is periodically reset to the original pre-trained model after finishing adaptation to each target, so they require additional domain information. Moreover, we evaluate our approach on the long-term TTA setup, which is detailed in Section 4.2. Following the previous TTA studies [65, 66], we eval- uate models with {CIFAR10, CIFAR10-C}, {CIFAR100, CIFAR100-C}, and {ImageNet, ImageNet-C } where the first and the second dataset in each bracket refers to the source and the target domain, respectively. The target do- mains include 15 types of corruptions ( e.g. noise, blur, weather, and digital) with 5 levels of severity, which are widely used in conventional benchmarks [25]. Implementation Details. We evaluate our approach within the frameworks officially provided by previous state-of- the-art methods [66, 50]. For fair comparisons, we use the same pre-trained model, which are WideResNet-28 and WideResNet-40 [71] models from the RobustBench [11], and ResNet-50 [24] model from TTT++ [42, 9]. Before the deployment, we pre-train the meta networks on the source dataset using a cross-entropy loss with SGD optimizer with the learning rate of 5e-2. Since the meta networks contain only a few layers, we pre-train them with a small number of epochs: 10 and 3 epochs for CIFAR and ImageNet, re- spectively. After deployment, similar to EATA [50], we use the same SGD optimizer with the learning rate of 5e-3. In Eq. (2), the entropy threshold H0 is set to 0.4 Ã— ln C where C denotes the number of task classes. The batch size is 64 and 32 for CIFAR and ImageNet, respectively. We set the importance of the regularization Î» in Eq. (3) to 0.5 to balance it with the entropy minimization loss. Additional implementation details can be found in Appendix C. Evaluation Metric. For all the experiments, we report error rates calculated during testing and the memory consump- tion, including the model parameter and the activation stor- 5Ours(i) (ii) (iii)(iv)(v)(vi) =â€–\t\t\t-\t\t\tâ€–! convbn convbn bnconv CBAMSE : update conv (a) Visualization of networks variants Avr. errArch CIFAR10-CWRN-28CIFAR10-CWRN-40CIFAR100-CWRN-40(i) 18.1 12.637.2(ii) Ours w\\o BN 18.7 13.7 38.2(iii) Ours w\\o Conv 20.7 14.9 40.1(iv) Conv 60.6 73.3 77.2(v) CBAM [67] 21.4 15.1 40.9(vi) SE [30] 22.3 16.2 40.5Ours 16.812.136.3 (b) Meta network design (K=5) Model #Block Avg. err WRN-28 (12)CIFAR10-C 3,3,3,3 17.34,4,2,2 17.92,2,4,416.9 WRN-40 (18)CIFAR10-C 4,4,5,5 12.86,6,3,3 13.73,3,6,612.2 WRN-40 (18)CIFAR100-C 4,4,5,5 36.96,6,3,3 38.53,3,6,636.4 (c) # of blocks of each partition (K=4) Table 4. Architecture ablation experiments. (a,b) We compare continual TTA performance on several memory-efficient designs. WRN refers to WideResNet [71] backbone. (c) We report the performance based on different designs of partitioning the model. The value next to the backboneâ€™s name denotes the total number of residual blocks of a model. age. We demonstrate the memory efficiency of our work by using the official code provided by TinyTL [4]. 4.1. Comparisons Comparisons with TTA methods. We compare our ap- proach to competing TTA methods on extensive bench- marks and various pre-trained models. The results of CIFAR10/100-C are detailed in Table 1. The model par- tition factor K are set to 4 and 5. Our approach outperforms existing TTA methods with the lowest memory usage in all pre-trained models. Specifically, in WideResNet-40, our method achieves superior performance while requiring 80% and 58% less memory than CoTTA [66] and EATA [50], re- spectively, which are also designed for continual TTA. Ap- proaches targeting single domain TTA [65, 42, 9] show poor performance due to error accumulation and catastrophic for- getting, as observed in CoTTA. The error rates for each cor- ruption type are provided in Appendix F. Table 2 shows the experiment for ImageNet-C. Two ResNet-50 backbones from RobustBench [11] are lever- aged. Following CoTTA, evaluations are conducted on ten diverse corruption-type sequences. We achieve comparable performance to CoTTA while utilizing 86% and 75% less memory with K=4 and 5, respectively. In addition, we ob- serve that our approach shows superior performance when adopting the model pre-trained with strong data augmenta- tion methods (e.g., Augmix [26]). Comparisons with on-device learning methods.We com- pare our approach with methods for memory-efficient on- device learning. TinyTL [4] and RepNet [69] focus on su- pervised on-device learning ( i.e., requiring labeled target data). However, since TTA assumes that we do not have access to the target labels, utilizing such methods to TTA di- rectly is infeasible. Therefore, we experimented by replac- ing supervised loss ( i.e., cross-entropy) with unsupervised loss (i.e., entropy minimization) in TinyTL and RepNet. As shown in Table 3, they suffer from performance degradation in continual TTA, showing inferior performance compared to our proposed approach even in the single domain TTA. Memory (MB) Avg. error (%)  (0.8%)              CIFAR100-C                      WideResNet-40 K=1 K=2 (3.7%) K=3 (4.3%) K=4 (10.8%) K=5 (11.3%) K=6 (12.8%) K=7 (13.3%) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Figure 4. Ablation study of K. We uniformly divide the encoder of the pre-trained model into the model partition factor K. The x- axis indicates the memory size including both model parameter size and activation size while the y-axis indicates the average error rate. The values in parentheses show the rate of increase for the model parameters compared to the original model. Similar to ours, AuxAdapt [73] adds and updates a small network ( i.e., ResNet-18) while freezing the pre-trained model. Unlike our approach, they only modify a prediction output, not intermediate features. While AuxAdapt requires the least memory usage, it fails to improve TTA performan- ce in single domain TTA. Nevertheless, since the original model is frozen, it suffers less from catastrophic forgetting and error accumulation than TinyTL [4] and RepNet [69] in the continual TTA. Through the results, we confirm that our proposed method brings both memory efficiency and a significant performance improvement in both TTA setups. 4.2. Empirical Study Architecture design. An important design of our meta net- works is injecting a single BN layer before the original net- works and utilizing a residual connection with one conv block. Table 4b studies the effectiveness of the proposed design by comparing it with six different variants. From the results, we observe that using only either conv block (ii) or BN (iii) aggravates the performance: error rate increases by 1.4% and 3.8% on CIFAR-100-C with WideResNet-40. In design (i), we enforce both BN parameters and Conv layers in the meta networks to take the output of the origi- nal networks as inputs. Such a design brings performance drop. We speculate that it is because the original network, 6Gaus.ShotImpu.Defo.Glas.Moti.ZoomSnowFros.Fog Brig.Cont.Elas.Pixe.Jpeg 27.5 30.0 32.5 35.0 37.5 40.0 42.5 45.0 25 26 27 28 29 30 31                                Corruption type in 1 round                                Ours (Clean) TENT (Clean) Ours (Corrupt) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ (a) Catastrophic forgetting effect Corrup&on Error (%) Round (b) Error accumulation effect Figure 5. Regularization ablation experiments. We conduct experiments with WideResNet-40 on CIFAR100-C. (a) We utilize a test set of the CIFAR-100 dataset to measure clean error after adapting to each corruption. Maintaining clean errors at a stable level indicates that our approach helps the model robust to catastrophic forgetting. (b) We simulate a long-term adaptation scenario by repeating 100 rounds of 15 corruption sequences. In the absence of regularization, error accumulation can lead to overfitting (i.e., the case of the error increases exponentially). However, our approach does not suffer from such an error accumulation. We set K to 5 in the above experiments. Batch size 16 8 4 2 1 Non training Source 69.7 69.7 69.7 69.7 69.7 BN Stats Adapt [49] 41.1 50.2 59.9 81.0 99.1 AdaptBN [55] 39.1 41.2 45.2 49.0 54.0 Training Con. TENT [65] 40.9 47.8 58.6 82.2 99.0 Con. TENT+AdaptBN 38.2 40.2 43.2 47.7 52.2 Ours (K=5) 40.0 45.8 63.4 80.8 99.0 Ours (K=5)+AdaptBN36.9 39.3 42.2 46.5 51.8 Table 5. Experiments with small batch sizes. We evaluate all baselines with WideResNet-40 on CIFAR100-C. Con. TENT is the abbreviation for continual TENT. which is not adapted to the target domain, lacks the ability to extract sufficiently meaningful features from the target image. Also, we observed a significant performance degra- dation after removing the residual connection in design (iv). In addition, since attention mechanisms [67, 30] generally have improved classification accuracy, we study how atten- tion mechanisms can further boost TTA performance of our approach in design (v, vi). The results show that it is diffi- cult for the attention module to train ideally in TTA setup using unsupervised learning, unlike when applying it to su- pervised learning. An ablation study on each element of meta networks can be found in Appendix D. Number of blocks in each partition. ResNet [24] consists of multiple residual blocks (e.g., BasicBlock and Bottleneck in Pytorch [54]). For instance, WideResNet-28 has 12 resid- ual blocks. By varying the number of blocks for each part of the original networks, we analyze TTA performance in Ta- ble 4c. We observe that splitting the shallow parts of the en- coder densely (e.g., 2,2,4,4 blocks, from the shallow to the deep parts sequentially) brings more performance gain than splitting the deep layers densely ( e.g., 4,4,2,2 blocks). We suggest that it is because we modify the lower-level feature more as we split shallow layers densely. Our observation is aligned with the finding of previous TTA works [9, 48], which show that updating the shallow layers more than the deep layers improves TTA performance. Number of model partition K. Fig. 4 shows both memory requirement and adaptation performance according to the model partition factor K. With a small K ( e.g., 1 or 2), the intermediate outputs are barely modified, making it difficult to achieve a reasonable level of performance. We achieve the best TTA performance with K of 4 or 5 as adjusting a greater numver of intermediate features. In the meanwhile, we observe that the average error rate is saturated and re- mains consistent when K is set to large values (e.g. 6,7 or 8) even with the increased amount of activations and learnable parameters. Therefore, we set K to 4 and 5. Catastrophic forgetting. We conduct experiments to con- firm the catastrophic forgetting effect (Fig. 5a). Once fin- ishing adaptation to each corruption, we evaluate the model on clean target data ( i.e., test-set of CIFAR dataset) with- out updating the model. For TENT with no regulariza- tion, the error rates for the clean target data ( i.e., clean er- ror (%)) increase gradually, which can be seen as the phe- nomenon of catastrophic forgetting. In contrast, our ap- proach consistently maintains the error rates for the clean target data, proving that our regularization loss effectively prevents catastrophic forgetting. These results indicate that our method can be reliably utilized in various domains, in- cluding the source and target domains. Error accumulation in long-term adaptation. To evalu- ate the error accumulation effect, we repeat all the corrup- tion sequences for 100 rounds. The results are described in Fig. 5b. For TENT, a gradual increase in error rates is ob- served in later rounds, even with small learning rates. For example, TENT [65] with the learning rate of 1e-5 achieves the error rate of 39.7%, and reached its lowest error rate of 36.5% after 8 rounds. However, it shows increased error rate of 38.6% after 100 rounds due to overfitting. It suggests 7Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Round 1 4 7 10 AllMethod Mem. (MB)Brig. Fog Fros. SnowBrig. Fog Fros. SnowBrig. Fog Fros. SnowBrig. Fog Fros. SnowMean Source 280 60.4 54.3 30.0 4.160.4 54.3 30.0 4.160.4 54.3 30.0 4.160.4 54.3 30.0 4.137.2BN Stats Adapt [49]280 69.1 61.0 44.8 39.169.1 61.0 44.8 39.169.1 61.0 44.8 39.169.1 61.0 44.8 39.153.6Continual TENT [65]2721 70.1 62.1 46.1 40.262.2 53.7 44.4 37.950.0 41.5 31.6 26.639.2 32.6 25.3 22.442.9Ours (K=4) 918(66%â†“) 70.262.446.341.970.062.846.542.270.062.846.542.170.162.846.642.255.3 Table 6. Semantic segmentation results in continual test-time adaptation tasks. We conduct experiments on Cityscapes [10] with four weather corruptions [25] applied. The four conditions are repeated ten times to simulate continual domain shifts. All results are evaluated based on DeepLabV3Plus-ResNet-50. that without regularization, TTA methods eventually face overfitting in long-term adaptation [75, 2, 35]. Our method in the absence of regularization (Î» = 0) also causes overfit- ting. On the other hand, when self-distilled regularization is involved (Î» >0), the performance remains consistent even in the long-term adaptation. Small batch size. We examine the scalability of our ap- proach with a TTA method designed for small batches size, named adapting BN statistics (i.e., AdaptBN [55, 72]). When the number of batches is too small, the estimated statistics can be unreliable [55]. Thus, they calibrate the source and target statistics for the normalization of BN lay- ers so as to alleviate the domain shift and preserve the dis- criminative structures. As shown in Table 5, training mod- els with small batch sizes (e.g., 2 or 1) generally increase the error rates. However, such an issue can be addressed by appying AdaptBN to our method. To be more sepcific, we achieve an absolute improvement of 17.9% and 2.2% from Source and AdaptBN, respectively, in the batch size of 1. Number of the source samples for meta networks. Like previous TTA works [9, 42, 34, 40] including EATA [50], our approach requires access to the source data for pre- training our proposed meta networks before model deploy- ment. In order to cope with the situation where we can only make use of a subset of the source dataset, we study the TTA performance of our method according to the number of ac- cessible source samples. The results are specified in Table 7 where we use WideResNet-40. We observe that our method outperforms the baseline model even with small number of training samples ( e.g., 10% or 20%) while showing com- parable performance with excessively small numbers ( e.g. 5%). Note that we still reduce the memory usage of about 51% compared to EATA. 5. Segmentation Experiments We investigate our approach in semantic segmentation. First, we create Cityscapes-C by applying the weather cor- ruptions (brightness, fog, frost, and snow [25]) to the vali- dation set of Cityscapes [10]. Then, to simulate continual distribution shifts, we repeat the four types of Cityscapes-C ten times. In this scenario, we conduct continual TTA using the publicly-available ResNet-50-based DeepLabV3 + [7], which is pre-trained on Cityscapes for domain generaliza- EATA [50] (188MB) # of source samples Target domain Ours(K=5) (92MB) 10k (20%) 5k (10%) 2.5k (5%) CIFAR10-C 13.0 12.1 12.4 12.9 13.1 CIFAR100-C 37.1 36.3 36.4 36.6 37.2 Table 7. Ablation of # of source samples to warm up the meta networks. Before deployment, we pre-trained the meta networks using only a subset of the source dataset (e.g., 20%, 10%, and 5%). The memory usage (MB) of each method is also presented. tion task [8] in semantic segmentation. For TTA, we use the batch size of 2. More details are specified in Appendix C. Results. We report the results based on mean intersection over union (mIoU) in Table 6. It demonstrates that our ap- proach helps to both minimize memory consumption and performs long-term adaptation stably for semantic segmen- tation. Unlike continual TENT, our method avoids catas- trophic forgetting and error accumulation, allowing us to achieve the highest mIoU score while using 66% less mem- ory usage in a continual TTA setup. Additional experiment results can be found in Appendix B. 6. Conclusion This paper proposed a simple yet effective approach that improves continual TTA performance and saves a signifi- cant amount of memory, which can be applied to edge de- vices with limited memory. First, we presented a memory- efficient architecture that consists of original networks and meta networks. This architecture requires much less mem- ory size than the previous TTA methods by decreasing the intermediate activations used for gradient calculations. Sec- ond, in order to preserve the source knowledge and prevent error accumulation during long-term adaptation with noisy unsupervised loss, we proposed self-distilled regularization that controls the output of meta networks not to deviate sig- nificantly from the output of the original networks. With ex- tensive experiments on diverse datasets and backbone net- works, we verified the memory efficiency and TTA perfor- mance of our approach. In this regard, we hope that our efforts will facilitate a variety of studies that make test-time adaptation for edge devices feasible in practice. Acknowledgments. We would like to thank Kyuwoong Hwang, Simyung Chang, and Byeonggeun Kim for their valuable feedback. We are also grateful for the helpful dis- cussions from Qualcomm AI Research teams. 8References [1] Kazuki Adachi, Shinâ€™ya Yamaguchi, and Atsutoshi Kuma- gai. Covariance-aware feature alignment with pre-computed source statistics for test-time adaptation. arXiv preprint arXiv:2204.13263, 2022. 2, 3 [2] Eric Arazo, Diego Ortego, Paul Albert, Noel E Oâ€™Connor, and Kevin McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. In IJCNN, 2020. 2, 3, 4, 8 [3] Kambiz Azarian, Debasmit Das, Hyojin Park, and Fatih Porikli. Test-time adaptation vs. training-time generaliza- tion: A case study in human instance segmentation using keypoints estimation. In WACV Workshops, 2023. 3 [4] Han Cai, Chuang Gan, Ligeng Zhu, and Song Han. Tinytl: Reduce memory, not parameters for efficient on-device learning. In NeurIPS, 2020. 2, 3, 5, 6, 12, 16 [5] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022. 3, 13 [6] Lin Chen, Huaian Chen, Zhixiang Wei, Xin Jin, Xiao Tan, Yi Jin, and Enhong Chen. Reusing the task-specific classifier as a discriminator: Discriminator-free adversarial domain adap- tation. In CVPR, 2022. 3 [7] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation. In ECCV, 2018. 8, 14 [8] Sungha Choi, Sanghun Jung, Huiwon Yun, Joanne T Kim, Seungryong Kim, and Jaegul Choo. Robustnet: Improving domain generalization in urban-scene segmentation via in- stance selective whitening. In CVPR, 2021. 1, 2, 3, 8, 14, 15 [9] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sun- grack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, 2022. 1, 2, 3, 4, 5, 6, 7, 8, 13, 15, 16, 17 [10] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In CVPR, 2016. 8, 14 [11] Francesco Croce, Maksym Andriushchenko, Vikash Se- hwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In NeurIPS Datasets and Benchmarks Track, 2021. 5, 6 [12] Debasmit Das, Shubhankar Borse, Hyojin Park, Kambiz Azarian, Hong Cai, Risheek Garrepalli, and Fatih Porikli. Transadapt: A transformative framework for online test time adaptive semantic segmentation. In ICASSP, 2023. 3 [13] Zhiwei Deng and Olga Russakovsky. Remember the past: Distilling datasets into addressable memories for neural net- works. arXiv preprint arXiv:2206.02916, 2022. 13 [14] Sauptik Dhar, Junyao Guo, Jiayi Liu, Samarth Tripathi, Un- mesh Kurup, and Mohak Shah. A survey of on-device ma- chine learning: An algorithms and learning theory perspec- tive. ACM Transactions on Internet of Things, 2021. 2 [15] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, et al. An image is worth 16x16 words: Trans- formers for image recognition at scale. In ICLR, 2021. 1 [16] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 1, 3 [17] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Robust continual test- time adaptation: Instance-aware bn and prediction-balanced memory. In NeurIPS, 2022. 2, 5, 16, 17 [18] Priya Goyal, Piotr Doll Â´ar, Ross Girshick, Pieter Noord- huis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large mini- batch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017. 16 [19] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, 2004. 2, 15 [20] Ishaan Gulrajani and David Lopez-Paz. In search of lost do- main generalization. In ICLR, 2021. 3 [21] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In ICML, 2017. 13 [22] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÂ´ar, and Ross Girshick. Masked autoencoders are scalable vision learners. In CVPR, 2022. 1 [23] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In CVPR, 2020. 1 [24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 5, 7, 12, 16 [25] Dan Hendrycks and Thomas Dietterich. Benchmarking neu- ral network robustness to common corruptions and perturba- tions. In ICLR, 2019. 5, 8 [26] Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. AugMix: A simple data processing method to improve robustness and uncertainty. In ICLR, 2020. 5, 6, 14 [27] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. In NeurIPS, 2014. 13 [28] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In ICML, 2019. 13 [29] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen- Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. In ICLR, 2022. 13 [30] Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation net- works. In CVPR, 2018. 6, 7 [31] Xuefeng Hu, Gokhan Uzunbas, Sirius Chen, Rui Wang, Ashish Shah, Ram Nevatia, and Ser-Nam Lim. Mixnorm: Test-time adaptation through online normalization estima- tion. arXiv preprint arXiv:2110.11478, 2021. 3 9[32] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier ad- justment module for model-agnostic domain generalization. In NeurIPS, 2021. 1 [33] Vidit Jain and Erik Learned-Miller. Online domain adapta- tion of a pre-trained cascade of classifiers. In CVPR, 2011. 3 [34] Sanghun Jung, Jungsoo Lee, Nanhee Kim, and Jaegul Choo. Cafa: Class-aware feature alignment for test-time adaptation. arXiv preprint arXiv:2206.00205, 2022. 2, 4, 8 [35] Tommie Kerssies, Joaquin Vanschoren, and Mert KÄ±lÄ±c Â¸kaya. Evaluating continual test-time adaptation for contextual and semantic domain shifts. arXiv preprint arXiv:2208.08767 , 2022. 3, 4, 8 [36] Ansh Khurana, Sujoy Paul, Piyush Rai, Soma Biswas, and Gaurav Aggarwal. Sita: Single image test-time adaptation. arXiv preprint arXiv:2112.02355, 2021. 3 [37] Andreas Krause, Pietro Perona, and Ryan Gomes. Discrim- inative clustering by regularized information maximization. In NeurIPS, 2010. 15 [38] Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, and Sanja Fidler. Semantic segmentation with generative models: Semi-supervised learning and strong out-of-domain generalization. In CVPR, 2021. 1 [39] Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan, and Ling-Yu Duan. Uncertainty modeling for out-of- distribution generalization. In ICLR, 2022. 3 [40] Hyesu Lim, Byeonggeun Kim, Jaegul Choo, and Sungha Choi. TTN: A domain-shift aware batch normalization in test-time adaptation. In ICLR, 2023. 2, 3, 4, 8, 13, 16 [41] Ji Lin, Wei-Ming Chen, Yujun Lin, Chuang Gan, Song Han, et al. Mcunet: Tiny deep learning on iot devices. InNeurIPS, 2020. 3 [42] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In NeurIPS, 2021. 1, 2, 3, 5, 6, 8, 13, 16, 17 [43] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation with residual trans- fer networks. In NeurIPS, 2016. 1 [44] David Lopez-Paz and Marcâ€™Aurelio Ranzato. Gradient episodic memory for continual learning. In NeurIPS, 2017. 13 [45] Robert A Marsden, Mario D Â¨obler, and Bin Yang. Gradual test-time adaptation by self-training and style transfer. arXiv preprint arXiv:2208.07736, 2022. 3 [46] Ke Mei, Chuang Zhu, Jiaqi Zou, and Shanghang Zhang. In- stance adaptive self-training for unsupervised domain adap- tation. In ECCV, 2020. 3 [47] Rafael M Â¨uller, Simon Kornblith, and Geoffrey E Hinton. When does label smoothing help? In NeurIPS, 2019. 13 [48] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and Jan Hendrik Metzen. Test-time adaptation to distribution shift by confi- dence maximization and input transformation.arXiv preprint arXiv:2106.14999, 2021. 3, 4, 7 [49] Zachary Nado, Shreyas Padhy, D Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robust- ness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. 5, 7, 8, 16, 17 [50] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, 2022. 2, 3, 4, 5, 6, 8, 12, 13, 14, 15, 16, 17 [51] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In ICLR, 2023. 3 [52] Xingang Pan, Ping Luo, Jianping Shi, and Xiaoou Tang. Two at once: Enhancing learning and generalization capacities via ibn-net. In ECCV, 2018. 3 [53] Kwanyong Park, Sanghyun Woo, Inkyu Shin, and In So Kweon. Discover, hallucinate, and adapt: Open compound domain adaptation for semantic segmentation. In NeurIPS, 2020. 3 [54] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, and et al. Lin. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, 2019. 7, 12, 16 [55] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. 7, 8, 16 [56] Inkyu Shin, Dong-Jin Kim, Jae Won Cho, Sanghyun Woo, Kwanyong Park, and In So Kweon. Labor: Labeling only if required for domain adaptive semantic segmentation. In ICCV, 2021. 3 [57] Inkyu Shin, Yi-Hsuan Tsai, Bingbing Zhuang, Samuel Schulter, Buyu Liu, Sparsh Garg, In So Kweon, and Kuk- Jin Yoon. Mm-tta: Multi-modal test-time adaptation for 3d semantic segmentation. In CVPR, 2022. 2, 3 [58] Inkyu Shin, Sanghyun Woo, Fei Pan, and InSo Kweon. Two- phase pseudo label densification for self-training based do- main adaptation. In ECCV, 2020. 3 [59] Junha Song, Kwanyong Park, Inkyu Shin, Sanghyun Woo, Chaoning Zhang, and In So Kweon. Test-time adaptation in the dynamic world with compound domain knowledge man- agement. arXiv preprint arXiv:2212.08356, 2023. 3 [60] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 2014. 13 [61] Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele. Meta-transfer learning for few-shot learning. InCVPR, 2019. 13 [62] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, 2020. 3 [63] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NeurIPS, 2017. 3 [64] Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Mathieu Cord, and Patrick PÂ´erez. Advent: Adversarial entropy mini- 10mization for domain adaptation in semantic segmentation. In CVPR, 2019. 3 [65] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 16, 17 [66] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Con- tinual test-time domain adaptation. In CVPR, 2022. 1, 2, 3, 4, 5, 6, 12, 13, 14, 16, 17 [67] Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module. In ECCV, 2018. 6, 7 [68] Li Yang, Adnan Siraj Rakin, and Deliang Fan. Da3: Dy- namic additive attention adaption for memory-efficient on- device multi-domain learning. In CVPR Workshops, 2022. 3 [69] Li Yang, Adnan Siraj Rakin, and Deliang Fan. Rep-net: Efficient on-device learning via feature reprogramming. In CVPR, 2022. 2, 3, 5, 6, 16 [70] Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. 3 [71] Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In BMVC, 2016. 5, 6, 12 [72] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. In NeurIPS, 2021. 3, 8 [73] Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In WACV, 2022. 5, 6, 16 [74] Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, and Lei Zhang. Exact feature distribution matching for arbitrary style transfer and domain generalization. In CVPR, 2022. 3 [75] Zixing Zhang, Fabien Ringeval, Bin Dong, Eduardo Coutinho, Erik Marchi, and BjÂ¨orn SchÂ¨uller. Enhanced semi- supervised learning for multimodal emotion recognition. In ICASSP, 2016. 2, 3, 4, 8 [76] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 3 11Appendix In this supplementary material, we provide, A. Efficiency for TTA methods B. Discussion and further experiments C. Further implementation details D. Additional ablations E. Baseline details F. Results of all corruptions A. Efficiency for TTA methods Memory efficiency. Existing TTA works [65, 50, 66] up- date model parameters to adapt to the target domain. This process inevitably requires additional memory to store the activations. Fig. 6 describes Eq. (1) of the main paper in more detail. For instance, 1) the backward propagation from the layer (c) to the layer ( b) can be accomplished without saving intermediate activations fi and fi+1, since it only re- quires âˆ‚L âˆ‚fi+1 =âˆ‚L âˆ‚LWT i+1 and âˆ‚L âˆ‚fi = âˆ‚L âˆ‚fi+1 WT i =âˆ‚L âˆ‚LWT i+1WT i op- erations. 2) During the forward propagation, the learnable layer (a) has to store the intermediate activation fiâˆ’1 to cal- culate the weight gradient âˆ‚L âˆ‚Wiâˆ’1 =fT iâˆ’1 âˆ‚L âˆ‚fi . : freeze: update â„’ðœ•â„’ðœ•â„’ðœ•â„’ðœ•ð‘“!\"#ðœ•â„’ðœ•ð‘“!ðœ•â„’ðœ•ð‘“!$# ð’‡ð’Š$ðŸ ð‘“! ð‘“!\"#ð‘Š!$#,ð‘!$# ð‘Š!,ð‘! ð‘Š!\"#,ð‘!\"#(ð‘Ž) (ð‘) (ð‘)ðœ•â„’ðœ•ð‘“!=ðœ•â„’ðœ•ð‘“!\"#ð‘Š!' ðœ•â„’ðœ•ð‘“!\"#=ðœ•â„’ðœ•â„’ð‘Š!\"#'ðœ•â„’ðœ•ð‘“!$#=ðœ•â„’ðœ•ð‘“!ð‘Š!$#'ðœ•â„’ðœ•ð‘Š!$#=ð’‡ð’Š$ðŸð‘»ðœ•â„’ðœ•ð‘“! ð‘“!\"#=ð‘“!ð‘Š!+ð‘!ðœ•â„’ðœ•ð‘!$#=ðœ•â„’ðœ•ð‘“! Figure 6. Forward and backward propagation. The black and red lines refer to forward and backward propagation, respectively. f and (a, b, c) are the activations and the linear layers, respectively. Computational efficiency. Wall-clock time and floating point operations (FLOPs) are standard measures of com- putational cost. We utilize wall-clock time to compare the computational cost of TTA methods since most libraries computing FLOPs only support inference, not training. Unfortunately, wall-clock time of EATA [50] and our ap- proach can not truly represent its computational efficiency since the current Pytorch version [54] does not support fine-grained implementation [4]. For example, EATA fil- ters samples to improve its computational efficiency. How- ever, its gradient computation is performed on the full mini- batch, so the wall-clock time for backpropagation in EATA is almost the same as that of TENT [65]. In our approach, our implementation follows Algorithm 1 to make each reg- ularization loss Rk Î¸k applied to parameters of k-th group of meta networks Î¸k in Eq. (3). In order to circumvent such an issue, the authors of EATA report the theoretical time, which assumes that PyTorch handles gradient back- propagation at an instance level. Similar to EATA, we also report both theoretical time and wall-clock time in Ta- ble 8. To compute the theoretical time of our approach, we simply subtract the time for re-forward (in Algorithm 1) from wall-clock time. We emphasize that this is mainly an engineering-based issue, and the optimized implementation can further improve computational efficiency. [50]. Using a single NVIDIA 2080Ti GPU, we measure the total time required to adapt to all 15 corruptions, includ- ing the time to load test data and perform TTA. The results in Table 8 show that our proposed method requires neg- ligible overhead compared to CoTTA [66]. For example, CoTTA needs approximately 10 times more training time than Continual TENT [65] with WideResNet-40. Note that meta networks enable our approach to use 80% and 58% less memory than CoTTA and EATA, even with such minor extra operations. B. Discussion and further experiments Comparison on gradually changing setup. In Table 1 and Table 2, we evaluate all methods on the continual TTA task, proposed in CoTTA [66] and EATA [50], where we continually adapt the deployed model to each cor- ruption type sequentially. Additionally, we conduct ex- periments on the gradually changing setup. This grad- WideResNet-40 [71] Avg. err Mem. (MB) Theo. time Wall time Source 69.7 11 - 40s Con. TENT [65] 38.3 188 - 2m 18s CoTTA [66] 38.1 409 - 22m 52s EATA [50] 37.1 188 2m 8s 2m 22s Ours (K=4) 36.4 80(80, 58%â†“) 2m 27s 2m 49s Ours (K=5) 36.3 92(77, 51%â†“) 2m 31s 2m 52s ResNet-50 [24] Avg. err Mem. (MB) Theo. time Wall time Source 73.8 91 - 1m 8s Con. TENT [65] 45.9 926 - 4m 2s CoTTA [66] 40.2 2064 - 38m 24s EATA [50] 39.9 926 3m 45s 4m 15s Ours (K=4) 39.5 296(86, 68%â†“) 4m 16s 4m 41s Ours (K=5) 39.3 498(76, 46%â†“) 4m 26s 5m 14s Table 8. Comparison of training time on CIFAR100-C. We re- port both theoretical time (in short, theo. time) and wall-clock time, taking to adapt to all 15 corruption types. Theoretical time is calculated by assuming that the ML frameworks ( e.g., Py- torch [54]) provide fine-grained implementations [4]. Con. TENT refers to continual TENT. 12Algorithm 1: PyTorch-style pseudocode for EcoTTA. # img_t: test image # model: original and meta networks # # ent_min(): Entropy minimization loss # Detach_parts(): Detach the graph connection # between each partition of networks # Attach_parts(): Attach the graph connection # between each partition of networks for img_t in test_loader: # 1. Forward output = model(img_t) # 2. Compute entropy loss loss_ent = ent_min(output) loss_ent.backward() # 3. Re-forward # (This process is not required # in fine-grained ML frameworks.) Detach_parts(model) _ = model(img_t) # 4. Compute regularization loss reg_loss = 0 for k_th_meta in meta_networks: reg_loss += k_th_meta.get_l1_loss() reg_loss.backward() # 5. Update params of meta networks optim.step() optim.zero_grad() Attach_parts(model) ual setup, proposed in CoTTA, represents the sequence by gradually changing severity for the 15 corruption types: . . .2âˆ’ â†’1| {z } t-1 and before change âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ type 1âˆ’ â†’2âˆ’ â†’3âˆ’ â†’4âˆ’ â†’5âˆ’ â†’4âˆ’ â†’3âˆ’ â†’2âˆ’ â†’1| {z } corruption type t, gradually changing severity change âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ type 1âˆ’ â†’2. . .| {z } t+1 and on , The results in Table 9 indicate that our approach outper- forms previous TTA methods [65, 50, 66] even with the gradually changing setup. Comparisons with methods for parameter efficient transfer learning. While our framework may be similar to parameter-efficient transfer learning (PETL) [29, 28, 61] in that only partial parameters are updated during training time for PETL or test time for TTA, we utilized meta net- works to minimize intermediate activations, which is crucial for memory-constrained edge devices. We conduct experi- ments by applying a PETL method [28] to the TTA setup. The adapter module is constructed by using 3x3 Conv and ReLU layers as the projection layer and the nonlinearity, re- spectively, and these modules are attached after each resid- ual block of the backbone networks. The Table 10 shows that PETA+SDR needs a 177% increase in memory usage with a 6.1% drop in performance, compared to our method. Comparisons with methods for continual learning. Typ- ical continual learning (CL) and continual TTA assume su- pervised and unsupervised learning, respectively. However, since both are focused on alleviating catastrophic forget- ting, we believe that CL methods can also be applied in continual TTA settings. The methods for addressing catas- trophic forgetting can be divided into regularization- and Method Con. TENT [65] EATA [50] CoTTA [66]Ours (K=4) Avg. err (%) 38.5 31.8 32.5 31.4 Mem. (MB) 188 188 409 80(58, 80%â†“) Table 9. Comparision on gradually changing setup. To con- duct experiments, we use WRN-40 backbone on CIFAR100-C. The values in parentheses refer to memory reduction rates com- pared to TENT/EATA and CoTTA, sequentially. Method Con. TENT [65]PETL [28] PETL+SDROurs (K=4) Avg. err (%)38.3 73.3 42.5 36.4Mem. (MB) 188 141 141 80 Table 10. Comparisons with methods for PETL. We com- pare our method with methods [28] for parameter-efficient trans- fer learning (PETL) with WRN-40 on CIFAR100-C. PETL+SDR refers to PETL with our proposed self-distilled regularization. RoundCon. TENTTS DO LS KD Ours (K=4) 1 38.3 37.4 41.0 38.4 39.8 36.410 99.0 96.1 96.3 41.1 40.4 36.3 Table 11. Comparisons with methods for continual learning. We report an average error rate (%) of 15 corruptions using WRN- 40 on CIFAR100-C. In the table, TS: Entropy minimization with temperature scaling [21], DO: Dropout [60], LS: Label smoothing with the pseudo label [47], and KD: Knowledge distillation [27]. replay-based methods. The former can be subdivided into weight regularization ( e.g., CoTTA [66] and EATA [50]) and knowledge distillation [27], while the latter includes GEM [44] and dataset distillation [13]. Suppose dataset dis- tillation is applied to the continual TTA setup; for example, we can periodically replay synthetic samples distilled from the source dataset to prevent the model from forgetting the source knowledge during TTA. Notably, our self-distilled regularization (SDR) is superior to conventional CL meth- ods in terms of the efficiency of TTA in on-device settings. Specifically, unlike previous regularization- or replay-based methods, we do not require storing a copy of the original model or a replay-and-train process. To further compare our SDR with existing regulariza- tion methods, we conduct experiments while keeping our architecture and adaptation loss but replacing SDR with other regularizations, as shown in Table 11. The results demonstrate that our SDR achieves superior performance compared to other regularizations. In addition, Knowledge distillation [27] alleviates the error accumulation effect in long-term adaptation ( e.g., round 10), while showing lim- ited performance for adapting to the target domain. Superiority of our approach compared to existing TTA methods. Our work focuses on proposing an efficient ar- chitecture for continual TTA, which has been overlooked in previous TTA studies [65, 66, 5, 42, 9, 40] by introduc- ing meta networks and self-distilled regularization, rather than adaptation loss such as entropy minimization proposed 13Method Mem. (MB) Round 1 Round 4 Round 7 Round 10 Source 280 37.2 37.2 37.2 37.2Con. TENT 2721 54.6 49.6 37.4 29.9Con. TENT* 2721 56.5 52.7 42.7 36.5CoTTA* 6418 56.7 56.7 56.7 56.7Ours 918(66, 85%â†“) 55.2 55.4 55.4 55.4Ours* 918(66, 85%â†“) 56.7 56.8 56.9 56.9 Table 12. Further experiments in semantic segmentation. We represent the results based on mean intersection over union (mIoU). * means that the method utilizes the same cross-entropy consistency loss. The values in parentheses refer to memory re- duction rates compared to TENT/EATA and CoTTA, sequentially. #Partitions WRN-28 (12) WRN-40 (18) ResNet-50 (16) K=4 2,2,4,4 3,3,6,6 3,3,5,5 K=5 2,2,2,2,4 3,3,3,3,6 2,2,4,4,4 Table 13. Details of # of blocks of each partition. The list of numbers denotes the number of residual blocks for each part of the original networks, from the shallow to the deep parts sequentially. The values in parentheses are the total number of residual blocks. in TENT [65] and EATA [50]. Thus, our method can be used with various adaptation losses. Moreover, even though our self-distilled regularization can be regarded as a teacher-student distillation from original networks to meta networks, it does not require a large activation size or the storage of an extra source model, unlike CoTTA [66]. In addition to the results in Table 6, we improve the segmentation experiments by comparing our approach with CoTTA [66]. As we aforementioned, our approach has scalability with diverse adaptation loss. Thus, as shown in Table 12, we additionally apply cross-entropy consis- tency loss* with multi-scaling input as proposed in CoTTA, where we use the multi-scale factors of [0.5, 1.0, 1.5, 2.0] and flip. Our method not only achieves comparable per- formance with 85% less memory than CoTTA, but shows consistent performance even for multiple rounds while con- tinual TENT [65] suffers from the error accumulation effect. C. Further implementation details Partition of a pre-trained model. As illustrated in Fig. 3, the given pre-trained model consists of three parts: clas- sifier, encoder, and input conv, where the encoder denotes layer1 to 4 in the case of ResNet. Our method is applied to the encoder and we divide it into K parts. Table 13 describes the details of the number of residual blocks for each part of the encoder. Our method is designed to divide the shallow layers more (i.e., densely) than the deep layers, improving the TTA performance as shown in Table 4c. Convolution layer in meta networks. As the hyperparam- eters of the convolution layer1, we set the bias to false and 1https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html (K=4) Kernel size= 1, padding=0Kernel size=3, padding=1 Arch Avg. err paramsâ†‘ Mem. Avg. err paramsâ†‘ Mem. WRN-28 17.2 0.8% 396 16.9 9.5% 404 WRN-40 12.4 0.6% 80 12.2 6.4% 80 ResNet-50 14.4 11.8% 296 14.2 142.2% 394 Table 14. Kernel size in the conv layer.We report the average er- ror rate (%), the increase rate of the model parameters compared to the original model (%), and the total memory consumption (MB) including the model and activation sizes, based on the kernel size of the conv layer in meta networks. (K=4) Transformations Dataset Arch EATA [50]None +Color +Blur +Gray CIFAR10-C WRN-40 13.0 12.5 12.3 12.3 12.2 CIFAR10-C WRN-28 18.6 17.8 17.4 17.2 16.9 CIFAR100-C WRN-4037.1 36.9 36.7 36.6 36.4 Table 15. Ablation of the combination of transformations. To warm up the meta networks, we use the following transformations in Pytorch: ColorJitter (Color), GaussianBlur (Blur), and Ran- domGrayscale (Gray). We report the average error rate (%). the stride to two if the corresponding part of the encoder in- cludes the stride of two; otherwise, one. As shown in the gray area in Table 14, we conduct experiments by modify- ing the kernel size and padding for each architecture. To be more specific, we obtain better performances by setting the kernel size to three with WideResNet (with 10% additional number of model parameters). On the other hand, utilizing the kernel size of three with ResNet leads to significant in- creases in parameters and memory sizes. Thus, we use one and three as the kernel size with ResNet and WideResNet, respectively. Warming up meta networks. Before the model deploy- ment, we warm up meta networks with the source data by applying the following transformations, which prevent the meta networks from being overfitted to the source domain. Regardless of the pre-trained modelâ€™s architecture and pre-training method, we use the same transformations to warm up meta networks. Even for WideResNet-40 pre- trained with AugMix [26], a strong data augmentation tech- nique, the following simple transformations are enough to warm up the meta networks. In addition, we provide the ablation of the combination of transformations in Table 15. from t o r c h v i s i o nimport t r a n s f o r m s a s T TRANSFORMS = t o r c h . nn . S e q u e n t i a l ( RandomApply ( T . C o l o r J i t t e r ( 0 . 4 , 0 . 4 , 0 . 4 , 0 . 1 ) , p = 0 . 4 ) RandomApply ( T . G a u s s i a n B l u r ( ( 3 , 3 ) , p = 0 . 2 ) T . RandomGrayscale ( P = 0 . 1 ) ) Semantic segmentation. For semantic segmentation exper- iments, we utilize ResNet-50-based DeepLabV3+ [7] from RobustNet repository2 [8]. We warm up the meta networks on the train set of Cityscapes [10] with SGD optimizer with the learning rate of 5e-2 and the epoch of 5. Image trans- 2https://github.com/shachoi/RobustNet 14: freeze : update â„’ ðœ•â„’ ðœ•â„’ ðœ•â„’ ðœ•ð‘“ð‘–+1 ðœ•â„’ ðœ•ð‘“ð‘– ðœ•â„’ ðœ•ð‘“ð‘–âˆ’1 ð‘“ð‘–âˆ’1 ð‘“ð‘– ð‘“ð‘–+1 ð‘Š1,ð‘1 ð‘Š2,ð‘2 ð‘Š3,ð‘3 ð¿1 ð¿2 ð¿3 Appendix entropy min. ð·ð‘¡ à·¤ð‘¥ð‘˜âˆ’1 ð‘¥ð‘˜ bn à·¤ð‘¥ð‘˜ relu bn conv Affine tra. Standard. â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ ï¿½ (a) Visualization of meta networks (K=5) CIFAR10-CWRN-28CIFAR10-CWRN-40CIFAR100-CWRN-40Variants1 2 3 4 5 6 7I âœ“ âœ“ âœ“ âœ“ âœ“19.9 15.4 39.2II âœ“ âœ“ âœ“ âœ“ âœ“18.6 13.4 38.0III âœ“ âœ“ âœ“ âœ“18.7 13.7 38.2IV âœ“ âœ“ âœ“ âœ“ âœ“18.6 12.4 36.7V âœ“ âœ“ âœ“ âœ“ âœ“19.8 12.9 37.2VI âœ“ âœ“ âœ“ âœ“ 32.3 14.5 51.8VIIâœ“ âœ“ âœ“ 20.7 14.9 40.1XIIIâœ“ âœ“ âœ“ âœ“ âœ“ âœ“18.1 12.6 37.2IX âœ“ âœ“ âœ“ âœ“60.6 73.3 77.2Oursâœ“âœ“âœ“âœ“âœ“ âœ“ 16.8 12.1 36.3 (b) Comparison of average error rate (%) on continual TTA setup (K=5) Table 16. Components of meta networks. We conduct an ablation study on components of meta networks ( i.e., 1âƒ âˆ¼7âƒ). Here, 1âƒ and 2âƒ refer to affine transformation and standardization in a BN layer after the original networks. 3âƒâˆ¼ 5âƒ and 6âƒâˆ¼ 7âƒ, respectively, indicate modules in a convolution block and two kinds of inputs of it. In table (b), âœ“ means applying the component to meta networks. formations follow the implementation details of [8]. After model deployment, we perform TTA using SGD optimizer with the learning rate of 1e-5, the image size of 1600Ã—800, the batch size of 2, and the importance of regularizationÎ» of 2. The main loss for adaptation is same as Lent in Eq. (2). D. Additional ablations Main task loss for adaptation. To adapt to the target do- main effectively, selecting the main task loss for adaptation is a non-trivial problem. So, we conduct a comparative experiment on three types of adaptation loss: L1) entropy minimization [19], L2) entropy minimization with mean en- tropy maximization [37], and L3) filtering samples using entropy minimization [50]. With a mini-batch of N test im- ages, the three adaptation losses are formulated as follows: L1 = 1 N NX i=1 H(Ë†yi), (5) L2 = Î»m1 1 N NX i=1 H(Ë†yi) âˆ’ Î»m2 H(y), (6) L3 = 1 N NX i=1 I{H(Ë†yi)<H0} Â· H(Ë†yi), (7) where Ë†yi is the logits output of i-th test data, y = 1 N PN i=1 p(Ë†yi), H(y) = âˆ’P C p(y) logp(y), p( Â·) is the softmax function, C is the number of classes, and I{Â·} is an indicator function. Î»m1 and Î»m2 indicate the importance of each term in Eq. (6) which are set to 0.2 and 0.25, respec- tively, following SWR&NSP [9]. The entropy thresholdH0 is set to 0.4 Ã— ln C following EATA [50]. The results are described in Table 17. Particularly, apply- ing any of the three losses, our method achieves comparable performance to EATA. Among them, using L3 of Eq. (7) achieves the lowest error rate in most cases. Therefore, we apply L3 to our approach as mentioned in Section 3.1. Components of meta networks. As shown in Table 16, we (K=5) Ours Dataset Arch EATA[50] L1 L2 L3 CIFAR10-C WRN-28 18.6 17.3 16.9 16.9 WRN-40 13.0 12.2 12.3 12.1 Resnet-50 14.2 15.0 14.3 14.1 CIFAR100-C WRN-40 37.1 36.5 36.4 36.3 Resnet-50 39.9 40.7 38.8 39.4 Table 17. Ablation study of main task loss. We compare the average error rate (%) of three types of adaptation losses. (K=5) Ours Dataset Arch MSE loss (Eq. (8))L1 loss (Eq. (4)) CIFAR10-C WRN-28 16.9 16.9 WRN-40 12.3 12.1 Resnet-50 14.1 14.1 CIFAR100-CWRN-40 36.6 36.3 Resnet-50 39.5 39.4 Table 18. Ablation study of loss function of our regularization. We present the average error (%) according to two types of loss functions for self-distilled regularization. conduct an ablation study on each element of our proposed meta networks. We observe that the affine transformation is more critical than standardization in a BN layer after the original networks. Specifically, removing the standardiza- tion (variant II) causes less performance drop than remov- ing the affine transformation (variant I). In addition, using only a conv layer in conv block (variant VI) also cause per- formance degradation, so it is crucial to use the ReLU and BN layers together in the conv block. Loss function choice of our regularization.As mentioned in Section 3.2, self-distilled regularization loss computes the mean absolute error ( i.e., L1 loss) of Eq. (4). This loss regularizes the output Ëœxk of each k-th group of the meta networks not to deviate from the outputxk of each k-th part of frozen original networks. The mean squared error ( i.e., MSE loss) also can be used to get a similar effect which is defined as: MSE = (Ëœxk âˆ’ xk)2. (8) 15We compare two kinds of loss functions for our regular- ization in Table 18. By observing a marginal performance difference, our method is robust to the loss function choice. Robustness to the importance of regularization Î». We show that our method is robust to the regularization term Î». We conduct experiments using a wide range of Î» as shown in Fig. 5 and the following table. Round\\Î» 0 0.1 0.5 1 2 5 10 1 36.31 36.30 36.29 36.56 37.20 38.41 39.58 10 55.47 43.83 36.42 36.14 36.48 37.47 38.95 The experiments are performed with WideResNet-40 on CIFAR100-C. When Î» is changed from 0.5 to 1, the per- formance difference was only 0.27% in the first round. We also test Î» to be extremely large ( e.g., 5, 8, and 10). Since setting Î» to 10 may mean that we hardly adapt the meta net- works to the target domain, the error rate (39.58%) with Î» of 10 was close to the one (41.1%) of BN Stats Adapt [49]. E. Baseline details E.1. TTA works We refer to the baselines for which the code was of- ficially released: TENT 3, TTT++4, CoTTA5, EATA6, and NOTE7. We did experiments on their code by adding the needed data loader or pre-trained model loader. In this sec- tion, implementation details of the baselines are provided. BN Stats Adapt [49] is one of the non-training TTA ap- proaches. It can be implemented by setting the model to the train mode8 of Pytorch [54] during TTA. TTT+++ [42] was originally implemented as the offline adaptation, i.e., multi-epoch training. So, we modified their setup to continual TTA. We further tuned the learn- ing rate as 0.005 and 0.00025 for adapting to CIFAR10-C and CIFAR100-C, respectively. NOTE [17] proposed the methods named IABN and PBRS with taking account of temporally correlated target data. However, our experiments were conducted with target data that was independent and identically distributed (i.i.d.). Hence, we adapted NOTE-i.i.d ( i.e., NOTE* in their git repository), which is a combination of TENT [65] and IABN without using PBRS. We fine-tuned the Î± of their main paper ( i.e., self.k in the code 9) to 8 and the learning rate to 1e-5. Others (e.g., TENT [65], SWR&NSP [9], CoTTA [66], and EATA [50]). We utilized the best hyperparameters specified in their paper and code. In the case where the batch size of 3https://github.com/DequanWang/tent 4https://github.com/vita-epfl/ttt-plus-plus 5https://github.com/qinenergy/cotta 6https://github.com/mr-eggplant/EATA 7https://github.com/TaesikGong/NOTE 8pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train 9https://github.com/TaesikGong/NOTE/blob/main/utils/iabn.py their works (e.g., 200 and 256) differs from one for our ex- periments (e.g., 64), we decreased the learning rate linearly based on the batch size [18]. AdaptBN [55]. We set the hyperparameter N of their main paper to 8. When AdaptBN is employed alongside TENT or our approach, we set the learning rate to 1e-5 or 5e-6 [40]. E.2. On-device learning works To unify the backbone network as ResNet-50 [24], we reproduced the following works by referencing their paper and published code: TinyTL 10, Rep-Net11, and AuxAdapt. This section presents additional implementation details for reproducing the above three works. TinyTL [4]. We attach the LiteResidualModules 12 to layer1 to 4 in the case of ResNet-50 13. As the hyperpa- rameters of the LiteResidualModules, the hyperparameter expand is set to 4 while the other hyperparameters follow the default values. Rep-Net [69]. We divide the encoder of ResNet-50 into six parts, as each part of the encoder has 2,2,3,3,3,3 resid- ual blocks (e.g., BasicBlock or Bottleneck in Pytorch) from the shallow to the deep parts sequentially. Then, we connect the ProgramModules14 to each corresponding part of the en- coder. For the ProgramModule, we set the hyperparameter expand to 4 while the rest hyperparameters are used as their default values. We copy the input conv of ResNet-50 and make use of it as the input conv of Rep-Net. AuxAdapt [73]. We use ResNet-18 as the AuxNet. We create pseudo labels by fusing the logits output of ResNet- 50 and ResNet-18, and optimize all parameters of ResNet- 18 using the pseudo labels with cross-entropy loss. Warming up the additional modules. Before model de- ployment, we pre-train the additional modules ( i.e., the LiteResidualModule of TinyTL [4], the ProgramModule of Rep-Net [69], and the AuxNet of AuxAdapt [73]) on the source data using the same strategy warming up the meta networks as mentioned in Section C. F. Results of all corruptions We report the error rates (%) of all corruptions on con- tinual TTA and memory consumption (MB) including the model parameters and activations in Table 19 and Table 20. These tables contain additional details to Table 1. 10https://github.com/mit-han-lab/tinyml/tree/master/tinytl 11https://github.com/ASU-ESIC-FAN-Lab/RepNet 12https://github.com/mit-han-lab/tinyml/blob/master/tinytl/tinytl/model/modules.py 13https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py 14github.com/ASU-ESIC-FAN-Lab/RepNet/blob/master/repnet/model/reprogram.py 16Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Arch Method Gaus. Shot Impu. Defo. Glas. Moti. Zoom Snow Fros. Fog Brig. Cont. Elas. Pixe. JpegAvg. err Mem. WRN-40(AugMix) Source 44.3 37.0 44.8 30.6 43.9 32.6 29.4 23.9 30.1 39.7 12.9 66.4 32.7 58.4 23.5 36.7 11tBN [49] 19.5 17.6 23.8 9.6 23.1 11.1 10.3 13.4 14.2 15.0 8.0 13.9 17.3 16.0 18.8 15.4 11Single do. TENT [65]16.4 13.9 19.1 8.3 19.1 9.3 8.6 10.9 11.3 12.0 6.9 11.6 14.6 12.2 15.6 12.7 188TENT continual [65]16.4 12.2 17.1 9.1 18.7 11.4 10.4 12.7 12.4 14.8 10.1 13.0 17.0 13.3 19.0 13.3 188TTT++ [42] 19.1 16.9 22.2 9.3 21.6 10.8 9.8 12.7 13.1 14.3 7.8 13.9 15.9 14.2 17.2 14.6 391SWRNSP [9] 15.9 13.3 18.2 8.4 18.5 9.5 8.6 11.0 10.2 11.7 7.0 8.1 14.6 11.3 15.1 12.1 400NOTE [17] 19.6 16.4 19.9 9.4 20.3 10.3 10.1 11.6 10.6 13.3 7.9 7.7 15.4 12.0 17.3 13.4 188EATA [50] 15.2 13.1 17.5 9.5 19.9 11.6 9.3 11.4 11.5 12.4 7.8 11.1 16.1 12.2 16.1 13.0 188CoTTA [66] 15.6 13.6 17.3 9.8 19.0 11.0 10.2 13.5 12.6 17.4 7.8 17.3 16.2 12.9 16.0 14.0 409Ours (K=4) 16.1 13.2 18.3 8.0 18.3 9.3 8.6 10.5 10.1 12.2 6.8 11.3 14.5 11.0 14.8 12.2 80Ours (K=5) 15.9 12.6 17.2 8.2 18.4 9.3 8.6 10.6 10.4 12.4 6.7 11.7 14.3 11.3 14.9 12.1 92 WRN-28 Source 72.3 65.7 72.9 46.9 54.3 34.8 42.0 25.1 41.3 26.0 9.3 46.7 26.6 58.5 30.3 43.5 58tBN [49] 28.6 26.8 37.0 13.2 35.4 14.4 12.6 18.0 18.2 16.0 8.6 13.3 24.0 20.3 27.8 20.9 58Single do. TENT [65]25.2 23.8 33.5 12.8 32.3 14.1 11.7 16.4 17.0 14.4 8.4 12.2 22.8 18.0 24.8 19.2 646Continual TENT [65]25.2 20.8 29.8 14.4 31.5 15.4 14.2 18.8 17.5 17.3 10.9 14.9 23.6 20.2 25.6 20.0 646TTT++ [42] 27.9 25.8 35.8 13.0 34.3 14.2 12.2 17.4 17.6 15.5 8.6 13.1 23.1 19.6 26.6 20.3 1405SWRNSP [9] 24.6 20.5 29.3 12.4 31.1 13.0 11.3 15.3 14.7 11.7 7.8 9.3 21.5 15.6 20.3 17.2 1551NOTE [17] 30.4 26.7 34.6 13.6 36.3 13.7 13.9 17.2 15.8 15.2 9.1 7.5 24.1 18.4 25.9 20.2 646EATA [50] 23.8 18.8 27.3 13.9 29.7 16.0 13.3 18.0 16.9 15.7 10.5 12.2 22.9 17.1 23.0 18.6 646CoTTA [66] 24.6 21.6 26.5 12.1 28.0 13.0 10.9 15.3 14.6 13.6 8.1 12.2 20.0 14.9 19.5 17.0 1697Ours (K=4) 23.5 19.0 26.6 11.5 30.6 13.1 10.9 15.2 14.5 13.1 7.8 11.4 20.9 15.4 20.8 16.9 404Ours (K=5) 23.8 18.7 25.7 11.5 29.8 13.3 11.3 15.3 15.0 13.0 7.9 11.3 20.2 15.1 20.5 16.8 471 Resnet-50 Source 65.6 60.7 74.4 28.9 79.9 46.0 25.7 35.0 49.4 54.7 13.0 83.2 41.2 46.7 27.7 48.8 91tBN [49] 18.0 17.2 29.3 10.7 27.2 15.5 8.9 16.7 14.6 21.0 9.3 12.7 20.9 12.4 14.8 16.6 91Single do. TENT [65]16.6 15.7 25.7 10.0 24.8 13.8 8.3 14.9 13.8 17.6 8.7 10.0 19.1 11.5 13.8 15.0 925TENT continual [65]16.6 14.4 22.9 10.4 22.6 13.4 10.3 15.8 14.6 18.0 10.5 11.7 18.4 13.1 15.3 15.2 925TTT++ [42] 18.2 16.9 28.7 10.5 26.5 14.5 8.9 16.5 14.5 20.9 9.0 9.0 20.4 12.3 14.7 16.1 1877SWRNSP [9] 17.3 16.1 26.1 10.6 25.6 14.1 8.7 15.6 13.6 18.6 8.8 10.0 19.3 12.0 14.2 15.4 1971EATA [50] 17.2 14.9 23.6 10.2 23.3 13.2 8.5 14.0 12.5 16.6 8.6 9.4 17.2 11.0 12.7 14.2 925CoTTA [66] 16.2 15.0 21.2 10.4 22.8 13.9 8.4 15.1 12.9 19.8 8.6 11.3 17.5 10.5 12.2 14.4 2066Ours (K=4) 16.5 14.5 24.3 9.7 23.7 13.3 8.8 14.7 12.9 17.0 9.1 9.4 17.6 11.4 13.1 14.4 296Ours (K=5) 16.6 14.4 23.6 9.8 23.4 12.7 8.6 14.5 12.6 16.6 8.7 9.0 17.0 11.3 12.6 14.1 498 Table 19. Comparison of error rate (%) on CIFARC10-C with severity level 5. We conduct experiments on continual TTA setup. Avg. err means the average error rate (%) of all 15 corruptions, and Mem. denotes total memory consumption, including model parameter sizes and activations. WRN refers to WideResNet. The implementation details of the baselines are described in Section E.1. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Arch Method Gaus. Shot Impu. Defo. Glas. Moti. Zoom Snow Fros. Fog Brig. Cont. Elas. Pixe. JpegAvg. err Mem. WRN-40(AugMix) Source 80.1 77.0 76.4 59.9 77.6 64.2 59.3 64.8 71.3 78.3 48.1 83.4 65.8 80.4 59.2 69.7 11tBN [49] 45.9 45.6 48.2 33.6 47.9 34.5 34.1 40.3 40.4 47.1 31.7 39.7 42.7 39.2 45.6 41.1 11Single do. TENT [65]41.2 40.6 42.2 30.9 43.4 31.8 30.6 35.3 36.2 40.1 28.5 35.5 39.1 33.9 41.7 36.7 188continual TENT [65]41.2 38.2 41.0 32.9 43.9 34.9 33.2 37.7 37.2 41.5 33.2 37.2 41.1 35.9 45.1 38.3 188TTT++ [42] 46.0 45.4 48.2 33.5 47.7 34.4 33.8 39.9 40.2 47.1 31.8 39.7 42.5 38.9 45.5 41.0 391SWRNSP [9] 42.4 40.9 42.7 30.6 43.9 31.7 31.3 36.1 36.2 41.5 28.7 34.1 39.2 33.6 41.3 36.6 400NOTE [17] 50.9 47.4 49.0 37.3 49.6 37.3 37.0 41.3 39.9 47.0 35.2 34.7 45.2 40.9 49.9 42.8 188EATA [50] 41.6 39.9 41.2 31.7 44.0 32.4 31.9 36.2 36.8 39.7 29.1 34.4 39.9 34.2 42.2 37.1 188CoTTA [66] 43.5 41.7 43.7 32.2 43.7 32.8 32.2 38.5 37.6 45.9 29.0 38.1 39.2 33.8 39.4 38.1 409Ours (K=4) 42.7 39.6 42.4 31.4 42.9 31.9 30.8 35.1 34.8 40.7 28.1 35.0 37.5 32.1 40.5 36.4 80Ours (K=5) 41.8 39.0 41.9 31.2 42.7 32.5 31.0 35.0 35.0 39.9 28.8 34.5 37.5 32.8 40.5 36.3 92 Resnet-50 Source 84.7 83.5 93.3 59.6 92.5 71.9 54.8 66.6 77.6 81.8 44.3 91.2 72.2 76.6 56.5 73.8 91tBN [49] 48.1 46.7 60.6 35.1 58.0 41.8 33.2 47.3 43.5 54.9 33.5 35.3 49.8 38.4 40.8 44.5 91Single do. TENT [65]44.1 42.7 53.9 32.6 52.0 37.5 30.5 43.4 40.2 45.7 30.4 31.4 45.1 35.0 37.6 40.1 926continual TENT [65]44.0 40.1 49.9 34.7 50.6 40.0 33.6 47.0 45.7 53.4 42.5 46.2 56.1 51.2 53.3 45.9 926TTT++ [42] 48.1 46.5 60.8 35.1 57.8 41.6 32.9 46.8 43.3 55.0 33.3 34.0 50.0 38.1 40.6 44.2 1876SWRNSP [9] 48.3 46.5 60.5 35.1 57.9 41.7 32.9 47.1 43.5 54.7 33.5 35.1 49.9 38.3 40.7 44.1 1970EATA [50] 44.8 41.9 52.6 33.0 51.1 37.8 30.3 43.0 40.1 45.1 30.1 31.8 45.2 35.2 37.4 39.9 926CoTTA [66] 43.6 42.8 50.4 34.2 51.6 39.2 31.4 43.4 39.6 47.4 31.3 32.2 43.4 35.8 36.7 40.2 2064Ours (K=4) 44.8 40.3 49.2 32.3 50.1 36.3 29.5 41.0 39.9 44.6 31.5 33.7 45.3 36.3 37.7 39.5 296Ours (K=5) 44.9 40.4 48.9 32.7 49.7 36.9 29.3 40.8 39.0 44.4 31.1 33.6 44.0 35.7 37.8 39.3 498 Table 20. Comparison of error rate (%) on CIFARC100-C with severity level 5.We conduct experiments on continual TTA setup. Avg. err means the average error rate (%) of all 15 corruptions, and Mem. denotes total memory consumption, including model parameter sizes and activations. WRN refers to WideResNet. The implementation details of the baselines are described in Section E.1. 17",
      "meta_data": {
        "arxiv_id": "2303.01904v4",
        "authors": [
          "Junha Song",
          "Jungsoo Lee",
          "In So Kweon",
          "Sungha Choi"
        ],
        "published_date": "2023-03-03T13:05:30Z",
        "pdf_url": "https://arxiv.org/pdf/2303.01904v4.pdf"
      }
    },
    {
      "title": "Robust Test-Time Adaptation in Dynamic Scenarios",
      "abstract": "Test-time adaptation (TTA) intends to adapt the pretrained model to test\ndistributions with only unlabeled test data streams. Most of the previous TTA\nmethods have achieved great success on simple test data streams such as\nindependently sampled data from single or multiple distributions. However,\nthese attempts may fail in dynamic scenarios of real-world applications like\nautonomous driving, where the environments gradually change and the test data\nis sampled correlatively over time. In this work, we explore such practical\ntest data streams to deploy the model on the fly, namely practical test-time\nadaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA)\nmethod against the complex data stream in PTTA. More specifically, we present a\nrobust batch normalization scheme to estimate the normalization statistics.\nMeanwhile, a memory bank is utilized to sample category-balanced data with\nconsideration of timeliness and uncertainty. Further, to stabilize the training\nprocedure, we develop a time-aware reweighting strategy with a teacher-student\nmodel. Extensive experiments prove that RoTTA enables continual testtime\nadaptation on the correlatively sampled data streams. Our method is easy to\nimplement, making it a good choice for rapid deployment. The code is publicly\navailable at https://github.com/BIT-DA/RoTTA",
      "full_text": "Robust Test-Time Adaptation in Dynamic Scenarios Longhui Yuan Binhui Xie Shuang Li \f School of Computer Science and Technology, Beijing Institute of Technology {longhuiyuan,binhuixie,shuangli}@bit.edu.cn Abstract Test-time adaptation (TTA) intends to adapt the pre- trained model to test distributions with only unlabeled test data streams. Most of the previous TTA methods have achieved great success on simple test data streams such as independently sampled data from single or multiple distri- butions. However, these attempts may fail in dynamic sce- narios of real-world applications like autonomous driving, where the environments gradually change and the test data is sampled correlatively over time. In this work, we ex- plore such practical test data streams to deploy the model on the fly, namely practical test-time adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA) method against the complex data stream in PTTA. More specifically, we present a robust batch normalization scheme to estimate the normalization statistics. Meanwhile, a memory bank is utilized to sample category-balanced data with consideration of timeliness and uncertainty. Further, to stabilize the training procedure, we develop a time-aware reweighting strategy with a teacher-student model. Exten- sive experiments prove that RoTTA enables continual test- time adaptation on the correlatively sampled data streams. Our method is easy to implement, making it a good choice for rapid deployment. The code is publicly available at https://github.com/BIT-DA/RoTTA 1. Introduction In recent years, many machine learning problems have made considerable headway with the success of deep neu- ral networks [13, 22, 33, 38]. Unfortunately, the perfor- mance of deep models drops significantly when training data and testing data come from different distributions [59], which limits their utility in real-world applications. To re- duce the distribution shift, a handful of works focus on transfer learning field [56], in particular, domain adapta- tion (DA) [17, 42, 45, 48, 69, 72] or domain generalization (DG) [40, 41, 52, 71, 83], in which one or more different but \fCorresponding author Test data stream Continual TTANon-i.i.d.TTAPractical  TTACategoryDistribution Fully TTA Correlation samplingDistributionchanging Figure 1. We consider the practical test-time adaptation (TTA) setup and compare it with related ones. First, Fully TTA [70] adapts models on a fixed test distribution with an independently sampled test stream. Then, on this basis, Continual TTA [73] takes the continually changing distributions into consideration. Next, Non-i.i.d. TTA [19] tries to tackle the correlatively sampled test streams on a single test distribution, where the label distribution among a batch of data deviates from that of the test distribution. To be more practical, Practical TTA strives to connect both worlds: distribution changing and correlation sampling. related labeled datasets (a.k.a. source domain) are collected to help the model generalize well to unlabeled or unseen samples in new datasets (a.k.a. target domain). While both DA and DG have extensively studied the problem of distribution shifts, they typically assume acces- sibility to the raw source data. However, in many practical scenarios like personal consumption records, the raw data should not be publicly available due to data protection reg- ulations. Further, existing methods have to perform heavy backward computation, resulting in unbearable training costs. Test-time adaptation (TTA) [3,11,16,24,26,54,65,81] attempts to address the distribution shift online at test time with only unlabeled test data streams. Unequivocally, TTA has drawn widespread attention in a variety of applications, e.g., 2D/3D visual recognition [2, 29, 49, 65, 82], multi- modality [63, 64] and document understanding [15]. Prior TTA studies [7, 20, 70, 73] mostly concentrate on a simple adaptation scenario, where test samples are inde- pendently sampled from a fixed target domain. To name a few, Sun et al. [65] adapt to online test samples drawn from a constant or smoothly changing distribution with an auxil- iary self-supervised task. Wang et al. [70] adapt to a fixed arXiv:2303.13899v1  [cs.CV]  24 Mar 2023Table 1. Comparison between our proposed practical test-time adaptation (PTTA) and related adaptation settings. Setting Adaptation StageAvailable Data Test Data Stream Train Test Source Target Distribution Sampling Protocol Domain Adaptation ! % ! ! - - Domain Generalization ! % ! % - - Test-Time Training [65] ! ! ! ! stationary independently Fully Test-Time Adaptation [70] % ! % ! stationary independently Continual Test-Time Adaptation [73]% ! % ! continually changing independently Non-i.i.d. Test-Time Adaptation [5, 19]% ! % ! stationary correlatively Practical Test-Time Adaptation (Ours)% ! % ! continually changing correlatively target distribution by performing entropy minimization on- line. However, such an assumption is violated when the test environments change frequently [73]. Later on, Boudiaf et al. [5] and Gonget al. [19] consider the temporal correlation ship within test samples. For example, in autonomous driv- ing, test samples are highly correlated over time as the car will follow more vehicles on the highway or will encounter more pedestrians in the streets. More realistically, the data distribution changes as the surrounding environment alerts in weather, location, or other factors. In a word, distribution change and data correlation occur simultaneously in reality. Confronting continually changing distributions, tradi- tional algorithms like pseudo labeling or entropy minimiza- tion become more unreliable as the error gradients cumu- late. Moreover, the high correlation among test samples re- sults in the erroneous estimation of statistics for batch nor- malization and collapse of the model. Driven by this analy- sis, adapting to such data streams will encounter two major obstacles: 1) incorrect estimation in the batch normaliza- tion statistics leads to erroneous predictions of test samples, consequently resulting in invalid adaptation; 2) the model will easily or quickly overfit to the distribution caused by the correlative sampling. Thus, such dynamic scenarios are pressing for a new TTA paradigm to realize robust adapta- tion. In this work, we launch a more realistic TTA setting, where distribution changing and correlative sampling oc- cur simultaneously at the test phase. We call this Practical Test-Time Adaptation, or briefly,PTTA. To understand more clearly the similarities and differences between PTTA and the previous setups, we visualize them in Figure 1 and sum- marize them in Table 1. To conquer this challenging prob- lem, we propose a Robust Test-Time Adaptation (RoTTA) method, which consists of three parts: 1) robust statistics es- timation, 2) category-balanced sampling considering time- liness and uncertainty and 3) time-aware robust training. More concretely, we first replace the erroneous statistics of the current batch with global ones maintained by the expo- nential moving average. It is a more stable manner to esti- mate the statistics in BatchNorm layers. Then, we simulate a batch of independent-like data in memory with category- balanced sampling while considering the timeliness and un- certainty of the buffered samples. That is, samples that are newer and less uncertain are kept in memory with higher priority. With this batch of category-balanced, timely and confident samples, we can obtain a snapshot of the current distribution. Finally, we introduce a time-aware reweight- ing strategy that considers the timeliness of the samples in the memory bank, with a teacher-student model to perform robust adaptation. With extensive experiments, we demon- strate that RoTTA can robustly adapt in the practical setup, i.e., PTTA. In a nutshell, our contributions can be summarized as: â€¢ We propose a new test-time adaptation setup that is more suitable for real-world applications, namely practical test-time adaptation (PTTA). PTTA considers both distribution changing and correlation sampling. â€¢ We benchmark the performance of prior methods in PTTA and uncover that they only consider one aspect of the problem, resulting in ineffective adaptation. â€¢ We propose a robust test-time adaptation method (RoTTA), which has a more comprehensive considera- tion of PTTA challenges. Ease of implementation and effectiveness make it a practical deployment option. â€¢ We extensively demonstrate the practicality of PTTA and the effectiveness of RoTTA on common TTA benchmarks [23], i.e., CIFAR-10-C and CIFAR-100- C and a large-scale DomainNet [58] dataset. RoTTA obtains state-of-the-art results, outperforming the best baseline by a large margin (reducing the averaged classification error by over 5.9%, 5.5% and 2.2% on CIFAR-10-C, CIFAR-100-C and DomainNet, respec- tively). 2. Related Work Domain adaptation (DA) studies the problem of transfer- ring the knowledge learned from a labeled source dataset to an unlabeled target dataset [8, 17, 43, 51, 67, 68]. Represen- tative techniques include latent distribution alignment [48, 77], adversarial training [17, 62], or self-training [75, 85]. The limitation of this setting, however, is that an unlabeled test dataset (target domain) is needed at training time, in addition to a labeled training dataset (source domain). Ac- cordingly, it might fail to handle more practical scenariosFeature ð¹Robust batch normalization (RBN)Updateðœ‡à¯š, ðœŽà¯šà¬¶NormalizeFeatureð¹â€²Update bank with current sample  Training lossâ„’à¯¥in Eq. (7) Teacher StudentAdaptation with RBNMemorybankEMA ð‘¡A stream of online dataUpdateTest timeCorrelationsamplingStrong & weakaugmentation flowDistributionsCategoryTeacherMajor classhas highest â„‹in majorRemoveAddWhen â„‹>â„‹Samples to beadded& removed Figure 2. Framework overview. Firstly, we replace the batch normalization layer with RBN which robustly normalizes the feature map. During the inference of the online test stream of PTTA, we utilize the predictions of samples to maintain a memory bank by category- balanced sampling with timeliness and uncertainty. Finally, we use the category-balanced, timely and confident data in the memory bank combined with a robust loss to adapt the model at test time. like test-time adaptation. Our practical test-time adaptation setting can be viewed as performing correlatively sample adaptation on the fly. It is worth noting that standard domain adaptation techniques might collapse when only continual data streams from multiple target domains are accessible. Domain generalization (DG) assumes that multiple source domains are available for model training and tries to learn models that can generalize well to any unseen domains [4, 26,40,41,52,84]. A broad spectrum of methodologies based on data augmentation [78, 84], meta-learning [14, 40], or domain alignment [50,52] has made great progress. In con- trast, this work instead aims to improve the performance of source pre-trained models at the test time by using unla- beled online data streams from multiple continually chang- ing target domains. Continual learning (CL) (also known as incremental learning, life-long learning) addresses the problem of learn- ing a model for many tasks sequentially without forgetting knowledge obtained from the preceding tasks. [1, 6, 31, 37, 60]. CL methods can often be categorized into replay- based [60, 66] and regularization-based [31, 44] methods. Ideas from continual learning are also adopted for continu- ous domain adaptation approaches [34, 74] In our work, we share the same motivation as CL and point out that prac- tical test-time adaptation (PTTA) also suffers catastrophic forgetting (i.e., performance degradation on new test sam- ples due to correlation sampling), which makes test-time adaptation approaches are unstable to deploy. Test-time adaptation (TTA) focus on more challenging settings where only source model and unlabeled target data are available [9, 18, 27, 28, 35, 46, 61]. A similar paradigm is source-free domain adaptation (SFDA) [10, 36, 47, 79], which also requires no access to the training (source) data. To name a few, Liang et al . [45] fit the source hypoth- esis by exploiting the information maximization and self- supervised pseudo-labeling. Kundu et al. [35] formalize a unified solution that explores SFDA without any category- gap knowledge. To fully utilize any arbitrary pre-trained model, Sun et al. [65] propose conducting adaptation on the fly with an auxiliary self-supervised task. Later on, Wanget al. [70] take a source pre-trained model and adapt it to the test data by updating a few trainable parameters in Batch- Norm layers [25] using entropy minimization [21]. While standard TTA has been widely studied in many tasks [2, 20, 63, 64, 70, 82], the fact remains that both dis- tribution changing [73] and data correlation sampling [19] has only been considered in isolation. For example, Gong et al. [19] propose instance-aware batch normalization and prediction-balanced reservoir sampling to address the chal- lenges of correlatively sampled test streams, however, it does not consider unstable adaptation resulting from long- term adaptation on continually changing distributions. On the other hand, Wang et al. [73] assume that the target test data is streamed from a continually changing environment and continually adapt an off-the-shelf source pre-trained model to the current test data. In this work, we launch PTTA, a more practical TTA setting to connect both worlds: distribution changing and correlation sampling. 3. Method 3.1. Problem Definition and Motivation Given a model fÎ¸0 with parameter Î¸0 pre-trained on source domain DS = {(xS, yS)}, the proposed practical test-time adaptation (PTTA) aims to adapt fÎ¸0 to a stream of online unlabeled samples X0, X1, ...,XT , where Xt is a batch of highly correlated samples from the distribution Ptest that changes with time t continually. More specifi- cally, at test time, with time going on, the test distribution Ptest changes continually as P0, P1, ...,Pâˆž. At time step t, we will receive a batch of unlabeled and correlated samplesmotion distribution changing snow time  Distributions and Labels of PTTA T est Stream uniform 10 1 0.1 0.01 0.001 Dirichlet Parameter  Figure 3. Illustration of the labels and distributions of the test stream of CIFAR10-C under the setup PTTA. And we adopt Dirichlet distribution to simulate the process of correlative sam- pling. It is clear that as the concentration parameter Î´ decreases, the correlation among sampled data increases, which is reflected in the increasing aggregation of categories. Xt from Ptest. Next, Xt is fed into the model fÎ¸t and the model needs to adapt itself to the current test data streams and make predictions fÎ¸t (Xt) on the fly. As a matter of fact, this setup is largely driven the prac- tical demands of deploying models in dynamic scenarios. Taking for example the case of autonomous driving men- tioned in Â§ 1, test samples are highly correlated and the data distribution changes continually with the weather or loca- tion. Another example is the situation of intelligent moni- toring, the camera will continuously capture more people at certain times, such as after work, but fewer of them during work time. Meanwhile, the light condition changes con- tinually from day to night. The deployed model should be robustly adapted in such dynamic scenarios. In a word, dis- tribution change and data correlation often happen simul- taneously in the real world. For this reason, existing TTA methods [7,9,19,28,70,73,81] might become unstable when the test stream is sampled from such dynamic scenarios. To obtain the test stream of PTTA, we adopt Dirich- let Distribution with parameter Î´ to simulate the correla- tion among test samples. We present the test data streams corresponding to different values of Î´ on the CIFAR10-C dataset in Figure 3. We can observe that the smaller Î´ is, the higher the correlation will be. For the sake of unity, we set Î´ = 0.1 as the default for all experiments. In the follow- ing, we present a robust test-time adaptation framework for the practical test-time adaptation setup defined above. An overview of our RoTTA is illustrated in Figure 2. 3.2. Robust Test-Time Adaptation Motivated by the fact that the statistics of current batch data, which are commonly used in previous TTA meth- ods [7, 20, 65, 70, 73], become unreliable when they en- counter correlative test data streams, we first turn to the global robust statistics for normalization. Then, to effec- tively adapt to the current distribution, we maintain a mem- ory bank by category-balanced sampling with considering timeliness and uncertainty, which captures a more stable snapshot of the distribution. Finally, we utilize the teacher- student model and design a timeliness-based reweighting strategy to train the model robustly. Robust batch normalization (RBN). Batch Normaliza- tion (BN) [25] is a widely-used training technique as it can accelerate the training and convergence speed of networks and stabilize the training process by reducing the risk of gradient explosion and vanishing. Given the feature map F âˆˆ RBÃ—CÃ—HÃ—W as the input for a BN layer when train- ing, the channel-wise mean Âµ âˆˆ RC and variance Ïƒ2 âˆˆ RC are calculated as follows: Âµc = 1 BHW BX b=1 HX h=1 WX w=1 F(b,c,h,w) , (1) Ïƒ2 c = 1 BHW BX b=1 HX h=1 WX w=1 (F(b,c,h,w) âˆ’ Âµc)2 . (2) Then the feature map is normalized and refined in a channel-wise manner as BN (F(b,c,h,w); Âµ, Ïƒ2) =Î³c F(b,c,h,w) âˆ’ Âµc âˆšÏƒ2c + Ïµ + Î²c , (3) where Î³, Î²âˆˆ RC are learnable parameters in the layer and Ïµ > 0 is a constant for numerical stability. Meanwhile, during training, the BN layer maintains a group of global running mean and running variance (Âµs, Ïƒ2 s) for inference. Due to the domain shift at test time, the global statis- tics (Âµs, Ïƒ2 s) normalize test features inaccurately, causing significant performance degradation. To tackle the prob- lem above, some methods [55, 70, 73] use the statistics of the current batch to perform normalization. Unfortunately, when the test samples have a high correlation under PTTA setup, the statistics of the current batch also fail to correctly normalize the feature map, as demonstrated in Figure 4c. Specifically, the performance of BN [53] decreases rapidly as the data correlation increases. Based on the analysis above, we propose a robust batch normalization (RBN) module, which maintains a group of global statistics (Âµg, Ïƒ2 g) to normalize the feature map ro- bustly. Before the whole test-time adaptation, (Âµg, Ïƒ2 g) is initialized as the running mean and variance (Âµs, Ïƒ2 s) of the pre-trained model. When adapting the model, we update the global statistics first by exponential moving average as Âµg = (1âˆ’ Î±)Âµg + Î±Âµ , (4) Ïƒ2 g = (1âˆ’ Î±)Ïƒ2 g + Î±Ïƒ2 , (5) where (Âµ, Ïƒ2) is the statistics of the buffered samples in the memory bank. Then we normalize and affine the feature as Eq. (3) with (Âµg, Ïƒ2 g). When inferring for test samples, we directly utilize (Âµg, Ïƒ2 g) to calculate the output as Eq (3). Al- though simple, RBN is effective enough to tackle the prob- lem of normalization on test streams of PTTA.Category-balanced sampling with timeliness and uncer- tainty (CSTU). In the PTTA setup, the correlation among test samples Xt at time t leads to a deviation between the observed distribution bPtest and the test distribution Ptest. Specifically, the marginal label distribution p(y|t) tends to differ from p(y). Continuously learning with Xt over time t can lead to model adaptation to an unreliable distribution bPtest, resulting in ineffective adaptation and an increased risk of model collapse. To address this issue, we propose a category-balanced memory bank M with a capacity of N, which takes into account the timeliness and uncertainty of samples when up- dating. In particular, we adopt the predictions of test sam- ples as pseudo labels to guide the update ofM. Meanwhile, to guarantee the balance among categories, we distribute the capacity of M equally to each category, and samples of the major categories will be replaced first (refer to lines 5-9 in Algorithm 1). Furthermore, due to the continually changing test distribution, old samples in M are limited in value, and could even impair the ability of the model to adapt to the current distribution. Additionally, samples of high uncer- tainty always produce erroneous gradient information that can hinder model adaptation, as suggested by [55]. With this in mind, we attach each sample in M with a group of heuristics (A, U), where A, initialized as 0 and in- creasing with time t, is the age of the sample, and U the un- certainty calculated as the entropy of the prediction. Next, we combine the timeliness and uncertainty to calculate a heuristic score, i.e., category-balanced sampling with time- liness and uncertainty (CSTU), as follows: H = Î»t 1 1 + exp(âˆ’A/N) + Î»u U log C , (6) where Î»t and Î»u make the trade-off between timeliness and uncertainty, and for simplicity, Î»t and Î»u are set to 1.0 for all experiments, andC is the number of categories. We sum- marize our sampling algorithm in Algorithm 1. With CSTU, we can obtain a robust snapshot of the current test distribu- tion Ptest, and effectively adapt the model to it. Robust training with timeliness. Actually, after replacing BN layers with our RBN and obtaining the memory bank selected via CSTU, we can directly adopt the widely used techniques like pseudo labeling or entropy minimization to perform test-time adaptation. However, we notice that too old or unreliable instances still have the opportunity to stay in M since keeping the category balance is assigned the top priority. In addition, too aggressive updates of the model will make the category balance ofM unreliable, resulting in unstable adaptation. Meanwhile, error accumulation caused by the distribution change also makes the aforementioned approaches unworkable. To further reduce the risk of error gradients information from old and unreliable instances and stabilize the adapta- tion, we turn to the robust unsupervised learning method Algorithm 1: CSTU for one test sample. 1 Input: a test sample x and the teacher model fÎ¸T . 2 Define: memory bank M and its capacity N, number of classes C, per class occupation O âˆˆRC, total occupation â„¦, classes to pop instance D. 3 Infer as p(y|x) =Softmax(fÎ¸T (x)). 4 Calculate the predicted category of x as Ë†y = arg maxc p(c|x), the uncertainty as Ux = âˆ’PC c=1 p(c|x) log(p(c|x)), the age as Ax = 0, and the heuristic score Hx of x with Eq (6) 5 if OË†y < N C then 6 if â„¦ <N: Search range D = âˆ…. 7 else: Search range D = {j|j = arg maxc Oc} 8 else 9 Search range D = {Ë†y} 10 if D is âˆ… then 11 Add (x, Ë†y, Hx, Ux) into M. 12 else 13 Find the instance (Ë†x, yË†x, AË†x, UË†x) with the highest value in Eq (6) HË†x among D. 14 if Hx < HË†x then 15 Remove (Ë†x, yË†x, AË†x, UË†x) from M. 16 Add (x, Ë†y, Hx, Ux) into M. 17 else 18 Discard x. 19 Increase the age of all instances in M. teacher-student model and propose a timeliness reweight- ing strategy. In addition, for the sake of time efficiency and stability, only affine parameters in RBN are trained during adaptation. At time step t, after inferring for the correlated data Xt with the teacher model fÎ¸T t and updating the memory bank M with Xt, we begin updating the student model fÎ¸S t and the teacher model fÎ¸T t . Firstly, we update parameters of stu- dent model Î¸S t â†’ Î¸S t+1 by minimizing the following loss: Lr = 1 â„¦ â„¦X i=1 L(xM i , Ai; Î¸T t , Î¸S t ) , (7) where â„¦ = |M| is the total occupation of the memory bank, and xM i and Ai(i = 1, ..., â„¦) are instances in the memory bank and their age respectively. Subsequently, the teacher model is updated by exponential moving average as Î¸T t+1 = (1âˆ’ Î½)Î¸T t + Î½Î¸S t+1 . (8) To calculate the loss value of an instancexM i from the mem- ory bank, the timeliness reweighting term is computed as E(Ai) = exp(âˆ’Ai/N) 1 + exp(âˆ’Ai/N) , (9)where Ai is the age of xM i , and N is the capacity of the bank. And then we calculate the cross entropy between the soft-max prediction pS(y|xâ€²â€² i ) of the strong-augmented view xâ€²â€² i from the student model and that pT (y|xâ€² i) of the weak- augmented view 1 xâ€² i from the teacher model as follows: â„“(xâ€² i, xâ€²â€² i ) =âˆ’1 C CX c=1 pT (c|xâ€² i) logpS(c|xâ€²â€² i ) . (10) Finally, equipped with Eq. (9) and Eq. (10), the right-hand side of Eq. (7) reduces to L(xM i , Ai; Î¸T t , Î¸S t ) =E(Ai)â„“(xâ€² i, xâ€²â€² i ) . (11) To sum up, equipped with RBN, CSTU, and robust training with timeliness, our RoTTA is capable of effectively adapt- ing any pre-trained models in dynamic scenarios. 4. Experiments 4.1. Setup Datasets. CIFAR10-C and CIFAR100-C [23] are the com- monly used TTA benchmarks to testify the robustness un- der corruptions. Both of them are obtained by applying 15 kinds of corruption with 5 different degrees of severity on their clean test images of original datasets CIFAR10 and CIFAR100 respectively. CIFAR10/CIFAR100 [32] have 50,000/10,000 training/test images, all of which fall into 10/100 categories. DomainNet [58] is the largest and hard- est dataset to date for domain adaptation and consists of about 0.6 million images with 345 classes. It consists of six different domains including Clipart (clp), Infograph (inf), Painting (pnt), Quickdraw (qdr), Real (rel), and Sketch (skt). We first pre-train a source model on the train set in one of six domains and testify all baseline methods on the test set of the remaining five domains. Implementation details. All experiments are conducted with PyTorch [57] framework. In the case of robustness to corruption, following the previous methods [55, 70, 73], we obtain the pre-trained model from RobustBench bench- mark [12], including the WildResNet-28 [80] for CIFAR10 â†’ CIFAR10-C, and the ResNeXt-29 [76] for CIFAR100 â†’ CIFAR100-C. Then, we change the test corruption at the highest severity 5 one by one to simulate that the test distri- bution continually changes with time in PTTA. And in the case of generalization under the huge domain gap, we train a ResNet-101 [22] by standard classification loss for each domain in DomainNet and adapt them continually to differ- ent domains except the source domain. Meanwhile, we uti- lize the Dirichlet distribution to simulate the correlatively sampled test stream for all datasets. For optimization, we adopt Adam [30] optimizer with learning rate 1.0 Ã— 10âˆ’3, 1Weak augmentation is ReSize+CenterCrop. Strong augmentation is a combination nine operations like Clip, ColorJitter, and RandomAffine. Î² = 0.9. For a fair comparison, we set the batch size for all methods as 64 and the capacity of the memory bank of RoTTA as N = 64. Concerning the hyperparameters, we adopt a unified set of values for RoTTA across all experi- ments including Î± = 0.05, Î½ = 0.001, Î»t = 1.0, Î»u = 1.0, and Î´ = 0.1. More details are provided in the appendix. 4.2. Comparisons with the State-of-the-arts Robustness under corruptions. The classification error on CIFAR10â†’CIFAR10-C and CIFAR100â†’CIFAR100-C are shown in Table 2 and Table 3 respectively. We change the type of the current corruption at the highest severity 5 as time goes on, and sample data correlatively for infer- ence and adaptation simultaneously. The same test stream is shared across all compared methods. From Table 2 and Table 3, we can see that RoTTA achieves the best performance compared to previous meth- ods. Moreover, RoTTA has a significant performance gain to the second-best method that 5.9% improvement on CIFAR10 â†’CIFAR10-C and 5.5% improvement on CIFAR100â†’CIFAR100-C respectively, verifying the effec- tiveness of RoTTA to adapt the model under PTTA. In more detail, we can observe that BN [53], PL [39], TENT [70] and CoTTA [73] negatively adapt the model to the test streams of both datasets compared to Source (âˆ’6.5 âˆ¼ âˆ’46.4%). This is attributed to the fact that these methods overlook the issues posed by correlation sampling, which can result in highly correlated data within a batch. As a consequence, traditional normalization statistics may be ineffective in appropriately normalizing the feature maps. Equipped with RBN and CSTU, RoTTA no longer suffers from this issue. Meanwhile, in Table 3, if focus on the adaptation procedure, we can see that the performance of PL [39], TENT [70] and NOTE [19] becomes worse and worse, and eventually, the model even collapses (error rate > 97%). This reveals that the impact of error accumula- tion on long-term adaptation can be catastrophic. To tackle this problem, RoTTA turns to robustly adapt the model with timeliness reweighting and confident samples in the mem- ory bank, and superior performance throughout the adapta- tion process demonstrates its effectiveness. In addition, we find that although LAME [5] never tunes the parameters of the model, it is still a competi- tive baseline for example it achieves the second-best result on CIFAR100â†’CIFAR100-C. However, its performance is very dependent on the performance of the pre-trained model e.g. negligible improvement on difficult corruptions (shot, gaussian, pixelate). On the contrary, our RoTTA is more flexible and achieves better and more robust results. Generalization under domain shift. We also evalu- ate RoTTA under a more challenging dataset DomainNet, where we continually adapt a source pre-trained model to correlatively sampled test streams of the rest domains. AsTable 2. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 3. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 4. Average classification error of DomainNet while continually adapting to different domains with correlatively sampled test stream. Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Sourceclp inf pnt qdr rel sktAvg. BN clp inf pnt qdr rel sktAvg. PL clp inf pnt qdr rel sktAvg.TENTclp inf pnt qdr rel sktAvg. clp N/A 83.9 65.4 88.6 48.0 59.1 69.0clp N/A 88.6 70.7 90.5 65.4 67.0 76.5clp N/A 94.5 98.9 99.5 99.7 99.7 98.5clp N/A 87.5 71.9 94.2 96.2 98.9 89.7inf 61.8 N/A 66.9 96.0 50.0 70.6 69.1inf 68.6 N/A 74.2 96.2 69.9 76.8 77.1inf 82.6 N/A 99.2 99.6 99.7 99.3 96.1inf 68.6 N/A 75.0 97.3 95.9 98.7 87.1pnt 56.5 83.7 N/A 94.2 42.6 63.4 68.1pnt 60.8 87.9 N/A 94.3 62.3 68.7 74.8pnt 78.6 99.4 N/A 99.7 99.6 99.7 95.4pnt 61.7 87.1 N/A 96.4 95.3 98.8 87.8qdr 89.2 99.0 98.6 N/A 95.0 92.3 94.8qdr 80.3 97.7 92.6 N/A 88.7 88.1 89.5qdr 81.7 99.5 99.6 N/A 99.7 99.8 96.1qdr 78.9 97.1 91.6 N/A 89.2 88.7 89.1rel 49.4 80.4 51.5 93.4 N/A 63.3 67.6rel 57.9 87.1 63.1 94.3 N/A 70.8 74.6rel 73.5 99.4 99.2 99.6 N/A 99.7 94.3rel 57.8 86.4 68.1 96.9 N/A 96.7 81.2skt 47.5 88.2 62.9 87.1 51.8 N/A 67.5skt 50.4 87.6 64.6 89.6 63.1 N/A 71.1skt 64.8 99.2 99.4 99.7 99.7 N/A 92.6skt 51.9 87.2 69.1 95.3 97.3 N/A 80.1Avg.60.9 87.0 69.1 91.9 57.5 69.7 72.7Avg.63.6 89.8 73.0 93.0 69.9 74.3 77.3Avg.76.2 98.4 99.3 99.6 99.7 99.6 95.5Avg.63.8 89.0 75.1 96.0 94.8 96.4 85.8 Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’Timetâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’LAMEclp inf pnt qdr rel sktAvg.COTTAclp inf pnt qdr rel sktAvg.NOTEclp inf pnt qdr rel sktAvg.RoTTAclp inf pnt qdr rel sktAvg. clp N/A 82.2 64.5 87.7 46.9 58.9 68.0clp N/A 90.6 77.9 89.3 76.3 72.7 81.4clp N/A 89.2 73.0 94.8 98.4 99.4 91.0clp N/A 85.5 62.0 82.0 49.3 59.8 67.7inf 60.1 N/A 65.7 95.4 48.5 69.4 67.8inf 74.5 N/A 82.0 95.7 80.2 81.5 82.8inf 75.4 N/A 78.7 98.7 98.1 99.5 90.1inf 61.8 N/A 63.7 91.5 52.5 67.6 67.4pnt 55.8 81.5 N/A 93.3 41.3 62.1 66.8pnt 66.3 89.8 N/A 93.4 74.0 75.4 79.8pnt 64.7 89.8 N/A 97.8 98.4 99.2 90.0pnt 53.3 84.1 N/A 89.1 47.3 61.4 67.0qdr 88.3 99.1 99.0 N/A 94.9 92.2 94.7qdr 82.3 98.2 94.6 N/A 92.5 90.1 91.5qdr 74.7 97.2 92.2 N/A 93.5 99.6 91.4qdr 77.5 97.0 89.8 N/A 80.3 82.2 85.3rel 48.0 79.3 50.1 91.6 N/A 60.2 65.8rel 64.0 90.3 73.2 93.5 N/A 77.6 79.7rel 61.3 89.2 68.9 98.8 N/A 99.2 83.5rel 49.1 82.3 50.3 88.0 N/A 61.1 66.2skt 45.6 87.1 59.5 83.9 49.9 N/A 65.2skt 56.1 89.2 71.9 89.2 73.5 N/A 76.0skt 55.2 89.7 70.1 96.9 98.3 N/A 82.0skt 42.6 83.7 54.4 80.9 47.5 N/A 61.8Avg.59.6 85.8 67.8 90.4 56.3 68.6 71.4Avg.68.6 91.6 79.9 92.2 79.3 79.5 81.9Avg.66.3 91.0 76.6 97.4 97.3 99.4 88.0Avg.56.8 86.5 64.0 86.3 55.4 66.469.2(+2.2) shown in Table 4, consistent with the previous analysis, most of the methods include BN [53], PL [39], TENT [70], CoTTA [73] and NOTE [19] even perform worse than the Source model ( âˆ’4.6 âˆ¼ âˆ’22.8%). RoTTA consistently achieves the best performance and has 2.2% gain than the second method LAME [5], demonstrating RoTTAâ€™s effec- tiveness again. 4.3. Ablation Study Effect of each component. To further investigate the effi- cacy of each component, we replace each part with the nor- mally used solutions to obtain three variants: (1) RoTTA w/o RBN, replace RBN with test-time BN in TENT [70]; (2) RoTTA w/o CSTU, directly adapt the model on test stream; (3) RoTTA w/o robust training (RT), directly adapt the model only with entropy minimization. As shown in Table 5, we can observe that significant performance degra- dation occurs for all variants, proving that every part of our proposed method is valid for PTTA. Take one com- ponent for a detailed example, without RBN robustly nor- malizing feature maps, the performance of RoTTA drops 50.2% and 16.3% on CIFAR10-C and CIFAR100-C respec- tively, proving that RBN is robust enough to tackle the prob- lem of normalization of correlatively sampled data streams. CSTU enables RoTTA to adapt to a more stable distribu- tion by maintaining a timely and confident snapshot of the test distribution. Meanwhile, robust training with timeliness greatly reduces the accumulation of errors. Every compo- nent behaves significantly to enable effective adaptation un- der PTTA. Effect of the distribution changing order. To exclude the effect of a fixed order of distribution changing, we con- ducted experiments on ten different sequences of changes on CIFAR10-C and CIFAR100-C with independently andBN PL TENT LAME CoTTA NOTE RoTTA0 10 20 30 40 50 60 70 80Classification error (%) Source CIFAR-10  CIFAR-10-C Independent Correlative (a) CIFAR10-C. BN PL TENT LAME CoTTA NOTE RoTTA0 20 40 60 80Classification error (%) Source CIFAR-100  CIFAR-100-C Independent Correlative (b) CIFAR100-C. uniform 10 1 0.1 0.01 0.001 30 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (c) Î´. 16 32 64 128 256 512 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (d) Batch size. Figure 4. (a) & (b) we adapt the model continually to different corruptions of 10 different orders with independently and correlatively sampled test streams on CIFAR10-C and CFAR100-C respectively and report their average classification error. (c) & (d) we verify the effect of Î´ and batch size to different methods on CIFAR100-C respectively. Table 5. Classification error of different variants of our RoTTA. Variant CIFAR10-C CIFAR100-C Avg. RoTTA w/o RBN 75.4 51.3 63.4 RoTTA w/o CSTU 47.1 46.3 46.7 RoTTA w/o RT 78.2 95.0 81.6 RoTTA 25.2 35.0 30.1 correlatively sampled test streams respectively. As shown in Figure 4a and 4b, no matter what kind of setup, RoTTA can achieve excellent results. The detailed results on the correlatively sampled test streams are shown in Table 6, RoTTA achieves 4.3% and 4.7% progress on CIFAR10- C and CIFAR100-C respectively. This shows that RoTTA can adapt the model robustly and effectively in long-term scenarios where distribution continually changes and test streams are sampled either independently or correlatively, making it a good choice for model deployment. Effect of Dirichlet concentration parameter Î´. We vary the value of Î´ on CIFAR100-C and compare RoTTA with other approaches in Figure 4c. As the value of Î´ increases, the performance of BN [53], PL [39], TENT [70] and CoTTA [73] drops quickly, because they never consider the increasing correlation among test samples. NOTE [19] is stable to correlatively sampled test streams but does not consider the distribution changing, causing ineffective adaptation. Meanwhile, the higher correlation between test samples will make the propagation of labels more accurate, which is why the result of LAME [5] slightly improves. Fi- nally, excellent and stable results once again prove the sta- bility and effectiveness of RoTTA. Effect of batch size. In real scenarios, considering deploy- ment environments may use different test batch sizes, we conduct experiments with different values of test batch sizes and results are shown in Figure 4d. For a fair comparison, we control the frequency of updating the model of RoTTA so that the number of samples involved in back-propagation is the same. As the batch size increases, we can see that all of the compared methods have a significant improvement except for lame which has a slight decrease. This is be- cause the number of categories in a batch increases with the Table 6. Average classification error of tasks CIFAR10 â†’ CIFAR10-C and CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions of 10 different orders at the high- est severity 5 with correlatively sampled test stream. Method CIFAR10-C CIFAR100-C Avg. Source 43.5 46.4 46.9 BN [53] 75.2 52.9 64.1 PL [39] 75.2 52.9 60.1 TENT [70] 82.3 93.2 87.8 LAME [5] 39.5 40.6 40.1 NOTE [19] 30.5 76.1 53.3 CoTTA [73] 83.1 52.8 67.9 RoTTA 26.2(+4.3) 35.9(+4.7) 31.1(+9.0) increasing batch size, causing the overall correlation to be- come lower but the propagation of labels to become more difficult. Most significantly, RoTTA achieves the best re- sults across different batch sizes, demonstrating its robust- ness in dynamic scenarios once again. 5. Conclusion This work proposes a more realistic TTA setting where distribution changing and correlative sampling occur si- multaneously at the test phase, namely Practical Test-Time Adaptation (PTTA). To tackle the problems of PTTA, we propose Robust Test-Time Adaptation (RoTTA) method against the complex data stream. More specifically, a group of robust statistics for the normalization of feature maps is estimated by robust batch normalization. Meanwhile, a memory bank is adopted to capture a snapshot of the test distribution by category-balanced sampling with consider- ing timeliness and uncertainty. Further, we develop a time- aware reweighting strategy with a teacher-student model to stabilize the adaptation process. Extensive experiments and ablation studies are conducted to verify the robustness and effectiveness of the proposed method. We believe this work will pave the way for thinking about adapting models into real-world applications by test-time adaptation algorithm. Acknowledgements. This paper was supported by National Key R&D Program of China (No. 2021YFB3301503), and also supported by the National Natural Science Foundation of China under Grant No. 61902028.References [1] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Ben- gio. Gradient based sample selection for online continual learning. In NeurIPS, pages 11816â€“11825, 2019. 3 [2] Fatemeh Azimi, Sebastian Palacio, Federico Raue, J Â¨orn Hees, Luca Bertinetto, and Andreas Dengel. Self-supervised test-time adaptation on video data. In WACV, pages 2603â€“ 2612, 2022. 1, 3 [3] Mathilde Bateson, Herve Lombaert, and Ismail Ben Ayed. Test-time adaptation with shape moments for image segmen- tation. In MICCAI, pages 736â€“745, 2022. 1 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. General- izing from several related classification tasks to a new unla- beled sample. In NeurIPS, pages 2178â€“2186, 2011. 3 [5] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In CVPR, pages 8344â€“8353, 2022. 2, 6, 7, 8, 13, 14, 15, 16, 17 [6] Francisco M Castro, Manuel J Mar Â´Ä±n-JimÂ´enez, NicolÂ´as Guil, Cordelia Schmid, and Karteek Alahari. End-to-end incre- mental learning. In ECCV, pages 233â€“248, 2018. 3 [7] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, pages 295â€“305, 2022. 1, 4 [8] Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Domain adaptive faster r-cnn for object de- tection in the wild. In CVPR, pages 3339â€“3348, 2018. 2 [9] Zhixiang Chi, Yang Wang, Yuanhao Yu, and Jin Tang. Test- time fast adaptation for dynamic scene deblurring via meta- auxiliary learning. In CVPR, pages 9137â€“9146, 2021. 3, 4 [10] Boris Chidlovskii, St Â´ephane Clinchant, and Gabriela Csurka. Domain adaptation in the absence of source domain data. In KDD, pages 451â€“460, 2016. 3 [11] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sun- grack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, pages 440â€“458, 2022. 1 [12] Francesco Croce, Maksym Andriushchenko, Vikash Se- hwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In Neurips, 2021. 6 [13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2021. 1 [14] Ying-Jun Du, Jun Xu, Huan Xiong, Qiang Qiu, Xiantong Zhen, Cees G. M. Snoek, and Ling Shao. Learning to learn with variational information bottleneck for domain general- ization. In ECCV, pages 200â€“216, 2020. 3 [15] Sayna Ebrahimi, Sercan Â¨O. Arik, and Tomas Pfister. Test- time adaptation for visual document understanding. CoRR, abs/2206.07240, 2022. 1 [16] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 1 [17] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Franc Â¸ois Laviolette, Mario Marchand, and Victor S. Lempitsky. Domain-adversarial training of neural networks. J. Mach. Learn. Res., 17:59:1â€“ 59:35, 2016. 1, 2 [18] Yunhe Gao, Xingjian Shi, Yi Zhu, Hao Wang, Zhiqiang Tang, Xiong Zhou, Mu Li, and Dimitris N. Metaxas. Vi- sual prompt tuning for test-time domain adaptation. CoRR, abs/2210.04831, 2022. 3 [19] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Robust continual test- time adaptation: Instance-aware BN and prediction-balanced memory. In NeurIPS, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [20] Sachin Goyal, Mingjie Sun, Aditi Raghunathan, and J Zico Kolter. Test time adaptation via conjugate pseudo-labels. In NeurIPS, 2022. 1, 3, 4 [21] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, pages 529â€“ 536, 2004. 3 [22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770â€“778, 2016. 1, 6 [23] Dan Hendrycks and Thomas G. Dietterich. Benchmarking neural network robustness to common corruptions and per- turbations. In ICLR, 2019. 2, 6 [24] Hengguan Huang, Xiangming Gu, Hao Wang, Chang Xiao, Hongfu Liu, and Ye Wang. Extrapolative continuous-time bayesian neural network for fast training-free test-time adap- tation. In NeurIPS, 2022. 1 [25] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In ICML, pages 448â€“456, 2015. 3, 4 [26] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier ad- justment module for model-agnostic domain generalization. In NeurIPS, pages 2427â€“2440, 2021. 1, 3 [27] Vidit Jain and Erik Learned-Miller. Online domain adapta- tion of a pre-trained cascade of classifiers. In CVPR, pages 577â€“584, 2011. 3 [28] Minguk Jang and Sae-Young Chung. Test-time adaptation via self-training with nearest neighbor information. CoRR, abs/2207.10792, 2022. 3, 4 [29] Junho Kim, Inwoo Hwang, and Young Min Kim. Ev-tta: Test-time adaptation for event-based object recognition. In CVPR, pages 17724â€“17733, 2022. 1 [30] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. 6 [31] James Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska- Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Ku- maran, and Raia Hadsell. Overcoming catastrophic forget- ting in neural networks. CoRR, abs/1612.00796, 2016. 3 [32] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 6[33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural net- works. In NeurIPS, pages 1097â€“1105, 2012. 1 [34] Ananya Kumar, Tengyu Ma, and Percy Liang. Understand- ing self-training for gradual domain adaptation. In ICML, pages 5468â€“5479, 2020. 3 [35] Jogendra Nath Kundu, Naveen Venkat, Rahul M. V ., and R. Venkatesh Babu. Universal source-free domain adapta- tion. In CVPR, pages 4543â€“4552, 2020. 3 [36] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free do- main adaptation method. In WACV, pages 615â€“625, 2021. 3 [37] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying for- getting in classification tasks. IEEE Trans. Pattern Anal. Mach. Intell., 44(7):3366â€“3385, 2022. 3 [38] Yann LeCun, Yoshua Bengio, and Geoffrey E. Hinton. Deep learning. Nat., 521(7553):436â€“444, 2015. 1 [39] Dong-Hyun Lee et al. Pseudo-label: The simple and effi- cient semi-supervised learning method for deep neural net- works. In Workshop on challenges in representation learn- ing, ICML, volume 3, page 896, 2013. 6, 7, 8, 12, 14, 15, 16, 17 [40] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, pages 3490â€“3497, 2018. 1, 3 [41] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In CVPR, pages 5400â€“5409, 2018. 1, 3 [42] Shuang Li, Binhui Xie, Qiuxia Lin, Chi Harold Liu, Gao Huang, and Guoren Wang. Generalized domain conditioned adaptation network. IEEE Trans. Pattern Anal. Mach. Intell., 44(8):4093â€“4109, 2022. 1 [43] Shuang Li, Mixue Xie, Kaixiong Gong, Chi Harold Liu, Yulin Wang, and Wei Li. Transferable semantic augmen- tation for domain adaptation. In CVPR, pages 11516â€“11525, 2021. 2 [44] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE Trans. Pattern Anal. Mach. Intell., 40(12):2935â€“2947, 2018. 3 [45] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for un- supervised domain adaptation. In ICML, pages 6028â€“6039, 2020. 1, 3 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. TTT++: when does self-supervised test-time training fail or thrive? In NeurIPS, pages 21808â€“21820, 2021. 3 [47] Yuang Liu, Wei Zhang, and Jun Wang. Source-free do- main adaptation for semantic segmentation. In CVPR, pages 1215â€“1224, 2021. 3 [48] Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and Michael I. Jordan. Transferable representation learning with deep adaptation networks. IEEE Trans. Pattern Anal. Mach. Intell., 41(12):3071â€“3085, 2019. 1, 2 [49] Wenao Ma, Cheng Chen, Shuang Zheng, Jing Qin, Huimao Zhang, and Qi Dou. Test-time adaptation with calibration of medical image classification nets for label distribution shift. In MICCAI, pages 313â€“323, 2022. 1 [50] Divyat Mahajan, Shruti Tople, and Amit Sharma. Domain generalization using causal matching. In ICML, pages 7313â€“ 7324, 2021. 3 [51] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT, 2009. 2 [52] Krikamol Muandet, David Balduzzi, and Bernhard SchÂ¨olkopf. Domain generalization via invariant fea- ture representation. In ICML, pages 10â€“18, 2013. 1, 3 [53] Zachary Nado, Shreyas Padhy, D. Sculley, Alexander Dâ€™Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robust- ness under covariate shift. CoRR, abs/2006.10963, 2020. 4, 6, 7, 8, 12, 14, 15, 16, 17 [54] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, pages 16888â€“16905, 2022. 1 [55] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, volume 162, pages 16888â€“16905, 2022. 4, 5, 6 [56] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans. Knowl. Data Eng., 22(10):1345â€“1359, 2010. 1 [57] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, pages 8024â€“8035, 2019. 6 [58] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, pages 1406â€“1415, 2019. 2, 6 [59] Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in ma- chine learning. 2008. 1 [60] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. icarl: Incremental classi- fier and representation learning. InCVPR, pages 5533â€“5542, 2017. 3 [61] Amelie Royer and Christoph H Lampert. Classifier adapta- tion at prediction time. In CVPR, pages 1401â€“1409, 2015. 3 [62] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat- suya Harada. Maximum classifier discrepancy for unsuper- vised domain adaptation. In CVPR, pages 3723â€“3732, 2018. 2 [63] Inkyu Shin, Yi-Hsuan Tsai, Bingbing Zhuang, Samuel Schulter, Buyu Liu, Sparsh Garg, In So Kweon, and Kuk- Jin Yoon. MM-TTA: multi-modal test-time adaptation for 3d semantic segmentation. In CVPR, pages 16907â€“16916, 2022. 1, 3[64] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test- time prompt tuning for zero-shot generalization in vision- language models. In NeurIPS, 2022. 1, 3 [65] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, pages 9229â€“9248, 2020. 1, 2, 3, 4 [66] Rishabh Tiwari, KrishnaTeja Killamsetty, Rishabh K. Iyer, and Pradeep Shenoy. GCR: gradient coreset based replay buffer selection for continual learning. In CVPR, pages 99â€“ 108, 2022. 3 [67] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Ki- hyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic seg- mentation. In CVPR, pages 7472â€“7481, 2018. 2 [68] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In ICCV, pages 4068â€“4076, 2015. 2 [69] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In CVPR, pages 2962â€“2971, 2017. 1 [70] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno A. Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17 [71] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. Generalizing to unseen domains: A survey on domain generalization. IEEE Trans. Knowl. Data Eng., 2022. 1 [72] Mei Wang and Weihong Deng. Deep visual domain adapta- tion: A survey. Neurocomputing, 312:135â€“153, 2018. 1 [73] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Con- tinual test-time domain adaptation. In CVPR, pages 7191â€“ 7201, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [74] Markus Wulfmeier, Alex Bewley, and Ingmar Posner. Incre- mental adversarial domain adaptation for continually chang- ing environments. In ICRA, pages 4489â€“4495, 2018. 3 [75] Binhui Xie, Shuang Li, Mingjia Li, Chi Harold Liu, Gao Huang, and Guoren Wang. Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation. IEEE Trans. Pattern Anal. Mach. Intell., pages 1â€“17, 2023. 2 [76] Saining Xie, Ross Girshick, Piotr Doll Â´ar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, pages 5987â€“5995, 2017. 6 [77] Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin. Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation. In ICCV, pages 1426â€“ 1435, 2019. 2 [78] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 3 [79] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adapta- tion. In ICCV, pages 8978â€“8987, 2021. 3 [80] Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In BMVC, 2016. 6 [81] Marvin Mengxin Zhang, Sergey Levine, and Chelsea Finn. MEMO: Test time robustness via adaptation and augmenta- tion. In NeurIPS, 2022. 1, 4 [82] Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In WACV, pages 2633â€“2642, 2022. 1, 3 [83] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE Trans. Pattern Anal. Mach. Intell., 2022. 1 [84] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 3 [85] Yang Zou, Zhiding Yu, BVK Vijaya Kumar, and Jinsong Wang. Unsupervised domain adaptation for semantic seg- mentation via class-balanced self-training. In ECCV, pages 289â€“305, 2018. 26. Appendix 6.1. Discussion Societal impact. RoTTA enables adapting pre-trained models on continually changing distributions with correl- atively sampled test streams without any more raw data or label requirements. Thus, our work may have a positive im- pact on communities to effectively deploy and adapt models in various real-world scenarios, which is economically and environmentally friendly. And since no training data is re- quired, this protects data privacy and has potential commer- cial value. We carry out experiments on benchmark datasets and do not notice any societal issues. It does not involve sensitive attributes. Future work. Our work suggests a few promising direc- tions for future work. Firstly, the proposed RoTTA is a preliminary attempt to perform test-time adaptation for the more realistic test stream under the setup PTTA. One could experiment to improve the algorithm by replacing some parts of RoTTA. More importantly, we hope that with this work, we can open a path to the original goal of test-time adaptation, which is performing test-time adaptation in real- world scenarios. Thus, one could improve PTTA to make it more realistic. Limitations. RoTTA achieves excellent performance on various tasks under the setup PTTA as demonstrated in Sec- tion 4 in the main paper, but we still find some limitations of it. Firstly, the adopted robust batch normalization (RBN) is a naive solution to the normalization of the correlatively sampled batch of data. This requires careful design of the value of Î± in RBN. Secondly, we observe that during the adaptation procedure of some methods like PL [39] and TENT [70], the model collapse finally. Although we de- sign many strategies to stabilize the adaptation and model collapse never occurs in the experiments of RoTTA, we are still missing a way to recover the model from the collapse state as a remedy. Thirdly, category similarity is only one kind of correlation. Although we conduct experiments on different datasets with Dirichlet distribution to simulate cor- relatively sampled test streams, we still need to validate our approach in some real-world scenarios. 6.2. Sensitivity to different hyper-parameters In this section, we conduct a detailed sensitivity analy- sis of the hyperparameters involved in RoTTA. All experi- ments are conducted on CIFAR100â†’CIFAR100-C, and the corruptions changes as motion, snow, fog, shot, defocus, contrast, zoom, brightness, frost, elastic, glass, gaussian, pixelate, jpeg, and impulse, and test streams are sampled correlatively with the Dirichlet parameter Î´ = 0.1. When we investigate the sensitivity to a specific hyperparameter, other hyperparameters are fixed to the default values, i.e., Î»t = 1.0, Î»u = 1.0, Î± = 0.05, and Î½ = 0.001, for all experiments. Table 7. Classification error with different value of Î»t/Î»u. Î»t/Î»u 0.0/2.0 0.5/1.5 1.0/1.0 1.5/ 0.5 2.0/ 0.0 CIFAR100-C 57.5 36.9 35.0 35.9 38.9 Trade-off between timeliness and uncertainty. When updating the memory bank, we take the timeliness and uncertainty of samples into account simultaneously, and Î»t and Î»u will make a trade-off between them. In Table 7, we show the results of RoTTA with varying Î»t/Î»u, i.e., Î»t/Î»u âˆˆ {0.0/2.0, 0.5/1.5, 1.0/1.0, 1.5/0.5, 2.0/0.0}. When we consider both of them, the results are relatively stable (35.0-36.9%). When we only think about one side, the performance drops significantly. For example, when we set Î»t/Î»u = 0.0/2.0 which means only considering uncer- tainty, the performance drops 22.5%. Thatâ€™s because some confident samples get stuck in the memory bank, making it not work the way we design it. Table 8. Classification error with varying Î± Î± 0.5 0.1 0.05 0.01 0.005 0.001 CIFAR100-C 39.0 36.0 35.0 36.0 38.1 41.5 Sensitivity to Î±. We show the results of RoTTA with vary- ing Î±, i.e., Î± âˆˆ {0.5, 0.1, 0.05, 0.01, 0.005, 0.001} in Ta- ble 8. A larger value of Î± means updating the global statis- tics faster and vice versa. We can see that RoTTA achieves competitive results (35.0 âˆ’ 36.0%) at appropriate values of Î±, i.e., Î± âˆˆ {0.1, 0.05, 0.01}. Updating too aggressively or too gently can lead to unreliable estimates of statistics. Table 9. Classification error with varying Î½ Î½ 0.05 0.01 0.005 0.001 0.0005 0.0001 CIFAR100-C 44.8 39.1 37.1 35.0 37.6 43.6 Sensitivity to Î½. We show the results of RoTTA with vary- ing Î½, i.e., Î½ âˆˆ {0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001} in Table 9. As we can see, the best performance is achieved at Î½ = 0.001. Updating the teacher model too quickly or too slowly can cause performance degradation. 6.3. Additional experiment details and results 6.3.1 Compared methods BN [53] utilizes statistics of the current batch of data to nor- malize their feature maps without tuning any parameters. PL [39] is based on BN [53], and adopts pseudo labels to train the affine parameters in BN layers.TENT [70] is the first to propose fully test-time adaptation. It adopts test-time batch normalization and utilizes entropy minimization to train the affine parameters of BN layers. We reimplement it following the released code https:// github.com/DequanWang/tent. LAME [5] adapts the output of the pre-trained model by optimizing a group of latent variables without tuning any in- ner parts of the model. We reimplement it following the re- leased code https://github.com/fiveai/LAME. CoTTA [73] considers performing test-time adapta- tion on continually changing distributions and pro- pose augmentation-averaged pseudo-labels and stochastic restoration to address error accumulation and catastrophic forgetting. We reimplement it following the released code https://github.com/qinenergy/cotta. NOTE [19] proposes instance-aware normalization and prediction-balanced reservoir sampling to stable the adapta- tion on temporally correlated test streams. We reimplement it following the released code https://github.com/ TaesikGong/NOTE. 6.3.2 Simulate correlatively sampling As we described in the scenarios of autonomous driving that the car will follow more vehicles on the highway or will en- counter more pedestrians on the sidewalk, so we use the same category to simulate correlation. From a macro point of view, the test distribution Ptest changes continually as P0, P1, ...,Pâˆž. During the period when Ptest = Pt, we adopt Dirichlet distribution to simulate correlatively sam- pled test stream. More specifically, we consider dividing samples of C classes into T slots. Firstly, we utilize Dirich- let distribution with parameter Î³ to generate the partition criterion q âˆˆ RCÃ—T . Then for each class c, we split samples into T parts according to qc and assign each part to each slot respectively. Finally, we concatenate all slots to sim- ulate the correlatively sampled test stream for Ptest = Pt. And as Ptest changes, we use the above method again to generate the test stream. 6.3.3 Detailed results of different orders We report the average classification error of ten different distribution changing orders in Table 6 of the main pa- per. And then we present the specific results here, includ- ing Table 10, 11, 12, 13, 14, 15, 16, 17, 18, and 19 for CIFAR10â†’CIFAR10-C and Table 20, 21, 22, 23, 24, 25, 26, 27, 28, and 29 for CIFAR100 â†’CIFAR100-C. We can see consistently superior performance of RoTTA. One thing to mention is that on DomainNet we use alphabetical order to determine the order of domain changes.Table 10. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 9.3 58.5 72.3 34.8 42.0 54.3 72.9 30.3 46.9 26.6 65.7 41.3 25.1 26.0 46.7 43.5BN [53] 71.1 75.2 76.8 74.2 73.7 80.1 79.3 77.5 73.8 77.7 77.2 73.3 73.8 72.7 71.7 75.2PL [39] 71.7 75.9 80.2 78.4 80.2 85.2 85.3 85.4 85.1 86.7 87.9 87.9 88.1 88.3 87.9 83.6TENT [70] 71.6 75.9 81.3 80.5 82.3 85.6 87.1 87.0 87.1 88.1 88.2 87.8 87.9 88.3 88.2 84.4LAME [5] 5.4 56.8 73.1 29.1 37.0 50.5 71.4 22.3 42.8 18.6 65.5 37.3 18.8 20.4 43.6 39.5CoTTA [73] 75.0 79.8 83.1 83.4 83.2 84.0 84.5 83.2 83.5 83.3 83.6 83.0 83.0 83.4 83.7 82.6NOTE [19] 10.1 29.9 47.1 23.4 28.4 48.4 46.1 41.8 26.9 36.1 37.5 25.0 25.0 23.2 14.2 30.9 RoTTA 10.4 26.6 37.5 23.9 17.0 40.9 39.7 30.1 18.0 29.9 30.1 23.6 21.7 17.6 19.0 25.7(+5.2) Table 11. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 30.3 65.7 42.0 41.3 46.7 26.0 46.9 26.6 72.3 9.3 54.3 72.9 58.5 25.1 34.8 43.5BN [53] 77.6 75.8 73.4 74.1 73.1 72.5 72.9 77.1 77.2 72.2 79.9 79.9 75.5 74.6 72.9 75.2PL [39] 77.6 77.1 76.6 78.3 77.5 79.8 82.0 84.8 86.1 83.5 87.8 87.1 86.5 85.6 85.7 82.4TENT [70] 78.5 78.2 79.2 81.8 84.8 84.8 86.4 87.3 87.9 86.7 87.3 87.8 87.2 87.5 87.1 84.8LAME [5] 22.5 65.2 37.0 37.1 44.0 20.3 41.7 18.7 72.8 5.2 51.2 71.5 57.0 19.0 29.4 39.5CoTTA [73]78.5 81.0 82.8 84.1 84.9 83.4 83.5 83.5 84.5 83.3 84.7 84.6 83.0 84.4 83.4 83.3NOTE [19]35.4 36.1 22.1 21.3 11.6 24.8 24.5 36.0 37.7 18.4 49.0 47.4 43.9 30.4 29.2 31.2 RoTTA 33.2 33.3 19.8 24.1 24.9 20.5 16.2 31.7 28.4 11.8 43.1 36.9 32.5 20.7 20.6 26.5(+4.7) Table 12. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 46.7 46.9 72.3 65.7 25.1 41.3 54.3 42.0 26.6 30.3 58.5 9.3 72.9 34.8 26.0 43.5BN [53] 72.3 72.6 76.9 77.1 74.8 73.5 80.0 73.2 77.4 78.6 76.4 71.0 79.1 73.9 71.5 75.2PL [39] 72.4 75.3 80.7 82.6 83.3 83.5 86.6 85.7 86.6 88.4 87.5 86.6 88.3 88.2 86.8 84.1TENT [70] 73.5 77.9 85.5 86.9 87.6 87.8 88.3 87.7 88.6 89.2 88.5 88.5 89.3 88.6 88.6 86.4LAME [5] 43.5 42.3 73.1 65.3 19.2 37.3 51.1 36.8 18.5 22.5 56.9 5.5 71.1 29.1 20.5 39.5CoTTA [73]79.4 80.3 83.8 83.9 83.9 83.4 85.0 83.2 85.1 84.3 83.9 83.3 84.7 83.9 82.5 83.4NOTE [19] 9.6 21.8 40.1 31.0 25.5 22.6 44.8 22.8 33.2 39.4 33.2 18.1 50.0 28.3 29.8 30.0 RoTTA 18.4 17.9 38.4 31.9 23.3 19.8 40.7 17.4 31.4 29.8 27.8 11.3 43.8 19.7 18.8 26.0(+4.0) Table 13. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 65.7 26.0 54.3 58.5 25.1 26.6 9.3 72.9 46.9 41.3 46.7 72.3 34.8 30.3 42.0 43.5BN [53] 76.4 72.0 80.4 76.2 74.8 77.0 71.1 79.6 73.8 74.4 73.0 77.0 72.5 78.3 72.5 75.3PL [39] 77.0 73.3 82.4 79.8 81.0 82.3 79.5 84.4 82.7 83.5 83.5 85.5 84.8 87.0 84.5 82.1TENT [70]76.9 74.6 82.3 81.7 82.0 84.9 84.8 87.3 86.6 87.3 87.6 89.2 88.3 88.9 87.3 84.6LAME [5] 65.3 20.6 50.9 56.7 19.2 18.8 5.4 71.8 42.8 37.2 43.3 73.2 29.4 22.6 36.9 39.6CoTTA [73]77.4 77.6 83.8 81.9 82.2 82.6 80.4 83.3 82.3 81.5 82.7 82.6 81.1 82.9 81.0 81.6NOTE [19]34.0 20.9 43.1 36.6 24.0 36.4 12.1 48.0 25.9 23.9 13.4 38.1 25.0 43.2 24.2 29.9 RoTTA 35.0 21.1 43.9 29.2 22.1 29.7 10.8 44.6 25.3 22.7 24.6 29.4 26.9 34.4 16.1 27.7(+2.2) Table 14. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 58.5 54.3 42.0 25.1 26.0 72.9 9.3 34.8 41.3 30.3 72.3 65.7 46.7 46.9 26.6 43.5BN [53] 76.0 79.6 73.3 75.2 72.9 79.8 71.1 73.5 74.1 78.6 77.4 76.1 72.0 73.8 76.4 75.3PL [39] 76.7 81.3 77.4 80.3 81.2 86.3 83.3 85.9 86.2 87.7 88.1 88.4 87.4 87.6 87.7 84.4TENT [70] 76.4 80.2 77.8 81.2 83.0 87.1 85.6 87.2 87.6 88.7 88.6 88.9 88.5 88.6 88.2 85.2LAME [5] 56.9 50.7 37.0 19.0 20.3 71.5 5.4 29.2 37.2 22.5 73.0 65.3 43.8 42.4 18.7 39.5CoTTA [73]77.1 83.6 84.1 84.8 84.4 85.2 84.0 84.3 84.9 84.9 85.0 84.7 85.3 84.4 84.3 84.1NOTE [19] 27.8 52.2 24.5 22.3 21.6 44.5 14.5 21.3 25.9 42.5 38.8 36.0 16.7 28.1 40.6 30.5 RoTTA 25.9 43.3 17.7 22.1 20.2 41.5 12.2 22.9 22.5 31.2 33.8 26.0 31.4 17.7 27.6 26.4(+4.1)Table 15. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 16. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 41.3 72.9 30.3 46.7 42.0 54.3 58.5 25.1 46.9 34.8 9.3 26.6 65.7 26.0 72.3 43.5BN [53] 73.8 79.1 77.9 73.0 73.7 80.1 75.7 74.4 73.7 74.0 71.7 77.0 75.9 72.8 76.2 75.3PL [39] 74.2 80.9 80.4 79.5 81.8 85.9 83.9 85.1 84.7 85.9 85.9 86.7 87.2 87.0 87.8 83.8TENT [70]73.9 80.3 81.8 81.6 83.6 86.3 85.6 85.7 86.4 87.7 87.4 88.8 88.8 88.5 88.4 85.0LAME [5] 37.4 71.8 22.4 43.5 37.0 50.5 57.0 19.0 42.8 29.1 5.4 18.7 65.2 20.4 72.9 39.5CoTTA [73]76.5 82.2 82.8 85.0 82.9 85.0 83.0 82.9 83.5 83.4 82.6 83.7 83.2 83.3 83.6 82.9NOTE [19]21.1 41.4 36.3 10.2 21.7 46.7 37.5 26.4 26.1 21.4 14.3 37.9 38.5 24.4 40.7 29.6 RoTTA 22.2 44.9 35.2 18.8 19.7 41.5 28.5 23.2 21.2 18.6 12.4 30.0 27.4 20.0 31.2 26.3(+3.3) Table 17. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 46.9 34.8 42.0 65.7 72.3 54.3 30.3 26.0 46.7 58.5 41.3 25.1 9.3 26.6 72.9 43.5BN [53] 72.8 72.7 73.3 77.2 77.3 80.0 77.6 72.6 73.3 76.6 73.8 74.1 70.3 77.5 79.0 75.2PL [39] 73.2 74.6 76.5 81.7 82.8 84.6 85.1 84.6 86.2 86.4 86.1 87.1 86.8 88.4 88.1 83.5TENT [70] 73.7 74.3 77.1 82.5 84.3 86.9 87.4 86.6 88.0 88.5 88.1 88.5 88.4 89.4 88.9 84.8LAME [5] 42.5 29.3 37.0 65.3 73.2 50.5 22.5 20.5 43.5 56.9 37.1 18.9 5.4 18.5 71.3 39.5CoTTA [73]76.3 79.8 82.4 83.3 83.8 84.5 83.1 82.7 84.7 82.9 83.0 83.3 81.4 83.8 83.8 82.6NOTE [19] 18.5 18.8 23.6 36.5 33.7 47.8 38.6 22.8 13.0 40.0 29.2 26.3 17.5 44.0 52.9 30.9 RoTTA 17.0 17.5 16.5 33.8 33.3 42.7 29.4 18.0 19.6 29.5 20.7 22.1 11.5 29.5 38.1 25.3(+5.6) Table 18. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.3 42.0 72.9 26.0 25.1 30.3 72.3 41.3 65.7 9.3 46.7 34.8 58.5 46.9 26.6 43.5BN [53] 79.7 72.3 79.8 73.2 74.7 77.7 76.6 73.2 77.1 72.2 73.0 73.3 75.5 73.8 76.4 75.2PL [39] 79.6 73.2 81.3 77.3 79.1 83.0 83.2 83.0 85.5 84.3 87.0 86.9 86.4 86.5 87.6 82.9TENT [70] 79.5 74.1 84.2 82.2 84.5 86.5 86.7 85.9 87.2 86.6 86.8 87.3 86.9 87.4 87.3 84.9LAME [5] 50.8 36.9 71.3 20.6 19.2 22.4 72.5 37.2 65.4 5.2 43.3 29.1 57.0 42.4 18.7 39.5CoTTA [73]81.5 79.4 85.2 84.1 84.5 84.2 84.8 84.0 84.8 83.2 85.2 83.8 83.2 84.6 83.6 83.7NOTE [19]45.0 21.2 42.3 21.0 21.6 38.4 36.4 21.4 33.1 16.7 14.6 25.4 43.5 29.1 38.5 29.9 RoTTA 42.6 17.6 48.1 23.9 21.9 32.6 32.1 20.7 30.2 12.0 21.9 20.0 33.7 16.4 28.1 26.8(+3.1) Table 19. Average classification error of the task CIFAR10â†’ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 46.7 72.3 46.9 42.0 41.3 54.3 30.3 26.0 58.5 26.6 65.7 72.9 25.1 34.8 9.3 43.5BN [53] 72.4 76.2 73.2 73.7 73.6 80.0 77.6 72.6 76.4 77.7 77.2 79.9 73.8 73.9 70.0 75.2PL [39] 73.0 78.2 76.7 79.7 81.6 85.6 86.0 85.3 87.2 88.2 88.3 88.9 88.5 89.2 88.2 84.3TENT [70] 73.6 80.9 83.1 85.6 87.1 88.5 88.8 88.4 89.2 89.3 89.0 89.0 89.3 89.9 89.1 86.7LAME [5] 43.5 73.2 42.3 37.0 37.2 50.5 22.5 20.5 57.0 18.6 65.5 71.5 18.8 29.1 5.6 39.5CoTTA [73]79.5 81.4 83.4 83.6 83.9 85.0 84.0 82.8 84.8 84.8 84.5 84.7 84.1 84.4 82.8 83.6NOTE [19] 9.6 43.6 26.5 24.8 23.9 46.9 38.0 23.4 34.0 41.2 41.5 45.0 27.6 25.8 19.0 31.4 RoTTA 18.4 36.0 21.1 15.6 23.0 41.7 30.8 19.1 34.1 31.1 31.3 39.9 26.0 18.8 12.8 26.6(+4.8)Table 20. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 29.5 74.7 73.0 30.8 28.8 54.1 39.4 41.2 29.3 37.2 68.0 45.8 39.5 50.3 55.1 46.4BN [53] 46.5 52.0 58.6 47.4 47.4 57.6 58.2 56.9 47.0 53.4 56.0 52.5 53.1 57.7 49.1 52.9PL [39] 48.5 60.7 77.1 85.9 91.5 95.5 95.8 96.6 96.8 96.9 97.3 97.5 97.6 97.7 97.9 88.9TENT [70] 49.8 69.4 92.2 96.0 96.7 97.3 97.5 97.9 97.5 97.9 98.0 98.2 98.2 98.2 98.2 92.2LAME [5] 21.7 75.1 72.7 22.9 20.6 49.0 32.1 33.3 21.2 28.0 66.8 40.0 30.6 43.9 51.3 40.6CoTTA [73] 46.8 48.4 54.7 48.7 48.6 53.5 55.4 52.8 49.8 51.8 53.5 52.9 54.1 56.7 53.6 52.1NOTE [19] 42.6 53.0 69.9 52.1 53.3 70.4 73.1 76.7 80.8 96.0 97.7 97.1 96.6 97.2 95.8 76.8 RoTTA 28.4 37.3 44.6 31.9 28.3 41.8 43.6 39.9 28.0 35.2 38.2 33.7 33.0 39.5 31.0 35.6(+5.0) Table 21. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 41.2 68.0 28.8 45.8 55.1 50.3 29.3 37.2 73.0 29.5 54.1 39.4 74.7 39.5 30.8 46.4BN [53] 58.3 56.8 47.8 51.8 48.9 57.3 46.8 53.5 57.8 45.5 57.1 58.5 51.7 53.3 48.8 52.9PL [39] 59.4 66.3 74.9 87.5 94.2 95.5 96.2 97.1 97.4 97.2 97.5 97.7 98.0 98.2 98.2 90.4TENT [70] 62.0 79.3 91.7 95.8 96.9 97.0 97.4 97.7 97.6 97.7 97.9 97.9 98.0 97.9 97.9 93.5LAME [5] 33.6 66.7 21.1 39.9 50.6 43.9 21.0 28.6 72.5 21.6 48.6 32.5 74.5 30.6 22.5 40.6CoTTA [73]54.6 54.1 49.6 52.1 52.7 58.0 50.3 53.3 55.0 49.1 55.4 55.7 51.0 54.6 52.1 53.2NOTE [19]60.4 63.0 49.9 55.7 47.0 65.2 59.4 76.6 90.9 87.2 96.8 97.0 97.3 96.7 96.8 76.0 RoTTA 43.9 45.3 31.0 37.3 35.7 41.2 27.7 34.8 39.7 26.6 39.5 41.9 32.0 33.0 30.5 36.0(+4.6) Table 22. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 55.1 29.3 73.0 68.0 39.5 45.8 54.1 28.8 37.2 41.2 74.7 29.5 39.4 30.8 50.3 46.4BN [53] 49.4 47.2 58.6 56.2 52.7 52.0 57.9 46.1 54.4 57.7 50.5 46.2 58.2 47.6 58.5 52.9PL [39] 54.8 64.2 83.3 92.4 95.5 96.5 96.9 96.4 97.2 97.4 97.8 97.8 97.9 97.7 98.0 90.9TENT [70] 60.2 83.1 95.2 96.5 96.9 97.3 97.0 97.3 97.8 97.8 97.6 97.9 97.8 97.9 98.1 93.9LAME [5] 51.3 21.3 72.7 66.3 30.2 40.0 48.6 20.9 27.7 33.3 75.0 21.5 32.2 22.5 43.8 40.5CoTTA [73]52.1 48.6 55.1 52.7 53.4 51.9 55.9 49.2 53.2 52.8 49.2 49.7 56.2 50.7 58.1 52.6NOTE [19] 39.5 45.9 68.8 61.8 57.4 58.5 71.4 66.5 80.8 90.9 94.2 94.9 97.0 95.5 96.6 74.6 RoTTA 41.7 30.5 44.9 40.5 35.4 34.1 40.5 28.2 34.5 39.5 31.1 26.7 43.3 31.4 38.8 36.1(+4.4) Table 23. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 68.0 50.3 54.1 74.7 39.5 37.2 29.5 39.4 29.3 45.8 55.1 73.0 30.8 41.2 28.8 46.4BN [53] 57.5 58.6 58.5 50.5 52.7 53.1 45.9 57.9 47.0 51.5 47.8 58.2 48.2 57.1 47.7 52.8PL [39] 59.5 72.9 85.1 89.6 94.5 96.8 97.1 97.9 97.8 98.0 98.3 98.2 98.0 98.0 98.2 92.0TENT [70]60.3 81.4 95.0 96.6 97.0 97.3 97.3 97.7 97.7 97.7 97.8 97.7 97.6 97.6 97.9 93.8LAME [5] 66.4 43.2 49.0 75.2 30.2 28.5 21.6 32.5 21.2 39.5 52.0 72.8 22.3 33.1 20.5 40.5CoTTA [73]54.5 58.4 55.6 50.0 53.9 53.4 50.3 56.7 51.3 53.2 53.7 56.1 52.0 54.5 51.5 53.7NOTE [19]61.8 60.2 63.4 55.6 59.8 65.9 58.6 75.1 77.8 93.8 94.2 97.0 95.0 95.5 94.4 76.5 RoTTA 45.5 44.5 43.5 35.6 35.1 35.7 26.2 44.0 29.7 34.2 32.0 40.7 31.4 39.4 27.7 36.3(+4.2) Table 24. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 74.7 54.1 28.8 39.5 50.3 39.4 29.5 30.8 45.8 41.2 73.0 68.0 55.1 29.3 37.2 46.4BN [53] 51.7 58.6 47.8 52.9 57.1 58.2 45.9 47.6 52.9 57.8 57.5 56.7 49.5 46.1 54.0 52.9PL [39] 52.4 68.0 73.4 87.9 93.7 96.1 95.7 96.0 96.5 96.7 97.5 97.7 97.7 97.3 97.7 89.6TENT [70] 53.5 77.8 91.1 96.0 97.0 97.6 97.4 97.6 97.9 98.1 98.1 98.0 98.1 97.9 98.1 92.9LAME [5] 74.8 48.2 21.1 30.6 43.4 32.5 21.6 23.0 39.6 33.3 72.7 66.5 51.5 20.7 27.5 40.5CoTTA [73]49.3 55.1 49.1 52.9 56.8 55.7 49.5 50.0 53.6 53.4 54.9 53.9 53.8 50.1 53.5 52.8NOTE [19] 52.2 64.9 47.5 57.0 61.9 67.3 60.4 67.8 77.4 90.6 97.1 96.8 92.8 95.9 96.6 75.1 RoTTA 36.4 44.4 29.7 36.5 41.0 44.1 26.8 29.5 33.0 40.3 40.3 38.2 33.9 28.5 34.9 35.8(+4.7)Table 25. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 26. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 45.8 39.4 41.2 55.1 28.8 54.1 74.7 39.5 29.3 30.8 29.5 37.2 68.0 50.3 73.0 46.4BN [53] 52.9 58.8 57.6 48.2 47.4 57.6 50.9 52.4 47.0 47.2 45.1 54.0 56.4 57.7 58.2 52.8PL [39] 56.9 73.3 86.7 94.4 95.8 97.3 97.2 97.4 97.6 97.4 97.7 97.6 97.8 98.3 98.1 92.2TENT [70]60.1 84.2 95.7 97.2 97.4 97.9 97.8 98.0 98.1 98.2 98.3 98.4 98.4 98.4 98.4 94.4LAME [5] 39.9 32.4 33.4 51.4 20.6 49.0 74.4 31.3 21.2 22.6 21.9 28.1 66.9 43.9 72.5 40.6CoTTA [73]51.5 55.3 54.3 51.8 49.4 55.3 50.7 54.2 51.4 50.6 49.5 53.6 55.0 57.1 55.8 53.0NOTE [19]51.6 60.9 60.3 45.4 54.3 70.8 68.8 75.0 75.7 87.1 94.7 95.6 96.7 96.4 97.2 75.4 RoTTA 40.0 46.3 42.8 36.4 29.2 42.3 33.2 34.4 28.4 29.2 26.4 34.5 38.5 39.8 39.3 36.0(+4.6) Table 27. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 29.3 30.8 28.8 68.0 73.0 54.1 41.2 50.3 55.1 74.7 45.8 39.5 29.5 37.2 39.4 46.4BN [53] 47.1 48.6 47.8 56.2 57.6 57.6 57.6 57.5 48.7 50.6 51.8 53.2 46.9 53.5 58.8 52.9PL [39] 48.8 58.7 69.9 88.0 95.1 96.6 96.7 96.9 97.4 97.4 98.2 98.2 98.2 98.3 98.5 89.1TENT [70] 51.0 67.6 85.8 95.9 97.2 97.5 97.2 97.7 98.1 97.9 97.7 97.7 98.0 98.0 98.2 91.7LAME [5] 21.2 22.8 21.1 66.3 72.8 49.0 33.3 44.8 51.7 74.9 39.8 31.2 21.3 27.3 32.3 40.6CoTTA [73]48.4 48.8 48.2 52.9 54.0 53.8 52.7 57.2 52.6 48.6 51.8 53.9 49.4 52.3 56.0 52.0NOTE [19] 45.1 46.7 49.1 67.3 65.5 69.4 75.5 80.3 83.8 96.0 97.6 97.1 96.1 97.9 98.7 77.7 RoTTA 29.6 31.3 28.8 43.9 41.5 41.3 40.9 39.8 32.1 32.6 33.1 33.0 26.5 34.5 42.9 35.4(+5.2) Table 28. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.1 28.8 39.4 50.3 39.5 41.2 73.0 45.8 68.0 29.5 55.1 30.8 74.7 29.3 37.2 46.4BN [53] 58.8 47.7 59.2 57.6 52.7 56.9 58.2 52.0 56.7 45.5 47.8 48.2 51.7 46.1 54.0 52.9PL [39] 60.1 59.5 75.1 85.7 91.5 94.6 96.5 97.1 97.4 97.3 98.0 97.7 97.9 97.8 97.7 89.6TENT [70] 61.6 71.5 91.0 95.9 96.6 97.1 96.9 97.3 97.4 97.2 97.9 98.0 98.1 97.9 97.8 92.8LAME [5] 48.6 20.6 32.3 44.4 30.2 33.6 72.4 40.0 66.3 21.6 52.0 22.8 74.6 20.7 27.5 40.5CoTTA [73]56.4 48.9 56.1 57.8 54.1 54.2 56.2 53.6 55.4 50.0 53.6 51.6 51.2 50.7 54.4 53.6NOTE [19]62.5 46.3 61.5 61.1 58.6 68.4 76.1 78.3 92.0 93.4 96.1 95.4 96.2 95.8 96.4 78.5 RoTTA 45.5 30.0 45.9 42.6 35.3 41.8 42.2 34.5 40.2 27.3 31.3 30.2 32.7 28.1 34.9 36.2(+4.3) Table 29. Average classification error of the task CIFAR100 â†’ CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time tâˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ â†’ Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 55.1 73.0 29.3 28.8 45.8 54.1 41.2 50.3 74.7 37.2 68.0 39.4 39.5 30.8 29.5 46.4BN [53] 49.5 58.8 47.0 46.5 52.2 57.6 57.6 57.6 51.7 53.5 56.0 58.5 53.1 47.6 46.3 52.9PL [39] 53.6 70.4 76.0 85.1 91.2 95.2 96.0 97.0 96.9 97.3 97.3 97.6 97.5 97.6 97.7 89.8TENT [70] 60.2 89.1 95.0 96.2 96.9 97.0 96.5 97.0 97.0 97.2 97.6 97.8 97.5 97.9 97.7 94.0LAME [5] 51.3 72.5 21.5 21.0 39.6 49.0 33.3 44.8 74.8 28.0 66.8 32.5 30.6 22.5 21.4 40.6CoTTA [73]52.3 55.3 49.5 48.1 52.1 54.8 52.7 56.9 50.6 52.6 53.7 55.8 54.6 50.6 50.5 52.7NOTE [19] 39.1 64.7 48.9 50.6 59.1 70.1 71.7 75.0 85.2 95.7 96.9 98.4 96.0 95.9 94.9 76.1 RoTTA 41.4 46.2 30.5 28.5 36.0 40.9 40.5 39.6 33.0 35.0 38.2 43.1 33.9 30.7 27.1 36.3(+4.3)",
      "meta_data": {
        "arxiv_id": "2303.13899v1",
        "authors": [
          "Longhui Yuan",
          "Binhui Xie",
          "Shuang Li"
        ],
        "published_date": "2023-03-24T10:19:14Z",
        "pdf_url": "https://arxiv.org/pdf/2303.13899v1.pdf"
      }
    },
    {
      "title": "Improved Test-Time Adaptation for Domain Generalization",
      "abstract": "The main challenge in domain generalization (DG) is to handle the\ndistribution shift problem that lies between the training and test data. Recent\nstudies suggest that test-time training (TTT), which adapts the learned model\nwith test data, might be a promising solution to the problem. Generally, a TTT\nstrategy hinges its performance on two main factors: selecting an appropriate\nauxiliary TTT task for updating and identifying reliable parameters to update\nduring the test phase. Both previous arts and our experiments indicate that TTT\nmay not improve but be detrimental to the learned model if those two factors\nare not properly considered. This work addresses those two factors by proposing\nan Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically\ndefining an auxiliary objective, we propose a learnable consistency loss for\nthe TTT task, which contains learnable parameters that can be adjusted toward\nbetter alignment between our TTT task and the main prediction task. Second, we\nintroduce additional adaptive parameters for the trained model, and we suggest\nonly updating the adaptive parameters during the test phase. Through extensive\nexperiments, we show that the proposed two strategies are beneficial for the\nlearned model (see Figure 1), and ITTA could achieve superior performance to\nthe current state-of-the-art methods on several DG benchmarks. Code is\navailable at https://github.com/liangchen527/ITTA.",
      "full_text": "Improved Test-Time Adaptation for Domain Generalization Liang Chen1 Yong Zhang2* Yibing Song3 Ying Shan2 Lingqiao Liu1âˆ— 1 The University of Adelaide 2 Tencent AI Lab 3 AI3 Institute, Fudan University {liangchen527, zhangyong201303, yibingsong.cv}@gmail.com yingsshan@tencent.com lingqiao.liu@adelaide.edu.au Abstract The main challenge in domain generalization (DG) is to handle the distribution shift problem that lies between the training and test data. Recent studies suggest that test-time training (TTT), which adapts the learned model with test data, might be a promising solution to the problem. Gen- erally, a TTT strategy hinges its performance on two main factors: selecting an appropriate auxiliary TTT task for up- dating and identifying reliable parameters to update during the test phase. Both previous arts and our experiments in- dicate that TTT may not improve but be detrimental to the learned model if those two factors are not properly consid- ered. This work addresses those two factors by proposing an Improved Test-Time Adaptation (ITTA) method. First, in- stead of heuristically defining an auxiliary objective, we pro- pose a learnable consistency loss for the TTT task, which con- tains learnable parameters that can be adjusted toward bet- ter alignment between our TTT task and the main prediction task. Second, we introduce additional adaptive parameters for the trained model, and we suggest only updating the adap- tive parameters during the test phase. Through extensive ex- periments, we show that the proposed two strategies are ben- eficial for the learned model (see Figure 1), and ITTA could achieve superior performance to the current state-of-the-art methods on several DG benchmarks. Code is available at https://github.com/liangchen527/ITTA. 1. Introduction Recent years have witnessed the rapid development of deep learning models, which often assume the training and test data are from the same domain and follow the same distribution. However, this assumption does not always hold in real-world scenarios. Distribution shift among the source and target domains is ubiquitous in related areas [35], such as autonomous driving or object recognition tasks, resulting *Corresponding authors. This work is done when L. Chen is an intern in Tencent AI Lab. 0.5 1.1 0.5 1.2 0.5 0.5 0.5 1.4 0.4 0.4 0.4 0.3 art cartoon photo sketch 79.9 75.4 94.4 75.8 83.3 76.0 94.4 76.7 84.7 78.0 94.5 78.2 Figure 1. Performance improvements from the proposed two strate- gies (i.e. introducing a learnable consistency loss and including additional adaptive parameters to improve TTT) for the baseline model (i.e. ResNet18 [30] with existing augmentation strategy [75]). Experiments are conducted on the PACS dataset [37] with the leave- one-out setting. Following [27], we use 60 sets of random seeds and hyper-parameters for each target domain. The reported average accuracy and error bars verify the effectiveness of our method. in poor performances for delicately designed models and hindering the further application of deep learning techniques. Domain generalization (DG) [2,8,16,23,24,31,38 â€“40,40, 44, 47, 51, 52, 69], designed to generalize a learned model to unseen target domains, has attracted a great deal of attention in the research community. The problem can be traced back to a decade ago [7], and various approaches have been pro- posed to push the DG boundary ever since. Those efforts in- clude invariant representation learning [28,47,49,58], adver- sarial learning [23,40,44,69], augmentation [9,41,42,66,75], or meta-learning [2, 16, 38, 39]. Despite successes on certain occasions, a recent study [27] shows that, under a rigorous evaluation protocol, most of these arts are inferior to the baseline empirical risk minimization (ERM) method [61]. This finding is not surprising, as most current arts strive to decrease the distribution shift only through the training data while overlooking the contributions from test samples. Recently, the test-time training (TTT) technique [60] has been gaining momentum for easing the distribution shift problem. TTT lies its success in enabling dynamic tuning of the pretrained model with the test samples via an auxil- iary TTT task, which seems to be a promising effort when arXiv:2304.04494v2  [cs.CV]  16 Apr 2023confronting data from different domains. However, TTT is not guaranteed to improve the performance. Previous arts [46, 63] indicate that selecting an appropriate auxiliary TTT task is crucial, and an inappropriate one that does not align with the main loss may deteriorate instead of improv- ing the performance. Meanwhile, it is pointed out in [63] that identifying reliable parameters to update is also essential for generalization, which is in line with our experimental findings in Sec. 5.3. Both of these two tasks are non-trivial, and there are limited efforts made to address them. This paper aims to improve the TTT strategy for better DG. First, different from previous works that empirically define auxiliary objectives and assume they are aligned with the main task, our work does not make such assumptions. Instead, we suggest learning an appropriate auxiliary loss for test-time updating. Specifically, encouraged by recent successes in multi-view consistency learning [13,26,29], we propose to augment the consistency loss by adding learn- able parameters based on the original implementation, where the parameters can be adjusted to assure our TTT task can be more aligned with the main task and are updated by en- forcing the two tasks share the same optimization direction. Second, considering that identifying reliable parameters to update is an everlasting job given the growing size of current deep models, we suggest introducing new adaptive param- eters after each block during the test phase, and we only tune the new parameters by the learned consistency loss while leaving the original parameters unchanged. Through extensive evaluations on the current benchmark [27], we illustrate that the learnable consistency loss performs more effectively than the self-supervised TTT tasks adopted in previous arts [60, 63], and by tuning only the new adaptive parameters, our method is superior to existing strategies that update all the parameters or part of them. This work aims to ease the distribution shift problem by improving TTT, and the main contributions are three-fold: â€¢ We introduce a learnable consistency loss for test-time adaptation, which can be enforced to be more aligned with the main loss by tuning its learnable parameters. â€¢ We introduce new adaptive parameters for the trained model and only update them during the test phase. â€¢ We conduct experiments on various DG benchmarks and illustrate that our ITTA performs competitively against current arts under the rigorous setting [27] for both the multi-source and single-source DG tasks. 2. Related Works 2.1. Domain Generalization. Being able to generalize to new environments while de- ploying is a challenging and practical requirement for cur- rent deep models. Existing DG approaches can be roughly categorized into three types. (1) Invariant representation learning: The pioneering work [5] theoretically proves that if the features remain invariant across different domains, then they are general and transferable to different domains. Guided by this finding, [47] uses maximum mean discrep- ancy (MMD) to align the learned features, and [25] proposes to use a multi-domain reconstruction auto-encoder to obtain invariant features. More recently, [58] suggests maximiz- ing the inner product of gradients from different domains to enforce invariance, and a similar idea is proposed in [52] where these gradients are expected to be similar to their mean values. (2) Optimization algorithms: Among the different optimization techniques adopted in DG, prevail- ing approaches resort to adversarial learning [23, 40, 44, 69] and meta-learning [2, 16, 38, 39]. Adversarial training is often used to enforce the learned features to be agnostic about the domain information. In [23], a domain-adversarial neural network (DANN) is implemented by asking the main- stream feature to maximize the domain classification loss. This idea is also adopted in [44], where adversarial training and an MMD constraint are employed to update an auto- encoder. Meanwhile, the meta-learning technique is used to simulate the distribution shifts between seen and unseen environments [2, 16, 38, 39], and most of these works are developed based on the MAML framework [20]. (3) Aug- mentation: Most augmentation skills applied in the general- ization tasks are operated in the feature level [34, 41, 48, 75] except for [11,66,68] which mix images [68] or its phase [66] to synthesize new data. To enable contrastive learning, we incorporate an existing augmentation strategy [75] in our framework. This method originated from AdaIN [32], which synthesizes new domain information by mixing the statistics of the features. Similar ideas can be found in [42, 48]. 2.2. Test-Time Training and Adaptation Test-Time Training (TTT) is first introduced in [60]. The basic paradigm is to employ a test-time task besides the main task during the training phase and update the pre- trained model using the test data with only the test-time objective before the final prediction step. The idea is empir- ically proved effective [60] and further developed in other related areas [3, 10, 12, 14, 21, 22, 43, 56, 63, 65, 73, 74]. Most current works focus on finding auxiliary tasks for updat- ing during the test phase, and the efforts derive from self- supervion [3, 10, 21, 22, 43, 60], meta-learning [65, 73, 74], information entropy [63], pseudo-labeling [12, 14], to name a few. However, not all empirically selected test-time tasks are effective. A recent study [46] indicates that only when the auxiliary loss aligns with the main loss can TTT improve the trained model. Inspired by that, we propose a learnable consistency loss and enforce alignment between the two ob- jectives. Results show that our strategy can be beneficial for the trained model (see Figure 1).subtract Figure 2. Training process of ITTA. We use x from the source domain as input for the feature extractor fÎ¸(Â·) to obtain the repre- sentation z and its augmented version zâ€², where the augmentation skill from [75] is applied. The classifier fÏ•(Â·) and weight subnet- work fw(Â·) are used to compute the main loss Lmain and learnable consistency loss Lwcont. Please refer to our text for details. Meanwhile, [63] suggests that auxiliary loss is not the only factor that affects the performance. Selecting reliable parameters to update is also crucial within the TTT frame- work. Given the large size of current models, correctly iden- tifying these parameters may require tremendous amounts of effort. To this end, instead of heuristically selecting candi- dates, we propose to include new adaptive parameters for up- dating during the test phase. Experimental results show that the proposed method can obtain comparable performances against existing skills. 3. Methodology In the task of DG, we are often given access to data from S (S â‰¥ 1) source domains Ds = {D1, D2, ..., DS} and expect a model to make good prediction on unseen target domains Dt = {D1, D2, ..., DT } (T â‰¥ 1). Our method aims to improve the test-time training (TTT) strategy for better DG. The improvements are two-fold. First, we pro- pose a learnable consistency loss for the TTT task, which could be enforced to align with the main objective by tuning its learnable weights. Second, we suggest including addi- tional adaptive parameters and only updating these adaptive parameters during the test phase. 3.1. A Learnable Consistency Loss for TTT The TTT strategies have shown promising performances when dealing with distribution shift problems [43, 63]. How- ever, their successes are depended on the empirically selected auxiliary TTT tasks, which may deteriorate the performances if chosen improperly. Motivated by the recent successes in multi-view consistency learning [13, 26, 29], we suggest adopting a consistency loss in our TTT task. Note that the naive consistency loss is still not guaranteed to be effective as prior art [46] indicates that only when the auxiliary loss aligns with the main loss, can TTT improves the perfor- mance. To this end, we propose to augment the auxiliary loss with learnable parameters that could be adjusted toward a better alignment between the TTT and main tasks. In our case, we make the adopted consistency loss learnable by introducing a weight subnetwork that allows flexible ways Algorithm 1 Pseudo code of the training phase of ITTA in a PyTorch-like style. # fÎ¸, fÏ•, fw: feature extractor, classifier, weight subnetwork # Î±, 0: weight paramter, all zero tensor # training process for x, yin training loader: # load a minibatch with N samples def forward process(x, y): z, zâ€² = fÎ¸.forward(x) # computing losses Lmain = CrossEntropyLoss(fÏ•.forward(z), y) Lmain+ =CrossEntropyLoss(fÏ•.forward(zâ€²), y) Lwcont = MSELoss(fw.forward(z âˆ’ zâ€²), 0) return Lmain, Lwcont # SGD update: feature extractor and classifier Lmain, Lwcont = forward process(x, y) ([fÎ¸.params, fÏ•.params]).zero grad() (Lmain + Î±Lwcont).backward() update( \u0002 fÎ¸.params, fÏ•.params \u0003 ) # compute objectives for updating weight subnetwork Lmain, Lwcont = forward process(x, y) Lmain.backward() Ë†gmain = fÎ¸.params.grad.clone().normalize() fÎ¸.params.zero grad() Lwcont.backward() Ë†gwcont = fÎ¸.params.grad.clone().normalize() # SGD update: weight subnetwork MSELoss(Ë†gmain, Ë†gwcont).backward() fw.params.zero grad() update(fw.params) to measure the consistency between two views of the same instance. We first introduce the pipeline of our training framework. Given the D dimensional representation z âˆˆ RD1 and its corresponding augmented version zâ€² that are obtained from a feature extractor (i.e. {z, zâ€²} = fÎ¸(x), where x is an input image from Ds, and fÎ¸(Â·) is the feature extractor parame- terized by Î¸. In our implementation, we use the existing augmentation method [75] to obtain zâ€² by modifying the intermediate activation in fÎ¸(x). We show in our supplemen- tary material that our framework can also thrive with other augmentation strategies), our learnable consistency loss is given by, Lwcont = âˆ¥fw(z âˆ’ zâ€²)âˆ¥, (1) where âˆ¥ Â· âˆ¥denotes the L2 norm; fw(Â·) is the weight sub- network parameterized by w. To make the training process more stable and potentially achieve better performance, we apply a dimension-wise nonlinear function to map each di- mension of z âˆ’ zâ€² before calculating the L2 norm. That is, âˆ€h âˆˆ RD, fw(h) is implemented by stacking layers of a nonlinear function: ReLU(a âˆ— h + b), where a âˆˆ RD and b âˆˆ RD are the weight and bias from the nonlinear function, 1We omit the batch dimensions of the variables for simplicity.â€¦ â€¦ subtract Figure 3. Test adaptation process of ITTA. Different from that in the training stage, we include additional adaptive parameters fÎ˜ after each block of the feature extractor fÎ¸. For each test sample x, the intermediate representations zi and zâ€²i obtained from fi Î¸ are passed to fi Î˜ before going to the next block fi+1 Î¸ . We use the learnable consistency loss Lwcont as the objective to update fÎ˜. Please refer to our text for details. and different layers of a, bform the parameter w in fw. In effect, this creates a piecewise-linear mapping function for h: depending on the value of h, the output could be 0, a constant, or a scaling-and-shifted version of h. More studies about the design of fw are provided in our supplementary material. Compared to the naive consistency learning with- out fw, our Lwcont can be more flexible with an adjustable fw, which we show in the following is the key for learning an appropriate loss in the improved TTT framework. Combining Lwcont with the main loss Lmain which applies the cross-entropy loss (CE) for both the origi- nal and augmented inputs ( i.e. Lmain = CE(fÏ•(z), y) + CE(fÏ•(zâ€²), y), where fÏ• is the classifier parameterized by Ï•, and y is the corresponding label), the objective for the feature extractor and classifier can be formulated into, min{Î¸,Ï•} Lmain + Î±Lwcont, (2) where Î± is the weight parameter that balances the contri- butions from the two terms. A simple illustration of the workflow is shown in Figure 2. From Eq. (2), the expected gradients for the feature ex- tractor from Lmain and Lwcont can be represented as, \u001a gmain = âˆ‡Î¸(CE(fÏ•(z), y) + CE(fÏ•(zâ€²), y)), (3) gwcont = âˆ‡Î¸âˆ¥fw(z âˆ’ zâ€²)âˆ¥. (4) We observe that the direction of gwcont is also determined by the weight subnetwork fw(Â·), which should be close with gmain to ensure alignment between Lmain and Lwcont [46, 60]. To this end, we propose a straightforward solution by enforcing equality between the normalized versions of gmain and gwcont, and we use this term as the objective for updating fw(Â·), which gives, min w Lalign, s.t. Lalign = âˆ¥Ë†gmain âˆ’ Ë†gwcontâˆ¥, (5) where Ë†gmain = gmainâˆ’Egmain Ïƒgmain , and similar for Ë†gwcont. In our implementation, we update {Î¸, Ï•} and w in an alternative manner. Pseudo code of the training process are shown in Algorithm 1. Algorithm 2 Pseudo code of the test phase of ITTA in a PyTorch-like style. # fÎ¸, fÏ•: feature extractor, classifier # fw, fÎ˜: weight subnetwork, additional adaptive blocks # m, 0: total number of blocks in fÎ¸, all zero tensor # test process for x in test loader: # load a test batch def forward process(x): z1, zâ€²1 = f1 Î˜.forward((f1 Î¸ .forward(x))) # first blocks for i in range(2, m + 1): # the following m âˆ’ 1 blocks zi, zâ€²i = fi Î¸.forward(ziâˆ’1), fi Î¸.forward(zâ€²iâˆ’1) zi, zâ€²i = fi Î˜.forward(zi), fi Î˜.forward(zâ€²i) return zi, zâ€²i # test adaptation phase: SGD update additional adaptive parameters z, zâ€² = forward process(x) Lwcont = MSELoss(fw.forward(z âˆ’ zâ€²), 0) fÎ˜.params.zero grad() Lwcont.backward() update(fÎ˜.params) # final prediction z, = forward process(x) result = fÏ•.forward(z) 3.2. Including Additional Adaptive Parameters Selecting expressive and reliable parameters to update during the test phase is also essential in the TTT frame- work [63]. Some strategies decide to update all the parame- ters from the feature extractor [3, 43], while others use only the parameters from the specific layers for updating [63, 71]. Given the fact that the sizes of current deep models are often very large and still growing, exhaustively trying different combinations among the millions of candidates seems to be an everlasting job. As there are no consensuses on which parameter should be updated, we suggest another easy alter- native in this work. Specifically, assuming there are a total of m blocks in the pretrained feature extractor fÎ¸(Â·), and the i-th block can be denoted as fi Î¸(Â·). Then the intermediate representation zi from fi Î¸(Â·) can be formulated as, zi = fi Î¸(ziâˆ’1), s.t. z1 = f1 Î¸ (x). (6) We propose to include additional adaptive blockfÎ˜ that is parameterized by Î˜ after each block of fÎ¸ during the test- time adaptation phase, which reformulates Eq. (6) into, zi = fi Î˜(fi Î¸(ziâˆ’1)), s.t. z1 = f1 Î˜(f1 Î¸ (x)), (7) where fÎ˜(Â·) does not change the dimension and sizes of the intermediate representations. In our work, we use a structure similar to fw to implement fÎ˜. Note zm is simplified as z in this phase, and the same process is applied for obtaining zâ€². Then, in the test-time adaptation phase, we suggest only updating the new adaptive parameters via the learned con- sistency loss. The optimization process can be written as,Table 1. Multi sources domain generalization. Experiments are conducted on the DomainBed benchmark [27]. All methods are examined for 60 trials in each unseen domain. Top5 accumulates the number of datasets where a method achieves the top 5 performances. The score here accumulates the numbers of the dataset where a specific art obtains larger accuracy than ERM on account of the variance. Best results are colored as red. Among the 22 methods compared, less than a quarter outperforms ERM in most datasets (Score â‰¥ 3). PACS VLCS OfficeHome TerraInc DomainNet Avg. Top5â†‘ Scoreâ†‘ MMD [40] 81.3 Â± 0.8 74.9 Â± 0.5 59.9 Â± 0.4 42.0 Â± 1.0 7.9 Â± 6.2 53.2 1 2 RSC [33] 80.5 Â± 0.2 75.4 Â± 0.3 58.4 Â± 0.6 39.4 Â± 1.3 27.9 Â± 2.0 56.3 0 1 IRM [1] 80.9 Â± 0.5 75.1 Â± 0.1 58.0 Â± 0.1 38.4 Â± 0.9 30.4 Â± 1.0 56.6 0 1 ARM [72] 80.6 Â± 0.5 75.9 Â± 0.3 59.6 Â± 0.3 37.4 Â± 1.9 29.9 Â± 0.1 56.7 0 0 DANN [23] 79.2 Â± 0.3 76.3 Â± 0.2 59.5 Â± 0.5 37.9 Â± 0.9 31.5 Â± 0.1 56.9 1 1 GroupGRO [55] 80.7 Â± 0.4 75.4 Â± 1.0 60.6 Â± 0.3 41.5 Â± 2.0 27.5 Â± 0.1 57.1 0 1 CDANN [44] 80.3 Â± 0.5 76.0 Â± 0.5 59.3 Â± 0.4 38.6 Â± 2.3 31.8 Â± 0.2 57.2 0 0 VREx [36] 80.2 Â± 0.5 75.3 Â± 0.6 59.5 Â± 0.1 43.2 Â± 0.3 28.1 Â± 1.0 57.3 1 1 CAD [53] 81.9 Â± 0.3 75.2 Â± 0.6 60.5 Â± 0.3 40.5 Â± 0.4 31.0 Â± 0.8 57.8 1 2 CondCAD [53] 80.8 Â± 0.5 76.1 Â± 0.3 61.0 Â± 0.4 39.7 Â± 0.4 31.9 Â± 0.7 57.9 0 1 MTL [6] 80.1 Â± 0.8 75.2 Â± 0.3 59.9 Â± 0.5 40.4 Â± 1.0 35.0 Â± 0.0 58.1 0 0 ERM [61] 79.8 Â± 0.4 75.8 Â± 0.2 60.6 Â± 0.2 38.8 Â± 1.0 35.3 Â± 0.1 58.1 1 - MixStyle [75] 82.6 Â± 0.4 75.2 Â± 0.7 59.6 Â± 0.8 40.9 Â± 1.1 33.9 Â± 0.1 58.4 1 1 MLDG [38] 81.3 Â± 0.2 75.2 Â± 0.3 60.9 Â± 0.2 40.1 Â± 0.9 35.4 Â± 0.0 58.6 1 1 Mixup [68] 79.2 Â± 0.9 76.2 Â± 0.3 61.7 Â± 0.5 42.1 Â± 0.7 34.0 Â± 0.0 58.6 2 2 Fishr [52] 81.3 Â± 0.3 76.2 Â± 0.3 60.9 Â± 0.3 42.6 Â± 1.0 34.2 Â± 0.3 59.0 2 2 SagNet [48] 81.7 Â± 0.6 75.4 Â± 0.8 62.5 Â± 0.3 40.6 Â± 1.5 35.3 Â± 0.1 59.1 1 2 SelfReg [34] 81.8 Â± 0.3 76.4 Â± 0.7 62.4 Â± 0.1 41.3 Â± 0.3 34.7 Â± 0.2 59.3 2 3 Fish [58] 82.0 Â± 0.3 76.9 Â± 0.2 62.0 Â± 0.6 40.2 Â± 0.6 35.5 Â± 0.0 59.3 3 4 CORAL [59] 81.7 Â± 0.0 75.5 Â± 0.4 62.4 Â± 0.4 41.4 Â± 1.8 36.1 Â± 0.2 59.4 2 3 SD [51] 81.9 Â± 0.3 75.5 Â± 0.4 62.9 Â± 0.2 42.0 Â± 1.0 36.3 Â± 0.2 59.7 4 4 Ours 83.8 Â± 0.3 76.9 Â± 0.6 62.0 Â± 0.2 43.2 Â± 0.5 34.9 Â± 0.1 60.2 4 4 min Î˜ âˆ¥fw(z âˆ’ zâ€²)âˆ¥, s.t. {z, zâ€²} = fÎ˜(fÎ¸(x)). (8) Note that different from the training phase, x in this stage is from the target domain Dt, and we use the online setting in [60] for updating. A simple illustration of the test adaptation pipeline is shown in Figure 3. For the final step, we use the original representation ob- tained from the pretrained feature extractor and the adapted adaptive parameters for prediction. Pseudo code of the test stage are shown in Algorithm 2. 4. Experiments 4.1. Settings Datasets. We evalute ITTA on five benchmark datasets: PACS [37] which consists of 9,991 images from 7 cate- gories. This dataset is probably the most widely-used DG benchmark owing to its large distributional shift across 4 do- mains including art painting, cartoon, photo, and sketch; VLCS [18] contains 10,729 images of 5 classes from 4 different datasets (i.e. domains) including PASCAL VOC 2007 [17], LabelMe [54], Caltech [19], and Sun [64] where each dataset is considered a domain in DG;OfficeHome [62] is composed of 15,588 images from 65 classes in office and home environments, and those images can be categorized into 4 domains (i.e. artistic, clipart, product, and real world); TerraInc [4] has 24,788 images from 10 classes. Those images are wild animals taken from 4 different locations (i.e. domains) including L100, L38, L43, and L46; Domain- Net [50] which contains 586,575 images from 345 classes, and the images in it can be depicted in 6 styles (i.e. clipart, infograph, painting, quickdraw, real, and sketch). Implementation details. For all the experiments, we use the ImageNet [15] pretrained ResNet18 [30] backbone that with 4 blocks as the feature extractor fÎ¸, which could en- large the gaps in DG compared to larger models [70]. Corre- spondingly, we also include 4 blocks of additional adaptive parameters (i.e. fÎ˜), and each block is implemented with 5 layers of learnable parameters with weight initialized as all ones and bias initialized as all zeros. For the weight subnet- work fw, we use 10 layers of learnable parameters with the initialization skill similar to that of fÎ˜. The classifier fÏ• is an MLP layer provided by the Domainbed benchmark [27]. For the weight parameter Î± in Eq. (2), we set it to be 1 for all experiments (please refer to our supplementary material for analysis). The random seeds, learning rates, batch size, and augmentation skills are all dynamically set for all the compared arts according to [27].Table 2. Single source domain generalization. Experiments are conducted on the PACS dataset [37]. Here A, C, P, and S are the art, cartoon, photo, and sketch domains in PACS. Aâ†’C represents models trained on the art domain and tested on the cartoon domain, and similar for others. All methods are examined for 60 trials in each unseen domain. Best results are colored as red. Aâ†’C A â†’P A â†’S C â†’A C â†’P C â†’S P â†’A P â†’C P â†’S S â†’A S â†’C S â†’P Avg. RSC 66.3 Â±1.3 88.2Â±0.6 57.2Â±3.1 65.8Â±1.5 82.4Â±0.6 68.7Â±2.5 60.5Â±2.0 41.3Â±6.0 53.1Â±2.8 53.8Â±1.6 65.9Â±0.7 48.4Â±1.9 62.6 Fish 67.1 Â±0.5 89.2Â±1.8 57.0Â±0.2 66.7Â±1.0 85.6Â±0.4 64.5Â±3.6 55.1Â±2.1 33.9Â±2.3 51.2Â±4.2 59.1Â±3.2 67.1Â±0.9 58.4Â±1.2 62.9 CDANN 66.5Â±1.7 92.2Â±0.6 65.0Â±0.9 70.6Â±0.1 82.9Â±1.4 67.7Â±3.0 60.6Â±0.3 42.2Â±6.4 46.9Â±9.9 51.4Â±2.3 60.7Â±1.2 51.9Â±0.4 63.2 SelfReg 63.9Â±1.9 90.1Â±1.0 56.8Â±2.2 70.2Â±2.3 85.4Â±0.3 70.2Â±2.2 60.9Â±2.6 38.8Â±4.0 50.5Â±3.2 54.5Â±4.7 66.2Â±1.2 51.7Â±4.1 63.3 DANN 67.5 Â±1.6 91.2Â±1.3 67.5Â±1.3 70.6Â±1.0 81.4Â±0.4 66.6Â±1.1 54.1Â±2.3 33.5Â±2.7 52.8Â±2.3 53.8Â±1.7 64.4Â±0.7 58.9Â±0.8 63.5 CAD 67.1 Â±1.5 89.6Â±0.4 60.2Â±0.2 67.7Â±3.1 83.7Â±1.4 70.2Â±2.6 60.6Â±2.6 38.3Â±3.7 53.8Â±3.2 50.7Â±1.6 65.8Â±1.3 54.4Â±1.7 63.5 GroupGRO66.5Â±1.2 90.5Â±1.5 58.9Â±2.5 70.8Â±0.9 85.7Â±1.2 69.7Â±1.8 62.3Â±2.1 41.1Â±2.7 48.2Â±4.1 54.8Â±0.5 65.2Â±1.6 53.9Â±1.4 64.0 MTL 67.3 Â±1.0 90.1Â±1.0 58.9Â±0.7 70.2Â±1.8 84.2Â±2.2 71.9Â±0.7 58.3Â±2.7 38.5Â±2.7 52.8Â±1.5 55.4Â±3.1 66.1Â±1.3 55.2Â±2.6 64.1 IRM 67.5 Â±1.8 93.0Â±0.5 62.9Â±4.7 67.6Â±1.3 83.8Â±0.4 68.9Â±0.8 63.7Â±1.8 39.9Â±3.7 49.0Â±5.4 54.9Â±1.4 63.1Â±2.1 54.9Â±1.4 64.1 ARM 66.0 Â±2.4 91.2Â±0.7 58.7Â±6.9 70.6Â±0.8 84.2Â±1.0 69.1Â±0.9 59.2Â±1.8 42.1Â±5.6 52.1Â±3.0 60.0Â±0.6 62.9Â±3.3 53.8Â±2.0 64.2 Mixup 65.5 Â±0.8 87.8Â±0.3 57.2Â±1.0 71.4Â±1.1 83.1Â±1.8 68.0Â±3.0 59.6Â±1.7 37.2Â±2.7 56.5Â±3.8 55.0Â±2.2 66.2Â±1.5 62.7Â±4.2 64.2 CORAL 66.8Â±0.5 90.3Â±0.7 61.5Â±1.9 67.9Â±2.1 85.4Â±0.3 70.4Â±1.3 55.9Â±2.9 40.4Â±4.9 49.8Â±8.5 55.8Â±2.1 67.6Â±0.9 58.9Â±3.8 64.2 SD 67.1 Â±1.3 91.7Â±1.2 63.7Â±4.1 70.3Â±0.9 84.4Â±0.7 69.4Â±2.3 57.5Â±2.5 42.6Â±0.8 47.7Â±1.7 55.9Â±2.4 65.7Â±0.8 55.8Â±2.1 64.3 MMD 67.1 Â±1.4 88.0Â±0.8 63.6Â±1.6 70.0Â±1.1 83.6Â±0.2 70.2Â±1.0 58.8Â±2.6 40.3Â±1.0 52.3Â±2.4 57.4Â±1.9 68.7Â±0.9 52.7Â±3.7 64.4 MLDG 67.3Â±2.0 90.8Â±0.5 64.4Â±0.9 70.8Â±1.0 84.2Â±0.3 69.7Â±1.8 61.6Â±1.0 41.3Â±5.1 50.4Â±0.2 49.9Â±2.5 66.8Â±0.4 58.7Â±3.4 64.7 CondCAD66.9Â±1.4 92.3Â±0.7 60.8Â±4.5 71.0Â±0.6 84.7Â±1.1 72.6Â±0.5 61.2Â±1.5 40.7Â±3.6 55.7Â±1.6 52.3Â±1.7 64.2Â±0.4 55.3Â±1.2 64.8 ERM 67.3 Â±0.7 91.7Â±0.9 60.1Â±4.7 70.4Â±0.6 82.3Â±2.7 68.1Â±0.9 59.6Â±1.8 44.7Â±2.8 56.5Â±2.7 52.8Â±2.3 68.1Â±0.7 58.4Â±0.9 65.0 VREx 67.1 Â±1.5 91.0Â±1.0 62.6Â±3.5 71.1Â±2.4 84.1Â±0.9 71.7Â±1.3 62.4Â±3.1 37.7Â±3.3 53.6Â±2.3 60.6Â±1.6 66.7Â±0.8 57.5Â±1.4 65.5 Fishr 67.9 Â±1.9 92.7Â±0.3 62.4Â±4.7 71.2Â±0.5 83.4Â±0.6 70.2Â±1.1 60.0Â±2.3 42.7Â±3.2 57.1Â±3.9 55.7Â±3.7 68.4Â±1.0 62.0Â±3.1 66.1 SagNet 67.6Â±1.4 92.3Â±0.5 59.5Â±1.7 71.8Â±0.3 82.8Â±0.6 69.9Â±1.8 62.5Â±2.5 45.2Â±2.5 64.1Â±2.0 55.8Â±1.1 65.7Â±1.4 55.9Â±3.5 66.1 MixStyle 68.5Â±2.0 91.2Â±1.6 65.1Â±0.7 73.2Â±1.3 85.0Â±0.8 71.7Â±1.5 63.6Â±1.7 46.3Â±1.1 51.6Â±3.7 54.2Â±1.5 67.0Â±3.4 58.3Â±1.4 66.3 Ours 68.9 Â±0.6 92.4Â±0.1 62.5Â±0.6 75.3Â±0.4 85.9Â±0.3 70.2Â±1.4 66.5Â±1.1 52.2Â±2.7 63.8Â±1.1 57.6Â±3.7 68.0Â±1.3 57.9Â±2.0 68.4 Training and evaluation details. For all the compared methods, we conduct 60 trials on each source domain, and each with 5,000 iteration steps. During the training stage, we split the examples from training domains to 8:2 (train:val) where the training and validation samples are dynamically selected among different training trials. During test, we select the model that performs the best in the validation samples and test it on the target domains. The strategy is referred to as the â€œtraining-domain validate setâ€ model selec- tion method in [27]. For each domain in different datasets, the final performance is the average accuracy from the 60 trials. 4.2. Multi-Source Generalization In these experiments, all five benchmark datasets afore- mentioned are used for evaluation, and the leave-one-out strategy is adopted for training (i.e. with S = |Ds âˆªDt|2 âˆ’1, and T = 1). Results are shown in Table 1. We note that ERM method obtains favorable performance against existing arts. In fact, as a strong baseline, ERM is superior to half of the methods in the term of average accuracy, and only 5 arts (i.e. SelfReg [34], Fish [58], CORAL [59], SD [51], and ours) among the compared 22 methods outperforms ERM in most datasets (i.e. with Score â‰¥ 3). In comparison, the proposed ITTA is more effective than all other models on average. In particular, ITTA achieves the best performances in 3 out of the 5 benchmarks (i.e. PACS, VLCS, and TerraInc datasets) and 4 in the top 5. Note that although our method does not obtain the best performances in the OfficeHome and DomainNet benchmarks, it still outperforms more than half 2We use | Â· |to denote the number of domains in the environment. of the existing models. The results validate the effectiveness of our method when tested in the multi-source setting. We present results of average accuracy in each domain from different datasets in the supplementary material. Please refer to it for details. 4.3. Single-Source Generalization In these experiments, we adopt the widely-used PACS [37] benchmark for evaluation, and the models are trained on one domain while tested on the remaining three (i.e. with S = 1, and T = 3). Although some approaches, such as MLDG [38] and Fishr [52], may require more than one domain information for their trainings, we can simu- late multi-domain information using only the source domain, and thus the experimental settings are still feasible for them. Compared to the multi-source generalization task, the single- source generalization is considered more difficult due to the limited domain information during the training phase. Evalu- ation results are presented in Table 2. We note that the ERM method outperforms most state-of-the-art models, and only 5 models, including VREx [36], Fishr [52], SagNet [48], MixStyle [75], and the proposed ITTA, can obtain better re- sults than ERM in the term of average accuracy. Meanwhile, our method achieves the best performances when trained in 5 out of the 12 source domain, and it obtains the best perfor- mance on average, leading more than 2% than the second best (i.e. MixStyle [75]) and 3% the ERM method. In line with the findings in [27], we notice that the naive ERM method [61] can indeed perform favorably against most existing models under rigorous evaluation protocol. As a matter of fact, the proposed method is the only one that consistently outperforms ERM in both the multi-sourceTable 3. Evaluations of different TTT-based models in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch Baseline 79.9 Â±0.5 75.4Â±1.1 94.4Â±0.5 75.8Â±1.2 81.4Â±0.5 TTT [60] 81.5Â±0.8 77.6Â±0.6 94.3Â±0.2 78.4Â±0.7 83.0Â±0.2 MT3 [3] 82.0 Â±1.0 76.5Â±1.0 94.1Â±0.2 77.7Â±1.3 82.6Â±0.6 TENT [63] 80.2Â±0.9 77.2Â±0.8 94.4Â±0.2 77.4Â±0.1 82.3Â±0.5 Ours 84.7 Â±0.4 78.0Â±0.4 94.5Â±0.4 78.2Â±0.3 83.8Â±0.3 and single-source settings. These results indicate that DG remains challenging for current efforts that aim to ease the distribution shift only through training data, and using the proposed improved TTT strategy may be a promising direc- tion for solving DG. 5. Analysis All experiments in this section are conducted on the widely-used PACS benchmark [37] with the leave-one-out strategy. The experimental settings are the same as that illus- trated in Sec. 4.1. Please refer to our supplementary material for more analysis. 5.1. Compared with Other TTT-Based Models Using test-time adaptation to ease the distribution shift problem has been explored in previous works, such as the original TTT method [60] and MT3 [3]. Their differences lie in that TTT uses a rotation estimation task for the test-time objective, and MT3 adopts a contrastive loss for the task and implements the overall framework using MAML [20]. There is also a recently proposed TENT [63] that aims to minimize the entropy of the final results by tuning the parameters from the batch normalization (BN) layers. To analyze the overall effectiveness of our method, we compare ITTA with these arts using the same baseline (i.e. ResNet18 [30] backbone with the existing augmentation skill [75]). Results are shown in Table 3. We observe that all the com- pared TTT-based methods can improve the baseline model in almost all target domains except for the â€œPhotoâ€ domain, which might be due to the ImageNet pretraining [67]. This phenomenon demonstrates that the TTT strategy may be a promising effort for easing the distribution shift problem. Meanwhile, we observe that the proposed ITTA is superior to all other approaches in most target domains and leads in the term of average accuracy. The main reason is that compared to the empirically designed TTT tasks adopted in previous works, the proposed learnable consistency loss is enforced to be more aligned with the main loss, thus more suitable for the test-time adaptation task [46]. Meanwhile, compared to the strategies that update the original param- eters from the trained model, the adaptation of the newly included parameters is also more effective for the overall (a) Input (b) Ours w/o fw (c) Ours (d) Main Figure 4. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels from the four target do- mains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). Ours w/o fw is the naive consis- tency loss with fw disabled in Eq. (1). The proposed learnable consistency loss can align well with the main classification task. TTT framework. In the following, we provide more analysis to support these claims. 5.2. Effectiveness of the Learnable Consistency Loss To examine the effectiveness of our learnable consistency loss, we conduct ablation studies by comparing our method with the following variants. (1) Ours w/o fw: we disable fw when computing the learnable consistency loss in Eq. (1), which uses the naive consistency loss for the auxiliary TTT task. (2) Ours w/ Ent.: after training the model using the baseline settings (i.e. ResNet18 with the augmentation strat- egy [75]), we use the entropy minimization task in [63] for the TTT task. (3) Ours w/ Rot.: we use the rotation estimation task in [60] for the TTT task. To ensure fair com- parisons, we use the same baseline settings and include the same additional adaptive parameters for all the variants. Results are shown in the 4th to 6th rows Table 4. We find that the results from the naive consistency loss ( i.e. Ours w/o fw) are slightly better than that from the other two specially-designed objectives (i.e. Ours w/ Ent. and Ours w/ Rot.) on average. Besides the possibility of deteriorating the performance [46], our results indicate that empirically select- ing a TTT task may also be far from optimal. Meanwhile, we observe that when enabling fw, the proposed learnable consistency loss is superior to that withoutfw in all target do-Table 4. Comparison between different TTT tasks and parameter selecting strategies in the unseen domain from the PACS benchmark [37]. Here the â€œEnt.â€, â€œRot.â€, and â€œLwcontâ€ denotes the entropy minimization task in [63], the rotation estimation task in [60], and the proposed learnable consistency objective, the â€œAllâ€, â€œBNâ€, and â€œAda.â€ are the strategies that update all the parameters, parameters from the batch normalization layer, and the proposed strategy that updates only the new additional adaptive parameters. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model TTT tasks Param selectings Target domain Avg.Ent. Rot. Lwcont All BN Ada. Art Cartoon Photo Sketch Ours âˆ’ âˆ’ âœ“ âˆ’ âˆ’ âœ“ 84.7Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 Ours w/ofw âˆ’ âˆ’ âˆ’ âˆ’ âˆ’ âœ“ 83.1Â±0.4 74.6 Â±0.6 94.0 Â±0.5 78.0 Â±0.8 82.5 Â±0.1 Ours w/ Ent. âœ“ âˆ’ âˆ’ âˆ’ âˆ’ âœ“ 79.9Â±2.4 77.3 Â±0.3 94.8 Â±0.8 77.6 Â±0.4 82.4 Â±0.8 Ours w/ Rot. âˆ’ âœ“ âˆ’ âˆ’ âˆ’ âœ“ 81.1Â±1.0 75.2 Â±0.5 94.9 Â±0.3 77.3 Â±0.6 82.1 Â±0.3 Ours w/o TTT âˆ’ âˆ’ âœ“ âˆ’ âˆ’ âˆ’ 83.3Â±0.5 76.0 Â±0.5 94.4 Â±0.5 76.7 Â±1.4 82.8 Â±0.3 Ours w/ All âˆ’ âˆ’ âœ“ âœ“ âˆ’ âˆ’ 83.0Â±0.7 77.0 Â±1.4 94.5 Â±0.7 77.4 Â±0.9 83.0 Â±0.2 Ours w/ BN âˆ’ âˆ’ âœ“ âˆ’ âœ“ âˆ’ 81.8Â±0.5 75.6 Â±0.3 94.4 Â±0.3 77.9 Â±1.1 82.4 Â±0.5 mains, and it leads in the term of average accuracy among the variants compared, illustrating its advantage against other adopted TTT tasks. These results are not surprising. By comparing the Grad-CAM [57] visualizations from the main classification task with the learnable and naive consistency losses in Figure 4, we find that the proposed learnable objec- tive can well align with the main loss when fw is enabled as the hot zones activated by these two tasks are similar, which guarantees the improvement for the test-time adapta- tion [46, 60]. Please refer to our supplementary material for more visualizations. 5.3. Effectiveness of the Adaptive Parameters We compare ITTA with three variants to demonstrate the effectiveness of the proposed additional adaptive parameters. (1) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model. (2) Ours w/ ALL: similar to the updating strategy in the original TTT method [60], we update all the parameters from the feature extractor during the test phase. (3) Ours w/ BN: following the suggestion from TENT [63], only parameters from the BN layers of the feature extractor are updated. Note the same pretrained model is shared for all variants in these experiments, and the objectives during the test adaptation phase are to minimize the same learned consistency loss. We list the results in the last three rows in Table 4. We observe that when only updating parameters from the BN layers, the performance is inferior to the strategy without test-time adaptation, and updating all the parameters does not ensure improvements in all target domains. The observations are in line with the findings in [63] that selecting reliable parameters to update is essential in the TTT system and may also interact with the choice of the TTT task. In comparison, when including additional adaptive parameters for updating, the pretrained model can be boosted in all environments. The results validate that our adaptive parameters are more effective than that selected with existing strategies [60, 63] when applied with the proposed learnable test-time objective. 5.4. Limitation Although the proposed learned loss can bring satisfaction improvements, we are aware that the lunch is not free. When the weight subnetwork fw is disabled, updating the joint loss in Eq. (2) only costs 1 forward and 1 backward. However, in order to update fw, we have to compute the second-order derivative in Eq. (5), which will require 1 more forward and 3 more backward processes, bringing extra burden to the system. Our future efforts aim to simplify the overall optimization process and reduce the cost for ITTA. 6. Conclusion In this paper, we aim to improve the current TTT strategy for alleviating the distribution shift problem in DG. First, given that the auxiliary TTT task plays a vital role in the over- all framework, and an empirically selecting one that does not align with the main task may potentially deteriorate instead of improving the performance, we propose a learnable con- sistency loss that can be enforced to be more aligned with the main loss by adjusting its learnable parameters. This strategy is ensured to improve the model and shows favorable perfor- mance against some specially-designed objectives. Second, considering that selecting reliable and effective parameters to update during the test phase is also essential while exhaus- tively trying different combinations may require tremendous effort, we propose a new alternative by including new ad- ditional adaptive parameters for adaptation during the test phase. This alternative is shown to outperform some pre- vious parameter selecting strategies via our experimental findings. By conducting extensive experiments under a rig- orous evaluation protocol, we show that our method can achieve superior performance against existing arts in both the multi-source and single-source DG tasks. Acknowledgements. Liang Chen is supported by the ChinaScholarship Council (CSC Student ID 202008440331). References [1] Martin Arjovsky, LÂ´eon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019. 5, 15, 16, 17 [2] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. In NeurIPS, 2018. 1, 2, 14, 15 [3] Alexander Bartler, Andre BÂ¨uhler, Felix Wiewel, Mario DÂ¨obler, and Bin Yang. Mt3: Meta test-time training for self- supervised test-time adaption. In AISTATS, 2022. 2, 4, 7 [4] Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In ECCV, 2018. 5, 17 [5] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In NeurIPS, 2006. 2 [6] Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton Scott. Domain generalization by marginal transfer learning. arXiv preprint arXiv:1711.07910, 2017. 5, 15, 16, 17 [7] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generaliz- ing from several related classification tasks to a new unlabeled sample. In NeurIPS, 2011. 1 [8] Chaoqi Chen, Jiongcheng Li, Xiaoguang Han, Xiaoqing Liu, and Yizhou Yu. Compound domain generalization via meta- knowledge encoding. In CVPR, 2022. 1 [9] Chaoqi Chen, Luyao Tang, Feng Liu, Gangming Zhao, Yue Huang, and Yizhou Yu. Mix and reason: Reasoning over se- mantic topology with data mixing for domain generalization. In NeurIPS, 2022. 1 [10] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022. 2 [11] Liang Chen, Yong Zhang, Yibing Song, Lingqiao Liu, and Jue Wang. Self-supervised learning of adversarial example: Towards good generalizations for deepfake detection. In CVPR, 2022. 2 [12] Liang Chen, Yong Zhang, Yibing Song, Jue Wang, and Lingqiao Liu. Ost: Improving generalization of deepfake detection via one-shot test-time training. In NeurIPS, 2022. 2, 12 [13] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geof- frey Hinton. A simple framework for contrastive learning of visual representations. In ICML, 2020. 2, 3 [14] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, 2022. 2 [15] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 5 [16] Qi Dou, Daniel Coelho de Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via model-agnostic learning of semantic features. In NeurIPS, 2019. 1, 2 [17] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303â€“338, 2010. 5 [18] Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In ICCV, 2013. 5, 16 [19] Li Fei-Fei, Rob Fergus, and Pietro Perona. Learning gener- ative visual models from few training examples: An incre- mental bayesian approach tested on 101 object categories. In CVPR worksho, 2004. 5 [20] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model- agnostic meta-learning for fast adaptation of deep networks. In ICML, 2017. 2, 7 [21] Francois Fleuret et al. Uncertainty reduction for model adap- tation in semantic segmentation. In CVPR, 2021. 2 [22] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 2 [23] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc Â¸ois Laviolette, Mario Marc- hand, and Victor Lempitsky. Domain-adversarial training of neural networks. JMLR, 17(1):2096â€“2030, 2016. 1, 2, 5, 15, 16, 17 [24] Muhammad Ghifary, David Balduzzi, W Bastiaan Kleijn, and Mengjie Zhang. Scatter component analysis: A unified framework for domain adaptation and domain generalization. IEEE TPAMI, 39(7):1414â€“1430, 2016. 1 [25] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generalization for object recognition with multi-task autoencoders. In ICCV, 2015. 2 [26] Jean-Bastien Grill, Florian Strub, Florent Altch Â´e, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doer- sch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Ghesh- laghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. In NeurIPS, 2020. 2, 3 [27] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In ICLR, 2021. 1, 2, 5, 6, 14, 15, 16, 17 [28] Sivan Harary, Eli Schwartz, Assaf Arbelle, Peter Staar, Shady Abu-Hussein, Elad Amrani, Roei Herzig, Amit Alfassy, Raja Giryes, Hilde Kuehne, et al. Unsupervised domain general- ization by learning a bridge across domains. In CVPR, 2022. 1 [29] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual repre- sentation learning. In CVPR, 2020. 2, 3 [30] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 5, 7, 14 [31] Shoubo Hu, Kun Zhang, Zhitang Chen, and Laiwan Chan. Domain generalization via multidomain discriminant analysis. In UAI, 2020. 1 [32] Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In ICCV, 2017. 2 [33] Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain generalization. In ECCV, 2020. 5, 15, 16, 17[34] Daehee Kim, Youngjun Yoo, Seunghyun Park, Jinkyu Kim, and Jaekoo Lee. Selfreg: Self-supervised contrastive regular- ization for domain generalization. In ICCV, 2021. 2, 5, 6, 15, 16, 17 [35] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribu- tion shifts. In ICML, 2021. 1 [36] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In ICML, 2021. 5, 6, 15, 16, 17 [37] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In ICCV, 2017. 1, 5, 6, 7, 8, 12, 13, 14, 15 [38] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, 2018. 1, 2, 5, 6, 15, 16, 17 [39] Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and Timothy M Hospedales. Episodic training for domain generalization. In ICCV, 2019. 1, 2 [40] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adversarial feature learning. In CVPR, 2018. 1, 2, 5, 15, 16, 17 [41] Pan Li, Da Li, Wei Li, Shaogang Gong, Yanwei Fu, and Timothy M Hospedales. A simple feature augmentation for domain generalization. In ICCV, 2021. 1, 2, 12, 14 [42] Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan, and Ling-Yu Duan. Uncertainty modeling for out- of-distribution generalization. In ICLR, 2022. 1, 2 [43] Yizhuo Li, Miao Hao, Zonglin Di, Nitesh Bharadwaj Gun- davarapu, and Xiaolong Wang. Test-time personalization with a transformer for human pose estimation. In NeurIPS, 2021. 2, 3, 4 [44] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep domain generaliza- tion via conditional invariant adversarial networks. In ECCV, 2018. 1, 2, 5, 15, 16, 17 [45] Yiying Li, Yongxin Yang, Wei Zhou, and Timothy Hospedales. Feature-critic networks for heterogeneous do- main generalization. In ICML, 2019. 14, 15 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In NeurIPS, 2021. 2, 3, 4, 7, 8, 12, 14, 15 [47] Krikamol Muandet, David Balduzzi, and Bernhard SchÂ¨olkopf. Domain generalization via invariant feature representation. In ICML, 2013. 1, 2 [48] Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing domain gap by reducing style bias. In CVPR, 2021. 2, 5, 6, 15, 16, 17 [49] Prashant Pandey, Mrigank Raman, Sumanth Varambally, and Prathosh Ap. Generalization on unseen domains via inference- time label-preserving target projections. In CVPR, 2021. 1 [50] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, 2019. 5, 17 [51] Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and Guillaume Lajoie. Gradient star- vation: A learning proclivity in neural networks. In NeurIPS, 2021. 1, 5, 6, 15, 16, 17 [52] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for out-of-distribution gen- eralization. In ICML, 2022. 1, 2, 5, 6, 15, 16, 17 [53] Yangjun Ruan, Yann Dubois, and Chris J Maddison. Optimal representations for covariate shift. In ICLR, 2022. 5, 15, 16, 17 [54] Bryan C Russell, Antonio Torralba, Kevin P Murphy, and William T Freeman. Labelme: a database and web-based tool for image annotation. IJCV, 77(1):157â€“173, 2008. 5 [55] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst- case generalization. In ICLR, 2020. 5, 15, 16, 17 [56] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. 2 [57] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad- cam: Visual explanations from deep networks via gradient- based localization. In ICCV, 2017. 7, 8, 11, 13 [58] Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In ICLR, 2021. 1, 2, 5, 6, 15, 16, 17 [59] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In ECCV, 2016. 5, 6, 15, 16, 17 [60] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, 2020. 1, 2, 4, 5, 7, 8, 11, 12, 13 [61] Vladimir Vapnik. The nature of statistical learning theory . Springer science & business media, 1999. 1, 5, 6, 15, 16, 17 [62] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017. 5, 16 [63] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 2, 3, 4, 7, 8, 11, 12, 13 [64] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Large-scale scene recog- nition from abbey to zoo. In CVPR, 2010. 5 [65] Zehao Xiao, Xiantong Zhen, Ling Shao, and Cees GM Snoek. Learning to generalize across domains on single test samples. In ICLR, 2022. 2 [66] Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. A fourier-based framework for domain generaliza- tion. In CVPR, 2021. 1, 2 [67] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 7[68] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020. 2, 5, 15, 16, 17 [69] Fu-En Yang, Yuan-Chia Cheng, Zu-Yun Shiau, and Yu- Chiang Frank Wang. Adversarial teacher-student representa- tion learning for domain generalization. In NeurIPS, 2021. 1, 2 [70] Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and Jun Zhu. Ood-bench: Quantifying and understanding two dimensions of out-of- distribution generalization. In CVPR, 2022. 5 [71] Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. 4 [72] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: A meta-learning approach for tackling group distri- bution shift. arXiv preprint arXiv:2007.02931, 2020. 5, 15, 16, 17 [73] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: Learning to adapt to domain shift. NeurIPS, 2021. 2 [74] Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu, and Jin Tang. Meta-dmoe: Adapting to domain shift by meta- distillation from mixture-of-experts. In NeurIPS, 2022. 2 [75] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 1, 2, 3, 5, 6, 7, 12, 15, 16, 17 Appendix In this supplementary material, we provide, 1. Resource usage for ITTA in Section 7. 2. Grad-CAM visualizations of different loss terms in Section 8. 3. Parameter analysis of ITTA in Section 9; 4. Using a different augmentation skill for ITTA in Sec- tion 10. 5. Using different updating steps or a strategy for ITTA during the test phase in Section 11. 6. Using different network structures for the learnable consistency loss and adaptive parameters in Section 12. 7. Comparisons with other related methods in Section 13. 8. Detailed experimental results in the DomainBed bench- mark in Section 14. 7. Resource Usage Comparisons Between ITTA and the Baseline Model Requiring extra resources for our ITTA is a common lim- itation for existing test-time-based arts. To further evaluate our method, in this section, we compare FLOPS, model size, and inference time in Table 5. We compare only with ERM as most existing methods utilize the same network during in- ferences. We note that compare to the baseline model, ITTA requires extra Flops and processing time, this is because the adaptation process uses extra forward and backward steps during the test phase. While the parameters between the two models are similar because the newly included adaptive blocks are much smaller in size compared to the original model. Table 5. Resource comparisons during testing. Here inc. and exc. columns in ITTA indicate to include and exclude the TTA phase. Model Flops (G) Params (M) Time (s) Baseline 1.82 11.18 0.004 ITTA (inc.| exc.) 6.12 | 1.83 14.95 | 14.94 0.021 | 0.005 8. Grad-CAM Visualizations of Different Self- Supervised Objectives In Section 5 of the manuscript, we provide Grad-CAM [57] visualizations of our learnable consistency and the main losses to illustrate their alignment. To further show the differences between several TTT tasks [60, 63], we present more visual examples in this section. Results are shown in Figure 5. We observe that the entropy minimization [63] and rotation estimation [60] objectives do not activate the same regions as the main loss. As shown in the first row, for the class label of giraffe, both the main loss and our learned loss can correctly locate the two giraffes in the image, while the rotation estimation task can only locate one target, the same observation can be found when the learned weightsare disabled in our loss term. Meanwhile, although the two objects can be found for the entropy minimization task, the corresponding hot region does not align with that of the main loss. Similar phenomena can be observed in other samples. These visual examples demonstrate that our learned objective can better align with the main task than the TTT tasks adopted in previous works [60, 63], explaining why using the proposed learnable consistency loss can better improve TTT. 9. Parameter Analysis In this section, we analyze the hyper-parameter used in ITTA. We use the weight parameterÎ± to balance the contri- butions from the main loss and weighted consistency loss (i.e. Lmain + Î±Lwcont in Eq. (2) of our manuscript). To analyze the sensitivity of ITTA regarding different values of Î±, we conduct ablation studies in the PACS benchmark [37]. Results are listed in Table 6. We observe that the proposed ITTA can obtain favorable performances when Î± is in the range of 0.1 to 10, and it performs the best on average when setting as 1. We thus fix the parameter as 1 in all experi- ments. 10. A Different Augmentation Skill for ITTA In our manuscript, we use the existing augmentation strat- egy from [75] to obtain the augmented feature. In this sec- tion, we replace this implementation with that from [41] to further verify if our ITTA can still thrive with another aug- mentation skill. Different from [75] that mixes the statics of the feature to synthesize new information, [41] uses an affine transformation to create new features, where the weight for the transformation is sampled from a normal distribution with the mean value of one and standard value of zero, and the bias for the transformation is sampled from a normal distribution with the mean and standard values both zero. Experiments are conducted on the PACS benchmark [37] with the leave-one-out strategy. We compare ITTA with several different variants. (1) Ours w/o fw & TTT: this variant is the baseline model which uses the naive consistency loss for training and does not include TTT during the test phase. (2) Ours w/o fw: we disable the fw in our consistency loss, which uses the naive consistency loss for the test-time updating. (3) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model when replacing the augmentation strategy. We also compare these variants with the ERM method to show their effectivenesses. Results are listed in Table 7. We observe that ERM per- forms favorably against the baseline model, indicating that this augmentation strategy may not be beneficial for the training process. Meanwhile, we observe that when fw is disabled, the performances seem to decrease in 3 out of 4 target domains, and the average accuracy is also inferior to the baseline (i.e. Ours w/o fw & TTT). This result is in line with the finding in [46] that an inappropriate TTT task may deteriorate the performance. In comparison, we note that the performances are both improved when fw is enabled (i.e. Ours w/o TTT and Ours), which once again demonstrates that the proposed learnable consistency loss can improve the trained model. Moreover, we can also observe that when combining fw and TTT, our model is superior to other vari- ants and the ERM method. These results demonstrate that the proposed two strategies can improve the current TTT framework despite a less effective augmentation strategy. 11. Different Updating Steps or Strategies for ITTA In the manuscript, we use one TTT step for ITTA before during the testing step. In this section, we conduct experi- ments to evaluate the performances of ITTA with different TTT steps. Experiments are conducted on the PACS bench- mark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper- parameter settings. Results are listed in Table 8. We observe that the average accuracies of using more TTT steps are not improved greatly while the computational times are propor- tional to the TTT steps. To this end, we use one TTT step for ITTA as a compromise between accuracy and efficiency. We use the online setting from TTT [60] for all arts, which assumes test samples arrive sequentially and updates the adaptive blocks based on the states optimized from a previous sample. In this section, we also test ITTA in an episodic manner (i.e. Epi) [12]. Results in Table 8 suggest that while the episodic updating strategy performs slightly worse than the current scheme, and it still outperforms the baseline. 12. Different Network Structures for the Learnable Consistency Loss and Adaptive Parameters In our implementation, we use 10 layers of learnable pa- rameters for fw, and we use 5 layers of learnable parameters for fÎ˜ after each block. In this section, we evaluate our ITTA with different network structures for these two mod- ules. Specifically, we compare the original implementation with the variants that use 1, 5, and 15 layers for fw and 1, 10, and 15 layers for fÎ˜ to evaluate the performances of dif- ferent structures. Similarly, we conduct experiments on the PACS benchmark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper-parameter settings. Evaluation results are listed in Table 9. We observe that their differences in the average accuracy are rather subtle on account of the variances. To(a) Input (b) Entropy (c) Rotation (d) Ours w/o fw (e) Ours (f) Main Figure 5. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels (i.e. giraffe, elephant, house, and horse from top to bottom) from the four target domains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). â€œEntropyâ€ and â€œRotationâ€ here denote the entropy minimization and rotation estimation tasks in [63] and [60]. Ours w/o fw is the learnable consistency loss in Eq. (1) in the manuscript (i.e. âˆ¥fw(z âˆ’ zâ€²)âˆ¥) when fw is disabled. The proposed learnable consistency loss can align well with the main classification task. Table 6. Sensitivity analysis of ITTA regarding different values ofÎ± in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Values Target domain Avg.Art Cartoon Photo Sketch Î± = 0.1 83.9 Â± 0.7 76.2 Â± 1.1 94.8 Â± 0.2 78.8 Â± 0.8 83.4 Â± 0.2 Î± = 1 (Ours) 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 Î± = 10 83.9 Â± 0.5 77.4 Â± 0.6 94.2 Â± 0.7 77.3 Â± 0.8 83.2 Â± 0.3 Î± = 100 81.5 Â± 1.2 77.0 Â± 0.6 92.6 Â± 0.7 78.9 Â± 2.1 82.5 Â± 0.9 this end, we use the original implementation with 10 layers of learnable parameters for fw and 5 layers of learnable pa- rameters for fÎ˜, which performs relatively better than other variants. Since the adaptive blocks fÎ˜ are attached after each layer of the network, one may wonder how the varying locations of the adaptive blocks affect the performance of ITTA. To answer this question, we further conduct experiments by adding the adaptive blocks after different layers of the orig- inal network. Denoting as Loc = lan given the n layers in the original network, we note that the model performs less effectively when the adaptive block is placed after the 1st layer of the network, and using all four adaptive blocks (i.e. ours) is more effective than other alternatives. 13. Comparisons with Other Related Methods Apart from the proposed ITTA, some other works also propose to include learnable parameters in their auxiliaryTable 7. Performances of our method with another augmentation strategy from [41] in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch ERM 78.0 Â± 1.3 73.4 Â± 0.8 94.1 Â± 0.4 73.6 Â± 2.2 79.8 Â± 0.4 Ours w/o fw & TTT 74.9 Â± 0.4 74.1 Â± 0.8 90.6 Â± 0.3 79.7 Â± 0.7 79.8 Â± 0.4 Ours w/o fw 77.1 Â± 1.0 73.6 Â± 1.1 89.9 Â± 0.4 78.4 Â± 0.8 79.7 Â± 0.2 Ours w/o TTT 77.5 Â± 0.3 73.2 Â± 0.6 92.4 Â± 0.4 78.0 Â± 1.0 80.3 Â± 0.3 Ours (w/ fw & TTT) 79.2 Â± 0.8 74.9 Â± 1.1 92.2 Â± 0.3 76.9 Â± 0.7 80.8 Â± 0.4 Table 8. Evaluations of ITTA in the unseen domain from PACS [37] with different TTT steps and updating strategies during the testing phase. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. The time consumption (TC) is computed using one image with the size of 224 Ã— 224. Epi. denotes updating ITTA in an episodic manner. Steps Target domain Avg. TCArt Cartoon Photo Sketch 1 step (Ours) 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 2.4 ms 2 step 84.2 Â± 0.9 77.5 Â± 0.6 94.4 Â± 0.4 79.1 Â± 1.0 83.8 Â± 0.1 4.2 ms 3 step 84.5 Â± 1.2 77.6 Â± 0.6 94.0 Â± 0.6 79.3 Â± 0.1 83.9 Â± 0.3 6.1 ms Epi. 83.6 Â± 0.7 77.9 Â± 0.5 95.2 Â± 0.1 76.6 Â± 0.5 83.3 Â± 0.4 losses. Examples include MetaReg [2] and Feature-Critic [45] which both suggest using meta-learning to produce more general models. The main difference between these arts and ITTA is that parameters in the auxiliary loss from [2,45] are gradually refined by episode training, and they are updated via a gradient alignment step in ITTA (see Sec. 3.1 in the manuscript), which is much simpler. In this sec- tion, we compare ITTA with these two arts in the PACS dataset [37] using the same settings aforementioned. Be- cause MetaReg [2] does not release codes, we thus directly cite the data from their paper in the comparison. Different from others, the results in [2] are averaged by 5 trials accord- ing to their paper, which is much less than our experimental settings. Meanwhile, we also compare with TTT++ [46] which suggests storing the momentum of the features from the source domain and enforcing the similarity between mo- mentums of features from the source and target domains. We use the same setting in Section 5.1 from the manuscript to evaluate TTT++. Results are listed in Table 10. We observe that our method consistently outperforms that from [2,45,46] for both the cases with and without TTT, indicating that the proposed learnable consistency loss and updating method is not only simpler but also more effective than the losses in [2, 45]. 14. Detailed Results in the DomainBed Bench- mark [27] this section presents the average accuracy in each domain from different datasets. As shown in Table 11, 12, 13, 14, and 15, these results are detailed illustrations of the results in Table 2 in our manuscript. For all the experiments, we use the â€œtraining-domain validate setâ€ as the model selection method. A total of 22 methods are examined for 60 trials in each unseen domain, and all methods are trained with the leave-one-out strategy using the ResNet18 [30] backbones.Table 9. Performances of our method with different network structures for the consistency loss (i.e. fw) and adaptive parameters (i.e. fÎ˜) in the unseen domain from PACS [37]. Here â€˜Loc=lanâ€™ locates the adaptive block after the n-th layer of the model (â€˜la4â€™ is the last layer). The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Structures Target domain Avg.Art Cartoon Photo Sketch Structures offw 1 layer 83.5 Â±1.2 76.0 Â±1.0 95.3 Â±0.2 78.7 Â±1.5 83.4 Â±0.4 5 layers 83.7 Â±0.6 76.8 Â±0.9 94.6 Â±0.3 78.8 Â±0.3 83.5 Â±0.3 10 layers (Ours) 84.7 Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 15 layers 84.1 Â±0.4 75.8 Â±0.2 94.3 Â±0.3 79.5 Â±0.4 83.4 Â±0.2 Structures offÎ˜ 1 layer 84.0 Â±0.6 77.4 Â±0.5 94.4 Â±0.5 78.3 Â±0.4 83.5 Â±0.3 5 layers (Ours) 84.7 Â±0.4 78.0 Â±0.4 94.5 Â±0.4 78.2 Â±0.3 83.8 Â±0.3 10 layers 84.8 Â±0.3 76.0 Â±0.6 94.1 Â±0.5 78.3 Â±0.1 83.3 Â±0.3 15 layers 83.9 Â±0.8 76.0 Â±0.5 93.8 Â±0.4 78.7 Â±1.4 83.1 Â±0.6 Locations offÎ˜ Loc=la1 83.4Â±0.7 76.8 Â±0.3 94.4 Â±0.3 77.8 Â±0.3 83.1 Â±0.3 Loc=la2 83.4Â±0.6 77.7 Â±0.6 94.2 Â±0.5 78.0 Â±0.5 83.3 Â±0.3 Loc=la3 84.0Â±0.4 77.5 Â±0.3 94.4 Â±0.1 77.8 Â±0.1 83.4 Â±0.2 Loc=la4 84.1Â±0.7 77.8 Â±0.5 94.8 Â±0.2 76.9 Â±1.5 83.4 Â±0.4 Table 10. Compare with learnable losses in [2, 45] in the unseen domain from PACS [37]. The reported accuracies ( %) and standard deviations are computed from 60 trials in each target domain except for [2] where the numbers are directly cited from their paper. Model Target domain Avg.Art Cartoon Photo Sketch MetaReg [2] 83.7 Â± 0.2 77.2 Â± 0.3 95.5 Â± 0.2 70.3 Â± 0.3 81.7 Feture-Critic [45] 78.4 Â± 1.6 75.4 Â± 1.2 92.6 Â± 0.5 73.3 Â± 1.4 80.0 Â± 0.3 TTT++ [46] 84.3 Â± 0.1 78.4 Â± 0.5 93.8 Â± 1.3 73.2 Â± 3.2 82.4 Â± 1.1 Ours w/o TTT 83.3 Â± 0.5 76.0 Â± 0.5 94.4 Â± 0.5 76.7 Â± 1.4 82.8 Â± 0.3 Ours 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3 Table 11. Average accuracies on the PACS [37] datasets using the default hyper-parameter settings in DomainBed [27]. art cartoon photo sketch Average ERM [61] 78.0 Â± 1.3 73.4 Â± 0.8 94.1 Â± 0.4 73.6 Â± 2.2 79.8 Â± 0.4 IRM [1] 76.9 Â± 2.6 75.1 Â± 0.7 94.3 Â± 0.4 77.4 Â± 0.4 80.9 Â± 0.5 GroupGRO [55] 77.7 Â± 2.6 76.4 Â± 0.3 94.0 Â± 0.3 74.8 Â± 1.3 80.7 Â± 0.4 Mixup [68] 79.3 Â± 1.1 74.2 Â± 0.3 94.9 Â± 0.3 68.3 Â± 2.7 79.2 Â± 0.9 MLDG [38] 78.4 Â± 0.7 75.1 Â± 0.5 94.8 Â± 0.4 76.7 Â± 0.8 81.3 Â± 0.2 CORAL [59] 81.5 Â± 0.5 75.4 Â± 0.7 95.2 Â± 0.5 74.8 Â± 0.4 81.7 Â± 0.0 MMD [40] 81.3 Â± 0.6 75.5 Â± 1.0 94.0 Â± 0.5 74.3 Â± 1.5 81.3 Â± 0.8 DANN [23] 79.0 Â± 0.6 72.5 Â± 0.7 94.4 Â± 0.5 70.8 Â± 3.0 79.2 Â± 0.3 CDANN [44] 80.4 Â± 0.8 73.7 Â± 0.3 93.1 Â± 0.6 74.2 Â± 1.7 80.3 Â± 0.5 MTL [6] 78.7 Â± 0.6 73.4 Â± 1.0 94.1 Â± 0.6 74.4 Â± 3.0 80.1 Â± 0.8 SagNet [48] 82.9 Â± 0.4 73.2 Â± 1.1 94.6 Â± 0.5 76.1 Â± 1.8 81.7 Â± 0.6 ARM [72] 79.4 Â± 0.6 75.0 Â± 0.7 94.3 Â± 0.6 73.8 Â± 0.6 80.6 Â± 0.5 VREx [36] 74.4 Â± 0.7 75.0 Â± 0.4 93.3 Â± 0.3 78.1 Â± 0.9 80.2 Â± 0.5 RSC [33] 78.5 Â± 1.1 73.3 Â± 0.9 93.6 Â± 0.6 76.5 Â± 1.4 80.5 Â± 0.2 SelfReg [34] 82.5 Â± 0.8 74.4 Â± 1.5 95.4 Â± 0.5 74.9 Â± 1.3 81.8 Â± 0.3 MixStyle [75] 82.6 Â± 1.2 76.3 Â± 0.4 94.2 Â± 0.3 77.5 Â± 1.3 82.6 Â± 0.4 Fish [58] 80.9 Â± 1.0 75.9 Â± 0.4 95.0 Â± 0.4 76.2 Â± 1.0 82.0 Â± 0.3 SD [51] 83.2 Â± 0.6 74.6 Â± 0.3 94.6 Â± 0.1 75.1 Â± 1.6 81.9 Â± 0.3 CAD [53] 83.9 Â± 0.8 74.2 Â± 0.4 94.6 Â± 0.4 75.0 Â± 1.2 81.9 Â± 0.3 CondCAD [53] 79.7 Â± 1.0 74.2 Â± 0.9 94.6 Â± 0.4 74.8 Â± 1.4 80.8 Â± 0.5 Fishr [52] 81.2 Â± 0.4 75.8 Â± 0.8 94.3 Â± 0.3 73.8 Â± 0.6 81.3 Â± 0.3 Ours 84.7 Â± 0.4 78.0 Â± 0.4 94.5 Â± 0.4 78.2 Â± 0.3 83.8 Â± 0.3Table 12. Average accuracies on the VLCS [18] datasets using the default hyper-parameter settings in DomainBed [27]. Caltech LabelMe Sun VOC Average ERM [61] 97.7 Â± 0.3 62.1 Â± 0.9 70.3 Â± 0.9 73.2 Â± 0.7 75.8 Â± 0.2 IRM [1] 96.1 Â± 0.8 62.5 Â± 0.3 69.9 Â± 0.7 72.0 Â± 1.4 75.1 Â± 0.1 GroupGRO [55] 96.7 Â± 0.6 61.7 Â± 1.5 70.2 Â± 1.8 72.9 Â± 0.6 75.4 Â± 1.0 Mixup [68] 95.6 Â± 1.5 62.7 Â± 0.4 71.3 Â± 0.3 75.4 Â± 0.2 76.2 Â± 0.3 MLDG [38] 95.8 Â± 0.5 63.3 Â± 0.8 68.5 Â± 0.5 73.1 Â± 0.8 75.2 Â± 0.3 CORAL [59] 96.5 Â± 0.3 62.8 Â± 0.1 69.1 Â± 0.6 73.8 Â± 1.0 75.5 Â± 0.4 MMD [40] 96.0 Â± 0.8 64.3 Â± 0.6 68.5 Â± 0.6 70.8 Â± 0.1 74.9 Â± 0.5 DANN [23] 97.2 Â± 0.1 63.3 Â± 0.6 70.2 Â± 0.9 74.4 Â± 0.2 76.3 Â± 0.2 CDANN [44] 95.4 Â± 1.2 62.6 Â± 0.6 69.9 Â± 1.3 76.2 Â± 0.5 76.0 Â± 0.5 MTL [6] 94.4 Â± 2.3 65.0 Â± 0.6 69.6 Â± 0.6 71.7 Â± 1.3 75.2 Â± 0.3 SagNet [48] 94.9 Â± 0.7 61.9 Â± 0.7 69.6 Â± 1.3 75.2 Â± 0.6 75.4 Â± 0.8 ARM [72] 96.9 Â± 0.5 61.9 Â± 0.4 71.6 Â± 0.1 73.3 Â± 0.4 75.9 Â± 0.3 VREx [36] 96.2 Â± 0.0 62.5 Â± 1.3 69.3 Â± 0.9 73.1 Â± 1.2 75.3 Â± 0.6 RSC [33] 96.2 Â± 0.0 63.6 Â± 1.3 69.8 Â± 1.0 72.0 Â± 0.4 75.4 Â± 0.3 SelfReg [34] 95.8 Â± 0.6 63.4 Â± 1.1 71.1 Â± 0.6 75.3 Â± 0.6 76.4 Â± 0.7 MixStyle [75] 97.3 Â± 0.3 61.6 Â± 0.1 70.4 Â± 0.7 71.3 Â± 1.9 75.2 Â± 0.7 Fish [58] 97.4 Â± 0.2 63.4 Â± 0.1 71.5 Â± 0.4 75.2 Â± 0.7 76.9 Â± 0.2 SD [51] 96.5 Â± 0.4 62.2 Â± 0.0 69.7 Â± 0.9 73.6 Â± 0.4 75.5 Â± 0.4 CAD [53] 94.5 Â± 0.9 63.5 Â± 0.6 70.4 Â± 1.2 72.4 Â± 1.3 75.2 Â± 0.6 CondCAD [53] 96.5 Â± 0.8 62.6 Â± 0.4 69.1 Â± 0.2 76.0 Â± 0.2 76.1 Â± 0.3 Fishr [52] 97.2 Â± 0.6 63.3 Â± 0.7 70.4 Â± 0.6 74.0 Â± 0.8 76.2 Â± 0.3 Ours 96.9 Â± 1.2 63.7 Â± 1.1 72.0 Â± 0.3 74.9 Â± 0.8 76.9 Â± 0.6 Table 13. Average accuracies on the OfficeHome [62] datasets using the default hyper-parameter settings in DomainBed [27]. art clipart product real Average ERM [61] 52.2 Â± 0.2 48.7 Â± 0.5 69.9 Â± 0.5 71.7 Â± 0.5 60.6 Â± 0.2 IRM [1] 49.7 Â± 0.2 46.8 Â± 0.5 67.5 Â± 0.4 68.1 Â± 0.6 58.0 Â± 0.1 GroupGRO [55] 52.6 Â± 1.1 48.2 Â± 0.9 69.9 Â± 0.4 71.5 Â± 0.8 60.6 Â± 0.3 Mixup [68] 54.0 Â± 0.7 49.3 Â± 0.7 70.7 Â± 0.7 72.6 Â± 0.3 61.7 Â± 0.5 MLDG [38] 53.1 Â± 0.3 48.4 Â± 0.3 70.5 Â± 0.7 71.7 Â± 0.4 60.9 Â± 0.2 CORAL [59] 55.1 Â± 0.7 49.7 Â± 0.9 71.8 Â± 0.2 73.1 Â± 0.5 62.4 Â± 0.4 MMD [40] 50.9 Â± 1.0 48.7 Â± 0.3 69.3 Â± 0.7 70.7 Â± 1.3 59.9 Â± 0.4 DANN [23] 51.8 Â± 0.5 47.1 Â± 0.1 69.1 Â± 0.7 70.2 Â± 0.7 59.5 Â± 0.5 CDANN [44] 51.4 Â± 0.5 46.9 Â± 0.6 68.4 Â± 0.5 70.4 Â± 0.4 59.3 Â± 0.4 MTL [6] 51.6 Â± 1.5 47.7 Â± 0.5 69.1 Â± 0.3 71.0 Â± 0.6 59.9 Â± 0.5 SagNet [48] 55.3 Â± 0.4 49.6 Â± 0.2 72.1 Â± 0.4 73.2 Â± 0.4 62.5 Â± 0.3 ARM [72] 51.3 Â± 0.9 48.5 Â± 0.4 68.0 Â± 0.3 70.6 Â± 0.1 59.6 Â± 0.3 VREx [36] 51.1 Â± 0.3 47.4 Â± 0.6 69.0 Â± 0.4 70.5 Â± 0.4 59.5 Â± 0.1 RSC [33] 49.0 Â± 0.1 46.2 Â± 1.5 67.8 Â± 0.7 70.6 Â± 0.3 58.4 Â± 0.6 SelfReg [34] 55.1 Â± 0.8 49.2 Â± 0.6 72.2 Â± 0.3 73.0 Â± 0.3 62.4 Â± 0.1 MixStyle [75] 50.8 Â± 0.6 51.4 Â± 1.1 67.6 Â± 1.3 68.8 Â± 0.5 59.6 Â± 0.8 Fish [58] 54.6 Â± 1.0 49.6 Â± 1.0 71.3 Â± 0.6 72.4 Â± 0.2 62.0 Â± 0.6 SD [51] 55.0 Â± 0.4 51.3 Â± 0.5 72.5 Â± 0.2 72.7 Â± 0.3 62.9 Â± 0.2 CAD [53] 52.1 Â± 0.6 48.3 Â± 0.5 69.7 Â± 0.3 71.9 Â± 0.4 60.5 Â± 0.3 CondCAD [53] 53.3 Â± 0.6 48.4 Â± 0.2 69.8 Â± 0.9 72.6 Â± 0.1 61.0 Â± 0.4 Fishr [52] 52.6 Â± 0.9 48.6 Â± 0.3 69.9 Â± 0.6 72.4 Â± 0.4 60.9 Â± 0.3 Ours 54.4 Â± 0.2 52.3 Â± 0.8 69.5 Â± 0.3 71.7 Â± 0.2 62.0 Â± 0.2Table 14. Average accuracies on the TerraInc [4] datasets using the default hyper-parameter settings in DomainBed [27]. L100 L38 L43 L46 Average ERM [61] 42.1 Â± 2.5 30.1 Â± 1.2 48.9 Â± 0.6 34.0 Â± 1.1 38.8 Â± 1.0 IRM [1] 41.8 Â± 1.8 29.0 Â± 3.6 49.6 Â± 2.1 33.1 Â± 1.5 38.4 Â± 0.9 GroupGRO [55] 45.3 Â± 4.6 36.1 Â± 4.4 51.0 Â± 0.8 33.7 Â± 0.9 41.5 Â± 2.0 Mixup [68] 49.4 Â± 2.0 35.9 Â± 1.8 53.0 Â± 0.7 30.0 Â± 0.9 42.1 Â± 0.7 MLDG [38] 39.6 Â± 2.3 33.2 Â± 2.7 52.4 Â± 0.5 35.1 Â± 1.5 40.1 Â± 0.9 CORAL [59] 46.7 Â± 3.2 36.9 Â± 4.3 49.5 Â± 1.9 32.5 Â± 0.7 41.4 Â± 1.8 MMD [40] 49.1 Â± 1.2 36.4 Â± 4.8 50.4 Â± 2.1 32.3 Â± 1.5 42.0 Â± 1.0 DANN [23] 44.3 Â± 3.6 28.0 Â± 1.5 47.9 Â± 1.0 31.3 Â± 0.6 37.9 Â± 0.9 CDANN [44] 36.9 Â± 6.4 32.7 Â± 6.2 51.1 Â± 1.3 33.5 Â± 0.5 38.6 Â± 2.3 MTL [6] 45.2 Â± 2.6 31.0 Â± 1.6 50.6 Â± 1.1 34.9 Â± 0.4 40.4 Â± 1.0 SagNet [48] 36.3 Â± 4.7 40.3 Â± 2.0 52.5 Â± 0.6 33.3 Â± 1.3 40.6 Â± 1.5 ARM [72] 41.5 Â± 4.5 27.7 Â± 2.4 50.9 Â± 1.0 29.6 Â± 1.5 37.4 Â± 1.9 VREx [36] 48.0 Â± 1.7 41.1 Â± 1.5 51.8 Â± 1.5 32.0 Â± 1.2 43.2 Â± 0.3 RSC [33] 42.8 Â± 2.4 32.2 Â± 3.8 49.6 Â± 0.9 32.9 Â± 1.2 39.4 Â± 1.3 SelfReg [34] 46.1 Â± 1.5 34.5 Â± 1.6 49.8 Â± 0.3 34.7 Â± 1.5 41.3 Â± 0.3 MixStyle [75] 50.6 Â± 1.9 28.0 Â± 4.5 52.1 Â± 0.7 33.0 Â± 0.2 40.9 Â± 1.1 Fish [58] 46.3 Â± 3.0 29.0 Â± 1.1 52.7 Â± 1.2 32.8 Â± 1.0 40.2 Â± 0.6 SD [51] 45.5 Â± 1.9 33.2 Â± 3.1 52.9 Â± 0.7 36.4 Â± 0.8 42.0 Â± 1.0 CAD [53] 43.1 Â± 2.6 31.1 Â± 1.9 53.1 Â± 1.6 34.7 Â± 1.3 40.5 Â± 0.4 CondCAD [53] 44.4 Â± 2.9 32.9 Â± 2.5 50.5 Â± 1.3 30.8 Â± 0.5 39.7 Â± 0.4 Fishr [52] 49.9 Â± 3.3 36.6 Â± 0.9 49.8 Â± 0.2 34.2 Â± 1.3 42.6 Â± 1.0 Ours 51.7 Â± 2.4 37.6 Â± 0.6 49.9 Â± 0.6 33.6 Â± 0.6 43.2 Â± 0.5 Table 15. Average accuracies on the DomainNet [50] datasets using the default hyper-parameter settings in DomainBed [27]. clip info paint quick real sketch Average ERM [61] 50.4 Â± 0.2 14.0 Â± 0.2 40.3 Â± 0.5 11.7 Â± 0.2 52.0 Â± 0.2 43.2 Â± 0.3 35.3 Â± 0.1 IRM [1] 43.2 Â± 0.9 12.6 Â± 0.3 35.0 Â± 1.4 9.9 Â± 0.4 43.4 Â± 3.0 38.4 Â± 0.4 30.4 Â± 1.0 GroupGRO [55] 38.2 Â± 0.5 13.0 Â± 0.3 28.7 Â± 0.3 8.2 Â± 0.1 43.4 Â± 0.5 33.7 Â± 0.0 27.5 Â± 0.1 Mixup [68] 48.9 Â± 0.3 13.6 Â± 0.3 39.5 Â± 0.5 10.9 Â± 0.4 49.9 Â± 0.2 41.2 Â± 0.2 34.0 Â± 0.0 MLDG [38] 51.1 Â± 0.3 14.1 Â± 0.3 40.7 Â± 0.3 11.7 Â± 0.1 52.3 Â± 0.3 42.7 Â± 0.2 35.4 Â± 0.0 CORAL [59] 51.2 Â± 0.2 15.4 Â± 0.2 42.0 Â± 0.2 12.7 Â± 0.1 52.0 Â± 0.3 43.4 Â± 0.0 36.1 Â± 0.2 MMD [40] 16.6 Â± 13.3 0.3 Â± 0.0 12.8 Â± 10.4 0.3 Â± 0.0 17.1 Â± 13.7 0.4 Â± 0.0 7.9 Â± 6.2 DANN [23] 45.0 Â± 0.2 12.8 Â± 0.2 36.0 Â± 0.2 10.4 Â± 0.3 46.7 Â± 0.3 38.0 Â± 0.3 31.5 Â± 0.1 CDANN [44] 45.3 Â± 0.2 12.6 Â± 0.2 36.6 Â± 0.2 10.3 Â± 0.4 47.5 Â± 0.1 38.9 Â± 0.4 31.8 Â± 0.2 MTL [6] 50.6 Â± 0.2 14.0 Â± 0.4 39.6 Â± 0.3 12.0 Â± 0.3 52.1 Â± 0.1 41.5 Â± 0.0 35.0 Â± 0.0 SagNet [48] 51.0 Â± 0.1 14.6 Â± 0.1 40.2 Â± 0.2 12.1 Â± 0.2 51.5 Â± 0.3 42.4 Â± 0.1 35.3 Â± 0.1 ARM [72] 43.0 Â± 0.2 11.7 Â± 0.2 34.6 Â± 0.1 9.8 Â± 0.4 43.2 Â± 0.3 37.0 Â± 0.3 29.9 Â± 0.1 VREx [36] 39.2 Â± 1.6 11.9 Â± 0.4 31.2 Â± 1.3 10.2 Â± 0.4 41.5 Â± 1.8 34.8 Â± 0.8 28.1 Â± 1.0 RSC [33] 39.5 Â± 3.7 11.4 Â± 0.8 30.5 Â± 3.1 10.2 Â± 0.8 41.0 Â± 1.4 34.7 Â± 2.6 27.9 Â± 2.0 SelfReg [34] 47.9 Â± 0.3 15.1 Â± 0.3 41.2 Â± 0.2 11.7 Â± 0.3 48.8 Â± 0.0 43.8 Â± 0.3 34.7 Â± 0.2 MixStyle [75] 49.1 Â± 0.4 13.4 Â± 0.0 39.3 Â± 0.0 11.4 Â± 0.4 47.7 Â± 0.3 42.7 Â± 0.1 33.9 Â± 0.1 Fish [58] 51.5 Â± 0.3 14.5 Â± 0.2 40.4 Â± 0.3 11.7 Â± 0.5 52.6 Â± 0.2 42.1 Â± 0.1 35.5 Â± 0.0 SD [51] 51.3 Â± 0.3 15.5 Â± 0.1 41.5 Â± 0.3 12.6 Â± 0.2 52.9 Â± 0.2 44.0 Â± 0.4 36.3 Â± 0.2 CAD [53] 45.4 Â± 1.0 12.1 Â± 0.5 34.9 Â± 1.1 10.2 Â± 0.6 45.1 Â± 1.6 38.5 Â± 0.6 31.0 Â± 0.8 CondCAD [53] 46.1 Â± 1.0 13.3 Â± 0.4 36.1 Â± 1.4 10.7 Â± 0.2 46.8 Â± 1.3 38.7 Â± 0.7 31.9 Â± 0.7 Fishr [52] 47.8 Â± 0.7 14.6 Â± 0.2 40.0 Â± 0.3 11.9 Â± 0.2 49.2 Â± 0.7 41.7 Â± 0.1 34.2 Â± 0.3 Ours 50.7 Â± 0.7 13.9 Â± 0.4 39.4 Â± 0.5 11.9 Â± 0.2 50.2 Â± 0.3 43.5 Â± 0.1 34.9 Â± 0.1",
      "meta_data": {
        "arxiv_id": "2304.04494v2",
        "authors": [
          "Liang Chen",
          "Yong Zhang",
          "Yibing Song",
          "Ying Shan",
          "Lingqiao Liu"
        ],
        "published_date": "2023-04-10T10:12:38Z",
        "pdf_url": "https://arxiv.org/pdf/2304.04494v2.pdf"
      }
    }
  ]
}