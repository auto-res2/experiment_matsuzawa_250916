# Quick CI-style configuration – finishes in <1 min on CPU
seed: 13

model:
  hidden: 32

training:
  epochs: 1
  lr: 1e-3
  batch_size: 8

data:
  dataset: "wikitext"  # HF dataset name
  split: "wikitext-2-raw-v1"  # legacy key – treated as HF *config* automatically
  tokenizer: "bert-base-uncased"
