# Quick CI-style configuration â€“ finishes in <1 min on CPU
seed: 13

model:
  hidden: 32

training:
  epochs: 1
  lr: 1e-3
  batch_size: 8

data:
  dataset: "wikitext"
  split: "wikitext-2-raw-v1"
  tokenizer: "bert-base-uncased"
