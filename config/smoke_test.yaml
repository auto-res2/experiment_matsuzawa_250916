name: 'smoke_test'
experiment_ids_to_run: [1]

paths:
  # For smoke test, MIMIC-IV is not used to ensure it runs without private data.
  mimic_iv_dir: 'data/raw/mimic-iv-dummy'
  processed_data_path: 'artifacts/data/smoke_test'
  training_output_path: '.research/iteration23/smoke_test_runs'

model_names:
  encoder: 'sentence-transformers/all-MiniLM-L6-v2'
  generator: 'gpt-3.5-turbo' # Use a fast OpenAI model
  scorer: 'gpt-4-turbo-preview'
  paraphraser: 'tuner007/pegasus_paraphrase'
  continual_backend: 'NousResearch/Llama-2-7b-chat-hf'

seeds: [42]

# --- Experiment 1: Zero/Low-Log Bootstrap ---
experiment_1:
  tasks: ['FinReg-Compliance-5'] # Only run the public data task
  methods: ['REFLECT-BO', 'Random']

# --- Experiment 2: Continual Private Adaptation ---
experiment_2:
  tasks: ['Super-NI']
  methods: ['REFLECT-BO', 'REFLECT-BO-NoDP']

# --- Experiment 3: Human-in-the-Loop ---
experiment_3:
  tasks: ['GSM8K']
  methods: ['REFLECT-BO']

sec_edgar_ciks: ['0000320193'] # Apple Inc. for a single data point

optimization_params:
  api_budget: 5
  bootstrap_budget: 2

hyperparameters:
  learning_rate: [0.0003]
  bo_beta: [0.25]
  cvar_alpha: [0.9]

federated_params:
  n_clients: 2
  episodes: 1

dp_params:
  epsilon: 1.0
  delta: 1.0e-6
  noise_multiplier: 1.1
  max_grad_norm: 1.0

kalman_params:
  tau: [2.5]
